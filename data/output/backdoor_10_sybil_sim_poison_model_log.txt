
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[0.52657666 0.53459885 0.         0.         0.37968941 0.68412266
 0.5549589  1.         0.49264451 1.         1.         1.
 0.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         0.         1.         1.        ]
wv_fg shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         1.         1.         1.
 0.09982841 0.         0.3367968  1.         1.         0.
 0.         0.59304554 0.         0.         0.         0.
 0.         0.90185299 1.         0.         0.        ]
wv_mn shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.27651223 0.         0.02632603 1.         1.
 0.         0.         1.         0.         1.         1.
 0.47678398 1.         0.74940048 1.         0.71855522 0.98102331
 1.         1.         1.         1.         1.         0.25938085
 0.1526925  1.         0.1539363  0.06437897 1.        ]
wv_ed shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.13848337 0.         0.01647678 1.         0.85326944
 0.         0.         0.74983745 0.         1.         1.
 0.         1.         1.         1.         0.         0.02145732
 1.         0.95436416 1.         0.8507156  1.         0.04671601
 0.         1.         0.         0.23564891 0.81586558]
wv_lg shape (35, 1)
[[0.34319889]
 [0.34349268]
 [0.34261327]
 [0.34320097]
 [0.34284886]
 [0.34320593]
 [0.34294731]
 [0.34311745]
 [0.34311051]
 [0.34329318]
 [0.34456301]
 [0.34439938]
 [0.34470883]
 [0.34423827]
 [0.34451312]
 [0.34426705]
 [0.34391184]
 [0.34357975]
 [0.34423951]
 [0.34479603]
 [0.34426241]
 [0.34469096]
 [0.34460379]
 [0.34437157]
 [0.34248949]
 [0.34476838]
 [0.34433632]
 [0.34405303]
 [0.34447829]
 [0.34416079]
 [0.34481493]
 [0.34420722]
 [0.34586634]
 [0.34419129]
 [0.34520483]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[0.         0.33788002 0.06665858 0.56201082 0.27798555 0.90664389
 0.         0.16748473 0.97605749 0.39365032 0.         1.
 0.         0.         0.         0.10267582 0.         0.
 0.         0.         0.         1.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         1.         0.         0.56237781]
wv_std shape (35,)
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.3771734  0.
 0.         0.         0.         0.         1.         1.
 0.         0.27063365 0.60303912 1.         0.         0.
 1.         0.         0.44967858 0.         0.10687875 0.
 0.         1.         0.         0.         0.        ]
xy shape: (35, 9)
[[0.52657666 0.         0.         0.         0.34319889 1.
  0.         1.         0.        ]
 [0.53459885 0.         0.         0.         0.34349268 1.
  0.33788002 1.         0.        ]
 [0.         0.         0.         0.         0.34261327 1.
  0.06665858 1.         0.        ]
 [0.         0.         0.         0.         0.34320097 1.
  0.56201082 1.         0.        ]
 [0.37968941 0.         0.         0.         0.34284886 1.
  0.27798555 1.         0.        ]
 [0.68412266 0.         0.         0.         0.34320593 1.
  0.90664389 1.         0.        ]
 [0.5549589  0.         0.         0.         0.34294731 1.
  0.         1.         0.        ]
 [1.         0.         0.27651223 0.13848337 0.34311745 1.
  0.16748473 1.         0.        ]
 [0.49264451 0.         0.         0.         0.34311051 1.
  0.97605749 1.         0.        ]
 [1.         0.         0.02632603 0.01647678 0.34329318 1.
  0.39365032 1.         0.        ]
 [1.         0.         1.         1.         0.34456301 1.
  0.         0.3771734  1.        ]
 [1.         0.         1.         0.85326944 0.34439938 1.
  1.         0.         1.        ]
 [0.         0.         0.         0.         0.34470883 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.34423827 1.
  0.         0.         1.        ]
 [1.         0.         1.         0.74983745 0.34451312 1.
  0.         0.         1.        ]
 [1.         1.         0.         0.         0.34426705 1.
  0.10267582 0.         1.        ]
 [1.         1.         1.         1.         0.34391184 1.
  0.         1.         1.        ]
 [1.         1.         1.         1.         0.34357975 1.
  0.         1.         1.        ]
 [1.         0.09982841 0.47678398 0.         0.34423951 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.34479603 1.
  0.         0.27063365 1.        ]
 [1.         0.3367968  0.74940048 1.         0.34426241 1.
  0.         0.60303912 1.        ]
 [1.         1.         1.         1.         0.34469096 1.
  1.         1.         1.        ]
 [1.         1.         0.71855522 0.         0.34460379 1.
  0.         0.         1.        ]
 [1.         0.         0.98102331 0.02145732 0.34437157 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.34248949 1.
  0.         1.         1.        ]
 [1.         0.59304554 1.         0.95436416 0.34476838 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.34433632 1.
  0.         0.44967858 1.        ]
 [1.         0.         1.         0.8507156  0.34405303 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.34447829 1.
  0.         0.10687875 1.        ]
 [1.         0.         0.25938085 0.04671601 0.34416079 1.
  0.         0.         1.        ]
 [1.         0.         0.1526925  0.         0.34481493 1.
  0.         0.         1.        ]
 [1.         0.90185299 1.         1.         0.34420722 1.
  0.         1.         1.        ]
 [0.         1.         0.1539363  0.         0.34586634 1.
  1.         0.         1.        ]
 [1.         0.         0.06437897 0.23564891 0.34419129 1.
  0.         0.         1.        ]
 [1.         0.         1.         0.81586558 0.34520483 1.
  0.56237781 0.         1.        ]]

Best Training Poisoning Accuracy:
0.75
#####################         POISON         ###############################################

############################################################################################

comm_round: 0 | global_test_acc: 58.333% | global_f1: 0.7368421052631579 | global_precision: 0.5833333333333334
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         5
           1       0.58      1.00      0.74         7

    accuracy                           0.58        12
   macro avg       0.29      0.50      0.37        12
weighted avg       0.34      0.58      0.43        12

Accuracy per class:
[[7 0]
 [5 0]]
[1. 0.]
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[0.         0.         0.         0.         0.         0.
 0.64368784 0.83391368 0.         0.72301246 1.         0.05462072
 1.         1.         0.91316577 1.         0.02854249 1.
 1.         0.66795323 1.         1.         1.         0.
 1.         1.         1.         1.         1.         1.
 1.         0.         1.         0.         1.        ]
wv_fg shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.61236651 0.         0.
 0.         0.         1.         0.         0.         0.
 0.         1.         0.         0.         0.        ]
wv_mn shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.08246668 0.         0.         0.         0.
 0.         1.         1.         1.         0.39747027 1.
 1.         1.         0.         1.         1.         1.
 0.45896898 1.         1.         0.83587281 0.         1.
 0.37968655 1.         0.34193737 0.         1.        ]
wv_ed shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.2502895  0.
 0.         0.97899286 1.         1.         0.         1.
 1.         1.         0.         0.23276594 1.         1.
 0.18452944 1.         1.         1.         0.         1.
 0.         1.         0.72166653 0.         1.        ]
wv_lg shape (35, 1)
[[0.34380058]
 [0.34396799]
 [0.34386581]
 [0.34385257]
 [0.34390375]
 [0.34365527]
 [0.34376994]
 [0.34399503]
 [0.34419327]
 [0.34375136]
 [0.34437435]
 [0.34567521]
 [0.34523364]
 [0.34462093]
 [0.34509907]
 [0.34461983]
 [0.34489989]
 [0.34541364]
 [0.3458623 ]
 [0.34483087]
 [0.34512408]
 [0.34635983]
 [0.34455746]
 [0.34454848]
 [0.34505493]
 [0.34487505]
 [0.34453303]
 [0.34522392]
 [0.34547093]
 [0.34511093]
 [0.34504224]
 [0.34452119]
 [0.34519811]
 [0.34470665]
 [0.34545928]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[0.24763665 0.86068788 0.54666508 0.8601972  0.33082525 0.28529837
 0.41857152 0.5396447  0.8950619  0.46992492 0.18415957 1.
 0.         0.         0.         0.         0.0174277  0.35132767
 0.         0.         0.         1.         0.25112549 0.
 0.98586313 0.04513825 1.         1.         0.15587461 0.
 1.         0.         0.33949908 0.         0.        ]
wv_std shape (35,)
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.         0.
 0.         0.09371608 1.         0.90500819 0.         0.
 0.12357621 0.97768734 0.         0.         0.55620247 1.
 0.         0.63305883 1.         0.         0.         0.49572403
 0.         1.         0.         0.         0.        ]
xy shape: (35, 9)
[[0.         0.         0.         0.         0.34380058 1.
  0.24763665 1.         0.        ]
 [0.         0.         0.         0.         0.34396799 1.
  0.86068788 1.         0.        ]
 [0.         0.         0.         0.         0.34386581 1.
  0.54666508 1.         0.        ]
 [0.         0.         0.         0.         0.34385257 1.
  0.8601972  1.         0.        ]
 [0.         0.         0.         0.         0.34390375 1.
  0.33082525 1.         0.        ]
 [0.         0.         0.         0.         0.34365527 1.
  0.28529837 1.         0.        ]
 [0.64368784 0.         0.         0.         0.34376994 1.
  0.41857152 1.         0.        ]
 [0.83391368 0.         0.08246668 0.         0.34399503 1.
  0.5396447  1.         0.        ]
 [0.         0.         0.         0.         0.34419327 1.
  0.8950619  1.         0.        ]
 [0.72301246 0.         0.         0.         0.34375136 1.
  0.46992492 1.         0.        ]
 [1.         0.         0.         0.2502895  0.34437435 1.
  0.18415957 0.         1.        ]
 [0.05462072 0.         0.         0.         0.34567521 1.
  1.         0.         1.        ]
 [1.         0.         0.         0.         0.34523364 1.
  0.         0.         1.        ]
 [1.         0.         1.         0.97899286 0.34462093 1.
  0.         0.09371608 1.        ]
 [0.91316577 0.         1.         1.         0.34509907 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.34461983 1.
  0.         0.90500819 1.        ]
 [0.02854249 0.         0.39747027 0.         0.34489989 1.
  0.0174277  0.         1.        ]
 [1.         0.         1.         1.         0.34541364 1.
  0.35132767 0.         1.        ]
 [1.         0.         1.         1.         0.3458623  1.
  0.         0.12357621 1.        ]
 [0.66795323 0.         1.         1.         0.34483087 1.
  0.         0.97768734 1.        ]
 [1.         0.         0.         0.         0.34512408 1.
  0.         0.         1.        ]
 [1.         0.61236651 1.         0.23276594 0.34635983 1.
  1.         0.         1.        ]
 [1.         0.         1.         1.         0.34455746 1.
  0.25112549 0.55620247 1.        ]
 [0.         0.         1.         1.         0.34454848 1.
  0.         1.         1.        ]
 [1.         0.         0.45896898 0.18452944 0.34505493 1.
  0.98586313 0.         1.        ]
 [1.         0.         1.         1.         0.34487505 1.
  0.04513825 0.63305883 1.        ]
 [1.         1.         1.         1.         0.34453303 1.
  1.         1.         1.        ]
 [1.         0.         0.83587281 1.         0.34522392 1.
  1.         0.         1.        ]
 [1.         0.         0.         0.         0.34547093 1.
  0.15587461 0.         1.        ]
 [1.         0.         1.         1.         0.34511093 1.
  0.         0.49572403 1.        ]
 [1.         0.         0.37968655 0.         0.34504224 1.
  1.         0.         1.        ]
 [0.         1.         1.         1.         0.34452119 1.
  0.         1.         1.        ]
 [1.         0.         0.34193737 0.72166653 0.34519811 1.
  0.33949908 0.         1.        ]
 [0.         0.         0.         0.         0.34470665 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.34545928 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.75
#####################         POISON         ###############################################

############################################################################################

comm_round: 1 | global_test_acc: 58.333% | global_f1: 0.7368421052631579 | global_precision: 0.5833333333333334
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         5
           1       0.58      1.00      0.74         7

    accuracy                           0.58        12
   macro avg       0.29      0.50      0.37        12
weighted avg       0.34      0.58      0.43        12

Accuracy per class:
[[7 0]
 [5 0]]
[1. 0.]
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[0.92778329 0.85223224 0.40094453 0.96881787 0.48678602 0.
 1.         1.         1.         1.         1.         1.
 1.         0.24671442 1.         1.         0.69789507 1.
 0.39034054 1.         0.1747261  0.2661546  1.         1.
 1.         1.         1.         1.         1.         0.
 1.         1.         0.         1.         1.        ]
wv_fg shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         1.
 0.         0.         0.         0.         0.         0.
 0.         1.         0.         0.12833553 0.         1.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.81615277 0.         0.        ]
wv_mn shape (35,)
[0.         0.         0.         0.         0.         0.
 0.23851259 0.21034528 0.03410128 0.56398788 0.73450231 0.23007661
 1.         1.         1.         1.         0.         1.
 0.         1.         0.12763959 1.         0.29150865 1.
 1.         0.13064202 0.88901433 1.         1.         0.
 0.73650066 1.         1.         1.         1.        ]
wv_ed shape (35,)
[0.         0.         0.         0.         0.         0.
 0.31341848 0.36941089 0.00773924 0.65385715 0.61698721 0.80264701
 1.         1.         1.         0.95551971 0.         0.99363989
 0.         1.         0.         1.         0.         1.
 1.         0.         1.         0.72245556 1.         0.
 0.06024441 0.9758859  1.         1.         1.        ]
wv_lg shape (35, 1)
[[0.34452512]
 [0.34464376]
 [0.34468547]
 [0.34449987]
 [0.34447637]
 [0.34482474]
 [0.3445633 ]
 [0.34465758]
 [0.34420872]
 [0.34481805]
 [0.3462968 ]
 [0.34550764]
 [0.3462466 ]
 [0.34554632]
 [0.3465049 ]
 [0.34597911]
 [0.34612799]
 [0.34565552]
 [0.34538069]
 [0.3449897 ]
 [0.34734557]
 [0.34600366]
 [0.34598595]
 [0.34616504]
 [0.34585388]
 [0.34570828]
 [0.34619812]
 [0.34668249]
 [0.34584543]
 [0.34655239]
 [0.34672112]
 [0.34604147]
 [0.34530962]
 [0.34553233]
 [0.34583676]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[1.         0.69904073 0.30349882 0.76621618 1.         1.
 0.48203734 0.96817723 1.         0.22853828 0.         0.
 1.         0.         0.         0.         0.         0.85486847
 0.         0.         0.         0.4148403  0.         1.
 0.67704465 0.         0.         0.37851546 0.         0.
 0.07774902 0.         1.         0.         0.        ]
wv_std shape (35,)
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.         1.
 0.85285581 1.         0.3007403  0.10725962 0.         0.1129
 0.         0.95754993 0.         1.         0.         0.21775034
 0.29572104 0.         0.55455361 0.         0.40343874 0.
 0.         0.         1.         1.         0.58451652]
xy shape: (35, 9)
[[0.92778329 0.         0.         0.         0.34452512 1.
  1.         1.         0.        ]
 [0.85223224 0.         0.         0.         0.34464376 1.
  0.69904073 1.         0.        ]
 [0.40094453 0.         0.         0.         0.34468547 1.
  0.30349882 1.         0.        ]
 [0.96881787 0.         0.         0.         0.34449987 1.
  0.76621618 1.         0.        ]
 [0.48678602 0.         0.         0.         0.34447637 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.34482474 1.
  1.         1.         0.        ]
 [1.         0.         0.23851259 0.31341848 0.3445633  1.
  0.48203734 1.         0.        ]
 [1.         0.         0.21034528 0.36941089 0.34465758 1.
  0.96817723 1.         0.        ]
 [1.         0.         0.03410128 0.00773924 0.34420872 1.
  1.         1.         0.        ]
 [1.         0.         0.56398788 0.65385715 0.34481805 1.
  0.22853828 1.         0.        ]
 [1.         0.         0.73450231 0.61698721 0.3462968  1.
  0.         0.         1.        ]
 [1.         1.         0.23007661 0.80264701 0.34550764 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.3462466  1.
  1.         0.85285581 1.        ]
 [0.24671442 0.         1.         1.         0.34554632 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.3465049  1.
  0.         0.3007403  1.        ]
 [1.         0.         1.         0.95551971 0.34597911 1.
  0.         0.10725962 1.        ]
 [0.69789507 0.         0.         0.         0.34612799 1.
  0.         0.         1.        ]
 [1.         0.         1.         0.99363989 0.34565552 1.
  0.85486847 0.1129     1.        ]
 [0.39034054 0.         0.         0.         0.34538069 1.
  0.         0.         1.        ]
 [1.         1.         1.         1.         0.3449897  1.
  0.         0.95754993 1.        ]
 [0.1747261  0.         0.12763959 0.         0.34734557 1.
  0.         0.         1.        ]
 [0.2661546  0.12833553 1.         1.         0.34600366 1.
  0.4148403  1.         1.        ]
 [1.         0.         0.29150865 0.         0.34598595 1.
  0.         0.         1.        ]
 [1.         1.         1.         1.         0.34616504 1.
  1.         0.21775034 1.        ]
 [1.         0.         1.         1.         0.34585388 1.
  0.67704465 0.29572104 1.        ]
 [1.         0.         0.13064202 0.         0.34570828 1.
  0.         0.         1.        ]
 [1.         0.         0.88901433 1.         0.34619812 1.
  0.         0.55455361 1.        ]
 [1.         0.         1.         0.72245556 0.34668249 1.
  0.37851546 0.         1.        ]
 [1.         0.         1.         1.         0.34584543 1.
  0.         0.40343874 1.        ]
 [0.         0.         0.         0.         0.34655239 1.
  0.         0.         1.        ]
 [1.         0.         0.73650066 0.06024441 0.34672112 1.
  0.07774902 0.         1.        ]
 [1.         0.         1.         0.9758859  0.34604147 1.
  0.         0.         1.        ]
 [0.         0.81615277 1.         1.         0.34530962 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.34553233 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.34583676 1.
  0.         0.58451652 1.        ]]

Best Training Poisoning Accuracy:
0.75
#####################         POISON         ###############################################

############################################################################################

comm_round: 2 | global_test_acc: 66.667% | global_f1: 0.8 | global_precision: 0.6666666666666666
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         4
           1       0.67      1.00      0.80         8

    accuracy                           0.67        12
   macro avg       0.33      0.50      0.40        12
weighted avg       0.44      0.67      0.53        12

Accuracy per class:
[[8 0]
 [4 0]]
[1. 0.]
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[0.         0.2597524  0.11403083 0.40411919 0.         0.65733743
 0.87382548 1.         0.26695568 0.97461497 1.         1.
 1.         1.         1.         1.         1.         0.
 0.02145117 1.         1.         1.         1.         1.
 1.         0.6608698  1.         1.         1.         1.
 1.         1.         1.         1.         1.        ]
wv_fg shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         1.         0.43689916
 0.3600811  1.         1.         0.35745517 1.         0.89815138
 1.         0.85181563 1.         0.         0.04043939 1.
 0.7675915  0.         1.         0.00701812 0.         0.
 1.         0.         0.         1.         0.        ]
wv_mn shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.0503687  0.         0.         1.         1.
 1.         1.         1.         0.05364156 1.         0.
 1.         1.         0.         0.         1.         1.
 1.         1.         1.         1.         0.08491954 1.
 0.64131164 0.08131758 0.66985214 1.         1.        ]
wv_ed shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.04326228 0.         0.         0.99743342 1.
 1.         1.         1.         0.         1.         0.
 1.         1.         0.         0.         1.         1.
 1.         1.         1.         1.         0.0015826  1.
 0.99549001 0.78191204 0.8947878  1.         1.        ]
wv_lg shape (35, 1)
[[0.34558947]
 [0.34514635]
 [0.34564602]
 [0.34537599]
 [0.34536424]
 [0.34511769]
 [0.34557561]
 [0.34549743]
 [0.34540759]
 [0.34544651]
 [0.34631062]
 [0.34643744]
 [0.34710478]
 [0.34695876]
 [0.34730215]
 [0.34642161]
 [0.34759664]
 [0.34826546]
 [0.34524172]
 [0.34646674]
 [0.34726891]
 [0.34643359]
 [0.34680499]
 [0.34504816]
 [0.34648647]
 [0.34645754]
 [0.34425715]
 [0.34746198]
 [0.34694699]
 [0.34708244]
 [0.34615751]
 [0.34627802]
 [0.34685044]
 [0.34700364]
 [0.34642506]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[1.         1.         0.30314135 1.         1.         1.
 1.         0.6040001  0.6461247  0.23033935 1.         0.
 0.         1.         1.         0.08495037 0.13849048 0.
 1.         0.39278052 0.         0.         0.50906106 0.
 0.25959356 1.         0.62756164 0.43831245 0.04584765 0.53142459
 0.         0.         1.         0.         0.        ]
wv_std shape (35,)
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.19762134 0.79054256
 0.97272092 0.         0.         0.         0.70378697 0.
 1.         1.         0.         0.         0.24111989 0.98343095
 0.80281508 1.         0.41959371 0.28263201 0.         0.
 0.43820129 0.18946476 0.         1.         1.        ]
xy shape: (35, 9)
[[0.         0.         0.         0.         0.34558947 1.
  1.         1.         0.        ]
 [0.2597524  0.         0.         0.         0.34514635 1.
  1.         1.         0.        ]
 [0.11403083 0.         0.         0.         0.34564602 1.
  0.30314135 1.         0.        ]
 [0.40411919 0.         0.         0.         0.34537599 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.34536424 1.
  1.         1.         0.        ]
 [0.65733743 0.         0.         0.         0.34511769 1.
  1.         1.         0.        ]
 [0.87382548 0.         0.         0.         0.34557561 1.
  1.         1.         0.        ]
 [1.         0.         0.0503687  0.04326228 0.34549743 1.
  0.6040001  1.         0.        ]
 [0.26695568 0.         0.         0.         0.34540759 1.
  0.6461247  1.         0.        ]
 [0.97461497 0.         0.         0.         0.34544651 1.
  0.23033935 1.         0.        ]
 [1.         1.         1.         0.99743342 0.34631062 1.
  1.         0.19762134 1.        ]
 [1.         0.43689916 1.         1.         0.34643744 1.
  0.         0.79054256 1.        ]
 [1.         0.3600811  1.         1.         0.34710478 1.
  0.         0.97272092 1.        ]
 [1.         1.         1.         1.         0.34695876 1.
  1.         0.         1.        ]
 [1.         1.         1.         1.         0.34730215 1.
  1.         0.         1.        ]
 [1.         0.35745517 0.05364156 0.         0.34642161 1.
  0.08495037 0.         1.        ]
 [1.         1.         1.         1.         0.34759664 1.
  0.13849048 0.70378697 1.        ]
 [0.         0.89815138 0.         0.         0.34826546 1.
  0.         0.         1.        ]
 [0.02145117 1.         1.         1.         0.34524172 1.
  1.         1.         1.        ]
 [1.         0.85181563 1.         1.         0.34646674 1.
  0.39278052 1.         1.        ]
 [1.         1.         0.         0.         0.34726891 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.34643359 1.
  0.         0.         1.        ]
 [1.         0.04043939 1.         1.         0.34680499 1.
  0.50906106 0.24111989 1.        ]
 [1.         1.         1.         1.         0.34504816 1.
  0.         0.98343095 1.        ]
 [1.         0.7675915  1.         1.         0.34648647 1.
  0.25959356 0.80281508 1.        ]
 [0.6608698  0.         1.         1.         0.34645754 1.
  1.         1.         1.        ]
 [1.         1.         1.         1.         0.34425715 1.
  0.62756164 0.41959371 1.        ]
 [1.         0.00701812 1.         1.         0.34746198 1.
  0.43831245 0.28263201 1.        ]
 [1.         0.         0.08491954 0.0015826  0.34694699 1.
  0.04584765 0.         1.        ]
 [1.         0.         1.         1.         0.34708244 1.
  0.53142459 0.         1.        ]
 [1.         1.         0.64131164 0.99549001 0.34615751 1.
  0.         0.43820129 1.        ]
 [1.         0.         0.08131758 0.78191204 0.34627802 1.
  0.         0.18946476 1.        ]
 [1.         0.         0.66985214 0.8947878  0.34685044 1.
  1.         0.         1.        ]
 [1.         1.         1.         1.         0.34700364 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.34642506 1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.75
#####################         POISON         ###############################################

############################################################################################

comm_round: 3 | global_test_acc: 58.333% | global_f1: 0.7368421052631579 | global_precision: 0.5833333333333334
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         5
           1       0.58      1.00      0.74         7

    accuracy                           0.58        12
   macro avg       0.29      0.50      0.37        12
weighted avg       0.34      0.58      0.43        12

Accuracy per class:
[[7 0]
 [5 0]]
[1. 0.]
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[0.48145739 0.         0.77623494 0.42060024 0.         0.
 1.         1.         0.         0.8144767  1.         1.
 1.         1.         1.         1.         1.         1.
 1.         0.         0.81060496 0.00611819 1.         1.
 0.         1.         0.37976916 1.         1.         1.
 1.         1.         1.         1.         1.        ]
wv_fg shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.03708172 0.46973464 0.         1.         0.05899218 0.
 0.         0.         0.         0.         0.         1.
 0.         0.         0.         0.         0.         0.
 0.         1.         0.         1.         0.        ]
wv_mn shape (35,)
[0.         0.         0.         0.         0.         0.
 0.30787811 0.50571925 0.         0.         1.         1.
 1.         1.         1.         0.54551388 1.         1.
 1.         1.         1.         1.         1.         1.
 0.         1.         1.         1.         1.         1.
 1.         0.         1.         1.         1.        ]
wv_ed shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.12939868 0.         0.         0.86507123 1.
 1.         1.         1.         0.         0.836172   1.
 1.         1.         1.         1.         0.52714324 1.
 0.         1.         1.         1.         1.         1.
 1.         0.         1.         1.         1.        ]
wv_lg shape (35, 1)
[[0.34632108]
 [0.34608235]
 [0.34549322]
 [0.34631205]
 [0.34608671]
 [0.34611732]
 [0.34600628]
 [0.34579582]
 [0.34599074]
 [0.34568657]
 [0.34749331]
 [0.34778807]
 [0.34722746]
 [0.34832088]
 [0.34822958]
 [0.34787174]
 [0.34709319]
 [0.34726134]
 [0.34650415]
 [0.3465528 ]
 [0.3477965 ]
 [0.34753521]
 [0.34833025]
 [0.34516264]
 [0.34816129]
 [0.34742894]
 [0.34806291]
 [0.34644504]
 [0.34806262]
 [0.34813388]
 [0.34815527]
 [0.34690079]
 [0.34801701]
 [0.34768655]
 [0.34679842]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[0.82216353 1.         0.81253089 0.66498186 1.         1.
 0.66214424 1.         0.78665591 0.77949617 0.44894925 0.68884513
 1.         0.         0.87226731 0.         0.629572   1.
 0.         0.59400866 1.         0.8020412  0.85997279 0.19881173
 0.91118075 0.         0.         0.         1.         0.70905057
 0.48859106 0.3718085  0.         1.         0.26276649]
wv_std shape (35,)
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.04330437 1.
 0.85776761 0.94150839 0.52287393 0.         0.30218899 1.
 1.         1.         1.         1.         0.         1.
 0.         1.         1.         1.         0.61991836 1.
 0.60935074 0.         0.59892828 0.45030476 1.        ]
xy shape: (35, 9)
[[0.48145739 0.         0.         0.         0.34632108 1.
  0.82216353 1.         0.        ]
 [0.         0.         0.         0.         0.34608235 1.
  1.         1.         0.        ]
 [0.77623494 0.         0.         0.         0.34549322 1.
  0.81253089 1.         0.        ]
 [0.42060024 0.         0.         0.         0.34631205 1.
  0.66498186 1.         0.        ]
 [0.         0.         0.         0.         0.34608671 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.34611732 1.
  1.         1.         0.        ]
 [1.         0.         0.30787811 0.         0.34600628 1.
  0.66214424 1.         0.        ]
 [1.         0.         0.50571925 0.12939868 0.34579582 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.34599074 1.
  0.78665591 1.         0.        ]
 [0.8144767  0.         0.         0.         0.34568657 1.
  0.77949617 1.         0.        ]
 [1.         0.         1.         0.86507123 0.34749331 1.
  0.44894925 0.04330437 1.        ]
 [1.         0.         1.         1.         0.34778807 1.
  0.68884513 1.         1.        ]
 [1.         0.03708172 1.         1.         0.34722746 1.
  1.         0.85776761 1.        ]
 [1.         0.46973464 1.         1.         0.34832088 1.
  0.         0.94150839 1.        ]
 [1.         0.         1.         1.         0.34822958 1.
  0.87226731 0.52287393 1.        ]
 [1.         1.         0.54551388 0.         0.34787174 1.
  0.         0.         1.        ]
 [1.         0.05899218 1.         0.836172   0.34709319 1.
  0.629572   0.30218899 1.        ]
 [1.         0.         1.         1.         0.34726134 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.34650415 1.
  0.         1.         1.        ]
 [0.         0.         1.         1.         0.3465528  1.
  0.59400866 1.         1.        ]
 [0.81060496 0.         1.         1.         0.3477965  1.
  1.         1.         1.        ]
 [0.00611819 0.         1.         1.         0.34753521 1.
  0.8020412  1.         1.        ]
 [1.         0.         1.         0.52714324 0.34833025 1.
  0.85997279 0.         1.        ]
 [1.         1.         1.         1.         0.34516264 1.
  0.19881173 1.         1.        ]
 [0.         0.         0.         0.         0.34816129 1.
  0.91118075 0.         1.        ]
 [1.         0.         1.         1.         0.34742894 1.
  0.         1.         1.        ]
 [0.37976916 0.         1.         1.         0.34806291 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.34644504 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.34806262 1.
  1.         0.61991836 1.        ]
 [1.         0.         1.         1.         0.34813388 1.
  0.70905057 1.         1.        ]
 [1.         0.         1.         1.         0.34815527 1.
  0.48859106 0.60935074 1.        ]
 [1.         1.         0.         0.         0.34690079 1.
  0.3718085  0.         1.        ]
 [1.         0.         1.         1.         0.34801701 1.
  0.         0.59892828 1.        ]
 [1.         1.         1.         1.         0.34768655 1.
  1.         0.45030476 1.        ]
 [1.         0.         1.         1.         0.34679842 1.
  0.26276649 1.         1.        ]]

Best Training Poisoning Accuracy:
0.6875
#####################         POISON         ###############################################

############################################################################################

comm_round: 4 | global_test_acc: 66.667% | global_f1: 0.8 | global_precision: 0.6666666666666666
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         4
           1       0.67      1.00      0.80         8

    accuracy                           0.67        12
   macro avg       0.33      0.50      0.40        12
weighted avg       0.44      0.67      0.53        12

Accuracy per class:
[[8 0]
 [4 0]]
[1. 0.]
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[0.45027123 0.         1.         0.         1.         0.
 1.         1.         0.         1.         1.         1.
 0.23098041 1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 0.         0.74302329 0.         1.         0.70815774]
wv_fg shape (35,)
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
wv_mn shape (35,)
[0.         0.         0.08264566 0.         0.         0.
 0.         0.82164748 0.         0.43715627 1.         0.6924579
 0.11208955 1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 0.62408603 0.9337424  1.         1.         0.52051912 0.93142217
 0.         0.         0.         1.         0.21604399]
wv_ed shape (35,)
[0.         0.         0.1043936  0.         0.         0.
 0.         0.70361034 0.         0.24260279 1.         0.57243909
 0.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 0.56084752 0.30542743 1.         0.75341528 0.47928857 1.
 0.         0.07792701 0.         0.96459463 0.08838671]
wv_lg shape (35, 1)
[[0.34703844]
 [0.34662764]
 [0.34692315]
 [0.3472477 ]
 [0.34715996]
 [0.34704514]
 [0.3469458 ]
 [0.34705169]
 [0.34687059]
 [0.34715545]
 [0.34879   ]
 [0.34806337]
 [0.34872282]
 [0.34799646]
 [0.34831688]
 [0.34888319]
 [0.3484788 ]
 [0.34813404]
 [0.34806399]
 [0.34902661]
 [0.3484356 ]
 [0.3478818 ]
 [0.34734589]
 [0.349296  ]
 [0.3481317 ]
 [0.34946936]
 [0.34908662]
 [0.34840926]
 [0.3482374 ]
 [0.34846067]
 [0.34905402]
 [0.34829761]
 [0.34827228]
 [0.34785905]
 [0.34836891]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.97902459 0.42609169
 0.         0.         0.         0.         1.         1.
 0.32827684 0.         0.         0.33096463 0.8877131  0.65877214
 0.         0.         1.         0.6582714  0.44555503 0.
 0.         0.         0.         0.         0.        ]
wv_std shape (35,)
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.83656538 0.
 0.         0.42837636 0.58238259 0.32054867 0.         0.63569209
 0.48376644 0.         0.         0.28538433 0.30942976 0.
 0.         0.         0.01901949 0.         0.         0.17154953
 0.         0.         0.         0.         0.        ]
xy shape: (35, 9)
[[0.45027123 0.         0.         0.         0.34703844 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.34662764 1.
  1.         1.         0.        ]
 [1.         0.         0.08264566 0.1043936  0.34692315 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.3472477  1.
  1.         1.         0.        ]
 [1.         0.         0.         0.         0.34715996 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.34704514 1.
  1.         1.         0.        ]
 [1.         0.         0.         0.         0.3469458  1.
  1.         1.         0.        ]
 [1.         0.         0.82164748 0.70361034 0.34705169 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.34687059 1.
  1.         1.         0.        ]
 [1.         0.         0.43715627 0.24260279 0.34715545 1.
  1.         1.         0.        ]
 [1.         0.         1.         1.         0.34879    1.
  0.97902459 0.83656538 1.        ]
 [1.         0.         0.6924579  0.57243909 0.34806337 1.
  0.42609169 0.         1.        ]
 [0.23098041 0.         0.11208955 0.         0.34872282 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.34799646 1.
  0.         0.42837636 1.        ]
 [1.         0.         1.         1.         0.34831688 1.
  0.         0.58238259 1.        ]
 [1.         0.         1.         1.         0.34888319 1.
  0.         0.32054867 1.        ]
 [1.         0.         1.         1.         0.3484788  1.
  1.         0.         1.        ]
 [1.         0.         1.         1.         0.34813404 1.
  1.         0.63569209 1.        ]
 [1.         0.         1.         1.         0.34806399 1.
  0.32827684 0.48376644 1.        ]
 [1.         0.         1.         1.         0.34902661 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.3484356  1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.3478818  1.
  0.33096463 0.28538433 1.        ]
 [1.         0.         1.         1.         0.34734589 1.
  0.8877131  0.30942976 1.        ]
 [1.         1.         1.         1.         0.349296   1.
  0.65877214 0.         1.        ]
 [1.         0.         0.62408603 0.56084752 0.3481317  1.
  0.         0.         1.        ]
 [1.         0.         0.9337424  0.30542743 0.34946936 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.34908662 1.
  1.         0.01901949 1.        ]
 [1.         0.         1.         0.75341528 0.34840926 1.
  0.6582714  0.         1.        ]
 [1.         0.         0.52051912 0.47928857 0.3482374  1.
  0.44555503 0.         1.        ]
 [1.         0.         0.93142217 1.         0.34846067 1.
  0.         0.17154953 1.        ]
 [0.         0.         0.         0.         0.34905402 1.
  0.         0.         1.        ]
 [0.74302329 0.         0.         0.07792701 0.34829761 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34827228 1.
  0.         0.         1.        ]
 [1.         0.         1.         0.96459463 0.34785905 1.
  0.         0.         1.        ]
 [0.70815774 0.         0.21604399 0.08838671 0.34836891 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.6875
#####################         POISON         ###############################################

############################################################################################

comm_round: 5 | global_test_acc: 66.667% | global_f1: 0.8 | global_precision: 0.6666666666666666
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         4
           1       0.67      1.00      0.80         8

    accuracy                           0.67        12
   macro avg       0.33      0.50      0.40        12
weighted avg       0.44      0.67      0.53        12

Accuracy per class:
[[8 0]
 [4 0]]
[1. 0.]
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[0.10100761 0.97525526 0.32963464 0.         0.7879976  0.
 0.45112933 1.         0.         0.84134913 1.         0.
 0.4439141  1.         1.         1.         1.         0.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.        ]
wv_fg shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.26484022
 0.73444208 1.         0.         0.         0.         0.
 1.         0.         0.         0.         1.         0.26484022
 1.         0.24781304 0.45676491 0.         0.         1.
 0.         0.         0.         0.         0.44025872]
wv_mn shape (35,)
[0.         0.15997703 0.         0.         0.         0.
 0.         0.70348546 0.         0.         0.12913825 0.
 0.         1.         1.         0.72912787 1.         0.
 1.         1.         1.         1.         0.         1.
 0.96826886 1.         1.         1.         0.90764232 1.
 1.         0.9320036  1.         1.         1.        ]
wv_ed shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.45742248 0.         0.         0.7810188  0.
 0.         1.         1.         0.56486245 1.         0.
 1.         1.         1.         1.         0.         1.
 1.         1.         1.         1.         0.34706648 1.
 0.72438806 0.42040538 1.         1.         1.        ]
wv_lg shape (35, 1)
[[0.34790002]
 [0.34815613]
 [0.34734301]
 [0.34807548]
 [0.34791154]
 [0.34765719]
 [0.34772536]
 [0.34796335]
 [0.34803764]
 [0.34838255]
 [0.34912188]
 [0.34887683]
 [0.34933375]
 [0.34763696]
 [0.34963656]
 [0.34885198]
 [0.34873965]
 [0.34932746]
 [0.34900902]
 [0.34848732]
 [0.34908597]
 [0.34912284]
 [0.34848049]
 [0.34877777]
 [0.34838071]
 [0.34911008]
 [0.3481278 ]
 [0.34938319]
 [0.34951254]
 [0.34941584]
 [0.34935989]
 [0.34983521]
 [0.34851488]
 [0.34902995]
 [0.34830411]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[0.24734801 0.44836109 0.42279451 0.82603582 0.66734558 1.
 0.31731178 0.05509669 0.         0.2798353  0.         0.
 0.         0.         0.         0.33644761 0.         0.
 1.         0.         0.         0.13046424 0.         0.
 0.         0.         0.24442782 0.         0.         1.
 0.         0.61234583 1.         0.         0.04702863]
wv_std shape (35,)
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.         0.
 0.         1.         1.         0.         0.70625571 0.
 1.         1.         0.         0.79270403 0.         1.
 1.         0.79155756 0.371876   1.         0.         0.55562844
 0.         0.         1.         0.         0.29032287]
xy shape: (35, 9)
[[0.10100761 0.         0.         0.         0.34790002 1.
  0.24734801 1.         0.        ]
 [0.97525526 0.         0.15997703 0.         0.34815613 1.
  0.44836109 1.         0.        ]
 [0.32963464 0.         0.         0.         0.34734301 1.
  0.42279451 1.         0.        ]
 [0.         0.         0.         0.         0.34807548 1.
  0.82603582 1.         0.        ]
 [0.7879976  0.         0.         0.         0.34791154 1.
  0.66734558 1.         0.        ]
 [0.         0.         0.         0.         0.34765719 1.
  1.         1.         0.        ]
 [0.45112933 0.         0.         0.         0.34772536 1.
  0.31731178 1.         0.        ]
 [1.         0.         0.70348546 0.45742248 0.34796335 1.
  0.05509669 1.         0.        ]
 [0.         0.         0.         0.         0.34803764 1.
  0.         1.         0.        ]
 [0.84134913 0.         0.         0.         0.34838255 1.
  0.2798353  1.         0.        ]
 [1.         0.         0.12913825 0.7810188  0.34912188 1.
  0.         0.         1.        ]
 [0.         0.26484022 0.         0.         0.34887683 1.
  0.         0.         1.        ]
 [0.4439141  0.73444208 0.         0.         0.34933375 1.
  0.         0.         1.        ]
 [1.         1.         1.         1.         0.34763696 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.34963656 1.
  0.         1.         1.        ]
 [1.         0.         0.72912787 0.56486245 0.34885198 1.
  0.33644761 0.         1.        ]
 [1.         0.         1.         1.         0.34873965 1.
  0.         0.70625571 1.        ]
 [0.         0.         0.         0.         0.34932746 1.
  0.         0.         1.        ]
 [1.         1.         1.         1.         0.34900902 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.34848732 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.34908597 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.34912284 1.
  0.13046424 0.79270403 1.        ]
 [1.         1.         0.         0.         0.34848049 1.
  0.         0.         1.        ]
 [1.         0.26484022 1.         1.         0.34877777 1.
  0.         1.         1.        ]
 [1.         1.         0.96826886 1.         0.34838071 1.
  0.         1.         1.        ]
 [1.         0.24781304 1.         1.         0.34911008 1.
  0.         0.79155756 1.        ]
 [1.         0.45676491 1.         1.         0.3481278  1.
  0.24442782 0.371876   1.        ]
 [1.         0.         1.         1.         0.34938319 1.
  0.         1.         1.        ]
 [1.         0.         0.90764232 0.34706648 0.34951254 1.
  0.         0.         1.        ]
 [1.         1.         1.         1.         0.34941584 1.
  1.         0.55562844 1.        ]
 [1.         0.         1.         0.72438806 0.34935989 1.
  0.         0.         1.        ]
 [1.         0.         0.9320036  0.42040538 0.34983521 1.
  0.61234583 0.         1.        ]
 [1.         0.         1.         1.         0.34851488 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.34902995 1.
  0.         0.         1.        ]
 [1.         0.44025872 1.         1.         0.34830411 1.
  0.04702863 0.29032287 1.        ]]

Best Training Poisoning Accuracy:
0.6875
#####################         POISON         ###############################################

############################################################################################

comm_round: 6 | global_test_acc: 75.000% | global_f1: 0.8571428571428571 | global_precision: 0.75
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.75      1.00      0.86         9

    accuracy                           0.75        12
   macro avg       0.38      0.50      0.43        12
weighted avg       0.56      0.75      0.64        12

Accuracy per class:
[[9 0]
 [3 0]]
[1. 0.]
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[0.         1.         0.         0.         1.         0.
 1.         1.         0.         1.         0.53430132 0.
 0.         0.         0.         1.         1.         0.27782104
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.         1.
 1.         1.         0.         1.         1.        ]
wv_fg shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.04125347
 0.         0.         0.         0.         0.         0.
 0.69033958 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.97751559 0.
 0.         0.         0.         1.         0.21079808]
wv_mn shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.3699358  0.         0.         0.         0.
 1.         1.         0.         0.80959706 1.         0.0930783
 1.         1.         1.         1.         1.         1.
 0.         1.         1.         1.         0.         1.
 1.         0.75719    0.         1.         1.        ]
wv_ed shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.54005374 0.         0.05686242 0.         0.
 1.         1.         0.         0.97695789 1.         0.
 1.         1.         1.         1.         1.         1.
 0.21184148 1.         1.         1.         0.         1.
 0.64059444 0.80656727 0.         1.         1.        ]
wv_lg shape (35, 1)
[[0.34831926]
 [0.34838493]
 [0.34743558]
 [0.34849113]
 [0.34838824]
 [0.34848304]
 [0.34848366]
 [0.34865207]
 [0.34857309]
 [0.34872977]
 [0.35067985]
 [0.34965941]
 [0.34968929]
 [0.34953977]
 [0.35063051]
 [0.34976441]
 [0.34996959]
 [0.35035554]
 [0.34991069]
 [0.34910282]
 [0.34929615]
 [0.34936714]
 [0.35002941]
 [0.34990189]
 [0.34955907]
 [0.34993212]
 [0.35027696]
 [0.35003086]
 [0.34980241]
 [0.34956849]
 [0.34924916]
 [0.34937263]
 [0.35042748]
 [0.3475779 ]
 [0.34952068]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[0.6932735  1.         0.38767829 1.         1.         1.
 0.17019382 0.59413043 0.86558091 0.1576839  1.         0.
 0.53619723 1.         0.         0.         0.11872587 0.18850521
 0.23214678 0.92510363 0.         1.         0.         0.
 0.         1.         0.32597123 1.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_std shape (35,)
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.         0.
 1.         1.         0.         0.36951384 0.11812262 0.
 0.73565799 0.91139403 1.         1.         1.         0.49213032
 0.00300757 0.22071794 1.         0.11506694 0.         0.33529236
 0.         0.22942947 0.         1.         1.        ]
xy shape: (35, 9)
[[0.         0.         0.         0.         0.34831926 1.
  0.6932735  1.         0.        ]
 [1.         0.         0.         0.         0.34838493 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.34743558 1.
  0.38767829 1.         0.        ]
 [0.         0.         0.         0.         0.34849113 1.
  1.         1.         0.        ]
 [1.         0.         0.         0.         0.34838824 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.34848304 1.
  1.         1.         0.        ]
 [1.         0.         0.         0.         0.34848366 1.
  0.17019382 1.         0.        ]
 [1.         0.         0.3699358  0.54005374 0.34865207 1.
  0.59413043 1.         0.        ]
 [0.         0.         0.         0.         0.34857309 1.
  0.86558091 1.         0.        ]
 [1.         0.         0.         0.05686242 0.34872977 1.
  0.1576839  1.         0.        ]
 [0.53430132 0.         0.         0.         0.35067985 1.
  1.         0.         1.        ]
 [0.         0.04125347 0.         0.         0.34965941 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.34968929 1.
  0.53619723 1.         1.        ]
 [0.         0.         1.         1.         0.34953977 1.
  1.         1.         1.        ]
 [0.         0.         0.         0.         0.35063051 1.
  0.         0.         1.        ]
 [1.         0.         0.80959706 0.97695789 0.34976441 1.
  0.         0.36951384 1.        ]
 [1.         0.         1.         1.         0.34996959 1.
  0.11872587 0.11812262 1.        ]
 [0.27782104 0.         0.0930783  0.         0.35035554 1.
  0.18850521 0.         1.        ]
 [1.         0.69033958 1.         1.         0.34991069 1.
  0.23214678 0.73565799 1.        ]
 [1.         0.         1.         1.         0.34910282 1.
  0.92510363 0.91139403 1.        ]
 [1.         0.         1.         1.         0.34929615 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.34936714 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.35002941 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.34990189 1.
  0.         0.49213032 1.        ]
 [1.         0.         0.         0.21184148 0.34955907 1.
  0.         0.00300757 1.        ]
 [1.         0.         1.         1.         0.34993212 1.
  1.         0.22071794 1.        ]
 [1.         0.         1.         1.         0.35027696 1.
  0.32597123 1.         1.        ]
 [1.         0.         1.         1.         0.35003086 1.
  1.         0.11506694 1.        ]
 [0.         0.97751559 0.         0.         0.34980241 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.34956849 1.
  0.         0.33529236 1.        ]
 [1.         0.         1.         0.64059444 0.34924916 1.
  0.         0.         1.        ]
 [1.         0.         0.75719    0.80656727 0.34937263 1.
  0.         0.22942947 1.        ]
 [0.         0.         0.         0.         0.35042748 1.
  0.         0.         1.        ]
 [1.         1.         1.         1.         0.3475779  1.
  0.         1.         1.        ]
 [1.         0.21079808 1.         1.         0.34952068 1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.6875
#####################         POISON         ###############################################

############################################################################################

comm_round: 7 | global_test_acc: 75.000% | global_f1: 0.8571428571428571 | global_precision: 0.75
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.75      1.00      0.86         9

    accuracy                           0.75        12
   macro avg       0.38      0.50      0.43        12
weighted avg       0.56      0.75      0.64        12

Accuracy per class:
[[9 0]
 [3 0]]
[1. 0.]
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[0.         0.87682162 0.         0.         1.         0.
 1.         1.         0.         1.         1.         1.
 1.         1.         0.         1.         1.         1.
 0.         1.         1.         0.4401257  1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.        ]
wv_fg shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.86774961 0.90741568 0.69165379 0.84484093 1.
 0.24428019 0.         0.         1.         1.         0.5908828
 0.         0.         1.         0.         0.90664912 0.
 0.         0.         1.         0.         0.03270012]
wv_mn shape (35,)
[0.         0.2923439  0.0229174  0.         0.19960573 0.
 1.         1.         0.         0.66057565 1.         0.11609787
 1.         1.         0.         1.         1.         1.
 0.         0.09904933 0.43815269 0.         1.         1.
 1.         0.97357796 1.         1.         1.         0.85540992
 0.86358462 1.         0.40028745 0.68020704 1.        ]
wv_ed shape (35,)
[0.         0.04882083 0.         0.         0.         0.
 0.78942881 1.         0.         0.3868955  1.         0.30421217
 0.70419845 1.         0.         1.         1.         0.28179275
 0.         0.37260879 0.62144123 0.         1.         1.
 1.         1.         1.         1.         1.         0.21650581
 0.75112302 1.         0.34842973 1.         1.        ]
wv_lg shape (35, 1)
[[0.34911194]
 [0.34922944]
 [0.34893234]
 [0.34901951]
 [0.34933394]
 [0.34920411]
 [0.34957296]
 [0.34914662]
 [0.34932496]
 [0.34923857]
 [0.35022855]
 [0.35006834]
 [0.34995517]
 [0.35041593]
 [0.35017131]
 [0.35023457]
 [0.34997505]
 [0.35095993]
 [0.34988057]
 [0.35064563]
 [0.35068739]
 [0.35062356]
 [0.3512134 ]
 [0.34970214]
 [0.34994544]
 [0.35084404]
 [0.349924  ]
 [0.35007668]
 [0.35015746]
 [0.35028842]
 [0.34977795]
 [0.35039848]
 [0.35098691]
 [0.35039339]
 [0.35054632]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[1.         1.         0.8854496  0.86767871 1.         1.
 1.         1.         1.         1.         0.         0.64189474
 1.         1.         0.71485018 0.05738039 0.         0.43656623
 0.         0.1573522  0.31756759 1.         0.53590398 1.
 0.         0.72249849 1.         0.87727791 0.04418465 0.77557403
 0.         0.28169604 0.         0.         0.01964589]
wv_std shape (35,)
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.         0.
 0.         0.2101185  0.         0.24136683 0.53222793 0.
 0.         0.         0.         0.         0.44641072 0.22174082
 0.34275816 0.         0.51598866 0.63868467 0.70937857 0.
 0.         0.5387716  0.         0.         0.54676105]
xy shape: (35, 9)
[[0.         0.         0.         0.         0.34911194 1.
  1.         1.         0.        ]
 [0.87682162 0.         0.2923439  0.04882083 0.34922944 1.
  1.         1.         0.        ]
 [0.         0.         0.0229174  0.         0.34893234 1.
  0.8854496  1.         0.        ]
 [0.         0.         0.         0.         0.34901951 1.
  0.86767871 1.         0.        ]
 [1.         0.         0.19960573 0.         0.34933394 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.34920411 1.
  1.         1.         0.        ]
 [1.         0.         1.         0.78942881 0.34957296 1.
  1.         1.         0.        ]
 [1.         0.         1.         1.         0.34914662 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.34932496 1.
  1.         1.         0.        ]
 [1.         0.         0.66057565 0.3868955  0.34923857 1.
  1.         1.         0.        ]
 [1.         0.         1.         1.         0.35022855 1.
  0.         0.         1.        ]
 [1.         0.         0.11609787 0.30421217 0.35006834 1.
  0.64189474 0.         1.        ]
 [1.         0.         1.         0.70419845 0.34995517 1.
  1.         0.         1.        ]
 [1.         0.86774961 1.         1.         0.35041593 1.
  1.         0.2101185  1.        ]
 [0.         0.90741568 0.         0.         0.35017131 1.
  0.71485018 0.         1.        ]
 [1.         0.69165379 1.         1.         0.35023457 1.
  0.05738039 0.24136683 1.        ]
 [1.         0.84484093 1.         1.         0.34997505 1.
  0.         0.53222793 1.        ]
 [1.         1.         1.         0.28179275 0.35095993 1.
  0.43656623 0.         1.        ]
 [0.         0.24428019 0.         0.         0.34988057 1.
  0.         0.         1.        ]
 [1.         0.         0.09904933 0.37260879 0.35064563 1.
  0.1573522  0.         1.        ]
 [1.         0.         0.43815269 0.62144123 0.35068739 1.
  0.31756759 0.         1.        ]
 [0.4401257  1.         0.         0.         0.35062356 1.
  1.         0.         1.        ]
 [1.         1.         1.         1.         0.3512134  1.
  0.53590398 0.44641072 1.        ]
 [1.         0.5908828  1.         1.         0.34970214 1.
  1.         0.22174082 1.        ]
 [1.         0.         1.         1.         0.34994544 1.
  0.         0.34275816 1.        ]
 [1.         0.         0.97357796 1.         0.35084404 1.
  0.72249849 0.         1.        ]
 [1.         1.         1.         1.         0.349924   1.
  1.         0.51598866 1.        ]
 [1.         0.         1.         1.         0.35007668 1.
  0.87727791 0.63868467 1.        ]
 [1.         0.90664912 1.         1.         0.35015746 1.
  0.04418465 0.70937857 1.        ]
 [1.         0.         0.85540992 0.21650581 0.35028842 1.
  0.77557403 0.         1.        ]
 [1.         0.         0.86358462 0.75112302 0.34977795 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35039848 1.
  0.28169604 0.5387716  1.        ]
 [1.         1.         0.40028745 0.34842973 0.35098691 1.
  0.         0.         1.        ]
 [1.         0.         0.68020704 1.         0.35039339 1.
  0.         0.         1.        ]
 [1.         0.03270012 1.         1.         0.35054632 1.
  0.01964589 0.54676105 1.        ]]

Best Training Poisoning Accuracy:
0.75
#####################         POISON         ###############################################

############################################################################################

comm_round: 8 | global_test_acc: 75.000% | global_f1: 0.8571428571428571 | global_precision: 0.75
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.75      1.00      0.86         9

    accuracy                           0.75        12
   macro avg       0.38      0.50      0.43        12
weighted avg       0.56      0.75      0.64        12

Accuracy per class:
[[9 0]
 [3 0]]
[1. 0.]
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[0.         0.70449605 1.         0.57994518 0.18481989 0.
 1.         1.         0.         1.         0.         1.
 1.         0.19458181 1.         1.         0.         0.
 1.         1.         1.         1.         1.         1.
 1.         0.         0.         1.         1.         1.
 0.         1.         0.37167014 1.         1.        ]
wv_fg shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.42460482 0.         0.         0.         0.         0.
 0.         0.         0.59293541 0.         0.         0.31624028
 0.         1.         0.17917049 0.13086777 0.         0.
 0.         0.         0.         0.         0.        ]
wv_mn shape (35,)
[0.         0.         0.         0.         0.         0.
 0.38744205 0.64920749 0.         0.35185875 0.         0.79079429
 1.         0.62896939 1.         1.         1.         0.
 1.         1.         1.         1.         1.         0.73418577
 1.         1.         0.         1.         1.         1.
 0.         0.68828732 1.         1.         0.46974866]
wv_ed shape (35,)
[0.         0.         0.         0.         0.         0.
 0.11437151 0.65435825 0.         0.28457773 0.         1.
 1.         0.         1.         0.76665899 1.         0.
 1.         1.         0.86577867 1.         1.         0.
 1.         1.         0.         1.         1.         0.27242818
 0.         0.67506053 1.         1.         0.23799739]
wv_lg shape (35, 1)
[[0.34981771]
 [0.34911004]
 [0.34979007]
 [0.3497994 ]
 [0.34989888]
 [0.34974674]
 [0.3498136 ]
 [0.34987606]
 [0.34994451]
 [0.34986117]
 [0.35081695]
 [0.35105247]
 [0.35052492]
 [0.35192183]
 [0.35101724]
 [0.35033469]
 [0.35039519]
 [0.35132882]
 [0.35085511]
 [0.35151507]
 [0.35223221]
 [0.35250351]
 [0.35106039]
 [0.35004544]
 [0.35073127]
 [0.3513188 ]
 [0.35121815]
 [0.35175947]
 [0.35076265]
 [0.35124602]
 [0.3510203 ]
 [0.35089773]
 [0.35024358]
 [0.35113929]
 [0.35090201]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[0.72437136 0.79375348 0.78467414 1.         0.57289688 1.
 0.48191406 0.55506078 0.97977975 0.59702601 0.01775198 0.14870924
 0.         1.         0.43503991 0.41784014 0.27464554 0.
 0.28820864 0.24126423 0.         1.         0.26098866 0.
 0.         0.         0.         1.         0.31262066 0.73270245
 0.         0.         0.         0.         0.        ]
wv_std shape (35,)
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.         0.
 0.         0.         0.         0.         1.         0.
 0.95358923 0.61784028 0.         0.         0.92248502 0.
 0.85792864 1.         0.         0.         0.         0.
 0.         0.         1.         0.08441165 0.        ]
xy shape: (35, 9)
[[0.         0.         0.         0.         0.34981771 1.
  0.72437136 1.         0.        ]
 [0.70449605 0.         0.         0.         0.34911004 1.
  0.79375348 1.         0.        ]
 [1.         0.         0.         0.         0.34979007 1.
  0.78467414 1.         0.        ]
 [0.57994518 0.         0.         0.         0.3497994  1.
  1.         1.         0.        ]
 [0.18481989 0.         0.         0.         0.34989888 1.
  0.57289688 1.         0.        ]
 [0.         0.         0.         0.         0.34974674 1.
  1.         1.         0.        ]
 [1.         0.         0.38744205 0.11437151 0.3498136  1.
  0.48191406 1.         0.        ]
 [1.         0.         0.64920749 0.65435825 0.34987606 1.
  0.55506078 1.         0.        ]
 [0.         0.         0.         0.         0.34994451 1.
  0.97977975 1.         0.        ]
 [1.         0.         0.35185875 0.28457773 0.34986117 1.
  0.59702601 1.         0.        ]
 [0.         0.         0.         0.         0.35081695 1.
  0.01775198 0.         1.        ]
 [1.         0.         0.79079429 1.         0.35105247 1.
  0.14870924 0.         1.        ]
 [1.         0.42460482 1.         1.         0.35052492 1.
  0.         0.         1.        ]
 [0.19458181 0.         0.62896939 0.         0.35192183 1.
  1.         0.         1.        ]
 [1.         0.         1.         1.         0.35101724 1.
  0.43503991 0.         1.        ]
 [1.         0.         1.         0.76665899 0.35033469 1.
  0.41784014 0.         1.        ]
 [0.         0.         1.         1.         0.35039519 1.
  0.27464554 1.         1.        ]
 [0.         0.         0.         0.         0.35132882 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35085511 1.
  0.28820864 0.95358923 1.        ]
 [1.         0.         1.         1.         0.35151507 1.
  0.24126423 0.61784028 1.        ]
 [1.         0.59293541 1.         0.86577867 0.35223221 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35250351 1.
  1.         0.         1.        ]
 [1.         0.         1.         1.         0.35106039 1.
  0.26098866 0.92248502 1.        ]
 [1.         0.31624028 0.73418577 0.         0.35004544 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35073127 1.
  0.         0.85792864 1.        ]
 [0.         1.         1.         1.         0.3513188  1.
  0.         1.         1.        ]
 [0.         0.17917049 0.         0.         0.35121815 1.
  0.         0.         1.        ]
 [1.         0.13086777 1.         1.         0.35175947 1.
  1.         0.         1.        ]
 [1.         0.         1.         1.         0.35076265 1.
  0.31262066 0.         1.        ]
 [1.         0.         1.         0.27242818 0.35124602 1.
  0.73270245 0.         1.        ]
 [0.         0.         0.         0.         0.3510203  1.
  0.         0.         1.        ]
 [1.         0.         0.68828732 0.67506053 0.35089773 1.
  0.         0.         1.        ]
 [0.37167014 0.         1.         1.         0.35024358 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.35113929 1.
  0.         0.08441165 1.        ]
 [1.         0.         0.46974866 0.23799739 0.35090201 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.6875
#####################         POISON         ###############################################

############################################################################################

comm_round: 9 | global_test_acc: 66.667% | global_f1: 0.8 | global_precision: 0.6666666666666666
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         4
           1       0.67      1.00      0.80         8

    accuracy                           0.67        12
   macro avg       0.33      0.50      0.40        12
weighted avg       0.44      0.67      0.53        12

Accuracy per class:
[[8 0]
 [4 0]]
[1. 0.]
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[0.         0.3133838  0.         0.33094716 0.24055929 0.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.         1.
 0.30703452 1.         1.         1.         1.        ]
wv_fg shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         1.
 0.12402336 0.         0.         0.         0.         0.
 0.         0.09212095 0.         0.         0.         0.
 0.         0.         0.         0.         0.         1.
 0.         0.         0.         0.         0.        ]
wv_mn shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.44993147 0.         0.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         0.84859293 1.         1.         1.         1.
 1.         1.         1.         1.         0.         1.
 0.         1.         0.8446305  1.         1.        ]
wv_ed shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.13524723 0.         0.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.         1.
 0.         1.         0.8948992  1.         1.        ]
wv_lg shape (35, 1)
[[0.35055443]
 [0.35079019]
 [0.35009518]
 [0.3502112 ]
 [0.35074311]
 [0.35076537]
 [0.35065023]
 [0.35050288]
 [0.35091813]
 [0.35067977]
 [0.351838  ]
 [0.35318385]
 [0.35155044]
 [0.3513858 ]
 [0.35114102]
 [0.3518443 ]
 [0.35093126]
 [0.35143271]
 [0.3502284 ]
 [0.35088276]
 [0.35094894]
 [0.35118853]
 [0.35081999]
 [0.35161637]
 [0.35237151]
 [0.3525422 ]
 [0.35235623]
 [0.35158899]
 [0.35217217]
 [0.35114419]
 [0.35241396]
 [0.35224348]
 [0.35100042]
 [0.35289211]
 [0.35192401]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[0.37792877 0.38704829 0.         0.39930689 0.2745387  0.89715321
 0.         0.0703988  0.         1.         0.         0.8051245
 1.         0.86106012 0.         0.         0.         0.
 0.08713246 0.58331107 0.         0.         0.         0.
 0.         0.76136768 0.         0.55393945 1.         1.
 0.78140947 0.         0.         1.         0.73451138]
wv_std shape (35,)
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         0.36180285
 1.         1.         1.         1.         1.         0.37808264
 1.         0.38658524 1.         0.29244357 0.97777791 1.
 0.61264447 1.         0.96169968 0.7045071  0.         1.
 0.         1.         0.04206925 0.         0.05584177]
xy shape: (35, 9)
[[0.         0.         0.         0.         0.35055443 1.
  0.37792877 1.         0.        ]
 [0.3133838  0.         0.         0.         0.35079019 1.
  0.38704829 1.         0.        ]
 [0.         0.         0.         0.         0.35009518 1.
  0.         1.         0.        ]
 [0.33094716 0.         0.         0.         0.3502112  1.
  0.39930689 1.         0.        ]
 [0.24055929 0.         0.         0.         0.35074311 1.
  0.2745387  1.         0.        ]
 [0.         0.         0.         0.         0.35076537 1.
  0.89715321 1.         0.        ]
 [1.         0.         0.         0.         0.35065023 1.
  0.         1.         0.        ]
 [1.         0.         0.44993147 0.13524723 0.35050288 1.
  0.0703988  1.         0.        ]
 [1.         0.         0.         0.         0.35091813 1.
  0.         1.         0.        ]
 [1.         0.         0.         0.         0.35067977 1.
  1.         1.         0.        ]
 [1.         0.         1.         1.         0.351838   1.
  0.         1.         1.        ]
 [1.         1.         1.         1.         0.35318385 1.
  0.8051245  0.36180285 1.        ]
 [1.         0.12402336 1.         1.         0.35155044 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.3513858  1.
  0.86106012 1.         1.        ]
 [1.         0.         1.         1.         0.35114102 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.3518443  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.35093126 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.35143271 1.
  0.         0.37808264 1.        ]
 [1.         0.         1.         1.         0.3502284  1.
  0.08713246 1.         1.        ]
 [1.         0.09212095 0.84859293 1.         0.35088276 1.
  0.58331107 0.38658524 1.        ]
 [1.         0.         1.         1.         0.35094894 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.35118853 1.
  0.         0.29244357 1.        ]
 [1.         0.         1.         1.         0.35081999 1.
  0.         0.97777791 1.        ]
 [1.         0.         1.         1.         0.35161637 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.35237151 1.
  0.         0.61264447 1.        ]
 [1.         0.         1.         1.         0.3525422  1.
  0.76136768 1.         1.        ]
 [1.         0.         1.         1.         0.35235623 1.
  0.         0.96169968 1.        ]
 [1.         0.         1.         1.         0.35158899 1.
  0.55393945 0.7045071  1.        ]
 [0.         0.         0.         0.         0.35217217 1.
  1.         0.         1.        ]
 [1.         1.         1.         1.         0.35114419 1.
  1.         1.         1.        ]
 [0.30703452 0.         0.         0.         0.35241396 1.
  0.78140947 0.         1.        ]
 [1.         0.         1.         1.         0.35224348 1.
  0.         1.         1.        ]
 [1.         0.         0.8446305  0.8948992  0.35100042 1.
  0.         0.04206925 1.        ]
 [1.         0.         1.         1.         0.35289211 1.
  1.         0.         1.        ]
 [1.         0.         1.         1.         0.35192401 1.
  0.73451138 0.05584177 1.        ]]

Best Training Poisoning Accuracy:
0.6875
#####################         POISON         ###############################################

############################################################################################

comm_round: 10 | global_test_acc: 66.667% | global_f1: 0.8 | global_precision: 0.6666666666666666
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         4
           1       0.67      1.00      0.80         8

    accuracy                           0.67        12
   macro avg       0.33      0.50      0.40        12
weighted avg       0.44      0.67      0.53        12

Accuracy per class:
[[8 0]
 [4 0]]
[1. 0.]
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[0.         0.31202154 0.47279787 0.         0.         0.
 0.16819754 1.         0.         1.         1.         1.
 0.98087143 1.         1.         0.         1.         1.
 0.12763293 0.         0.64871413 1.         1.         1.
 0.14894933 1.         0.         1.         1.         0.
 0.         1.         1.         0.59145142 1.        ]
wv_fg shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.14206118
 0.         0.         0.24966503 1.         0.         0.
 0.         1.         0.         0.         0.         0.
 0.5167177  0.         0.49311828 0.         0.         0.
 0.         0.         1.         0.         0.        ]
wv_mn shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.40496261 0.         0.         1.         1.
 1.         1.         1.         1.         1.         1.
 0.         1.         0.         1.         1.         1.
 0.         1.         0.         1.         1.         0.19101191
 0.         1.         1.         1.         1.        ]
wv_ed shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.30040232 0.         0.         0.37265224 0.64046992
 1.         1.         1.         1.         1.         1.
 0.         1.         0.         1.         1.         1.
 0.         1.         0.         1.         0.59899801 0.
 0.         0.85632649 1.         1.         1.        ]
wv_lg shape (35, 1)
[[0.35125474]
 [0.35115183]
 [0.35102462]
 [0.35122869]
 [0.35107353]
 [0.35141371]
 [0.35086508]
 [0.35136478]
 [0.35067394]
 [0.35131572]
 [0.35329605]
 [0.3524989 ]
 [0.3524077 ]
 [0.35261012]
 [0.35181919]
 [0.3524785 ]
 [0.35164904]
 [0.35132761]
 [0.35251172]
 [0.35031098]
 [0.35189957]
 [0.35270433]
 [0.35216971]
 [0.35285968]
 [0.35230625]
 [0.35266804]
 [0.35226232]
 [0.3523891 ]
 [0.35261611]
 [0.35250006]
 [0.35296682]
 [0.35338714]
 [0.35292108]
 [0.35203478]
 [0.35200761]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[0.74049297 0.82909126 0.90073776 0.72782842 1.         1.
 0.95585165 0.8391435  0.74877344 1.         0.77832344 0.04267136
 0.         1.         1.         1.         0.70635386 0.56561714
 0.         0.         1.         0.0951934  0.65779457 1.
 1.         0.89740274 0.5761568  0.16825114 1.         0.66529259
 0.17872501 0.9173813  0.         0.         0.61126901]
wv_std shape (35,)
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.         0.
 1.         1.         1.         1.         0.52275796 0.87801858
 0.         1.         0.         1.         0.59723177 0.46915953
 0.         0.86321707 0.         0.21282206 0.         0.
 0.         0.         0.73350338 1.         0.38224606]
xy shape: (35, 9)
[[0.         0.         0.         0.         0.35125474 1.
  0.74049297 1.         0.        ]
 [0.31202154 0.         0.         0.         0.35115183 1.
  0.82909126 1.         0.        ]
 [0.47279787 0.         0.         0.         0.35102462 1.
  0.90073776 1.         0.        ]
 [0.         0.         0.         0.         0.35122869 1.
  0.72782842 1.         0.        ]
 [0.         0.         0.         0.         0.35107353 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.35141371 1.
  1.         1.         0.        ]
 [0.16819754 0.         0.         0.         0.35086508 1.
  0.95585165 1.         0.        ]
 [1.         0.         0.40496261 0.30040232 0.35136478 1.
  0.8391435  1.         0.        ]
 [0.         0.         0.         0.         0.35067394 1.
  0.74877344 1.         0.        ]
 [1.         0.         0.         0.         0.35131572 1.
  1.         1.         0.        ]
 [1.         0.         1.         0.37265224 0.35329605 1.
  0.77832344 0.         1.        ]
 [1.         0.14206118 1.         0.64046992 0.3524989  1.
  0.04267136 0.         1.        ]
 [0.98087143 0.         1.         1.         0.3524077  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.35261012 1.
  1.         1.         1.        ]
 [1.         0.24966503 1.         1.         0.35181919 1.
  1.         1.         1.        ]
 [0.         1.         1.         1.         0.3524785  1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.35164904 1.
  0.70635386 0.52275796 1.        ]
 [1.         0.         1.         1.         0.35132761 1.
  0.56561714 0.87801858 1.        ]
 [0.12763293 0.         0.         0.         0.35251172 1.
  0.         0.         1.        ]
 [0.         1.         1.         1.         0.35031098 1.
  0.         1.         1.        ]
 [0.64871413 0.         0.         0.         0.35189957 1.
  1.         0.         1.        ]
 [1.         0.         1.         1.         0.35270433 1.
  0.0951934  1.         1.        ]
 [1.         0.         1.         1.         0.35216971 1.
  0.65779457 0.59723177 1.        ]
 [1.         0.         1.         1.         0.35285968 1.
  1.         0.46915953 1.        ]
 [0.14894933 0.5167177  0.         0.         0.35230625 1.
  1.         0.         1.        ]
 [1.         0.         1.         1.         0.35266804 1.
  0.89740274 0.86321707 1.        ]
 [0.         0.49311828 0.         0.         0.35226232 1.
  0.5761568  0.         1.        ]
 [1.         0.         1.         1.         0.3523891  1.
  0.16825114 0.21282206 1.        ]
 [1.         0.         1.         0.59899801 0.35261611 1.
  1.         0.         1.        ]
 [0.         0.         0.19101191 0.         0.35250006 1.
  0.66529259 0.         1.        ]
 [0.         0.         0.         0.         0.35296682 1.
  0.17872501 0.         1.        ]
 [1.         0.         1.         0.85632649 0.35338714 1.
  0.9173813  0.         1.        ]
 [1.         1.         1.         1.         0.35292108 1.
  0.         0.73350338 1.        ]
 [0.59145142 0.         1.         1.         0.35203478 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.35200761 1.
  0.61126901 0.38224606 1.        ]]

Best Training Poisoning Accuracy:
0.5625
#####################         POISON         ###############################################

############################################################################################

comm_round: 11 | global_test_acc: 91.667% | global_f1: 0.9565217391304348 | global_precision: 0.9166666666666666
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.92      1.00      0.96        11

    accuracy                           0.92        12
   macro avg       0.46      0.50      0.48        12
weighted avg       0.84      0.92      0.88        12

Accuracy per class:
[[11  0]
 [ 1  0]]
[1. 0.]
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[0.         0.1447764  0.         0.15415065 0.         0.
 1.         1.         0.41619874 0.24079037 1.         0.
 1.         1.         0.         1.         0.         0.
 1.         0.44377866 1.         0.         0.         1.
 1.         0.         1.         1.         1.         1.
 0.90531655 1.         1.         1.         0.        ]
wv_fg shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 1.         0.         0.         0.         0.         0.
 1.         0.         0.79044783 0.21342896 0.        ]
wv_mn shape (35,)
[0.         0.         0.         0.         0.         0.
 0.12691818 0.591862   0.         0.         0.74221852 1.
 1.         1.         0.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 0.40668348 1.         1.         0.56988965 1.         1.
 0.         1.         1.         1.         1.        ]
wv_ed shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.49714482 0.         0.         0.         1.
 0.60382151 1.         0.         1.         1.         1.
 1.         1.         0.51901172 1.         1.         1.
 0.33531095 1.         1.         0.13539203 1.         1.
 0.         1.         1.         1.         1.        ]
wv_lg shape (35, 1)
[[0.3520535 ]
 [0.35207804]
 [0.35161522]
 [0.3521775 ]
 [0.35158221]
 [0.35194473]
 [0.35185023]
 [0.35184774]
 [0.35209367]
 [0.35178091]
 [0.35334617]
 [0.35329949]
 [0.35266088]
 [0.35273186]
 [0.35342245]
 [0.35336571]
 [0.35231069]
 [0.35350993]
 [0.35302351]
 [0.35288073]
 [0.35142211]
 [0.3537584 ]
 [0.35293101]
 [0.35324136]
 [0.35296442]
 [0.35358933]
 [0.35360216]
 [0.35220283]
 [0.35329503]
 [0.35227104]
 [0.35313528]
 [0.35276249]
 [0.3530401 ]
 [0.35244404]
 [0.3520363 ]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[0.         0.05561933 0.         0.29423127 0.04718112 0.29652772
 0.         0.         0.         0.         0.         0.47209154
 0.25797037 0.         0.         1.         0.         0.
 0.         0.         0.         0.49936863 0.         0.
 0.         1.         0.         0.         0.         0.
 0.         0.         0.         0.0609401  0.        ]
wv_std shape (35,)
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.         1.
 0.         0.67606447 0.         0.69405787 1.         1.
 0.60970799 1.         0.         1.         1.         0.05932777
 0.         1.         0.         0.         0.         0.76118779
 0.         0.66540474 0.51275532 0.83530652 1.        ]
xy shape: (35, 9)
[[0.         0.         0.         0.         0.3520535  1.
  0.         1.         0.        ]
 [0.1447764  0.         0.         0.         0.35207804 1.
  0.05561933 1.         0.        ]
 [0.         0.         0.         0.         0.35161522 1.
  0.         1.         0.        ]
 [0.15415065 0.         0.         0.         0.3521775  1.
  0.29423127 1.         0.        ]
 [0.         0.         0.         0.         0.35158221 1.
  0.04718112 1.         0.        ]
 [0.         0.         0.         0.         0.35194473 1.
  0.29652772 1.         0.        ]
 [1.         0.         0.12691818 0.         0.35185023 1.
  0.         1.         0.        ]
 [1.         0.         0.591862   0.49714482 0.35184774 1.
  0.         1.         0.        ]
 [0.41619874 0.         0.         0.         0.35209367 1.
  0.         1.         0.        ]
 [0.24079037 0.         0.         0.         0.35178091 1.
  0.         1.         0.        ]
 [1.         0.         0.74221852 0.         0.35334617 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.35329949 1.
  0.47209154 1.         1.        ]
 [1.         0.         1.         0.60382151 0.35266088 1.
  0.25797037 0.         1.        ]
 [1.         0.         1.         1.         0.35273186 1.
  0.         0.67606447 1.        ]
 [0.         0.         0.         0.         0.35342245 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35336571 1.
  1.         0.69405787 1.        ]
 [0.         0.         1.         1.         0.35231069 1.
  0.         1.         1.        ]
 [0.         0.         1.         1.         0.35350993 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.35302351 1.
  0.         0.60970799 1.        ]
 [0.44377866 0.         1.         1.         0.35288073 1.
  0.         1.         1.        ]
 [1.         0.         1.         0.51901172 0.35142211 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.3537584  1.
  0.49936863 1.         1.        ]
 [0.         0.         1.         1.         0.35293101 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.35324136 1.
  0.         0.05932777 1.        ]
 [1.         1.         0.40668348 0.33531095 0.35296442 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.35358933 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.35360216 1.
  0.         0.         1.        ]
 [1.         0.         0.56988965 0.13539203 0.35220283 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35329503 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35227104 1.
  0.         0.76118779 1.        ]
 [0.90531655 1.         0.         0.         0.35313528 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35276249 1.
  0.         0.66540474 1.        ]
 [1.         0.79044783 1.         1.         0.3530401  1.
  0.         0.51275532 1.        ]
 [1.         0.21342896 1.         1.         0.35244404 1.
  0.0609401  0.83530652 1.        ]
 [0.         0.         1.         1.         0.3520363  1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.75
#####################         POISON         ###############################################

############################################################################################

comm_round: 12 | global_test_acc: 66.667% | global_f1: 0.8 | global_precision: 0.6666666666666666
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         4
           1       0.67      1.00      0.80         8

    accuracy                           0.67        12
   macro avg       0.33      0.50      0.40        12
weighted avg       0.44      0.67      0.53        12

Accuracy per class:
[[8 0]
 [4 0]]
[1. 0.]
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[0.        1.        1.        1.        0.9806002 0.7013606 1.
 1.        1.        1.        0.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.        1.        1.        0.        1.        1.
 1.        1.        0.        1.        1.        1.        0.       ]
wv_fg shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         1.         1.         0.         0.         1.
 1.         0.72367137 0.26105803 1.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.17231064 0.         0.         1.         1.        ]
wv_mn shape (35,)
[0.         0.         0.08267005 0.         0.         0.
 0.33963565 1.         0.         0.67946688 1.         1.
 0.0842212  1.         0.         1.         1.         1.
 1.         1.         1.         1.         0.         0.
 1.         1.         1.         1.         0.27467078 1.
 1.         1.         0.         1.         0.        ]
wv_ed shape (35,)
[0.         0.         0.         0.         0.         0.
 0.13474568 0.94310385 0.         0.52399205 1.         1.
 0.19462722 1.         0.         1.         1.         1.
 1.         1.         0.64193199 1.         0.         0.34620174
 1.         1.         1.         1.         0.36521614 1.
 1.         1.         0.08327955 0.8791793  0.        ]
wv_lg shape (35, 1)
[[0.35244478]
 [0.3522817 ]
 [0.3526035 ]
 [0.35225466]
 [0.35207135]
 [0.35248764]
 [0.35256267]
 [0.35252466]
 [0.35268031]
 [0.3524512 ]
 [0.35373504]
 [0.35362649]
 [0.35372432]
 [0.35397169]
 [0.35249408]
 [0.35367128]
 [0.35438049]
 [0.35471731]
 [0.35295683]
 [0.35401244]
 [0.35393463]
 [0.35271782]
 [0.35387586]
 [0.35360585]
 [0.35443615]
 [0.35310506]
 [0.35394224]
 [0.35358005]
 [0.35312872]
 [0.35418465]
 [0.35293753]
 [0.35364809]
 [0.35318062]
 [0.35488111]
 [0.35367646]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[1.         0.99355197 0.57331446 1.         1.         1.
 0.54608997 0.48508936 0.65949758 0.4518615  0.         1.
 0.         1.         0.         0.37684735 1.         1.
 1.         0.9158557  0.         0.         0.37898562 0.
 1.         0.33432038 0.39406915 0.         0.30367261 0.95470638
 1.         0.76007866 0.         1.         0.19545702]
wv_std shape (35,)
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         0.18415133
 0.         0.5391925  0.         0.73779444 0.         0.42691687
 0.14334338 0.96725002 0.         0.79069381 0.         0.
 0.35459933 1.         0.92547049 1.         0.         0.23935766
 1.         0.23349404 0.         0.         0.        ]
xy shape: (35, 9)
[[0.         0.         0.         0.         0.35244478 1.
  1.         1.         0.        ]
 [1.         0.         0.         0.         0.3522817  1.
  0.99355197 1.         0.        ]
 [1.         0.         0.08267005 0.         0.3526035  1.
  0.57331446 1.         0.        ]
 [1.         0.         0.         0.         0.35225466 1.
  1.         1.         0.        ]
 [0.9806002  0.         0.         0.         0.35207135 1.
  1.         1.         0.        ]
 [0.7013606  0.         0.         0.         0.35248764 1.
  1.         1.         0.        ]
 [1.         0.         0.33963565 0.13474568 0.35256267 1.
  0.54608997 1.         0.        ]
 [1.         0.         1.         0.94310385 0.35252466 1.
  0.48508936 1.         0.        ]
 [1.         0.         0.         0.         0.35268031 1.
  0.65949758 1.         0.        ]
 [1.         0.         0.67946688 0.52399205 0.3524512  1.
  0.4518615  1.         0.        ]
 [0.         0.         1.         1.         0.35373504 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.35362649 1.
  1.         0.18415133 1.        ]
 [1.         0.         0.0842212  0.19462722 0.35372432 1.
  0.         0.         1.        ]
 [1.         1.         1.         1.         0.35397169 1.
  1.         0.5391925  1.        ]
 [1.         1.         0.         0.         0.35249408 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35367128 1.
  0.37684735 0.73779444 1.        ]
 [1.         0.         1.         1.         0.35438049 1.
  1.         0.         1.        ]
 [1.         1.         1.         1.         0.35471731 1.
  1.         0.42691687 1.        ]
 [1.         1.         1.         1.         0.35295683 1.
  1.         0.14334338 1.        ]
 [1.         0.72367137 1.         1.         0.35401244 1.
  0.9158557  0.96725002 1.        ]
 [1.         0.26105803 1.         0.64193199 0.35393463 1.
  0.         0.         1.        ]
 [1.         1.         1.         1.         0.35271782 1.
  0.         0.79069381 1.        ]
 [0.         0.         0.         0.         0.35387586 1.
  0.37898562 0.         1.        ]
 [1.         0.         0.         0.34620174 0.35360585 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35443615 1.
  1.         0.35459933 1.        ]
 [0.         0.         1.         1.         0.35310506 1.
  0.33432038 1.         1.        ]
 [1.         0.         1.         1.         0.35394224 1.
  0.39406915 0.92547049 1.        ]
 [1.         0.         1.         1.         0.35358005 1.
  0.         1.         1.        ]
 [1.         0.         0.27467078 0.36521614 0.35312872 1.
  0.30367261 0.         1.        ]
 [1.         0.         1.         1.         0.35418465 1.
  0.95470638 0.23935766 1.        ]
 [0.         0.17231064 1.         1.         0.35293753 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.35364809 1.
  0.76007866 0.23349404 1.        ]
 [1.         0.         0.         0.08327955 0.35318062 1.
  0.         0.         1.        ]
 [1.         1.         1.         0.8791793  0.35488111 1.
  1.         0.         1.        ]
 [0.         1.         0.         0.         0.35367646 1.
  0.19545702 0.         1.        ]]

Best Training Poisoning Accuracy:
0.75
#####################         POISON         ###############################################

############################################################################################

comm_round: 13 | global_test_acc: 50.000% | global_f1: 0.6666666666666666 | global_precision: 0.5
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         6
           1       0.50      1.00      0.67         6

    accuracy                           0.50        12
   macro avg       0.25      0.50      0.33        12
weighted avg       0.25      0.50      0.33        12

Accuracy per class:
[[6 0]
 [6 0]]
[1. 0.]
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[0.64610061 0.2778876  0.35350849 0.08283422 0.04805542 0.
 0.47769198 1.         0.         1.         0.20710654 1.
 1.         1.         1.         0.7480402  0.88987152 1.
 1.         1.         1.         1.         1.         1.
 1.         1.         0.         1.         1.         1.
 1.         1.         1.         1.         1.        ]
wv_fg shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         1.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         1.         0.12035154
 0.         0.         0.         0.         0.        ]
wv_mn shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.68709708 0.         0.04942154 1.         0.26629823
 1.         1.         1.         1.         1.         1.
 0.94200619 1.         0.68536491 1.         1.         1.
 1.         1.         0.         1.         0.         1.
 1.         1.         1.         0.         0.        ]
wv_ed shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.65847349 0.         0.08361082 1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         0.         1.         0.         1.
 1.         1.         1.         0.         0.        ]
wv_lg shape (35, 1)
[[0.35306549]
 [0.35324807]
 [0.3532723 ]
 [0.35325896]
 [0.3534385 ]
 [0.35326487]
 [0.35275479]
 [0.3533066 ]
 [0.35280391]
 [0.35322846]
 [0.35341132]
 [0.35453064]
 [0.35482092]
 [0.35451103]
 [0.3543844 ]
 [0.35400697]
 [0.35520544]
 [0.35419422]
 [0.35404406]
 [0.35386519]
 [0.35391124]
 [0.35371082]
 [0.3537536 ]
 [0.35456865]
 [0.35431249]
 [0.35441534]
 [0.35510622]
 [0.35490352]
 [0.35471057]
 [0.35404284]
 [0.35452441]
 [0.35381442]
 [0.35366612]
 [0.35439332]
 [0.35476215]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[0.87661538 1.         0.54178926 1.         1.         0.9510732
 0.68468762 0.28501882 1.         0.4359026  1.         0.
 0.35334037 0.         0.         0.93374015 0.33358309 0.
 0.40848792 0.51446537 0.         0.46157352 1.         0.
 0.         0.         0.         0.         0.         1.
 0.         1.         0.         0.         0.        ]
wv_std shape (35,)
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         0.
 0.         0.54317075 0.04249965 1.         1.         0.45717941
 0.61245842 0.8904288  0.13549113 1.         0.77514705 0.59720525
 1.         1.         0.         1.         0.         0.36358939
 1.         0.79674292 0.74475855 0.         0.        ]
xy shape: (35, 9)
[[0.64610061 0.         0.         0.         0.35306549 1.
  0.87661538 1.         0.        ]
 [0.2778876  0.         0.         0.         0.35324807 1.
  1.         1.         0.        ]
 [0.35350849 0.         0.         0.         0.3532723  1.
  0.54178926 1.         0.        ]
 [0.08283422 0.         0.         0.         0.35325896 1.
  1.         1.         0.        ]
 [0.04805542 0.         0.         0.         0.3534385  1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.35326487 1.
  0.9510732  1.         0.        ]
 [0.47769198 0.         0.         0.         0.35275479 1.
  0.68468762 1.         0.        ]
 [1.         0.         0.68709708 0.65847349 0.3533066  1.
  0.28501882 1.         0.        ]
 [0.         0.         0.         0.         0.35280391 1.
  1.         1.         0.        ]
 [1.         0.         0.04942154 0.08361082 0.35322846 1.
  0.4359026  1.         0.        ]
 [0.20710654 0.         1.         1.         0.35341132 1.
  1.         1.         1.        ]
 [1.         0.         0.26629823 1.         0.35453064 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35482092 1.
  0.35334037 0.         1.        ]
 [1.         0.         1.         1.         0.35451103 1.
  0.         0.54317075 1.        ]
 [1.         0.         1.         1.         0.3543844  1.
  0.         0.04249965 1.        ]
 [0.7480402  0.         1.         1.         0.35400697 1.
  0.93374015 1.         1.        ]
 [0.88987152 1.         1.         1.         0.35520544 1.
  0.33358309 1.         1.        ]
 [1.         0.         1.         1.         0.35419422 1.
  0.         0.45717941 1.        ]
 [1.         0.         0.94200619 1.         0.35404406 1.
  0.40848792 0.61245842 1.        ]
 [1.         0.         1.         1.         0.35386519 1.
  0.51446537 0.8904288  1.        ]
 [1.         0.         0.68536491 1.         0.35391124 1.
  0.         0.13549113 1.        ]
 [1.         0.         1.         1.         0.35371082 1.
  0.46157352 1.         1.        ]
 [1.         0.         1.         1.         0.3537536  1.
  1.         0.77514705 1.        ]
 [1.         0.         1.         1.         0.35456865 1.
  0.         0.59720525 1.        ]
 [1.         0.         1.         1.         0.35431249 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.35441534 1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.35510622 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35490352 1.
  0.         1.         1.        ]
 [1.         1.         0.         0.         0.35471057 1.
  0.         0.         1.        ]
 [1.         0.12035154 1.         1.         0.35404284 1.
  1.         0.36358939 1.        ]
 [1.         0.         1.         1.         0.35452441 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.35381442 1.
  1.         0.79674292 1.        ]
 [1.         0.         1.         1.         0.35366612 1.
  0.         0.74475855 1.        ]
 [1.         0.         0.         0.         0.35439332 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.35476215 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.75
#####################         POISON         ###############################################

############################################################################################

comm_round: 14 | global_test_acc: 75.000% | global_f1: 0.8571428571428571 | global_precision: 0.75
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.75      1.00      0.86         9

    accuracy                           0.75        12
   macro avg       0.38      0.50      0.43        12
weighted avg       0.56      0.75      0.64        12

Accuracy per class:
[[9 0]
 [3 0]]
[1. 0.]
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[0.         1.         0.33873421 0.43635873 0.         0.
 1.         1.         1.         1.         1.         1.
 0.         1.         1.         1.         1.         1.
 1.         1.         0.01293554 1.         1.         1.
 0.         1.         1.         0.58740474 0.         1.
 1.         1.         1.         1.         1.        ]
wv_fg shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.20430862 0.         0.         0.         0.
 0.         0.         1.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_mn shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.60639074 0.         0.         1.         0.40982357
 0.         0.03703301 1.         0.         0.61403065 1.
 1.         1.         1.         0.96183555 1.         1.
 1.         1.         0.7366293  0.         0.         1.
 0.56049698 0.         0.83089839 0.23606603 1.        ]
wv_ed shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.69896021 0.         0.         1.         0.59335135
 0.         0.         1.         0.77620877 1.         1.
 1.         0.83350615 1.         1.         1.         1.
 1.         1.         1.         0.         0.         1.
 1.         0.0161388  0.88745058 0.67628279 1.        ]
wv_lg shape (35, 1)
[[0.35364388]
 [0.35383035]
 [0.35400436]
 [0.35367446]
 [0.35374793]
 [0.35365419]
 [0.35393703]
 [0.35403796]
 [0.35420607]
 [0.35387224]
 [0.35506571]
 [0.3547109 ]
 [0.35472249]
 [0.35519326]
 [0.35477125]
 [0.35457775]
 [0.35467326]
 [0.35408703]
 [0.35485   ]
 [0.35573695]
 [0.35350503]
 [0.35523463]
 [0.35492186]
 [0.35518243]
 [0.35494278]
 [0.35521002]
 [0.355198  ]
 [0.35556584]
 [0.35623962]
 [0.35557158]
 [0.35400241]
 [0.35591395]
 [0.35529564]
 [0.3551761 ]
 [0.35600817]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[0.97365025 0.63595428 0.39825007 0.71937998 0.56001667 1.
 0.59229698 0.78659066 0.07948786 0.32813423 0.06917935 1.
 0.         1.         0.         0.         0.         0.
 0.         0.09906347 1.         0.         0.         0.
 0.         0.         1.         0.72155649 1.         0.
 0.         0.         0.         0.         1.        ]
wv_std shape (35,)
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.74687855 0.
 0.         0.         1.         0.25939034 0.10128862 0.11320757
 1.         0.         1.         0.59177321 1.         0.66977442
 1.         0.87183293 0.         0.         0.         1.
 0.2737907  0.         0.         0.         0.62658888]
xy shape: (35, 9)
[[0.         0.         0.         0.         0.35364388 1.
  0.97365025 1.         0.        ]
 [1.         0.         0.         0.         0.35383035 1.
  0.63595428 1.         0.        ]
 [0.33873421 0.         0.         0.         0.35400436 1.
  0.39825007 1.         0.        ]
 [0.43635873 0.         0.         0.         0.35367446 1.
  0.71937998 1.         0.        ]
 [0.         0.         0.         0.         0.35374793 1.
  0.56001667 1.         0.        ]
 [0.         0.         0.         0.         0.35365419 1.
  1.         1.         0.        ]
 [1.         0.         0.         0.         0.35393703 1.
  0.59229698 1.         0.        ]
 [1.         0.         0.60639074 0.69896021 0.35403796 1.
  0.78659066 1.         0.        ]
 [1.         0.         0.         0.         0.35420607 1.
  0.07948786 1.         0.        ]
 [1.         0.         0.         0.         0.35387224 1.
  0.32813423 1.         0.        ]
 [1.         0.         1.         1.         0.35506571 1.
  0.06917935 0.74687855 1.        ]
 [1.         0.         0.40982357 0.59335135 0.3547109  1.
  1.         0.         1.        ]
 [0.         0.         0.         0.         0.35472249 1.
  0.         0.         1.        ]
 [1.         0.20430862 0.03703301 0.         0.35519326 1.
  1.         0.         1.        ]
 [1.         0.         1.         1.         0.35477125 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.77620877 0.35457775 1.
  0.         0.25939034 1.        ]
 [1.         0.         0.61403065 1.         0.35467326 1.
  0.         0.10128862 1.        ]
 [1.         0.         1.         1.         0.35408703 1.
  0.         0.11320757 1.        ]
 [1.         0.         1.         1.         0.35485    1.
  0.         1.         1.        ]
 [1.         0.         1.         0.83350615 0.35573695 1.
  0.09906347 0.         1.        ]
 [0.01293554 1.         1.         1.         0.35350503 1.
  1.         1.         1.        ]
 [1.         0.         0.96183555 1.         0.35523463 1.
  0.         0.59177321 1.        ]
 [1.         0.         1.         1.         0.35492186 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.35518243 1.
  0.         0.66977442 1.        ]
 [0.         0.         1.         1.         0.35494278 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.35521002 1.
  0.         0.87183293 1.        ]
 [1.         0.         0.7366293  1.         0.355198   1.
  1.         0.         1.        ]
 [0.58740474 0.         0.         0.         0.35556584 1.
  0.72155649 0.         1.        ]
 [0.         0.         0.         0.         0.35623962 1.
  1.         0.         1.        ]
 [1.         0.         1.         1.         0.35557158 1.
  0.         1.         1.        ]
 [1.         0.         0.56049698 1.         0.35400241 1.
  0.         0.2737907  1.        ]
 [1.         0.         0.         0.0161388  0.35591395 1.
  0.         0.         1.        ]
 [1.         0.         0.83089839 0.88745058 0.35529564 1.
  0.         0.         1.        ]
 [1.         0.         0.23606603 0.67628279 0.3551761  1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35600817 1.
  1.         0.62658888 1.        ]]

Best Training Poisoning Accuracy:
0.75
#####################         POISON         ###############################################

############################################################################################

comm_round: 15 | global_test_acc: 75.000% | global_f1: 0.8571428571428571 | global_precision: 0.75
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.75      1.00      0.86         9

    accuracy                           0.75        12
   macro avg       0.38      0.50      0.43        12
weighted avg       0.56      0.75      0.64        12

Accuracy per class:
[[9 0]
 [3 0]]
[1. 0.]
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[0.         0.12258771 0.43240592 0.         0.         0.22699093
 0.32773501 1.         0.         0.62477035 0.80088429 1.
 0.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 0.38447001 1.         1.         0.         1.         0.
 1.         1.         0.         1.         1.        ]
wv_fg shape (35,)
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
wv_mn shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.46989717 0.         0.         1.         0.54984726
 0.         1.         0.44509596 0.76106481 0.13441527 1.
 1.         1.         1.         0.64781891 0.95557496 1.
 1.         1.         1.         1.         1.         1.
 0.79011767 0.         1.         0.3789564  1.        ]
wv_ed shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.39373399 0.         0.         1.         0.
 0.         0.56209789 0.39814836 0.71757914 0.19976594 1.
 1.         0.403549   1.         0.         1.         1.
 1.         1.         1.         1.         1.         1.
 0.37003745 0.         1.         0.98937784 1.        ]
wv_lg shape (35, 1)
[[0.35467367]
 [0.35428101]
 [0.35413117]
 [0.35423467]
 [0.35419886]
 [0.35474205]
 [0.35458128]
 [0.35476765]
 [0.35403103]
 [0.35447571]
 [0.35555737]
 [0.3560032 ]
 [0.35581915]
 [0.35519043]
 [0.35559386]
 [0.35513741]
 [0.3550443 ]
 [0.35571332]
 [0.3557531 ]
 [0.35604396]
 [0.35601232]
 [0.35524395]
 [0.35626572]
 [0.35531855]
 [0.35616078]
 [0.35520583]
 [0.35588637]
 [0.35558872]
 [0.35598355]
 [0.35527805]
 [0.35577215]
 [0.35642108]
 [0.35558697]
 [0.35539352]
 [0.35507517]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[0.40768427 0.         0.         0.81853531 0.33409773 0.2143204
 0.69109162 0.         0.37880932 0.13504027 0.         0.
 0.         0.68732309 1.         0.         0.         0.
 0.19710716 0.         0.02191704 1.         0.         0.
 0.46095873 0.         0.         0.         0.7891639  1.
 0.99843639 0.         0.         0.         0.        ]
wv_std shape (35,)
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         0.
 0.         0.         0.25114653 0.02713397 0.         0.
 0.13218534 0.         0.48600542 0.         0.         0.5086002
 1.         1.         0.         1.         0.41745648 1.
 0.         0.         1.         0.75797188 0.39395646]
xy shape: (35, 9)
[[0.         0.         0.         0.         0.35467367 1.
  0.40768427 1.         0.        ]
 [0.12258771 0.         0.         0.         0.35428101 1.
  0.         1.         0.        ]
 [0.43240592 0.         0.         0.         0.35413117 1.
  0.         1.         0.        ]
 [0.         0.         0.         0.         0.35423467 1.
  0.81853531 1.         0.        ]
 [0.         0.         0.         0.         0.35419886 1.
  0.33409773 1.         0.        ]
 [0.22699093 0.         0.         0.         0.35474205 1.
  0.2143204  1.         0.        ]
 [0.32773501 0.         0.         0.         0.35458128 1.
  0.69109162 1.         0.        ]
 [1.         0.         0.46989717 0.39373399 0.35476765 1.
  0.         1.         0.        ]
 [0.         0.         0.         0.         0.35403103 1.
  0.37880932 1.         0.        ]
 [0.62477035 0.         0.         0.         0.35447571 1.
  0.13504027 1.         0.        ]
 [0.80088429 0.         1.         1.         0.35555737 1.
  0.         1.         1.        ]
 [1.         0.         0.54984726 0.         0.3560032  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35581915 1.
  0.         0.         1.        ]
 [1.         0.         1.         0.56209789 0.35519043 1.
  0.68732309 0.         1.        ]
 [1.         1.         0.44509596 0.39814836 0.35559386 1.
  1.         0.25114653 1.        ]
 [1.         0.         0.76106481 0.71757914 0.35513741 1.
  0.         0.02713397 1.        ]
 [1.         0.         0.13441527 0.19976594 0.3550443  1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35571332 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.3557531  1.
  0.19710716 0.13218534 1.        ]
 [1.         0.         1.         0.403549   0.35604396 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35601232 1.
  0.02191704 0.48600542 1.        ]
 [1.         0.         0.64781891 0.         0.35524395 1.
  1.         0.         1.        ]
 [1.         0.         0.95557496 1.         0.35626572 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35531855 1.
  0.         0.5086002  1.        ]
 [0.38447001 0.         1.         1.         0.35616078 1.
  0.46095873 1.         1.        ]
 [1.         0.         1.         1.         0.35520583 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.35588637 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.35558872 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.35598355 1.
  0.7891639  0.41745648 1.        ]
 [0.         0.         1.         1.         0.35527805 1.
  1.         1.         1.        ]
 [1.         0.         0.79011767 0.37003745 0.35577215 1.
  0.99843639 0.         1.        ]
 [1.         0.         0.         0.         0.35642108 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.35558697 1.
  0.         1.         1.        ]
 [1.         0.         0.3789564  0.98937784 0.35539352 1.
  0.         0.75797188 1.        ]
 [1.         0.         1.         1.         0.35507517 1.
  0.         0.39395646 1.        ]]

Best Training Poisoning Accuracy:
0.75
#####################         POISON         ###############################################

############################################################################################

comm_round: 16 | global_test_acc: 50.000% | global_f1: 0.6666666666666666 | global_precision: 0.5
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         6
           1       0.50      1.00      0.67         6

    accuracy                           0.50        12
   macro avg       0.25      0.50      0.33        12
weighted avg       0.25      0.50      0.33        12

Accuracy per class:
[[6 0]
 [6 0]]
[1. 0.]
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[0.98364333 1.         0.34385378 1.         1.         0.
 1.         1.         0.88730519 1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 0.         1.         1.         1.         1.        ]
wv_fg shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.11221157
 1.         0.         0.         0.         0.         0.
 0.         1.         0.         0.         0.         0.
 0.         0.04287589 0.         0.         0.         0.
 0.         0.30358226 0.         0.         0.        ]
wv_mn shape (35,)
[0.26474085 0.59532592 0.25180785 0.87200315 0.36017256 0.
 1.         1.         0.         0.95421626 1.         0.62975157
 0.72550427 1.         0.86875304 1.         1.         1.
 1.         1.         0.62975157 1.         1.         1.
 0.77110431 1.         1.         1.         0.75223253 1.
 0.         1.         1.         1.         1.        ]
wv_ed shape (35,)
[0.         0.28902664 0.         0.70451238 0.         0.
 0.91758861 0.75824671 0.         0.79166983 1.         0.63430614
 0.81428216 1.         0.51474715 1.         0.50053289 0.59556027
 1.         1.         1.         1.         1.         1.
 0.21522091 1.         0.93921316 1.         1.         1.
 0.         1.         1.         1.         1.        ]
wv_lg shape (35, 1)
[[0.35484035]
 [0.35523285]
 [0.35486183]
 [0.35541777]
 [0.35545541]
 [0.35542636]
 [0.35540982]
 [0.35522196]
 [0.35515198]
 [0.35536471]
 [0.35626921]
 [0.35698053]
 [0.35586809]
 [0.35673311]
 [0.35758708]
 [0.35596267]
 [0.35626767]
 [0.35686681]
 [0.35614676]
 [0.35462198]
 [0.3555727 ]
 [0.35679794]
 [0.35579177]
 [0.35619403]
 [0.35622871]
 [0.35683276]
 [0.3564837 ]
 [0.35620128]
 [0.35628824]
 [0.35634945]
 [0.35620098]
 [0.35546014]
 [0.3563167 ]
 [0.35647894]
 [0.3558022 ]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[0.93571332 0.754331   0.77241931 0.81494525 1.         1.
 0.54618392 0.8433794  1.         0.94023313 0.72260155 1.
 0.         0.         0.51798079 1.         1.         0.
 0.07407894 0.36067255 0.         0.         0.         0.41091274
 0.02966824 0.66857336 0.52699318 0.29822218 0.         0.
 0.23611436 0.         0.00511249 0.         0.29937276]
wv_std shape (35,)
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.95659411 0.
 0.         1.         0.         0.11012459 0.         0.
 1.         0.50432917 1.         0.         1.         0.
 0.         0.37523177 0.         0.72973877 0.82171369 0.
 0.         1.         0.         0.26435262 0.34224488]
xy shape: (35, 9)
[[0.98364333 0.         0.26474085 0.         0.35484035 1.
  0.93571332 1.         0.        ]
 [1.         0.         0.59532592 0.28902664 0.35523285 1.
  0.754331   1.         0.        ]
 [0.34385378 0.         0.25180785 0.         0.35486183 1.
  0.77241931 1.         0.        ]
 [1.         0.         0.87200315 0.70451238 0.35541777 1.
  0.81494525 1.         0.        ]
 [1.         0.         0.36017256 0.         0.35545541 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.35542636 1.
  1.         1.         0.        ]
 [1.         0.         1.         0.91758861 0.35540982 1.
  0.54618392 1.         0.        ]
 [1.         0.         1.         0.75824671 0.35522196 1.
  0.8433794  1.         0.        ]
 [0.88730519 0.         0.         0.         0.35515198 1.
  1.         1.         0.        ]
 [1.         0.         0.95421626 0.79166983 0.35536471 1.
  0.94023313 1.         0.        ]
 [1.         0.         1.         1.         0.35626921 1.
  0.72260155 0.95659411 1.        ]
 [1.         0.11221157 0.62975157 0.63430614 0.35698053 1.
  1.         0.         1.        ]
 [1.         1.         0.72550427 0.81428216 0.35586809 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35673311 1.
  0.         1.         1.        ]
 [1.         0.         0.86875304 0.51474715 0.35758708 1.
  0.51798079 0.         1.        ]
 [1.         0.         1.         1.         0.35596267 1.
  1.         0.11012459 1.        ]
 [1.         0.         1.         0.50053289 0.35626767 1.
  1.         0.         1.        ]
 [1.         0.         1.         0.59556027 0.35686681 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35614676 1.
  0.07407894 1.         1.        ]
 [1.         1.         1.         1.         0.35462198 1.
  0.36067255 0.50432917 1.        ]
 [1.         0.         0.62975157 1.         0.3555727  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.35679794 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35579177 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.35619403 1.
  0.41091274 0.         1.        ]
 [1.         0.         0.77110431 0.21522091 0.35622871 1.
  0.02966824 0.         1.        ]
 [1.         0.04287589 1.         1.         0.35683276 1.
  0.66857336 0.37523177 1.        ]
 [1.         0.         1.         0.93921316 0.3564837  1.
  0.52699318 0.         1.        ]
 [1.         0.         1.         1.         0.35620128 1.
  0.29822218 0.72973877 1.        ]
 [1.         0.         0.75223253 1.         0.35628824 1.
  0.         0.82171369 1.        ]
 [1.         0.         1.         1.         0.35634945 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35620098 1.
  0.23611436 0.         1.        ]
 [1.         0.30358226 1.         1.         0.35546014 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.3563167  1.
  0.00511249 0.         1.        ]
 [1.         0.         1.         1.         0.35647894 1.
  0.         0.26435262 1.        ]
 [1.         0.         1.         1.         0.3558022  1.
  0.29937276 0.34224488 1.        ]]

Best Training Poisoning Accuracy:
0.75
#####################         POISON         ###############################################

############################################################################################

comm_round: 17 | global_test_acc: 91.667% | global_f1: 0.9565217391304348 | global_precision: 0.9166666666666666
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.92      1.00      0.96        11

    accuracy                           0.92        12
   macro avg       0.46      0.50      0.48        12
weighted avg       0.84      0.92      0.88        12

Accuracy per class:
[[11  0]
 [ 1  0]]
[1. 0.]
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[1.         1.         1.         0.         0.73869527 0.
 1.         1.         1.         1.         1.         1.
 1.         0.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.74358543 1.
 1.         0.59595299 0.67220811 0.         0.20412032]
wv_fg shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.06400253 1.         1.         0.12312577
 0.20488847 0.         0.         0.         0.09188755 0.
 0.         0.         0.47903623 0.22688656 0.         0.
 0.         0.         0.         0.18994176 0.        ]
wv_mn shape (35,)
[0.69337508 0.56006513 0.88190708 0.         0.07161795 0.
 1.         1.         0.14613614 1.         1.         0.13745471
 0.34369026 0.         1.         1.         0.5781822  0.93094213
 1.         0.96276991 1.         1.         1.         0.05497381
 0.91489427 1.         1.         0.41682056 0.28077486 1.
 0.         0.         0.78925604 0.         0.64510386]
wv_ed shape (35,)
[0.37176934 0.34431776 0.48239964 0.         0.         0.
 0.72407865 1.         0.00748233 1.         1.         0.
 0.54771166 0.         1.         0.25108958 0.         0.25520189
 0.56234901 1.         1.         0.60232654 1.         0.
 0.34621889 1.         1.         0.65997544 0.         1.
 0.         0.         0.         0.         0.        ]
wv_lg shape (35, 1)
[[0.35578638]
 [0.3559322 ]
 [0.35584027]
 [0.35566456]
 [0.35590436]
 [0.35536171]
 [0.35565222]
 [0.35588929]
 [0.35527772]
 [0.3559321 ]
 [0.35734692]
 [0.35671499]
 [0.3564332 ]
 [0.3572596 ]
 [0.35741613]
 [0.35698286]
 [0.356958  ]
 [0.357288  ]
 [0.35759486]
 [0.35642863]
 [0.35670139]
 [0.35671356]
 [0.35625055]
 [0.35613608]
 [0.35636707]
 [0.35687162]
 [0.35663165]
 [0.35563753]
 [0.35685458]
 [0.35640375]
 [0.35694576]
 [0.35649066]
 [0.35694994]
 [0.35709055]
 [0.3566847 ]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[0.67231285 0.45732087 0.34377936 1.         0.66270132 0.34150398
 1.         0.4213793  1.         0.86873865 0.08817714 0.18801801
 0.         0.99761237 0.27988389 0.29616797 0.         0.
 0.         0.53311283 0.10560096 0.27608919 0.         0.19858717
 0.77500372 1.         0.         0.         0.37556801 0.51688171
 0.         1.         1.         0.16172677 1.        ]
wv_std shape (35,)
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.01080073 0.
 0.         0.         0.04106305 0.         0.         0.
 0.         0.48635536 0.83239189 0.         1.         0.
 0.         0.46486434 0.43023152 0.59176521 0.         0.23377037
 0.         0.         0.         0.         0.        ]
xy shape: (35, 9)
[[1.         0.         0.69337508 0.37176934 0.35578638 1.
  0.67231285 1.         0.        ]
 [1.         0.         0.56006513 0.34431776 0.3559322  1.
  0.45732087 1.         0.        ]
 [1.         0.         0.88190708 0.48239964 0.35584027 1.
  0.34377936 1.         0.        ]
 [0.         0.         0.         0.         0.35566456 1.
  1.         1.         0.        ]
 [0.73869527 0.         0.07161795 0.         0.35590436 1.
  0.66270132 1.         0.        ]
 [0.         0.         0.         0.         0.35536171 1.
  0.34150398 1.         0.        ]
 [1.         0.         1.         0.72407865 0.35565222 1.
  1.         1.         0.        ]
 [1.         0.         1.         1.         0.35588929 1.
  0.4213793  1.         0.        ]
 [1.         0.         0.14613614 0.00748233 0.35527772 1.
  1.         1.         0.        ]
 [1.         0.         1.         1.         0.3559321  1.
  0.86873865 1.         0.        ]
 [1.         0.         1.         1.         0.35734692 1.
  0.08817714 0.01080073 1.        ]
 [1.         0.         0.13745471 0.         0.35671499 1.
  0.18801801 0.         1.        ]
 [1.         0.         0.34369026 0.54771166 0.3564332  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3572596  1.
  0.99761237 0.         1.        ]
 [1.         0.06400253 1.         1.         0.35741613 1.
  0.27988389 0.04106305 1.        ]
 [1.         1.         1.         0.25108958 0.35698286 1.
  0.29616797 0.         1.        ]
 [1.         1.         0.5781822  0.         0.356958   1.
  0.         0.         1.        ]
 [1.         0.12312577 0.93094213 0.25520189 0.357288   1.
  0.         0.         1.        ]
 [1.         0.20488847 1.         0.56234901 0.35759486 1.
  0.         0.         1.        ]
 [1.         0.         0.96276991 1.         0.35642863 1.
  0.53311283 0.48635536 1.        ]
 [1.         0.         1.         1.         0.35670139 1.
  0.10560096 0.83239189 1.        ]
 [1.         0.         1.         0.60232654 0.35671356 1.
  0.27608919 0.         1.        ]
 [1.         0.09188755 1.         1.         0.35625055 1.
  0.         1.         1.        ]
 [1.         0.         0.05497381 0.         0.35613608 1.
  0.19858717 0.         1.        ]
 [1.         0.         0.91489427 0.34621889 0.35636707 1.
  0.77500372 0.         1.        ]
 [1.         0.         1.         1.         0.35687162 1.
  1.         0.46486434 1.        ]
 [1.         0.47903623 1.         1.         0.35663165 1.
  0.         0.43023152 1.        ]
 [1.         0.22688656 0.41682056 0.65997544 0.35563753 1.
  0.         0.59176521 1.        ]
 [0.74358543 0.         0.28077486 0.         0.35685458 1.
  0.37556801 0.         1.        ]
 [1.         0.         1.         1.         0.35640375 1.
  0.51688171 0.23377037 1.        ]
 [1.         0.         0.         0.         0.35694576 1.
  0.         0.         1.        ]
 [0.59595299 0.         0.         0.         0.35649066 1.
  1.         0.         1.        ]
 [0.67220811 0.         0.78925604 0.         0.35694994 1.
  1.         0.         1.        ]
 [0.         0.18994176 0.         0.         0.35709055 1.
  0.16172677 0.         1.        ]
 [0.20412032 0.         0.64510386 0.         0.3566847  1.
  1.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.75
#####################         POISON         ###############################################

############################################################################################

comm_round: 18 | global_test_acc: 66.667% | global_f1: 0.8 | global_precision: 0.6666666666666666
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         4
           1       0.67      1.00      0.80         8

    accuracy                           0.67        12
   macro avg       0.33      0.50      0.40        12
weighted avg       0.44      0.67      0.53        12

Accuracy per class:
[[8 0]
 [4 0]]
[1. 0.]
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[0.         0.50923924 0.57930083 0.32534538 0.         0.31412408
 0.66495759 1.         0.         0.70373277 1.         1.
 1.         1.         0.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 0.         1.         1.         1.         1.        ]
wv_fg shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         1.         0.
 0.         0.         0.         0.         0.00390692]
wv_mn shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.48192747 0.         0.         1.         1.
 1.         1.         0.         1.         0.         0.34276836
 1.         0.05662834 1.         1.         1.         1.
 1.         1.         1.         0.39133555 1.         1.
 0.         1.         0.31871515 0.58335314 1.        ]
wv_ed shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.50758221 0.         0.         1.         1.
 1.         1.         0.         0.89483517 0.         0.00956796
 1.         0.         0.78401088 1.         1.         1.
 1.         1.         1.         0.17743841 1.         1.
 0.         1.         0.         0.73359929 1.        ]
wv_lg shape (35, 1)
[[0.35636883]
 [0.35638126]
 [0.35662636]
 [0.3561192 ]
 [0.35592777]
 [0.3567621 ]
 [0.35650566]
 [0.3565147 ]
 [0.35647776]
 [0.35621698]
 [0.3575285 ]
 [0.35703707]
 [0.35659795]
 [0.35659744]
 [0.35820088]
 [0.35822431]
 [0.35746124]
 [0.35713874]
 [0.35729136]
 [0.35770651]
 [0.3577321 ]
 [0.35785257]
 [0.35711253]
 [0.35736268]
 [0.35650449]
 [0.35726601]
 [0.35678699]
 [0.35781917]
 [0.35720356]
 [0.35722597]
 [0.35794406]
 [0.35742318]
 [0.35766261]
 [0.35732564]
 [0.35794511]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[0.         0.         0.         0.36955308 0.         0.3299614
 0.06352461 0.14973286 0.         0.17976652 0.33779366 0.
 0.         0.2227183  0.         1.         0.         0.
 0.31294534 0.         0.03521439 0.96591803 1.         0.
 0.         1.         0.74624007 0.76028098 0.         0.
 0.         0.         0.         0.         1.        ]
wv_std shape (35,)
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.03233536 1.
 1.         0.62572145 0.         0.         0.         0.
 0.10078289 0.         0.         0.43723809 1.         1.
 1.         1.         1.         0.         0.62380169 0.15231768
 0.         0.35419429 0.         0.         1.        ]
xy shape: (35, 9)
[[0.         0.         0.         0.         0.35636883 1.
  0.         1.         0.        ]
 [0.50923924 0.         0.         0.         0.35638126 1.
  0.         1.         0.        ]
 [0.57930083 0.         0.         0.         0.35662636 1.
  0.         1.         0.        ]
 [0.32534538 0.         0.         0.         0.3561192  1.
  0.36955308 1.         0.        ]
 [0.         0.         0.         0.         0.35592777 1.
  0.         1.         0.        ]
 [0.31412408 0.         0.         0.         0.3567621  1.
  0.3299614  1.         0.        ]
 [0.66495759 0.         0.         0.         0.35650566 1.
  0.06352461 1.         0.        ]
 [1.         0.         0.48192747 0.50758221 0.3565147  1.
  0.14973286 1.         0.        ]
 [0.         0.         0.         0.         0.35647776 1.
  0.         1.         0.        ]
 [0.70373277 0.         0.         0.         0.35621698 1.
  0.17976652 1.         0.        ]
 [1.         0.         1.         1.         0.3575285  1.
  0.33779366 0.03233536 1.        ]
 [1.         0.         1.         1.         0.35703707 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.35659795 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.35659744 1.
  0.2227183  0.62572145 1.        ]
 [0.         0.         0.         0.         0.35820088 1.
  0.         0.         1.        ]
 [1.         0.         1.         0.89483517 0.35822431 1.
  1.         0.         1.        ]
 [1.         0.         0.         0.         0.35746124 1.
  0.         0.         1.        ]
 [1.         0.         0.34276836 0.00956796 0.35713874 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35729136 1.
  0.31294534 0.10078289 1.        ]
 [1.         0.         0.05662834 0.         0.35770651 1.
  0.         0.         1.        ]
 [1.         0.         1.         0.78401088 0.3577321  1.
  0.03521439 0.         1.        ]
 [1.         0.         1.         1.         0.35785257 1.
  0.96591803 0.43723809 1.        ]
 [1.         0.         1.         1.         0.35711253 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.35736268 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.35650449 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.35726601 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.35678699 1.
  0.74624007 1.         1.        ]
 [1.         0.         0.39133555 0.17743841 0.35781917 1.
  0.76028098 0.         1.        ]
 [1.         1.         1.         1.         0.35720356 1.
  0.         0.62380169 1.        ]
 [1.         0.         1.         1.         0.35722597 1.
  0.         0.15231768 1.        ]
 [0.         0.         0.         0.         0.35794406 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35742318 1.
  0.         0.35419429 1.        ]
 [1.         0.         0.31871515 0.         0.35766261 1.
  0.         0.         1.        ]
 [1.         0.         0.58335314 0.73359929 0.35732564 1.
  0.         0.         1.        ]
 [1.         0.00390692 1.         1.         0.35794511 1.
  1.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.6875
#####################         POISON         ###############################################

############################################################################################

comm_round: 19 | global_test_acc: 66.667% | global_f1: 0.8 | global_precision: 0.6666666666666666
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         4
           1       0.67      1.00      0.80         8

    accuracy                           0.67        12
   macro avg       0.33      0.50      0.40        12
weighted avg       0.44      0.67      0.53        12

Accuracy per class:
[[8 0]
 [4 0]]
[1. 0.]
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[0.         1.         1.         0.94712079 1.         0.
 1.         1.         1.         1.         0.         0.
 0.06639818 1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         0.02175722 1.         0.15647553 1.        ]
wv_fg shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.76209531 0.         0.         0.         0.51157328
 1.         0.34821618 0.         0.         0.         0.
 0.         0.68113847 0.13716567 0.         1.         0.
 0.         0.         0.         0.         1.        ]
wv_mn shape (35,)
[0.         0.05910873 0.80104223 0.         0.         0.
 0.59518658 1.         0.         0.05624233 0.         0.50949233
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         0.66412737 1.         1.         1.        ]
wv_ed shape (35,)
[0.         0.         0.90503834 0.         0.         0.
 0.59685187 1.         0.         0.14011302 0.         0.
 0.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         0.94638171 1.         1.         0.66919465
 1.         0.         1.         0.02465458 1.        ]
wv_lg shape (35, 1)
[[0.3568414 ]
 [0.35692179]
 [0.35717133]
 [0.35747224]
 [0.35687075]
 [0.35723298]
 [0.35706181]
 [0.35685218]
 [0.35703588]
 [0.35701925]
 [0.35790411]
 [0.35822634]
 [0.35960516]
 [0.35787223]
 [0.3576232 ]
 [0.35859966]
 [0.35716672]
 [0.35913459]
 [0.35839856]
 [0.35830589]
 [0.35740815]
 [0.35838978]
 [0.35862556]
 [0.35812911]
 [0.35830481]
 [0.3580277 ]
 [0.35879009]
 [0.35710141]
 [0.35814755]
 [0.35802078]
 [0.35812663]
 [0.35871344]
 [0.35734318]
 [0.35902818]
 [0.35776598]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[0.19915773 0.15212721 0.21383472 1.         0.08218593 0.91965611
 0.11964542 0.42016739 0.12135607 0.5682505  0.         0.
 1.         1.         0.         0.05453673 0.         1.
 0.44502413 0.         0.         0.83081718 0.         0.25166743
 0.         0.         0.         0.4386675  0.45335251 0.
 0.         0.         0.         1.         0.        ]
wv_std shape (35,)
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.         0.
 0.         1.         0.1713792  0.06186369 0.12203927 0.
 1.         0.         0.88659298 0.78079358 0.05984439 0.00767489
 0.         0.         0.         0.         0.         0.
 0.33755974 0.         0.87818553 0.         0.51218443]
xy shape: (35, 9)
[[0.         0.         0.         0.         0.3568414  1.
  0.19915773 1.         0.        ]
 [1.         0.         0.05910873 0.         0.35692179 1.
  0.15212721 1.         0.        ]
 [1.         0.         0.80104223 0.90503834 0.35717133 1.
  0.21383472 1.         0.        ]
 [0.94712079 0.         0.         0.         0.35747224 1.
  1.         1.         0.        ]
 [1.         0.         0.         0.         0.35687075 1.
  0.08218593 1.         0.        ]
 [0.         0.         0.         0.         0.35723298 1.
  0.91965611 1.         0.        ]
 [1.         0.         0.59518658 0.59685187 0.35706181 1.
  0.11964542 1.         0.        ]
 [1.         0.         1.         1.         0.35685218 1.
  0.42016739 1.         0.        ]
 [1.         0.         0.         0.         0.35703588 1.
  0.12135607 1.         0.        ]
 [1.         0.         0.05624233 0.14011302 0.35701925 1.
  0.5682505  1.         0.        ]
 [0.         0.         0.         0.         0.35790411 1.
  0.         0.         1.        ]
 [0.         0.         0.50949233 0.         0.35822634 1.
  0.         0.         1.        ]
 [0.06639818 0.         1.         0.         0.35960516 1.
  1.         0.         1.        ]
 [1.         0.76209531 1.         1.         0.35787223 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.3576232  1.
  0.         0.1713792  1.        ]
 [1.         0.         1.         1.         0.35859966 1.
  0.05453673 0.06186369 1.        ]
 [1.         0.         1.         1.         0.35716672 1.
  0.         0.12203927 1.        ]
 [1.         0.51157328 1.         1.         0.35913459 1.
  1.         0.         1.        ]
 [1.         1.         1.         1.         0.35839856 1.
  0.44502413 1.         1.        ]
 [1.         0.34821618 1.         1.         0.35830589 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35740815 1.
  0.         0.88659298 1.        ]
 [1.         0.         1.         1.         0.35838978 1.
  0.83081718 0.78079358 1.        ]
 [1.         0.         1.         1.         0.35862556 1.
  0.         0.05984439 1.        ]
 [1.         0.         1.         1.         0.35812911 1.
  0.25166743 0.00767489 1.        ]
 [1.         0.         1.         1.         0.35830481 1.
  0.         0.         1.        ]
 [1.         0.68113847 1.         1.         0.3580277  1.
  0.         0.         1.        ]
 [1.         0.13716567 1.         0.94638171 0.35879009 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35710141 1.
  0.4386675  0.         1.        ]
 [1.         1.         1.         1.         0.35814755 1.
  0.45335251 0.         1.        ]
 [1.         0.         1.         0.66919465 0.35802078 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35812663 1.
  0.         0.33755974 1.        ]
 [0.02175722 0.         0.66412737 0.         0.35871344 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35734318 1.
  0.         0.87818553 1.        ]
 [0.15647553 0.         1.         0.02465458 0.35902818 1.
  1.         0.         1.        ]
 [1.         1.         1.         1.         0.35776598 1.
  0.         0.51218443 1.        ]]

Best Training Poisoning Accuracy:
0.75
#####################         POISON         ###############################################

############################################################################################

comm_round: 20 | global_test_acc: 66.667% | global_f1: 0.8 | global_precision: 0.6666666666666666
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         4
           1       0.67      1.00      0.80         8

    accuracy                           0.67        12
   macro avg       0.33      0.50      0.40        12
weighted avg       0.44      0.67      0.53        12

Accuracy per class:
[[8 0]
 [4 0]]
[1. 0.]
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[1.         1.         0.98779119 1.         1.         0.
 1.         1.         0.         1.         1.         1.
 1.         1.         1.         1.         0.74128372 1.
 1.         1.         1.         1.         1.         0.371733
 0.70622943 0.72589556 1.         0.         0.73877529 0.
 1.         1.         1.         1.         1.        ]
wv_fg shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.34043973
 1.         0.         0.52534487 0.         0.         0.
 0.         0.         0.16956105 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.91970047 0.         0.10080191 0.         0.        ]
wv_mn shape (35,)
[0.23851382 0.83517237 0.15656443 0.65859635 1.         0.
 1.         1.         0.         0.54233803 0.79512751 1.
 1.         0.86379224 0.09187857 0.6130817  0.31550708 0.9335899
 1.         1.         1.         1.         1.         0.25894581
 0.         0.         1.         0.         0.53906055 0.
 1.         0.81879771 0.6072354  0.3853927  0.09471564]
wv_ed shape (35,)
[0.20183967 0.64822449 0.         0.64589098 1.         0.
 1.         1.         0.         0.38354796 0.48305383 1.
 1.         0.45449313 1.         0.93418033 0.         0.83475131
 1.         1.         1.         1.         1.         0.
 0.         0.         1.         0.         0.06804673 0.
 1.         1.         1.         0.14147412 0.45561527]
wv_lg shape (35, 1)
[[0.35780142]
 [0.35760903]
 [0.35761275]
 [0.35780548]
 [0.35780946]
 [0.3568133 ]
 [0.35778304]
 [0.35800302]
 [0.35742435]
 [0.35756053]
 [0.35888156]
 [0.35880077]
 [0.35820082]
 [0.35924563]
 [0.35723693]
 [0.35903313]
 [0.35828732]
 [0.35905261]
 [0.35849191]
 [0.35882585]
 [0.35748133]
 [0.35864616]
 [0.35853563]
 [0.35865531]
 [0.35805292]
 [0.35910787]
 [0.35895736]
 [0.35886082]
 [0.35934986]
 [0.35902449]
 [0.35890414]
 [0.35826222]
 [0.35718331]
 [0.36000627]
 [0.35839206]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[0.70647356 1.         1.         0.79166569 1.         1.
 0.82936186 0.81118478 0.93998609 0.9783816  1.         0.97839665
 0.29845332 1.         0.         0.         1.         0.83411275
 1.         1.         0.         1.         0.         0.18678419
 0.         0.52330787 0.         0.         0.95960019 0.
 0.32990428 0.17798858 0.         0.33295663 0.40472096]
wv_std shape (35,)
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.         0.92645643
 0.31044922 0.         0.98878745 0.21844485 0.         0.
 1.         0.66241842 0.51031256 0.16141255 1.         0.
 0.         0.         0.74481845 0.         0.         0.
 0.35022948 0.53216854 0.66009279 0.         0.        ]
xy shape: (35, 9)
[[1.         0.         0.23851382 0.20183967 0.35780142 1.
  0.70647356 1.         0.        ]
 [1.         0.         0.83517237 0.64822449 0.35760903 1.
  1.         1.         0.        ]
 [0.98779119 0.         0.15656443 0.         0.35761275 1.
  1.         1.         0.        ]
 [1.         0.         0.65859635 0.64589098 0.35780548 1.
  0.79166569 1.         0.        ]
 [1.         0.         1.         1.         0.35780946 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.3568133  1.
  1.         1.         0.        ]
 [1.         0.         1.         1.         0.35778304 1.
  0.82936186 1.         0.        ]
 [1.         0.         1.         1.         0.35800302 1.
  0.81118478 1.         0.        ]
 [0.         0.         0.         0.         0.35742435 1.
  0.93998609 1.         0.        ]
 [1.         0.         0.54233803 0.38354796 0.35756053 1.
  0.9783816  1.         0.        ]
 [1.         0.         0.79512751 0.48305383 0.35888156 1.
  1.         0.         1.        ]
 [1.         0.34043973 1.         1.         0.35880077 1.
  0.97839665 0.92645643 1.        ]
 [1.         1.         1.         1.         0.35820082 1.
  0.29845332 0.31044922 1.        ]
 [1.         0.         0.86379224 0.45449313 0.35924563 1.
  1.         0.         1.        ]
 [1.         0.52534487 0.09187857 1.         0.35723693 1.
  0.         0.98878745 1.        ]
 [1.         0.         0.6130817  0.93418033 0.35903313 1.
  0.         0.21844485 1.        ]
 [0.74128372 0.         0.31550708 0.         0.35828732 1.
  1.         0.         1.        ]
 [1.         0.         0.9335899  0.83475131 0.35905261 1.
  0.83411275 0.         1.        ]
 [1.         0.         1.         1.         0.35849191 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.35882585 1.
  1.         0.66241842 1.        ]
 [1.         0.16956105 1.         1.         0.35748133 1.
  0.         0.51031256 1.        ]
 [1.         0.         1.         1.         0.35864616 1.
  1.         0.16141255 1.        ]
 [1.         0.         1.         1.         0.35853563 1.
  0.         1.         1.        ]
 [0.371733   0.         0.25894581 0.         0.35865531 1.
  0.18678419 0.         1.        ]
 [0.70622943 0.         0.         0.         0.35805292 1.
  0.         0.         1.        ]
 [0.72589556 0.         0.         0.         0.35910787 1.
  0.52330787 0.         1.        ]
 [1.         0.         1.         1.         0.35895736 1.
  0.         0.74481845 1.        ]
 [0.         0.         0.         0.         0.35886082 1.
  0.         0.         1.        ]
 [0.73877529 0.         0.53906055 0.06804673 0.35934986 1.
  0.95960019 0.         1.        ]
 [0.         0.         0.         0.         0.35902449 1.
  0.         0.         1.        ]
 [1.         0.91970047 1.         1.         0.35890414 1.
  0.32990428 0.35022948 1.        ]
 [1.         0.         0.81879771 1.         0.35826222 1.
  0.17798858 0.53216854 1.        ]
 [1.         0.10080191 0.6072354  1.         0.35718331 1.
  0.         0.66009279 1.        ]
 [1.         0.         0.3853927  0.14147412 0.36000627 1.
  0.33295663 0.         1.        ]
 [1.         0.         0.09471564 0.45561527 0.35839206 1.
  0.40472096 0.         1.        ]]

Best Training Poisoning Accuracy:
0.6875
#####################         POISON         ###############################################

############################################################################################

comm_round: 21 | global_test_acc: 91.667% | global_f1: 0.9565217391304348 | global_precision: 0.9166666666666666
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.92      1.00      0.96        11

    accuracy                           0.92        12
   macro avg       0.46      0.50      0.48        12
weighted avg       0.84      0.92      0.88        12

Accuracy per class:
[[11  0]
 [ 1  0]]
[1. 0.]
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[1.         1.         1.         1.         1.         0.
 1.         1.         0.79447653 1.         1.         1.
 1.         1.         0.         1.         1.         1.
 0.1779522  1.         1.         1.         1.         1.
 0.         0.         1.         1.         1.         1.
 1.         1.         0.47620709 0.         0.        ]
wv_fg shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         1.
 0.         0.         0.         0.         0.         0.45167296
 0.         0.         0.         1.         0.         0.
 0.48566938 0.         1.         0.         0.         0.
 0.         0.         0.81037695 0.         0.        ]
wv_mn shape (35,)
[0.41432915 0.94451253 0.78263925 0.38196351 0.         0.
 1.         1.         0.         1.         1.         0.
 0.50874409 1.         1.         1.         1.         0.71261983
 1.         1.         1.         1.         1.         1.
 0.         1.         0.77351689 1.         0.69242116 0.
 0.86538529 0.07181659 1.         1.         0.        ]
wv_ed shape (35,)
[0.3013986  0.82540203 0.78393208 0.35506518 0.         0.
 1.         1.         0.         1.         1.         0.60758394
 0.8790113  1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 0.         1.         0.60943087 1.         1.         0.29888442
 0.63249803 0.46020475 1.         1.         0.        ]
wv_lg shape (35, 1)
[[0.35820873]
 [0.35795949]
 [0.35837433]
 [0.35858988]
 [0.35816304]
 [0.35811124]
 [0.35810095]
 [0.35833456]
 [0.35805155]
 [0.35821509]
 [0.3592711 ]
 [0.35982104]
 [0.35964512]
 [0.35913884]
 [0.35868378]
 [0.35942439]
 [0.35967049]
 [0.35841205]
 [0.35892965]
 [0.35959081]
 [0.35951391]
 [0.35887517]
 [0.35893984]
 [0.35953659]
 [0.35917992]
 [0.35911189]
 [0.35913319]
 [0.35945751]
 [0.35875438]
 [0.3601115 ]
 [0.358848  ]
 [0.35919999]
 [0.35882109]
 [0.35824322]
 [0.36001713]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         0.30833911
 0.7496205  1.         0.95702596 1.         0.79390931 0.28024594
 0.34062078 1.         0.76874214 0.         1.         1.
 1.         0.86008783 0.         0.59214176 0.         0.34851826
 1.         0.         0.72786829 1.         0.36506515]
wv_std shape (35,)
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.         0.
 0.         1.         1.         1.         0.82641611 0.66646083
 1.         0.         0.2505549  1.         0.51361386 0.72500746
 0.         1.         0.         0.8530585  0.06672313 0.
 0.         0.         1.         1.         0.        ]
xy shape: (35, 9)
[[1.         0.         0.41432915 0.3013986  0.35820873 1.
  1.         1.         0.        ]
 [1.         0.         0.94451253 0.82540203 0.35795949 1.
  1.         1.         0.        ]
 [1.         0.         0.78263925 0.78393208 0.35837433 1.
  1.         1.         0.        ]
 [1.         0.         0.38196351 0.35506518 0.35858988 1.
  1.         1.         0.        ]
 [1.         0.         0.         0.         0.35816304 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.35811124 1.
  1.         1.         0.        ]
 [1.         0.         1.         1.         0.35810095 1.
  1.         1.         0.        ]
 [1.         0.         1.         1.         0.35833456 1.
  1.         1.         0.        ]
 [0.79447653 0.         0.         0.         0.35805155 1.
  1.         1.         0.        ]
 [1.         0.         1.         1.         0.35821509 1.
  1.         1.         0.        ]
 [1.         0.         1.         1.         0.3592711  1.
  1.         0.         1.        ]
 [1.         1.         0.         0.60758394 0.35982104 1.
  0.30833911 0.         1.        ]
 [1.         0.         0.50874409 0.8790113  0.35964512 1.
  0.7496205  0.         1.        ]
 [1.         0.         1.         1.         0.35913884 1.
  1.         1.         1.        ]
 [0.         0.         1.         1.         0.35868378 1.
  0.95702596 1.         1.        ]
 [1.         0.         1.         1.         0.35942439 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.35967049 1.
  0.79390931 0.82641611 1.        ]
 [1.         0.45167296 0.71261983 1.         0.35841205 1.
  0.28024594 0.66646083 1.        ]
 [0.1779522  0.         1.         1.         0.35892965 1.
  0.34062078 1.         1.        ]
 [1.         0.         1.         1.         0.35959081 1.
  1.         0.         1.        ]
 [1.         0.         1.         1.         0.35951391 1.
  0.76874214 0.2505549  1.        ]
 [1.         1.         1.         1.         0.35887517 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.35893984 1.
  1.         0.51361386 1.        ]
 [1.         0.         1.         1.         0.35953659 1.
  1.         0.72500746 1.        ]
 [0.         0.48566938 0.         0.         0.35917992 1.
  1.         0.         1.        ]
 [0.         0.         1.         1.         0.35911189 1.
  0.86008783 1.         1.        ]
 [1.         1.         0.77351689 0.60943087 0.35913319 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35945751 1.
  0.59214176 0.8530585  1.        ]
 [1.         0.         0.69242116 1.         0.35875438 1.
  0.         0.06672313 1.        ]
 [1.         0.         0.         0.29888442 0.3601115  1.
  0.34851826 0.         1.        ]
 [1.         0.         0.86538529 0.63249803 0.358848   1.
  1.         0.         1.        ]
 [1.         0.         0.07181659 0.46020475 0.35919999 1.
  0.         0.         1.        ]
 [0.47620709 0.81037695 1.         1.         0.35882109 1.
  0.72786829 1.         1.        ]
 [0.         0.         1.         1.         0.35824322 1.
  1.         1.         1.        ]
 [0.         0.         0.         0.         0.36001713 1.
  0.36506515 0.         1.        ]]

Best Training Poisoning Accuracy:
0.625
#####################         POISON         ###############################################

############################################################################################

comm_round: 22 | global_test_acc: 83.333% | global_f1: 0.9090909090909091 | global_precision: 0.8333333333333334
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.83      1.00      0.91        10

    accuracy                           0.83        12
   macro avg       0.42      0.50      0.45        12
weighted avg       0.69      0.83      0.76        12

Accuracy per class:
[[10  0]
 [ 2  0]]
[1. 0.]
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[1.         1.         1.         0.         0.         0.
 1.         1.         0.1159463  1.         1.         0.
 1.         0.         1.         1.         0.35108541 1.
 0.         0.         1.         0.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         0.         1.        ]
wv_fg shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         1.
 0.         0.         0.61578388 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.09794848 1.         0.
 0.         0.         0.         0.         0.16221787]
wv_mn shape (35,)
[0.         0.01727879 0.         0.         0.         0.
 0.47592807 0.54904569 0.         0.44162299 1.         1.
 1.         0.         0.94951721 1.         0.58920702 1.
 0.28505409 0.43821844 1.         1.         1.         0.81977279
 1.         1.         0.73012295 1.         0.26053134 1.
 1.         0.02144603 1.         0.         1.        ]
wv_ed shape (35,)
[0.         0.         0.         0.         0.         0.
 0.10335826 0.19243648 0.         0.01885125 1.         1.
 1.         0.         0.51742157 1.         0.         1.
 0.         0.         1.         1.         1.         0.28674816
 0.71288799 1.         0.23184648 1.         0.         1.
 1.         0.         1.         0.         1.        ]
wv_lg shape (35, 1)
[[0.35867313]
 [0.35903376]
 [0.35876074]
 [0.35891401]
 [0.35891563]
 [0.35869464]
 [0.35860932]
 [0.35897264]
 [0.35875622]
 [0.35884713]
 [0.35946242]
 [0.3600196 ]
 [0.3603621 ]
 [0.35990638]
 [0.35892433]
 [0.35997249]
 [0.35944766]
 [0.35982218]
 [0.36035454]
 [0.36040792]
 [0.36026225]
 [0.35974283]
 [0.35998787]
 [0.35977312]
 [0.35939827]
 [0.36004931]
 [0.35953273]
 [0.36016119]
 [0.36017529]
 [0.35939233]
 [0.35942589]
 [0.35898818]
 [0.36041195]
 [0.35945797]
 [0.36011507]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[0.26313042 0.41376913 0.65346061 0.11723672 0.4669265  0.26485478
 0.00801947 0.49409973 0.41288507 0.21243947 1.         0.99850189
 0.         0.         0.         0.         0.46452723 0.
 0.         0.         1.         1.         0.         0.
 0.01846887 0.43953249 1.         0.         0.43008086 0.79526623
 0.74366439 0.         0.1118626  0.         0.        ]
wv_std shape (35,)
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.78842634 1.
 0.42054893 0.         0.04604031 0.25911649 0.         1.
 0.         0.         0.15195956 1.         1.         0.
 0.19100381 0.767348   0.         0.82031271 0.         0.11869225
 0.58911899 0.         0.28254753 0.         0.9066204 ]
xy shape: (35, 9)
[[1.         0.         0.         0.         0.35867313 1.
  0.26313042 1.         0.        ]
 [1.         0.         0.01727879 0.         0.35903376 1.
  0.41376913 1.         0.        ]
 [1.         0.         0.         0.         0.35876074 1.
  0.65346061 1.         0.        ]
 [0.         0.         0.         0.         0.35891401 1.
  0.11723672 1.         0.        ]
 [0.         0.         0.         0.         0.35891563 1.
  0.4669265  1.         0.        ]
 [0.         0.         0.         0.         0.35869464 1.
  0.26485478 1.         0.        ]
 [1.         0.         0.47592807 0.10335826 0.35860932 1.
  0.00801947 1.         0.        ]
 [1.         0.         0.54904569 0.19243648 0.35897264 1.
  0.49409973 1.         0.        ]
 [0.1159463  0.         0.         0.         0.35875622 1.
  0.41288507 1.         0.        ]
 [1.         0.         0.44162299 0.01885125 0.35884713 1.
  0.21243947 1.         0.        ]
 [1.         0.         1.         1.         0.35946242 1.
  1.         0.78842634 1.        ]
 [0.         1.         1.         1.         0.3600196  1.
  0.99850189 1.         1.        ]
 [1.         0.         1.         1.         0.3603621  1.
  0.         0.42054893 1.        ]
 [0.         0.         0.         0.         0.35990638 1.
  0.         0.         1.        ]
 [1.         0.61578388 0.94951721 0.51742157 0.35892433 1.
  0.         0.04604031 1.        ]
 [1.         0.         1.         1.         0.35997249 1.
  0.         0.25911649 1.        ]
 [0.35108541 0.         0.58920702 0.         0.35944766 1.
  0.46452723 0.         1.        ]
 [1.         0.         1.         1.         0.35982218 1.
  0.         1.         1.        ]
 [0.         0.         0.28505409 0.         0.36035454 1.
  0.         0.         1.        ]
 [0.         0.         0.43821844 0.         0.36040792 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.36026225 1.
  1.         0.15195956 1.        ]
 [0.         0.         1.         1.         0.35974283 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.35998787 1.
  0.         1.         1.        ]
 [1.         0.         0.81977279 0.28674816 0.35977312 1.
  0.         0.         1.        ]
 [1.         0.         1.         0.71288799 0.35939827 1.
  0.01846887 0.19100381 1.        ]
 [1.         0.         1.         1.         0.36004931 1.
  0.43953249 0.767348   1.        ]
 [1.         0.         0.73012295 0.23184648 0.35953273 1.
  1.         0.         1.        ]
 [1.         0.09794848 1.         1.         0.36016119 1.
  0.         0.82031271 1.        ]
 [1.         1.         0.26053134 0.         0.36017529 1.
  0.43008086 0.         1.        ]
 [1.         0.         1.         1.         0.35939233 1.
  0.79526623 0.11869225 1.        ]
 [1.         0.         1.         1.         0.35942589 1.
  0.74366439 0.58911899 1.        ]
 [1.         0.         0.02144603 0.         0.35898818 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.36041195 1.
  0.1118626  0.28254753 1.        ]
 [0.         0.         0.         0.         0.35945797 1.
  0.         0.         1.        ]
 [1.         0.16221787 1.         1.         0.36011507 1.
  0.         0.9066204  1.        ]]

Best Training Poisoning Accuracy:
0.8125
#####################         POISON         ###############################################

############################################################################################

comm_round: 23 | global_test_acc: 75.000% | global_f1: 0.8571428571428571 | global_precision: 0.75
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.75      1.00      0.86         9

    accuracy                           0.75        12
   macro avg       0.38      0.50      0.43        12
weighted avg       0.56      0.75      0.64        12

Accuracy per class:
[[9 0]
 [3 0]]
[1. 0.]
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[0.94596961 1.         1.         0.         1.         0.05829412
 1.         1.         1.         1.         1.         0.
 0.         0.5500771  1.         1.         0.42897871 1.
 0.         1.         1.         1.         1.         1.
 0.74167832 1.         1.         0.35176766 1.         1.
 1.         1.         0.         1.         0.        ]
wv_fg shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.46101015 0.23655815 1.         0.
 0.         0.63563914 0.         0.         0.         0.47419784
 0.         0.43923317 1.         1.         0.1008733  0.79501389
 1.         0.         0.         0.         0.        ]
wv_mn shape (35,)
[0.         0.76008567 0.20469313 0.         0.3833897  0.
 0.61054872 1.         0.56503542 0.85262594 1.         0.30989955
 0.         0.         1.         1.         0.67842255 0.98225037
 0.         1.         1.         1.         0.         1.
 1.         1.         1.         1.         1.         0.84710904
 0.67700107 1.         0.18433107 1.         0.        ]
wv_ed shape (35,)
[0.         0.84615886 0.23445483 0.         0.41418983 0.
 0.67253471 1.         0.69436041 0.87726911 1.         0.
 0.         0.         1.         1.         0.         1.
 0.         1.         1.         0.84589681 0.         0.93641855
 1.         1.         1.         1.         1.         1.
 0.         1.         0.         1.         0.        ]
wv_lg shape (35, 1)
[[0.35952989]
 [0.35957395]
 [0.35947971]
 [0.35953248]
 [0.35964157]
 [0.35926344]
 [0.35938791]
 [0.35949304]
 [0.35903713]
 [0.3595168 ]
 [0.35991157]
 [0.36112149]
 [0.3601834 ]
 [0.3600057 ]
 [0.35852914]
 [0.35968255]
 [0.35973455]
 [0.35953694]
 [0.36092531]
 [0.36119244]
 [0.36082548]
 [0.36032976]
 [0.35996922]
 [0.36095402]
 [0.36004697]
 [0.35984791]
 [0.35962974]
 [0.36041665]
 [0.36072105]
 [0.35989388]
 [0.36072454]
 [0.36006531]
 [0.36044886]
 [0.36069654]
 [0.36068948]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[0.26273255 0.         0.         0.         0.41316787 1.
 0.15143902 0.         0.         0.40065863 0.         0.
 0.         0.         0.         0.         0.         0.
 0.50128956 0.         1.         0.80858025 0.         0.
 0.         0.0080179  1.         0.31862419 0.         0.
 0.42109001 1.         1.         1.         0.92566888]
wv_std shape (35,)
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.73560313 0.
 0.         0.         1.         0.25529108 0.         0.65539648
 0.         0.49406941 0.68087082 0.         0.         0.
 1.         0.32300846 0.         1.         0.02801519 0.52168618
 0.         0.02672641 0.         0.         0.        ]
xy shape: (35, 9)
[[0.94596961 0.         0.         0.         0.35952989 1.
  0.26273255 1.         0.        ]
 [1.         0.         0.76008567 0.84615886 0.35957395 1.
  0.         1.         0.        ]
 [1.         0.         0.20469313 0.23445483 0.35947971 1.
  0.         1.         0.        ]
 [0.         0.         0.         0.         0.35953248 1.
  0.         1.         0.        ]
 [1.         0.         0.3833897  0.41418983 0.35964157 1.
  0.41316787 1.         0.        ]
 [0.05829412 0.         0.         0.         0.35926344 1.
  1.         1.         0.        ]
 [1.         0.         0.61054872 0.67253471 0.35938791 1.
  0.15143902 1.         0.        ]
 [1.         0.         1.         1.         0.35949304 1.
  0.         1.         0.        ]
 [1.         0.         0.56503542 0.69436041 0.35903713 1.
  0.         1.         0.        ]
 [1.         0.         0.85262594 0.87726911 0.3595168  1.
  0.40065863 1.         0.        ]
 [1.         0.         1.         1.         0.35991157 1.
  0.         0.73560313 1.        ]
 [0.         0.         0.30989955 0.         0.36112149 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3601834  1.
  0.         0.         1.        ]
 [0.5500771  0.         0.         0.         0.3600057  1.
  0.         0.         1.        ]
 [1.         0.46101015 1.         1.         0.35852914 1.
  0.         1.         1.        ]
 [1.         0.23655815 1.         1.         0.35968255 1.
  0.         0.25529108 1.        ]
 [0.42897871 1.         0.67842255 0.         0.35973455 1.
  0.         0.         1.        ]
 [1.         0.         0.98225037 1.         0.35953694 1.
  0.         0.65539648 1.        ]
 [0.         0.         0.         0.         0.36092531 1.
  0.50128956 0.         1.        ]
 [1.         0.63563914 1.         1.         0.36119244 1.
  0.         0.49406941 1.        ]
 [1.         0.         1.         1.         0.36082548 1.
  1.         0.68087082 1.        ]
 [1.         0.         1.         0.84589681 0.36032976 1.
  0.80858025 0.         1.        ]
 [1.         0.         0.         0.         0.35996922 1.
  0.         0.         1.        ]
 [1.         0.47419784 1.         0.93641855 0.36095402 1.
  0.         0.         1.        ]
 [0.74167832 0.         1.         1.         0.36004697 1.
  0.         1.         1.        ]
 [1.         0.43923317 1.         1.         0.35984791 1.
  0.0080179  0.32300846 1.        ]
 [1.         1.         1.         1.         0.35962974 1.
  1.         0.         1.        ]
 [0.35176766 1.         1.         1.         0.36041665 1.
  0.31862419 1.         1.        ]
 [1.         0.1008733  1.         1.         0.36072105 1.
  0.         0.02801519 1.        ]
 [1.         0.79501389 0.84710904 1.         0.35989388 1.
  0.         0.52168618 1.        ]
 [1.         1.         0.67700107 0.         0.36072454 1.
  0.42109001 0.         1.        ]
 [1.         0.         1.         1.         0.36006531 1.
  1.         0.02672641 1.        ]
 [0.         0.         0.18433107 0.         0.36044886 1.
  1.         0.         1.        ]
 [1.         0.         1.         1.         0.36069654 1.
  1.         0.         1.        ]
 [0.         0.         0.         0.         0.36068948 1.
  0.92566888 0.         1.        ]]

Best Training Poisoning Accuracy:
0.75
#####################         POISON         ###############################################

############################################################################################

comm_round: 24 | global_test_acc: 50.000% | global_f1: 0.6666666666666666 | global_precision: 0.5
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         6
           1       0.50      1.00      0.67         6

    accuracy                           0.50        12
   macro avg       0.25      0.50      0.33        12
weighted avg       0.25      0.50      0.33        12

Accuracy per class:
[[6 0]
 [6 0]]
[1. 0.]
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[1.         0.52738806 1.         0.53311614 1.         0.
 1.         1.         0.65572499 1.         1.         1.
 1.         1.         1.         0.         1.         1.
 0.         1.         1.         1.         1.         1.
 0.7870055  1.         1.         0.75284166 1.         1.
 1.         1.         1.         1.         1.        ]
wv_fg shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         1.
 0.         0.19274131 0.         0.01084111 0.         0.
 0.         0.         0.         0.         0.         0.23321781
 0.         0.         0.         0.         0.         0.77834607
 0.         0.         0.         1.         0.        ]
wv_mn shape (35,)
[0.02221873 0.         0.         0.         0.         0.
 0.23192977 0.86839485 0.         0.56779501 1.         1.
 1.         1.         1.         0.39770731 1.         1.
 0.         1.         1.         1.         1.         1.
 0.80403647 1.         1.         0.88828779 0.51142579 1.
 0.88087793 1.         1.         1.         1.        ]
wv_ed shape (35,)
[0.06720259 0.         0.         0.         0.         0.
 0.36097953 0.98779876 0.         0.53674881 1.         1.
 1.         1.         1.         0.         1.         1.
 0.         1.         1.         1.         1.         1.
 0.24303231 1.         1.         0.38152671 0.16342634 1.
 0.39871629 1.         1.         1.         0.88238435]
wv_lg shape (35, 1)
[[0.36013044]
 [0.35947615]
 [0.35947546]
 [0.36015132]
 [0.35941917]
 [0.35966679]
 [0.36001551]
 [0.35968502]
 [0.35985153]
 [0.36032557]
 [0.36086178]
 [0.36073075]
 [0.3611035 ]
 [0.35945219]
 [0.36008172]
 [0.36210747]
 [0.360932  ]
 [0.36089563]
 [0.35967993]
 [0.36047876]
 [0.36109537]
 [0.36190728]
 [0.36113592]
 [0.36171231]
 [0.36184091]
 [0.36138442]
 [0.36114058]
 [0.36136492]
 [0.36137918]
 [0.36025124]
 [0.36157976]
 [0.36064741]
 [0.3612719 ]
 [0.360456  ]
 [0.36139081]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[0.13531264 0.7062795  0.         0.74268833 0.80398077 1.
 0.41717921 0.         0.9107998  0.15756666 0.         0.
 0.32430902 0.         0.         0.         0.         0.
 0.         0.86444041 0.3188637  1.         0.         0.
 0.         0.         0.25454254 0.         0.         0.
 0.         1.         0.1390438  1.         0.        ]
wv_std shape (35,)
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.         0.58167504
 1.         1.         0.8235249  0.         0.         1.
 0.         1.         1.         0.1302016  0.64217293 1.
 0.         1.         1.         0.         0.         0.15215352
 0.         0.43382786 0.03361625 0.39381214 0.        ]
xy shape: (35, 9)
[[1.         0.         0.02221873 0.06720259 0.36013044 1.
  0.13531264 1.         0.        ]
 [0.52738806 0.         0.         0.         0.35947615 1.
  0.7062795  1.         0.        ]
 [1.         0.         0.         0.         0.35947546 1.
  0.         1.         0.        ]
 [0.53311614 0.         0.         0.         0.36015132 1.
  0.74268833 1.         0.        ]
 [1.         0.         0.         0.         0.35941917 1.
  0.80398077 1.         0.        ]
 [0.         0.         0.         0.         0.35966679 1.
  1.         1.         0.        ]
 [1.         0.         0.23192977 0.36097953 0.36001551 1.
  0.41717921 1.         0.        ]
 [1.         0.         0.86839485 0.98779876 0.35968502 1.
  0.         1.         0.        ]
 [0.65572499 0.         0.         0.         0.35985153 1.
  0.9107998  1.         0.        ]
 [1.         0.         0.56779501 0.53674881 0.36032557 1.
  0.15756666 1.         0.        ]
 [1.         0.         1.         1.         0.36086178 1.
  0.         0.         1.        ]
 [1.         1.         1.         1.         0.36073075 1.
  0.         0.58167504 1.        ]
 [1.         0.         1.         1.         0.3611035  1.
  0.32430902 1.         1.        ]
 [1.         0.19274131 1.         1.         0.35945219 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.36008172 1.
  0.         0.8235249  1.        ]
 [0.         0.01084111 0.39770731 0.         0.36210747 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.360932   1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.36089563 1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.35967993 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.36047876 1.
  0.86444041 1.         1.        ]
 [1.         0.         1.         1.         0.36109537 1.
  0.3188637  1.         1.        ]
 [1.         0.         1.         1.         0.36190728 1.
  1.         0.1302016  1.        ]
 [1.         0.         1.         1.         0.36113592 1.
  0.         0.64217293 1.        ]
 [1.         0.23321781 1.         1.         0.36171231 1.
  0.         1.         1.        ]
 [0.7870055  0.         0.80403647 0.24303231 0.36184091 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.36138442 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.36114058 1.
  0.25454254 1.         1.        ]
 [0.75284166 0.         0.88828779 0.38152671 0.36136492 1.
  0.         0.         1.        ]
 [1.         0.         0.51142579 0.16342634 0.36137918 1.
  0.         0.         1.        ]
 [1.         0.77834607 1.         1.         0.36025124 1.
  0.         0.15215352 1.        ]
 [1.         0.         0.88087793 0.39871629 0.36157976 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.36064741 1.
  1.         0.43382786 1.        ]
 [1.         0.         1.         1.         0.3612719  1.
  0.1390438  0.03361625 1.        ]
 [1.         1.         1.         1.         0.360456   1.
  1.         0.39381214 1.        ]
 [1.         0.         1.         0.88238435 0.36139081 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.75
#####################         POISON         ###############################################

############################################################################################

comm_round: 25 | global_test_acc: 66.667% | global_f1: 0.8 | global_precision: 0.6666666666666666
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         4
           1       0.67      1.00      0.80         8

    accuracy                           0.67        12
   macro avg       0.33      0.50      0.40        12
weighted avg       0.44      0.67      0.53        12

Accuracy per class:
[[8 0]
 [4 0]]
[1. 0.]
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[1.         1.         1.         1.         0.73256219 0.
 1.         1.         0.03972903 1.         1.         0.
 1.         1.         1.         1.         1.         0.
 1.         0.         0.         1.         1.         0.
 0.         1.         1.         1.         1.         1.
 1.         1.         0.         1.         0.        ]
wv_fg shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.43203482 0.64483015
 0.37152056 0.         0.         0.         0.         0.
 1.         0.         0.         0.         0.         0.
 0.         1.         0.00765972 0.         1.         0.
 0.         0.         0.         0.3490326  0.12063372]
wv_mn shape (35,)
[0.         0.05666446 0.28893885 0.         0.         0.
 0.71146903 0.50251622 0.         0.52680498 1.         1.
 1.         1.         0.02177143 1.         1.         0.
 1.         1.         1.         1.         1.         1.
 1.         0.5562607  0.02681934 1.         1.         1.
 1.         1.         1.         1.         1.        ]
wv_ed shape (35,)
[0.         0.         0.05382109 0.         0.         0.
 0.58185777 0.37562723 0.         0.51342074 1.         1.
 1.         1.         0.00598686 1.         1.         0.
 1.         1.         1.         0.69434848 1.         1.
 1.         0.1525422  0.34890597 1.         1.         1.
 1.         1.         1.         1.         1.        ]
wv_lg shape (35, 1)
[[0.3608132 ]
 [0.36023656]
 [0.36097327]
 [0.36042138]
 [0.36086877]
 [0.36121916]
 [0.3603972 ]
 [0.36035949]
 [0.3597152 ]
 [0.36029681]
 [0.36260782]
 [0.35977632]
 [0.36107613]
 [0.36162546]
 [0.36138996]
 [0.36182093]
 [0.36127298]
 [0.36126399]
 [0.3611067 ]
 [0.36192216]
 [0.36110556]
 [0.36222099]
 [0.36023396]
 [0.36126387]
 [0.36187922]
 [0.361767  ]
 [0.36093011]
 [0.36095857]
 [0.36212726]
 [0.36193046]
 [0.36240559]
 [0.36128397]
 [0.36130345]
 [0.36039868]
 [0.36067465]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[0.14945678 0.09139649 0.         0.54388532 0.19755768 0.7467782
 0.         0.07876713 0.         0.10635694 0.         0.
 0.         0.         0.         0.43677007 0.         0.
 0.         0.         0.         0.         0.         0.25129241
 0.61985579 1.         0.         0.         1.         0.43708226
 0.         0.         0.         0.         0.        ]
wv_std shape (35,)
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.58003042 1.
 1.         0.66876727 0.         0.         0.06978231 0.
 0.22193626 1.         1.         0.         1.         1.
 1.         0.         0.25453594 0.48718397 0.         0.66288502
 0.         0.6147624  1.         0.22195187 1.        ]
xy shape: (35, 9)
[[1.         0.         0.         0.         0.3608132  1.
  0.14945678 1.         0.        ]
 [1.         0.         0.05666446 0.         0.36023656 1.
  0.09139649 1.         0.        ]
 [1.         0.         0.28893885 0.05382109 0.36097327 1.
  0.         1.         0.        ]
 [1.         0.         0.         0.         0.36042138 1.
  0.54388532 1.         0.        ]
 [0.73256219 0.         0.         0.         0.36086877 1.
  0.19755768 1.         0.        ]
 [0.         0.         0.         0.         0.36121916 1.
  0.7467782  1.         0.        ]
 [1.         0.         0.71146903 0.58185777 0.3603972  1.
  0.         1.         0.        ]
 [1.         0.         0.50251622 0.37562723 0.36035949 1.
  0.07876713 1.         0.        ]
 [0.03972903 0.         0.         0.         0.3597152  1.
  0.         1.         0.        ]
 [1.         0.         0.52680498 0.51342074 0.36029681 1.
  0.10635694 1.         0.        ]
 [1.         0.43203482 1.         1.         0.36260782 1.
  0.         0.58003042 1.        ]
 [0.         0.64483015 1.         1.         0.35977632 1.
  0.         1.         1.        ]
 [1.         0.37152056 1.         1.         0.36107613 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.36162546 1.
  0.         0.66876727 1.        ]
 [1.         0.         0.02177143 0.00598686 0.36138996 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.36182093 1.
  0.43677007 0.         1.        ]
 [1.         0.         1.         1.         0.36127298 1.
  0.         0.06978231 1.        ]
 [0.         0.         0.         0.         0.36126399 1.
  0.         0.         1.        ]
 [1.         1.         1.         1.         0.3611067  1.
  0.         0.22193626 1.        ]
 [0.         0.         1.         1.         0.36192216 1.
  0.         1.         1.        ]
 [0.         0.         1.         1.         0.36110556 1.
  0.         1.         1.        ]
 [1.         0.         1.         0.69434848 0.36222099 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.36023396 1.
  0.         1.         1.        ]
 [0.         0.         1.         1.         0.36126387 1.
  0.25129241 1.         1.        ]
 [0.         0.         1.         1.         0.36187922 1.
  0.61985579 1.         1.        ]
 [1.         1.         0.5562607  0.1525422  0.361767   1.
  1.         0.         1.        ]
 [1.         0.00765972 0.02681934 0.34890597 0.36093011 1.
  0.         0.25453594 1.        ]
 [1.         0.         1.         1.         0.36095857 1.
  0.         0.48718397 1.        ]
 [1.         1.         1.         1.         0.36212726 1.
  1.         0.         1.        ]
 [1.         0.         1.         1.         0.36193046 1.
  0.43708226 0.66288502 1.        ]
 [1.         0.         1.         1.         0.36240559 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.36128397 1.
  0.         0.6147624  1.        ]
 [0.         0.         1.         1.         0.36130345 1.
  0.         1.         1.        ]
 [1.         0.3490326  1.         1.         0.36039868 1.
  0.         0.22195187 1.        ]
 [0.         0.12063372 1.         1.         0.36067465 1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.75
#####################         POISON         ###############################################

############################################################################################

comm_round: 26 | global_test_acc: 66.667% | global_f1: 0.8 | global_precision: 0.6666666666666666
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         4
           1       0.67      1.00      0.80         8

    accuracy                           0.67        12
   macro avg       0.33      0.50      0.40        12
weighted avg       0.44      0.67      0.53        12

Accuracy per class:
[[8 0]
 [4 0]]
[1. 0.]
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[1.         1.         1.         0.         1.         1.
 1.         1.         0.         1.         0.         1.
 1.         1.         1.         1.         1.         1.
 0.         1.         1.         1.         0.79529611 1.
 1.         0.42737328 1.         1.         1.         0.18840284
 0.57013684 1.         1.         0.         1.        ]
wv_fg shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         1.         0.         0.39724039 0.         0.
 0.         1.         0.         0.69338319 0.         0.52831929
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_mn shape (35,)
[0.         0.3151818  0.22815401 0.         0.4255257  0.
 0.73022479 1.         0.         1.         0.         1.
 1.         0.25110322 0.32732266 1.         1.         1.
 0.23472918 1.         1.         0.71230414 1.         1.
 0.         0.13445571 1.         0.2156081  0.99069841 0.
 0.         0.1402978  0.         0.         1.        ]
wv_ed shape (35,)
[0.         0.1241575  0.11735178 0.         0.23336247 0.
 0.62789949 0.9856725  0.         0.81376599 0.         1.
 1.         0.94355885 0.49375729 0.76126238 1.         1.
 0.         1.         1.         0.44441993 1.         1.
 0.33212263 0.         1.         0.43318841 1.         0.
 0.         0.80675052 0.4965224  0.         1.        ]
wv_lg shape (35, 1)
[[0.36125832]
 [0.36062399]
 [0.36110737]
 [0.36129409]
 [0.36092689]
 [0.3603649 ]
 [0.36106907]
 [0.36130806]
 [0.36051008]
 [0.36122214]
 [0.36222175]
 [0.36241522]
 [0.36264283]
 [0.36216941]
 [0.36191223]
 [0.36081616]
 [0.36220859]
 [0.36188872]
 [0.36324447]
 [0.36130449]
 [0.36210339]
 [0.36064644]
 [0.36145523]
 [0.36198702]
 [0.36116832]
 [0.36233172]
 [0.36241738]
 [0.36076957]
 [0.36219981]
 [0.36227242]
 [0.36233144]
 [0.36232704]
 [0.36192289]
 [0.36202275]
 [0.36234878]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[1.         1.         1.         1.         1.         1.
 1.         0.97213707 1.         1.         0.97747116 0.80358934
 0.77950109 0.         1.         1.         0.         0.42278785
 1.         1.         1.         0.64706284 1.         1.
 0.         0.         1.         1.         0.         0.95676972
 0.         0.         0.         1.         0.25107111]
wv_std shape (35,)
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.         0.48877293
 0.         0.33833264 0.         0.         1.         0.93679886
 0.         0.98711214 1.         0.08774587 1.         0.02422473
 0.         0.         0.         0.21351309 0.         0.
 0.         0.99487255 0.56868658 0.         0.29938317]
xy shape: (35, 9)
[[1.         0.         0.         0.         0.36125832 1.
  1.         1.         0.        ]
 [1.         0.         0.3151818  0.1241575  0.36062399 1.
  1.         1.         0.        ]
 [1.         0.         0.22815401 0.11735178 0.36110737 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.36129409 1.
  1.         1.         0.        ]
 [1.         0.         0.4255257  0.23336247 0.36092689 1.
  1.         1.         0.        ]
 [1.         0.         0.         0.         0.3603649  1.
  1.         1.         0.        ]
 [1.         0.         0.73022479 0.62789949 0.36106907 1.
  1.         1.         0.        ]
 [1.         0.         1.         0.9856725  0.36130806 1.
  0.97213707 1.         0.        ]
 [0.         0.         0.         0.         0.36051008 1.
  1.         1.         0.        ]
 [1.         0.         1.         0.81376599 0.36122214 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.36222175 1.
  0.97747116 0.         1.        ]
 [1.         0.         1.         1.         0.36241522 1.
  0.80358934 0.48877293 1.        ]
 [1.         0.         1.         1.         0.36264283 1.
  0.77950109 0.         1.        ]
 [1.         1.         0.25110322 0.94355885 0.36216941 1.
  0.         0.33833264 1.        ]
 [1.         0.         0.32732266 0.49375729 0.36191223 1.
  1.         0.         1.        ]
 [1.         0.39724039 1.         0.76126238 0.36081616 1.
  1.         0.         1.        ]
 [1.         0.         1.         1.         0.36220859 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.36188872 1.
  0.42278785 0.93679886 1.        ]
 [0.         0.         0.23472918 0.         0.36324447 1.
  1.         0.         1.        ]
 [1.         1.         1.         1.         0.36130449 1.
  1.         0.98711214 1.        ]
 [1.         0.         1.         1.         0.36210339 1.
  1.         1.         1.        ]
 [1.         0.69338319 0.71230414 0.44441993 0.36064644 1.
  0.64706284 0.08774587 1.        ]
 [0.79529611 0.         1.         1.         0.36145523 1.
  1.         1.         1.        ]
 [1.         0.52831929 1.         1.         0.36198702 1.
  1.         0.02422473 1.        ]
 [1.         0.         0.         0.33212263 0.36116832 1.
  0.         0.         1.        ]
 [0.42737328 0.         0.13445571 0.         0.36233172 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.36241738 1.
  1.         0.         1.        ]
 [1.         0.         0.2156081  0.43318841 0.36076957 1.
  1.         0.21351309 1.        ]
 [1.         0.         0.99069841 1.         0.36219981 1.
  0.         0.         1.        ]
 [0.18840284 0.         0.         0.         0.36227242 1.
  0.95676972 0.         1.        ]
 [0.57013684 0.         0.         0.         0.36233144 1.
  0.         0.         1.        ]
 [1.         0.         0.1402978  0.80675052 0.36232704 1.
  0.         0.99487255 1.        ]
 [1.         0.         0.         0.4965224  0.36192289 1.
  0.         0.56868658 1.        ]
 [0.         0.         0.         0.         0.36202275 1.
  1.         0.         1.        ]
 [1.         0.         1.         1.         0.36234878 1.
  0.25107111 0.29938317 1.        ]]

Best Training Poisoning Accuracy:
0.75
#####################         POISON         ###############################################

############################################################################################

comm_round: 27 | global_test_acc: 66.667% | global_f1: 0.8 | global_precision: 0.6666666666666666
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         4
           1       0.67      1.00      0.80         8

    accuracy                           0.67        12
   macro avg       0.33      0.50      0.40        12
weighted avg       0.44      0.67      0.53        12

Accuracy per class:
[[8 0]
 [4 0]]
[1. 0.]
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[1.         1.         1.         1.         1.         0.
 1.         1.         1.         1.         0.         0.83190218
 1.         0.         1.         1.         0.         0.
 0.         1.         1.         1.         1.         0.39118462
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.        ]
wv_fg shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         1.         0.
 0.         0.         1.         0.         0.59725382 0.
 0.         0.         0.         0.07291987 0.         0.
 0.         0.78092771 0.         0.         0.42364951 0.
 1.         0.         0.22381823 0.         0.        ]
wv_mn shape (35,)
[0.         0.12403722 0.         0.         0.         0.
 0.57869872 0.87424374 0.         0.76126415 0.         1.
 1.         1.         0.79857144 1.         0.         1.
 1.         1.         0.69456478 1.         1.         0.96629251
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.41032175]
wv_ed shape (35,)
[0.         0.04226892 0.         0.         0.         0.
 0.56595636 0.8585149  0.         0.82542992 0.         1.
 0.67447668 1.         0.49209664 1.         0.         1.
 1.         1.         0.83333468 1.         1.         0.00643407
 1.         1.         1.         1.         0.77346781 1.
 1.         0.93742231 1.         0.96849888 0.75339814]
wv_lg shape (35, 1)
[[0.36167728]
 [0.3614134 ]
 [0.36106703]
 [0.36171795]
 [0.36112864]
 [0.36161581]
 [0.36150353]
 [0.36168783]
 [0.36177381]
 [0.36134668]
 [0.36402854]
 [0.36241007]
 [0.36238399]
 [0.36258515]
 [0.35999861]
 [0.36229578]
 [0.36250423]
 [0.36258976]
 [0.36292595]
 [0.36226468]
 [0.36237157]
 [0.36242658]
 [0.3631568 ]
 [0.36327319]
 [0.36318373]
 [0.36203786]
 [0.3624672 ]
 [0.36208075]
 [0.36355519]
 [0.36232927]
 [0.36277483]
 [0.36264961]
 [0.36169723]
 [0.36198319]
 [0.36175158]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.         0.37784252
 1.         0.96865254 0.         1.         0.         1.
 1.         1.         1.         0.39688461 1.         1.
 1.         0.         1.         0.49747636 1.         0.98916662
 0.         1.         0.         1.         0.7479374 ]
wv_std shape (35,)
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.         0.91917379
 0.         1.         1.         0.41955917 0.         1.
 1.         1.         0.         0.59410179 0.5528395  0.
 0.29219368 0.07395965 0.         0.99121518 0.         0.11381212
 0.9083862  0.         0.         0.         0.        ]
xy shape: (35, 9)
[[1.         0.         0.         0.         0.36167728 1.
  1.         1.         0.        ]
 [1.         0.         0.12403722 0.04226892 0.3614134  1.
  1.         1.         0.        ]
 [1.         0.         0.         0.         0.36106703 1.
  1.         1.         0.        ]
 [1.         0.         0.         0.         0.36171795 1.
  1.         1.         0.        ]
 [1.         0.         0.         0.         0.36112864 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.36161581 1.
  1.         1.         0.        ]
 [1.         0.         0.57869872 0.56595636 0.36150353 1.
  1.         1.         0.        ]
 [1.         0.         0.87424374 0.8585149  0.36168783 1.
  1.         1.         0.        ]
 [1.         0.         0.         0.         0.36177381 1.
  1.         1.         0.        ]
 [1.         0.         0.76126415 0.82542992 0.36134668 1.
  1.         1.         0.        ]
 [0.         1.         0.         0.         0.36402854 1.
  0.         0.         1.        ]
 [0.83190218 0.         1.         1.         0.36241007 1.
  0.37784252 0.91917379 1.        ]
 [1.         0.         1.         0.67447668 0.36238399 1.
  1.         0.         1.        ]
 [0.         0.         1.         1.         0.36258515 1.
  0.96865254 1.         1.        ]
 [1.         1.         0.79857144 0.49209664 0.35999861 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.36229578 1.
  1.         0.41955917 1.        ]
 [0.         0.59725382 0.         0.         0.36250423 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.36258976 1.
  1.         1.         1.        ]
 [0.         0.         1.         1.         0.36292595 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36226468 1.
  1.         1.         1.        ]
 [1.         0.         0.69456478 0.83333468 0.36237157 1.
  1.         0.         1.        ]
 [1.         0.07291987 1.         1.         0.36242658 1.
  0.39688461 0.59410179 1.        ]
 [1.         0.         1.         1.         0.3631568  1.
  1.         0.5528395  1.        ]
 [0.39118462 0.         0.96629251 0.00643407 0.36327319 1.
  1.         0.         1.        ]
 [1.         0.         1.         1.         0.36318373 1.
  1.         0.29219368 1.        ]
 [1.         0.78092771 1.         1.         0.36203786 1.
  0.         0.07395965 1.        ]
 [1.         0.         1.         1.         0.3624672  1.
  1.         0.         1.        ]
 [1.         0.         1.         1.         0.36208075 1.
  0.49747636 0.99121518 1.        ]
 [1.         0.42364951 1.         0.77346781 0.36355519 1.
  1.         0.         1.        ]
 [1.         0.         1.         1.         0.36232927 1.
  0.98916662 0.11381212 1.        ]
 [1.         1.         1.         1.         0.36277483 1.
  0.         0.9083862  1.        ]
 [1.         0.         1.         0.93742231 0.36264961 1.
  1.         0.         1.        ]
 [1.         0.22381823 1.         1.         0.36169723 1.
  0.         0.         1.        ]
 [1.         0.         1.         0.96849888 0.36198319 1.
  1.         0.         1.        ]
 [1.         0.         0.41032175 0.75339814 0.36175158 1.
  0.7479374  0.         1.        ]]

Best Training Poisoning Accuracy:
0.6875
#####################         POISON         ###############################################

############################################################################################

comm_round: 28 | global_test_acc: 75.000% | global_f1: 0.8571428571428571 | global_precision: 0.75
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.75      1.00      0.86         9

    accuracy                           0.75        12
   macro avg       0.38      0.50      0.43        12
weighted avg       0.56      0.75      0.64        12

Accuracy per class:
[[9 0]
 [3 0]]
[1. 0.]
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[1.         1.         1.         0.         1.         0.30594001
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         0.67265986 1.         0.         1.         1.
 1.         1.         1.         1.         1.        ]
wv_fg shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         1.         0.         0.55700833 0.34296124 0.
 0.         0.         0.05399102 1.         0.         0.
 0.         0.         0.         1.         0.         0.
 0.45420217 0.         0.         0.         0.        ]
wv_mn shape (35,)
[0.         1.         0.85658069 0.         0.         0.
 0.47547943 1.         1.         1.         0.91494538 0.
 1.         1.         1.         1.         1.         0.90863652
 0.84198973 0.83436521 1.         1.         1.         1.
 1.         0.         0.         0.         1.         0.56016828
 1.         1.         1.         1.         1.        ]
wv_ed shape (35,)
[0.         0.75981288 0.67135219 0.         0.         0.
 0.34037536 1.         0.81899381 0.98593174 0.61405397 0.
 1.         1.         1.         0.91268664 1.         0.92740527
 0.95409808 1.         1.         1.         1.         1.
 1.         0.         0.         0.         1.         0.8151889
 1.         1.         0.82718884 1.         1.        ]
wv_lg shape (35, 1)
[[0.36210439]
 [0.36220444]
 [0.36221052]
 [0.3623318 ]
 [0.36222565]
 [0.3616    ]
 [0.36225837]
 [0.36228324]
 [0.36200673]
 [0.3623838 ]
 [0.36242603]
 [0.36296189]
 [0.36351989]
 [0.3633659 ]
 [0.36277654]
 [0.36265771]
 [0.36386526]
 [0.36294853]
 [0.36240435]
 [0.36288799]
 [0.36302947]
 [0.36321821]
 [0.36287219]
 [0.36313741]
 [0.36362818]
 [0.36315148]
 [0.36244079]
 [0.36367893]
 [0.36267735]
 [0.36303956]
 [0.36279379]
 [0.36348755]
 [0.36236503]
 [0.36250891]
 [0.36250317]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[0.99044506 1.         1.         1.         1.         1.
 1.         0.89335442 1.         0.98195476 0.         0.48677099
 1.         0.34006426 0.9534261  1.         1.         0.
 0.66056637 0.         1.         0.75338828 0.14096524 0.53160959
 0.05947894 0.18109274 0.         0.         1.         0.32976578
 1.         0.396846   0.         0.10430713 0.        ]
wv_std shape (35,)
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.         0.
 0.08454241 1.         0.28975752 0.         0.         0.
 0.08556106 0.82479962 0.30424901 0.05629138 1.         0.08201935
 0.55677602 0.         0.         0.         0.         0.
 0.87022606 0.         0.         1.         1.        ]
xy shape: (35, 9)
[[1.         0.         0.         0.         0.36210439 1.
  0.99044506 1.         0.        ]
 [1.         0.         1.         0.75981288 0.36220444 1.
  1.         1.         0.        ]
 [1.         0.         0.85658069 0.67135219 0.36221052 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.3623318  1.
  1.         1.         0.        ]
 [1.         0.         0.         0.         0.36222565 1.
  1.         1.         0.        ]
 [0.30594001 0.         0.         0.         0.3616     1.
  1.         1.         0.        ]
 [1.         0.         0.47547943 0.34037536 0.36225837 1.
  1.         1.         0.        ]
 [1.         0.         1.         1.         0.36228324 1.
  0.89335442 1.         0.        ]
 [1.         0.         1.         0.81899381 0.36200673 1.
  1.         1.         0.        ]
 [1.         0.         1.         0.98593174 0.3623838  1.
  0.98195476 1.         0.        ]
 [1.         0.         0.91494538 0.61405397 0.36242603 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.36296189 1.
  0.48677099 0.         1.        ]
 [1.         0.         1.         1.         0.36351989 1.
  1.         0.08454241 1.        ]
 [1.         1.         1.         1.         0.3633659  1.
  0.34006426 1.         1.        ]
 [1.         0.         1.         1.         0.36277654 1.
  0.9534261  0.28975752 1.        ]
 [1.         0.55700833 1.         0.91268664 0.36265771 1.
  1.         0.         1.        ]
 [1.         0.34296124 1.         1.         0.36386526 1.
  1.         0.         1.        ]
 [1.         0.         0.90863652 0.92740527 0.36294853 1.
  0.         0.         1.        ]
 [1.         0.         0.84198973 0.95409808 0.36240435 1.
  0.66056637 0.08556106 1.        ]
 [1.         0.         0.83436521 1.         0.36288799 1.
  0.         0.82479962 1.        ]
 [1.         0.05399102 1.         1.         0.36302947 1.
  1.         0.30424901 1.        ]
 [1.         1.         1.         1.         0.36321821 1.
  0.75338828 0.05629138 1.        ]
 [1.         0.         1.         1.         0.36287219 1.
  0.14096524 1.         1.        ]
 [1.         0.         1.         1.         0.36313741 1.
  0.53160959 0.08201935 1.        ]
 [1.         0.         1.         1.         0.36362818 1.
  0.05947894 0.55677602 1.        ]
 [0.67265986 0.         0.         0.         0.36315148 1.
  0.18109274 0.         1.        ]
 [1.         0.         0.         0.         0.36244079 1.
  0.         0.         1.        ]
 [0.         1.         0.         0.         0.36367893 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.36267735 1.
  1.         0.         1.        ]
 [1.         0.         0.56016828 0.8151889  0.36303956 1.
  0.32976578 0.         1.        ]
 [1.         0.45420217 1.         1.         0.36279379 1.
  1.         0.87022606 1.        ]
 [1.         0.         1.         1.         0.36348755 1.
  0.396846   0.         1.        ]
 [1.         0.         1.         0.82718884 0.36236503 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.36250891 1.
  0.10430713 1.         1.        ]
 [1.         0.         1.         1.         0.36250317 1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.75
#####################         POISON         ###############################################

############################################################################################

comm_round: 29 | global_test_acc: 75.000% | global_f1: 0.8571428571428571 | global_precision: 0.75
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.75      1.00      0.86         9

    accuracy                           0.75        12
   macro avg       0.38      0.50      0.43        12
weighted avg       0.56      0.75      0.64        12

Accuracy per class:
[[9 0]
 [3 0]]
[1. 0.]
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 0. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1.]
wv_fg shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         1.         1.         0.         0.         0.
 0.         0.         0.         1.         1.         0.
 0.         1.         1.         0.         0.         0.
 0.91728936 0.         0.         0.06424401 0.        ]
wv_mn shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.16592658
 0.         0.         1.         0.91174542 0.         0.
 0.71603281 0.37687684 1.         0.19609459 1.         0.53203086
 0.         0.         0.51276319 1.         1.         1.
 0.57056057 0.51707731 0.         0.64392431 0.43220994]
wv_ed shape (35,)
[0.         0.         0.04016617 0.         0.         0.
 0.         0.         0.         0.         0.         0.58239876
 0.         0.40458164 1.         0.97414097 0.20092343 0.42199169
 1.         0.         1.         1.         1.         1.
 0.         0.         0.22909194 1.         1.         1.
 1.         0.38866433 0.         1.         1.        ]
wv_lg shape (35, 1)
[[0.25498104]
 [0.25498486]
 [0.25499483]
 [0.25499813]
 [0.2549869 ]
 [0.25499243]
 [0.25499898]
 [0.25499922]
 [0.25499904]
 [0.25499423]
 [0.25556228]
 [0.25551991]
 [0.25554702]
 [0.25552507]
 [0.25554836]
 [0.25554762]
 [0.25550616]
 [0.25554367]
 [0.25548276]
 [0.25559815]
 [0.25556124]
 [0.25551438]
 [0.25557541]
 [0.25552564]
 [0.25552269]
 [0.25560986]
 [0.25558278]
 [0.2555208 ]
 [0.25547578]
 [0.25561524]
 [0.25558546]
 [0.2555134 ]
 [0.25555517]
 [0.25550983]
 [0.25549202]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         0.50577907
 0.38865987 0.         1.         0.29917852 0.92388104 0.00757796
 0.3616323  1.         0.71302295 0.         0.64884933 0.45682658
 0.60420194 0.         0.59677163 0.59064821 0.04170163 1.
 0.         0.0077046  0.69935573 0.3237337  0.        ]
wv_std shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
xy shape: (35, 9)
[[0.         0.         0.         0.         0.25498104 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.25498486 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.04016617 0.25499483 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.25499813 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.2549869  1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.25499243 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.25499898 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.25499922 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.25499904 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.25499423 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.25556228 1.
  1.         0.         1.        ]
 [1.         0.         0.16592658 0.58239876 0.25551991 1.
  0.50577907 0.         1.        ]
 [0.         0.         0.         0.         0.25554702 1.
  0.38865987 0.         1.        ]
 [1.         1.         0.         0.40458164 0.25552507 1.
  0.         0.         1.        ]
 [1.         1.         1.         1.         0.25554836 1.
  1.         0.         1.        ]
 [1.         0.         0.91174542 0.97414097 0.25554762 1.
  0.29917852 0.         1.        ]
 [1.         0.         0.         0.20092343 0.25550616 1.
  0.92388104 0.         1.        ]
 [1.         0.         0.         0.42199169 0.25554367 1.
  0.00757796 0.         1.        ]
 [1.         0.         0.71603281 1.         0.25548276 1.
  0.3616323  0.         1.        ]
 [1.         0.         0.37687684 0.         0.25559815 1.
  1.         0.         1.        ]
 [1.         0.         1.         1.         0.25556124 1.
  0.71302295 0.         1.        ]
 [1.         1.         0.19609459 1.         0.25551438 1.
  0.         0.         1.        ]
 [1.         1.         1.         1.         0.25557541 1.
  0.64884933 0.         1.        ]
 [1.         0.         0.53203086 1.         0.25552564 1.
  0.45682658 0.         1.        ]
 [0.         0.         0.         0.         0.25552269 1.
  0.60420194 0.         1.        ]
 [0.         1.         0.         0.         0.25560986 1.
  0.         0.         1.        ]
 [1.         1.         0.51276319 0.22909194 0.25558278 1.
  0.59677163 0.         1.        ]
 [1.         0.         1.         1.         0.2555208  1.
  0.59064821 0.         1.        ]
 [1.         0.         1.         1.         0.25547578 1.
  0.04170163 0.         1.        ]
 [1.         0.         1.         1.         0.25561524 1.
  1.         0.         1.        ]
 [1.         0.91728936 0.57056057 1.         0.25558546 1.
  0.         0.         1.        ]
 [1.         0.         0.51707731 0.38866433 0.2555134  1.
  0.0077046  0.         1.        ]
 [0.         0.         0.         0.         0.25555517 1.
  0.69935573 0.         1.        ]
 [1.         0.06424401 0.64392431 1.         0.25550983 1.
  0.3237337  0.         1.        ]
 [1.         0.         0.43220994 1.         0.25549202 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.6499999761581421
#####################         POISON         ###############################################

############################################################################################

comm_round: 0 | global_test_acc: 75.000% | global_f1: 0.8571428571428571 | global_precision: 0.75
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.75      1.00      0.86         9

    accuracy                           0.75        12
   macro avg       0.38      0.50      0.43        12
weighted avg       0.56      0.75      0.64        12
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1.]
wv_fg shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         1.         0.
 0.         0.         0.         0.03931674 0.         0.
 0.         0.         0.         0.41040585 1.         0.
 0.         0.         0.49895064 0.         0.        ]
wv_mn shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.02604643 0.
 0.         1.         1.         0.         0.         0.02108774
 0.         0.         0.         0.83453002 0.         1.
 0.95638564 0.98731577 1.         1.         1.         1.
 0.31468209 1.         0.61551137 0.08256821 0.75347823]
wv_ed shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.12356113 0.
 0.         0.82590116 1.         0.         0.         0.
 0.         0.         0.         0.08017969 0.         0.88012725
 0.78905765 0.82082379 0.32034083 1.         0.88169878 1.
 0.         1.         0.23471712 0.         0.44828376]
wv_lg shape (35, 1)
[[0.25537584]
 [0.25536195]
 [0.25537978]
 [0.25536733]
 [0.2553934 ]
 [0.25538165]
 [0.25538058]
 [0.2553843 ]
 [0.25538137]
 [0.25538822]
 [0.25598665]
 [0.25589165]
 [0.25588898]
 [0.25593942]
 [0.25584996]
 [0.25594516]
 [0.25603788]
 [0.25597635]
 [0.25594956]
 [0.25595869]
 [0.25591598]
 [0.25594956]
 [0.25591601]
 [0.25598358]
 [0.25591608]
 [0.25595317]
 [0.25596165]
 [0.25595796]
 [0.25596086]
 [0.25598104]
 [0.2559796 ]
 [0.25594421]
 [0.25587277]
 [0.25601585]
 [0.25591482]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.33615015 0.
 0.         0.         0.         0.         0.1182143  1.
 1.         0.13166042 0.58745093 0.01413189 0.         1.
 0.05709132 0.         0.38438835 0.         1.         0.28303999
 0.66706096 0.         0.43618696 0.67848099 0.90784234]
wv_std shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
xy shape: (35, 9)
[[0.         0.         0.         0.         0.25537584 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.25536195 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.25537978 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.25536733 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.2553934  1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.25538165 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.25538058 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.2553843  1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.25538137 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.25538822 1.
  1.         1.         0.        ]
 [1.         0.         0.02604643 0.12356113 0.25598665 1.
  0.33615015 0.         1.        ]
 [0.         0.         0.         0.         0.25589165 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.25588898 1.
  0.         0.         1.        ]
 [1.         0.         1.         0.82590116 0.25593942 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.25584996 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.25594516 1.
  0.         0.         1.        ]
 [0.         1.         0.         0.         0.25603788 1.
  0.1182143  0.         1.        ]
 [1.         0.         0.02108774 0.         0.25597635 1.
  1.         0.         1.        ]
 [0.         0.         0.         0.         0.25594956 1.
  1.         0.         1.        ]
 [0.         0.         0.         0.         0.25595869 1.
  0.13166042 0.         1.        ]
 [0.         0.         0.         0.         0.25591598 1.
  0.58745093 0.         1.        ]
 [1.         0.03931674 0.83453002 0.08017969 0.25594956 1.
  0.01413189 0.         1.        ]
 [1.         0.         0.         0.         0.25591601 1.
  0.         0.         1.        ]
 [1.         0.         1.         0.88012725 0.25598358 1.
  1.         0.         1.        ]
 [1.         0.         0.95638564 0.78905765 0.25591608 1.
  0.05709132 0.         1.        ]
 [1.         0.         0.98731577 0.82082379 0.25595317 1.
  0.         0.         1.        ]
 [1.         0.         1.         0.32034083 0.25596165 1.
  0.38438835 0.         1.        ]
 [1.         0.41040585 1.         1.         0.25595796 1.
  0.         0.         1.        ]
 [1.         1.         1.         0.88169878 0.25596086 1.
  1.         0.         1.        ]
 [1.         0.         1.         1.         0.25598104 1.
  0.28303999 0.         1.        ]
 [0.         0.         0.31468209 0.         0.2559796  1.
  0.66706096 0.         1.        ]
 [1.         0.         1.         1.         0.25594421 1.
  0.         0.         1.        ]
 [1.         0.49895064 0.61551137 0.23471712 0.25587277 1.
  0.43618696 0.         1.        ]
 [0.         0.         0.08256821 0.         0.25601585 1.
  0.67848099 0.         1.        ]
 [1.         0.         0.75347823 0.44828376 0.25591482 1.
  0.90784234 0.         1.        ]]

Best Training Poisoning Accuracy:
0.8500000238418579
#####################         POISON         ###############################################

############################################################################################

comm_round: 1 | global_test_acc: 58.333% | global_f1: 0.7368421052631579 | global_precision: 0.5833333333333334
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         5
           1       0.58      1.00      0.74         7

    accuracy                           0.58        12
   macro avg       0.29      0.50      0.37        12
weighted avg       0.34      0.58      0.43        12
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1.
 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1.]
wv_fg shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.35827885
 1.         0.         0.         0.         0.         0.
 0.         0.23263398 0.0785273  0.         0.21622238 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.24941482]
wv_mn shape (35,)
[0.         0.         0.         0.         0.         0.
 0.18891797 0.23956218 0.         0.15420625 0.         0.
 1.         0.         0.32012774 0.         0.57197344 0.79822472
 0.18279493 0.         0.0246328  1.         0.32108553 1.
 0.         0.         0.3690809  1.         1.         0.97059827
 1.         1.         1.         0.         1.        ]
wv_ed shape (35,)
[0.         0.         0.         0.         0.         0.
 0.27371554 0.14798415 0.         0.10990267 0.33951173 0.
 1.         0.         0.37275775 0.         0.54664775 1.
 0.03910399 0.         0.69094366 1.         0.         1.
 0.         0.         0.29134096 1.         1.         1.
 1.         0.48347944 1.         0.         1.        ]
wv_lg shape (35, 1)
[[0.25576773]
 [0.25578159]
 [0.25577993]
 [0.25576035]
 [0.25575887]
 [0.25576699]
 [0.25578757]
 [0.25577514]
 [0.25577013]
 [0.25578964]
 [0.25629756]
 [0.25629211]
 [0.25632906]
 [0.25638083]
 [0.25632958]
 [0.25635788]
 [0.25632213]
 [0.25634736]
 [0.25630327]
 [0.25626361]
 [0.25630537]
 [0.25639995]
 [0.25636076]
 [0.2563365 ]
 [0.25637227]
 [0.25633928]
 [0.25628744]
 [0.25635749]
 [0.25637783]
 [0.25633249]
 [0.25637451]
 [0.25640756]
 [0.25636735]
 [0.25641149]
 [0.25626985]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         0.
 1.         0.         1.         1.         0.00429533 0.
 1.         0.         0.         0.         0.93381118 1.
 1.         1.         0.1377962  1.         1.         0.
 1.         0.92185073 1.         0.         1.        ]
wv_std shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
xy shape: (35, 9)
[[0.         0.         0.         0.         0.25576773 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.25578159 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.25577993 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.25576035 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.25575887 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.25576699 1.
  1.         1.         0.        ]
 [0.         0.         0.18891797 0.27371554 0.25578757 1.
  1.         1.         0.        ]
 [0.         0.         0.23956218 0.14798415 0.25577514 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.25577013 1.
  1.         1.         0.        ]
 [0.         0.         0.15420625 0.10990267 0.25578964 1.
  1.         1.         0.        ]
 [1.         0.         0.         0.33951173 0.25629756 1.
  1.         0.         1.        ]
 [0.         0.35827885 0.         0.         0.25629211 1.
  0.         0.         1.        ]
 [1.         1.         1.         1.         0.25632906 1.
  1.         0.         1.        ]
 [0.         0.         0.         0.         0.25638083 1.
  0.         0.         1.        ]
 [1.         0.         0.32012774 0.37275775 0.25632958 1.
  1.         0.         1.        ]
 [0.         0.         0.         0.         0.25635788 1.
  1.         0.         1.        ]
 [1.         0.         0.57197344 0.54664775 0.25632213 1.
  0.00429533 0.         1.        ]
 [1.         0.         0.79822472 1.         0.25634736 1.
  0.         0.         1.        ]
 [0.         0.         0.18279493 0.03910399 0.25630327 1.
  1.         0.         1.        ]
 [0.         0.23263398 0.         0.         0.25626361 1.
  0.         0.         1.        ]
 [1.         0.0785273  0.0246328  0.69094366 0.25630537 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.25639995 1.
  0.         0.         1.        ]
 [0.         0.21622238 0.32108553 0.         0.25636076 1.
  0.93381118 0.         1.        ]
 [1.         0.         1.         1.         0.2563365  1.
  1.         0.         1.        ]
 [0.         0.         0.         0.         0.25637227 1.
  1.         0.         1.        ]
 [0.         0.         0.         0.         0.25633928 1.
  1.         0.         1.        ]
 [1.         0.         0.3690809  0.29134096 0.25628744 1.
  0.1377962  0.         1.        ]
 [1.         0.         1.         1.         0.25635749 1.
  1.         0.         1.        ]
 [1.         0.         1.         1.         0.25637783 1.
  1.         0.         1.        ]
 [1.         0.         0.97059827 1.         0.25633249 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.25637451 1.
  1.         0.         1.        ]
 [1.         0.         1.         0.48347944 0.25640756 1.
  0.92185073 0.         1.        ]
 [1.         0.         1.         1.         0.25636735 1.
  1.         0.         1.        ]
 [0.         0.         0.         0.         0.25641149 1.
  0.         0.         1.        ]
 [1.         0.24941482 1.         1.         0.25626985 1.
  1.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.6499999761581421
#####################         POISON         ###############################################

############################################################################################

comm_round: 2 | global_test_acc: 83.333% | global_f1: 0.9090909090909091 | global_precision: 0.8333333333333334
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.83      1.00      0.91        10

    accuracy                           0.83        12
   macro avg       0.42      0.50      0.45        12
weighted avg       0.69      0.83      0.76        12
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0.
 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1.]
wv_fg shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         1.         0.         0.
 0.         1.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         1.
 0.         0.         0.         0.         0.84676421]
wv_mn shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.12505177 0.         0.         0.         0.47402818
 1.         0.         0.34181888 0.         0.         0.
 0.83836035 0.         0.14878693 0.09219974 0.         0.
 1.         0.81894375 1.         0.17048537 0.96102005 0.
 1.         0.70218403 1.         0.39034904 1.        ]
wv_ed shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.09609843 0.         0.         0.65797994 0.23586088
 1.         0.         0.4356701  0.         0.         0.
 0.6893337  0.         0.37007256 0.0225804  0.         0.
 1.         0.90197809 1.         0.59151331 0.59167558 0.
 1.         0.65125082 1.         0.45471065 1.        ]
wv_lg shape (35, 1)
[[0.25615934]
 [0.25617581]
 [0.25617546]
 [0.25618369]
 [0.25616924]
 [0.2561653 ]
 [0.25617916]
 [0.25618188]
 [0.25617306]
 [0.25616334]
 [0.25672698]
 [0.25680824]
 [0.25676193]
 [0.25682087]
 [0.25679721]
 [0.25676288]
 [0.25680611]
 [0.25682617]
 [0.25673905]
 [0.2567474 ]
 [0.25675424]
 [0.25671839]
 [0.25678614]
 [0.25675938]
 [0.25674711]
 [0.25673765]
 [0.25675187]
 [0.25676547]
 [0.2567389 ]
 [0.25670378]
 [0.25671588]
 [0.25679625]
 [0.2567998 ]
 [0.25678499]
 [0.25665616]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.         0.90211176
 1.         0.         0.89329928 1.         0.28861529 0.
 0.         0.00269711 0.76859353 0.1011202  0.         0.
 0.86618559 0.61304181 0.08123549 0.16672747 1.         0.
 1.         0.4663924  1.         0.         0.22914231]
wv_std shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
xy shape: (35, 9)
[[0.         0.         0.         0.         0.25615934 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.25617581 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.25617546 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.25618369 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.25616924 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.2561653  1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.25617916 1.
  1.         1.         0.        ]
 [0.         0.         0.12505177 0.09609843 0.25618188 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.25617306 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.25616334 1.
  1.         1.         0.        ]
 [1.         0.         0.         0.65797994 0.25672698 1.
  0.         0.         1.        ]
 [1.         0.         0.47402818 0.23586088 0.25680824 1.
  0.90211176 0.         1.        ]
 [1.         0.         1.         1.         0.25676193 1.
  1.         0.         1.        ]
 [0.         0.         0.         0.         0.25682087 1.
  0.         0.         1.        ]
 [1.         0.         0.34181888 0.4356701  0.25679721 1.
  0.89329928 0.         1.        ]
 [0.         1.         0.         0.         0.25676288 1.
  1.         0.         1.        ]
 [0.         0.         0.         0.         0.25680611 1.
  0.28861529 0.         1.        ]
 [0.         0.         0.         0.         0.25682617 1.
  0.         0.         1.        ]
 [1.         0.         0.83836035 0.6893337  0.25673905 1.
  0.         0.         1.        ]
 [0.         1.         0.         0.         0.2567474  1.
  0.00269711 0.         1.        ]
 [1.         0.         0.14878693 0.37007256 0.25675424 1.
  0.76859353 0.         1.        ]
 [0.         0.         0.09219974 0.0225804  0.25671839 1.
  0.1011202  0.         1.        ]
 [0.         0.         0.         0.         0.25678614 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.25675938 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.25674711 1.
  0.86618559 0.         1.        ]
 [1.         0.         0.81894375 0.90197809 0.25673765 1.
  0.61304181 0.         1.        ]
 [1.         0.         1.         1.         0.25675187 1.
  0.08123549 0.         1.        ]
 [1.         0.         0.17048537 0.59151331 0.25676547 1.
  0.16672747 0.         1.        ]
 [1.         0.         0.96102005 0.59167558 0.2567389  1.
  1.         0.         1.        ]
 [0.         1.         0.         0.         0.25670378 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.25671588 1.
  1.         0.         1.        ]
 [1.         0.         0.70218403 0.65125082 0.25679625 1.
  0.4663924  0.         1.        ]
 [1.         0.         1.         1.         0.2567998  1.
  1.         0.         1.        ]
 [1.         0.         0.39034904 0.45471065 0.25678499 1.
  0.         0.         1.        ]
 [1.         0.84676421 1.         1.         0.25665616 1.
  0.22914231 0.         1.        ]]

Best Training Poisoning Accuracy:
0.75
#####################         POISON         ###############################################

############################################################################################

comm_round: 3 | global_test_acc: 66.667% | global_f1: 0.8 | global_precision: 0.6666666666666666
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         4
           1       0.67      1.00      0.80         8

    accuracy                           0.67        12
   macro avg       0.33      0.50      0.40        12
weighted avg       0.44      0.67      0.53        12
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_fg shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.08017768
 0.         0.         0.         0.         1.         0.
 1.         0.         0.         0.         0.         0.
 1.         1.         0.         0.         0.         0.
 0.         0.         0.78086361 0.27803935 0.        ]
wv_mn shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.38247053 0.
 0.         0.24196858 1.         1.         0.         0.8414593
 0.         1.         0.72105133 1.         1.         0.
 0.         0.         1.         1.         0.86117712 1.
 1.         0.62079764 0.         0.         0.67853278]
wv_ed shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.66431913 0.
 0.         0.         1.         1.         0.         1.
 0.         0.83072926 0.         1.         1.         0.
 0.06675863 0.         1.         1.         0.00773546 0.65234785
 1.         0.70365113 0.         0.02359696 0.        ]
wv_lg shape (35, 1)
[[0.25658699]
 [0.25655305]
 [0.2565537 ]
 [0.25658119]
 [0.25656392]
 [0.25660166]
 [0.25658916]
 [0.2565981 ]
 [0.25657916]
 [0.25659094]
 [0.25717668]
 [0.25722857]
 [0.25718776]
 [0.25716554]
 [0.2571545 ]
 [0.25717512]
 [0.25726989]
 [0.25710515]
 [0.25715168]
 [0.25719614]
 [0.25719854]
 [0.25709642]
 [0.25720177]
 [0.25716353]
 [0.2571906 ]
 [0.25724113]
 [0.25716779]
 [0.25711975]
 [0.25723395]
 [0.25718653]
 [0.25712662]
 [0.25718398]
 [0.25719462]
 [0.25722896]
 [0.25726082]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.         0.
 0.         0.89960139 0.59713297 0.37003918 1.         0.
 0.         0.81891557 1.         0.         0.16302072 0.51166508
 0.15732236 0.09698844 0.         0.38327117 1.         0.97182308
 0.         0.         0.         0.         1.        ]
wv_std shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
xy shape: (35, 9)
[[0.         0.         0.         0.         0.25658699 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.25655305 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.2565537  1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.25658119 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.25656392 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.25660166 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.25658916 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.2565981  1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.25657916 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.25659094 1.
  1.         1.         0.        ]
 [1.         0.         0.38247053 0.66431913 0.25717668 1.
  0.         0.         1.        ]
 [0.         0.08017768 0.         0.         0.25722857 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.25718776 1.
  0.         0.         1.        ]
 [0.         0.         0.24196858 0.         0.25716554 1.
  0.89960139 0.         1.        ]
 [1.         0.         1.         1.         0.2571545  1.
  0.59713297 0.         1.        ]
 [1.         0.         1.         1.         0.25717512 1.
  0.37003918 0.         1.        ]
 [0.         1.         0.         0.         0.25726989 1.
  1.         0.         1.        ]
 [1.         0.         0.8414593  1.         0.25710515 1.
  0.         0.         1.        ]
 [0.         1.         0.         0.         0.25715168 1.
  0.         0.         1.        ]
 [1.         0.         1.         0.83072926 0.25719614 1.
  0.81891557 0.         1.        ]
 [1.         0.         0.72105133 0.         0.25719854 1.
  1.         0.         1.        ]
 [1.         0.         1.         1.         0.25709642 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.25720177 1.
  0.16302072 0.         1.        ]
 [0.         0.         0.         0.         0.25716353 1.
  0.51166508 0.         1.        ]
 [1.         1.         0.         0.06675863 0.2571906  1.
  0.15732236 0.         1.        ]
 [1.         1.         0.         0.         0.25724113 1.
  0.09698844 0.         1.        ]
 [1.         0.         1.         1.         0.25716779 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.25711975 1.
  0.38327117 0.         1.        ]
 [1.         0.         0.86117712 0.00773546 0.25723395 1.
  1.         0.         1.        ]
 [1.         0.         1.         0.65234785 0.25718653 1.
  0.97182308 0.         1.        ]
 [1.         0.         1.         1.         0.25712662 1.
  0.         0.         1.        ]
 [1.         0.         0.62079764 0.70365113 0.25718398 1.
  0.         0.         1.        ]
 [1.         0.78086361 0.         0.         0.25719462 1.
  0.         0.         1.        ]
 [1.         0.27803935 0.         0.02359696 0.25722896 1.
  0.         0.         1.        ]
 [1.         0.         0.67853278 0.         0.25726082 1.
  1.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.75
#####################         POISON         ###############################################

############################################################################################

comm_round: 4 | global_test_acc: 66.667% | global_f1: 0.8 | global_precision: 0.6666666666666666
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         4
           1       0.67      1.00      0.80         8

    accuracy                           0.67        12
   macro avg       0.33      0.50      0.40        12
weighted avg       0.44      0.67      0.53        12
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_fg shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         1.         1.         0.
 1.         0.         0.87481029 1.         0.         0.
 0.         0.         0.22290975 1.         0.         1.
 0.         0.54819991 0.         0.         0.8088971 ]
wv_mn shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.4140365  1.         0.         0.         0.66605159 0.
 0.67948418 1.         0.         0.33841577 0.72686413 1.
 0.63915896 0.         0.77640328 1.         1.         0.77066866
 0.9776788  0.         0.64546914 1.         0.0583945 ]
wv_ed shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 1.         1.         0.         0.         0.52811966 0.
 1.         1.         0.06723939 0.79216077 1.         1.
 0.49637037 0.11986998 0.95626674 1.         1.         0.50249033
 1.         0.24686686 0.56406381 1.         0.61131039]
wv_lg shape (35, 1)
[[0.25701429]
 [0.25700213]
 [0.25700803]
 [0.25697671]
 [0.25697113]
 [0.25695105]
 [0.25698884]
 [0.25702067]
 [0.25698028]
 [0.25700161]
 [0.25761438]
 [0.25761953]
 [0.25755699]
 [0.25762814]
 [0.25761915]
 [0.25766605]
 [0.25764146]
 [0.2575575 ]
 [0.25749491]
 [0.2575788 ]
 [0.25765496]
 [0.25763119]
 [0.25757417]
 [0.25755057]
 [0.25761898]
 [0.25761348]
 [0.25760159]
 [0.25765362]
 [0.25763202]
 [0.25772965]
 [0.25754709]
 [0.25765018]
 [0.25765418]
 [0.25756933]
 [0.25758491]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[1.         0.76376747 0.77367468 0.99394839 1.         0.8239203
 0.93291715 0.87915368 0.7263709  0.9274595  0.         1.
 0.         0.         0.         0.44486332 0.79430782 0.
 0.         0.         0.         0.         0.         0.
 0.37016788 0.         0.         0.         0.         0.
 0.         0.         0.12148506 0.         0.        ]
wv_std shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
xy shape: (35, 9)
[[0.         0.         0.         0.         0.25701429 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.25700213 1.
  0.76376747 1.         0.        ]
 [0.         0.         0.         0.         0.25700803 1.
  0.77367468 1.         0.        ]
 [0.         0.         0.         0.         0.25697671 1.
  0.99394839 1.         0.        ]
 [0.         0.         0.         0.         0.25697113 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.25695105 1.
  0.8239203  1.         0.        ]
 [0.         0.         0.         0.         0.25698884 1.
  0.93291715 1.         0.        ]
 [0.         0.         0.         0.         0.25702067 1.
  0.87915368 1.         0.        ]
 [0.         0.         0.         0.         0.25698028 1.
  0.7263709  1.         0.        ]
 [0.         0.         0.         0.         0.25700161 1.
  0.9274595  1.         0.        ]
 [0.         0.         0.         0.         0.25761438 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.25761953 1.
  1.         0.         1.        ]
 [1.         0.         0.4140365  1.         0.25755699 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.25762814 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.25761915 1.
  0.         0.         1.        ]
 [0.         1.         0.         0.         0.25766605 1.
  0.44486332 0.         1.        ]
 [1.         1.         0.66605159 0.52811966 0.25764146 1.
  0.79430782 0.         1.        ]
 [0.         0.         0.         0.         0.2575575  1.
  0.         0.         1.        ]
 [1.         1.         0.67948418 1.         0.25749491 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.2575788  1.
  0.         0.         1.        ]
 [1.         0.87481029 0.         0.06723939 0.25765496 1.
  0.         0.         1.        ]
 [1.         1.         0.33841577 0.79216077 0.25763119 1.
  0.         0.         1.        ]
 [1.         0.         0.72686413 1.         0.25757417 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.25755057 1.
  0.         0.         1.        ]
 [1.         0.         0.63915896 0.49637037 0.25761898 1.
  0.37016788 0.         1.        ]
 [1.         0.         0.         0.11986998 0.25761348 1.
  0.         0.         1.        ]
 [1.         0.22290975 0.77640328 0.95626674 0.25760159 1.
  0.         0.         1.        ]
 [1.         1.         1.         1.         0.25765362 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.25763202 1.
  0.         0.         1.        ]
 [1.         1.         0.77066866 0.50249033 0.25772965 1.
  0.         0.         1.        ]
 [1.         0.         0.9776788  1.         0.25754709 1.
  0.         0.         1.        ]
 [1.         0.54819991 0.         0.24686686 0.25765018 1.
  0.         0.         1.        ]
 [1.         0.         0.64546914 0.56406381 0.25765418 1.
  0.12148506 0.         1.        ]
 [1.         0.         1.         1.         0.25756933 1.
  0.         0.         1.        ]
 [1.         0.8088971  0.0583945  0.61131039 0.25758491 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.800000011920929
#####################         POISON         ###############################################

############################################################################################

comm_round: 5 | global_test_acc: 58.333% | global_f1: 0.7368421052631579 | global_precision: 0.5833333333333334
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         5
           1       0.58      1.00      0.74         7

    accuracy                           0.58        12
   macro avg       0.29      0.50      0.37        12
weighted avg       0.34      0.58      0.43        12
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 0.
 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1.]
wv_fg shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.84211449 1.
 0.         0.         0.         0.21964658 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.94816743 0.         0.
 0.         0.         0.         0.         0.        ]
wv_mn shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.34859256
 0.         0.26823774 0.         0.         0.         0.
 0.94538707 0.52852549 0.         0.         0.055893   0.
 0.         0.44467618 0.51863778 1.         1.         0.
 1.         0.         0.         1.         0.93058608]
wv_ed shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.19578251
 0.         0.3843546  0.26999276 0.47503263 0.         0.
 1.         1.         0.         0.         0.52354602 0.
 0.         0.24741501 0.05016935 1.         1.         0.02143092
 1.         0.         0.         0.90839047 0.95378289]
wv_lg shape (35, 1)
[[0.25741756]
 [0.25740957]
 [0.25743731]
 [0.25740342]
 [0.25742574]
 [0.25742827]
 [0.2574293 ]
 [0.25743844]
 [0.25742135]
 [0.25742607]
 [0.25814993]
 [0.25814696]
 [0.25811232]
 [0.25804119]
 [0.25803378]
 [0.25803272]
 [0.25809979]
 [0.25805443]
 [0.2579934 ]
 [0.25801226]
 [0.25810187]
 [0.25808115]
 [0.2579928 ]
 [0.25806238]
 [0.25808694]
 [0.25808059]
 [0.25808341]
 [0.25800935]
 [0.25803287]
 [0.25804917]
 [0.25805207]
 [0.25803205]
 [0.25808337]
 [0.2580174 ]
 [0.25807111]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.         1.
 0.86504922 1.         0.         0.         0.         1.
 0.         0.         0.22243876 0.74676617 0.         0.
 0.         0.26677096 1.         0.         1.         0.
 0.39801619 0.         0.93346404 0.         1.        ]
wv_std shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
xy shape: (35, 9)
[[0.         0.         0.         0.         0.25741756 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.25740957 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.25743731 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.25740342 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.25742574 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.25742827 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.2574293  1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.25743844 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.25742135 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.25742607 1.
  1.         1.         0.        ]
 [0.         0.84211449 0.         0.         0.25814993 1.
  0.         0.         1.        ]
 [1.         1.         0.34859256 0.19578251 0.25814696 1.
  1.         0.         1.        ]
 [0.         0.         0.         0.         0.25811232 1.
  0.86504922 0.         1.        ]
 [1.         0.         0.26823774 0.3843546  0.25804119 1.
  1.         0.         1.        ]
 [1.         0.         0.         0.26999276 0.25803378 1.
  0.         0.         1.        ]
 [1.         0.21964658 0.         0.47503263 0.25803272 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.25809979 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.25805443 1.
  1.         0.         1.        ]
 [1.         0.         0.94538707 1.         0.2579934  1.
  0.         0.         1.        ]
 [1.         0.         0.52852549 1.         0.25801226 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.25810187 1.
  0.22243876 0.         1.        ]
 [0.         0.         0.         0.         0.25808115 1.
  0.74676617 0.         1.        ]
 [1.         0.         0.055893   0.52354602 0.2579928  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.25806238 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.25808694 1.
  0.         0.         1.        ]
 [1.         0.         0.44467618 0.24741501 0.25808059 1.
  0.26677096 0.         1.        ]
 [1.         0.         0.51863778 0.05016935 0.25808341 1.
  1.         0.         1.        ]
 [1.         0.94816743 1.         1.         0.25800935 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.25803287 1.
  1.         0.         1.        ]
 [1.         0.         0.         0.02143092 0.25804917 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.25805207 1.
  0.39801619 0.         1.        ]
 [0.         0.         0.         0.         0.25803205 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.25808337 1.
  0.93346404 0.         1.        ]
 [1.         0.         1.         0.90839047 0.2580174  1.
  0.         0.         1.        ]
 [1.         0.         0.93058608 0.95378289 0.25807111 1.
  1.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.75
#####################         POISON         ###############################################

############################################################################################

comm_round: 6 | global_test_acc: 75.000% | global_f1: 0.8571428571428571 | global_precision: 0.75
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.75      1.00      0.86         9

    accuracy                           0.75        12
   macro avg       0.38      0.50      0.43        12
weighted avg       0.56      0.75      0.64        12
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 1. 0. 1. 1. 1.
 0. 1. 1. 0. 0. 1. 1. 1. 1. 0. 1.]
wv_fg shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 1.         0.96515273 0.         1.         0.         0.
 0.76990563 0.         0.         0.20771846 0.         0.
 0.         0.         0.05844994 0.         0.         0.
 0.         0.         0.         0.         1.        ]
wv_mn shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.67494155 0.         0.         0.76969029 0.89686916
 0.         0.         0.         0.34662407 1.         1.
 1.         0.95746279 0.         0.         0.         1.
 0.         1.         0.77475015 0.04258184 0.         1.
 1.         0.96738118 1.         0.         1.        ]
wv_ed shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.50153819 0.         0.         0.8623064  0.96131033
 0.         0.         0.         1.         1.         1.
 0.46095806 0.80610126 0.22832037 0.74187385 0.75645524 1.
 0.33077488 1.         0.54899381 0.23961398 0.16195522 1.
 1.         0.73356476 1.         0.10041335 0.54758891]
wv_lg shape (35, 1)
[[0.25785983]
 [0.25786958]
 [0.25788203]
 [0.25786667]
 [0.25787581]
 [0.25785577]
 [0.25787641]
 [0.25788018]
 [0.25786276]
 [0.25786241]
 [0.25849667]
 [0.25857723]
 [0.25840309]
 [0.25852683]
 [0.25847449]
 [0.25847048]
 [0.25850793]
 [0.25843286]
 [0.25852433]
 [0.25845301]
 [0.25847952]
 [0.25846042]
 [0.25847733]
 [0.258473  ]
 [0.25848654]
 [0.25849111]
 [0.25847505]
 [0.25848867]
 [0.25853189]
 [0.25847532]
 [0.25852727]
 [0.25843765]
 [0.25849457]
 [0.25842638]
 [0.25853493]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[1.         0.7029226  0.84194239 1.         0.92304856 1.
 1.         0.77285685 1.         0.76616965 0.         0.42717307
 0.         0.448952   0.         0.         0.55557084 0.15333766
 0.42749341 0.61202714 0.         0.         0.         0.
 0.24654268 0.         0.         0.15453936 0.         0.37689573
 0.02714264 0.25959682 0.         0.         1.        ]
wv_std shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
xy shape: (35, 9)
[[0.         0.         0.         0.         0.25785983 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.25786958 1.
  0.7029226  1.         0.        ]
 [0.         0.         0.         0.         0.25788203 1.
  0.84194239 1.         0.        ]
 [0.         0.         0.         0.         0.25786667 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.25787581 1.
  0.92304856 1.         0.        ]
 [0.         0.         0.         0.         0.25785577 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.25787641 1.
  1.         1.         0.        ]
 [0.         0.         0.67494155 0.50153819 0.25788018 1.
  0.77285685 1.         0.        ]
 [0.         0.         0.         0.         0.25786276 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.25786241 1.
  0.76616965 1.         0.        ]
 [1.         0.         0.76969029 0.8623064  0.25849667 1.
  0.         0.         1.        ]
 [1.         0.         0.89686916 0.96131033 0.25857723 1.
  0.42717307 0.         1.        ]
 [0.         1.         0.         0.         0.25840309 1.
  0.         0.         1.        ]
 [0.         0.96515273 0.         0.         0.25852683 1.
  0.448952   0.         1.        ]
 [0.         0.         0.         0.         0.25847449 1.
  0.         0.         1.        ]
 [1.         1.         0.34662407 1.         0.25847048 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.25850793 1.
  0.55557084 0.         1.        ]
 [1.         0.         1.         1.         0.25843286 1.
  0.15333766 0.         1.        ]
 [0.         0.76990563 1.         0.46095806 0.25852433 1.
  0.42749341 0.         1.        ]
 [1.         0.         0.95746279 0.80610126 0.25845301 1.
  0.61202714 0.         1.        ]
 [0.         0.         0.         0.22832037 0.25847952 1.
  0.         0.         1.        ]
 [1.         0.20771846 0.         0.74187385 0.25846042 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.75645524 0.25847733 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.258473   1.
  0.         0.         1.        ]
 [0.         0.         0.         0.33077488 0.25848654 1.
  0.24654268 0.         1.        ]
 [1.         0.         1.         1.         0.25849111 1.
  0.         0.         1.        ]
 [1.         0.05844994 0.77475015 0.54899381 0.25847505 1.
  0.         0.         1.        ]
 [0.         0.         0.04258184 0.23961398 0.25848867 1.
  0.15453936 0.         1.        ]
 [0.         0.         0.         0.16195522 0.25853189 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.25847532 1.
  0.37689573 0.         1.        ]
 [1.         0.         1.         1.         0.25852727 1.
  0.02714264 0.         1.        ]
 [1.         0.         0.96738118 0.73356476 0.25843765 1.
  0.25959682 0.         1.        ]
 [1.         0.         1.         1.         0.25849457 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.10041335 0.25842638 1.
  0.         0.         1.        ]
 [1.         1.         1.         0.54758891 0.25853493 1.
  1.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.6499999761581421
#####################         POISON         ###############################################

############################################################################################

comm_round: 7 | global_test_acc: 75.000% | global_f1: 0.8571428571428571 | global_precision: 0.75
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.75      1.00      0.86         9

    accuracy                           0.75        12
   macro avg       0.38      0.50      0.43        12
weighted avg       0.56      0.75      0.64        12
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1.
 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 0.]
wv_fg shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.49497953 0.
 0.         1.         0.         0.         0.39636833 1.
 0.         0.         0.         0.         0.08310559 0.
 0.         0.29125532 0.         0.         0.        ]
wv_mn shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.67403231 0.78781209
 0.         0.         1.         1.         0.         0.
 1.         0.         0.19273537 0.74347092 1.         1.
 0.98320389 0.93393432 0.         1.         1.         0.
 0.         1.         1.         0.99074121 0.        ]
wv_ed shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.38077665 0.01157594
 0.         0.         1.         1.         0.         0.
 1.         0.         0.         0.50801849 1.         1.
 0.80326772 0.         0.         1.         0.7063038  0.
 0.         1.         1.         1.         0.        ]
wv_lg shape (35, 1)
[[0.2582857 ]
 [0.25831082]
 [0.25831246]
 [0.25828026]
 [0.25828939]
 [0.25829901]
 [0.25832487]
 [0.25832098]
 [0.25830001]
 [0.25829799]
 [0.25895865]
 [0.25900028]
 [0.25893674]
 [0.25894305]
 [0.25887231]
 [0.2588442 ]
 [0.25905489]
 [0.25896252]
 [0.25884642]
 [0.25898921]
 [0.25892682]
 [0.25892605]
 [0.25886095]
 [0.25890505]
 [0.25885826]
 [0.25892134]
 [0.25897616]
 [0.25891127]
 [0.25897223]
 [0.25891612]
 [0.25894355]
 [0.25899288]
 [0.25891772]
 [0.25896641]
 [0.25892299]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[1.         1.         0.9339961  1.         0.99773959 1.
 0.93394327 0.86689944 1.         1.         0.03184617 0.22810182
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.03295618 0.         0.76657619
 0.         1.         0.         0.76367557 1.         0.
 0.         0.83324753 0.48637997 0.         0.        ]
wv_std shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
xy shape: (35, 9)
[[0.         0.         0.         0.         0.2582857  1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.25831082 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.25831246 1.
  0.9339961  1.         0.        ]
 [0.         0.         0.         0.         0.25828026 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.25828939 1.
  0.99773959 1.         0.        ]
 [0.         0.         0.         0.         0.25829901 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.25832487 1.
  0.93394327 1.         0.        ]
 [0.         0.         0.         0.         0.25832098 1.
  0.86689944 1.         0.        ]
 [0.         0.         0.         0.         0.25830001 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.25829799 1.
  1.         1.         0.        ]
 [1.         0.         0.67403231 0.38077665 0.25895865 1.
  0.03184617 0.         1.        ]
 [1.         0.         0.78781209 0.01157594 0.25900028 1.
  0.22810182 0.         1.        ]
 [0.         0.         0.         0.         0.25893674 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.25894305 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.25887231 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.2588442  1.
  0.         0.         1.        ]
 [0.         0.49497953 0.         0.         0.25905489 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.25896252 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.25884642 1.
  0.         0.         1.        ]
 [0.         1.         0.         0.         0.25898921 1.
  0.         0.         1.        ]
 [0.         0.         0.19273537 0.         0.25892682 1.
  0.         0.         1.        ]
 [1.         0.         0.74347092 0.50801849 0.25892605 1.
  0.03295618 0.         1.        ]
 [1.         0.39636833 1.         1.         0.25886095 1.
  0.         0.         1.        ]
 [1.         1.         1.         1.         0.25890505 1.
  0.76657619 0.         1.        ]
 [1.         0.         0.98320389 0.80326772 0.25885826 1.
  0.         0.         1.        ]
 [0.         0.         0.93393432 0.         0.25892134 1.
  1.         0.         1.        ]
 [0.         0.         0.         0.         0.25897616 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.25891127 1.
  0.76367557 0.         1.        ]
 [1.         0.08310559 1.         0.7063038  0.25897223 1.
  1.         0.         1.        ]
 [1.         0.         0.         0.         0.25891612 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.25894355 1.
  0.         0.         1.        ]
 [1.         0.29125532 1.         1.         0.25899288 1.
  0.83324753 0.         1.        ]
 [1.         0.         1.         1.         0.25891772 1.
  0.48637997 0.         1.        ]
 [1.         0.         0.99074121 1.         0.25896641 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.25892299 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.800000011920929
#####################         POISON         ###############################################

############################################################################################

comm_round: 8 | global_test_acc: 58.333% | global_f1: 0.7368421052631579 | global_precision: 0.5833333333333334
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         5
           1       0.58      1.00      0.74         7

    accuracy                           0.58        12
   macro avg       0.29      0.50      0.37        12
weighted avg       0.34      0.58      0.43        12
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_fg shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.10577916 1.
 1.         1.         0.4321442  1.         0.83602326 1.
 1.         0.49151607 0.06853855 0.10577916 0.         1.
 1.         1.         1.         1.         0.4321442  0.06853855
 0.49151607 1.         0.         1.         1.        ]
wv_mn shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.00623871 0.         0.         0.6513646  1.
 0.74959027 0.         0.         0.57702203 0.45514754 0.79266222
 1.         0.         0.         0.57727589 1.         1.
 1.         1.         1.         1.         0.         0.89158099
 0.38872366 0.         0.15819798 0.         0.16597103]
wv_ed shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.58651957 0.73595322
 0.88692957 0.         0.18272465 0.64658583 0.72110043 0.76046061
 1.         0.34104341 0.11313687 0.44814962 0.91906897 0.80766081
 1.         0.76667085 1.         1.         0.         0.78222626
 0.83457454 0.         0.48155329 0.33486135 0.18090932]
wv_lg shape (35, 1)
[[0.25873224]
 [0.25873353]
 [0.25876054]
 [0.25873351]
 [0.25871665]
 [0.25875042]
 [0.25873348]
 [0.25876869]
 [0.25875613]
 [0.25874095]
 [0.25940456]
 [0.25942948]
 [0.25943928]
 [0.25946935]
 [0.25945094]
 [0.25945209]
 [0.25940579]
 [0.25939535]
 [0.25936468]
 [0.25933928]
 [0.25938041]
 [0.2593974 ]
 [0.25936947]
 [0.25937325]
 [0.25937866]
 [0.25935599]
 [0.25930619]
 [0.25937569]
 [0.25947285]
 [0.25937018]
 [0.25935141]
 [0.25938804]
 [0.25937807]
 [0.25944025]
 [0.25942899]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 0.         0.17121352 0.22646059 1.         1.         0.
 0.         0.         0.         1.         0.         1.
 1.         1.         0.         0.06622884 1.         0.
 0.35664195 0.         0.         0.         0.38267986]
wv_std shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
xy shape: (35, 9)
[[0.         0.         0.         0.         0.25873224 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.25873353 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.25876054 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.25873351 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.25871665 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.25875042 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.25873348 1.
  1.         1.         0.        ]
 [0.         0.         0.00623871 0.         0.25876869 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.25875613 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.25874095 1.
  1.         1.         0.        ]
 [1.         0.10577916 0.6513646  0.58651957 0.25940456 1.
  1.         0.         1.        ]
 [1.         1.         1.         0.73595322 0.25942948 1.
  1.         0.         1.        ]
 [1.         1.         0.74959027 0.88692957 0.25943928 1.
  0.         0.         1.        ]
 [0.         1.         0.         0.         0.25946935 1.
  0.17121352 0.         1.        ]
 [1.         0.4321442  0.         0.18272465 0.25945094 1.
  0.22646059 0.         1.        ]
 [1.         1.         0.57702203 0.64658583 0.25945209 1.
  1.         0.         1.        ]
 [1.         0.83602326 0.45514754 0.72110043 0.25940579 1.
  1.         0.         1.        ]
 [1.         1.         0.79266222 0.76046061 0.25939535 1.
  0.         0.         1.        ]
 [1.         1.         1.         1.         0.25936468 1.
  0.         0.         1.        ]
 [1.         0.49151607 0.         0.34104341 0.25933928 1.
  0.         0.         1.        ]
 [1.         0.06853855 0.         0.11313687 0.25938041 1.
  0.         0.         1.        ]
 [1.         0.10577916 0.57727589 0.44814962 0.2593974  1.
  1.         0.         1.        ]
 [1.         0.         1.         0.91906897 0.25936947 1.
  0.         0.         1.        ]
 [1.         1.         1.         0.80766081 0.25937325 1.
  1.         0.         1.        ]
 [1.         1.         1.         1.         0.25937866 1.
  1.         0.         1.        ]
 [1.         1.         1.         0.76667085 0.25935599 1.
  1.         0.         1.        ]
 [1.         1.         1.         1.         0.25930619 1.
  0.         0.         1.        ]
 [1.         1.         1.         1.         0.25937569 1.
  0.06622884 0.         1.        ]
 [1.         0.4321442  0.         0.         0.25947285 1.
  1.         0.         1.        ]
 [1.         0.06853855 0.89158099 0.78222626 0.25937018 1.
  0.         0.         1.        ]
 [1.         0.49151607 0.38872366 0.83457454 0.25935141 1.
  0.35664195 0.         1.        ]
 [1.         1.         0.         0.         0.25938804 1.
  0.         0.         1.        ]
 [1.         0.         0.15819798 0.48155329 0.25937807 1.
  0.         0.         1.        ]
 [1.         1.         0.         0.33486135 0.25944025 1.
  0.         0.         1.        ]
 [1.         1.         0.16597103 0.18090932 0.25942899 1.
  0.38267986 0.         1.        ]]

Best Training Poisoning Accuracy:
0.800000011920929
#####################         POISON         ###############################################

############################################################################################

comm_round: 9 | global_test_acc: 58.333% | global_f1: 0.7368421052631579 | global_precision: 0.5833333333333334
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         5
           1       0.58      1.00      0.74         7

    accuracy                           0.58        12
   macro avg       0.29      0.50      0.37        12
weighted avg       0.34      0.58      0.43        12
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_fg shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.48503428 0.         0.48503428 0.         0.
 0.         0.         0.         0.51661229 0.         0.
 0.         0.         0.         0.49502579 1.         0.33945264
 0.         0.         0.         0.         0.        ]
wv_mn shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         1.         0.18259757
 0.27705255 0.         0.09092256 0.         0.         1.
 0.         0.         0.11109931 1.         1.         1.
 0.         0.11939889 0.         0.         0.45812554 0.84993087
 1.         0.         1.         0.85010444 0.        ]
wv_ed shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         1.         0.35611854
 0.46505861 0.         0.01502508 0.         0.         1.
 0.         0.15980862 0.6298045  0.51420613 1.         1.
 0.1469456  0.4952677  0.         0.16918069 0.09442357 1.
 1.         0.09678995 1.         1.         0.        ]
wv_lg shape (35, 1)
[[0.25919811]
 [0.25920015]
 [0.25918746]
 [0.25921584]
 [0.25918934]
 [0.25917746]
 [0.25919705]
 [0.25920325]
 [0.25915238]
 [0.25920847]
 [0.25985034]
 [0.25988455]
 [0.2598418 ]
 [0.25988557]
 [0.25988904]
 [0.25986216]
 [0.25988174]
 [0.25978319]
 [0.2598695 ]
 [0.25980067]
 [0.25984204]
 [0.25984073]
 [0.25979295]
 [0.25986697]
 [0.25980278]
 [0.25987086]
 [0.25987184]
 [0.25990383]
 [0.25993585]
 [0.25982405]
 [0.25984567]
 [0.25980764]
 [0.25986504]
 [0.25986089]
 [0.25982387]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.         0.
 0.         1.         0.         1.         0.07845502 0.
 0.01245658 0.         0.         1.         0.2393603  0.25378224
 0.         0.         0.         0.         0.88198501 0.74942485
 1.         0.         1.         1.         0.        ]
wv_std shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
xy shape: (35, 9)
[[0.         0.         0.         0.         0.25919811 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.25920015 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.25918746 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.25921584 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.25918934 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.25917746 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.25919705 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.25920325 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.25915238 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.25920847 1.
  1.         1.         0.        ]
 [1.         0.         1.         1.         0.25985034 1.
  0.         0.         1.        ]
 [1.         0.         0.18259757 0.35611854 0.25988455 1.
  0.         0.         1.        ]
 [1.         0.         0.27705255 0.46505861 0.2598418  1.
  0.         0.         1.        ]
 [0.         0.48503428 0.         0.         0.25988557 1.
  1.         0.         1.        ]
 [1.         0.         0.09092256 0.01502508 0.25988904 1.
  0.         0.         1.        ]
 [0.         0.48503428 0.         0.         0.25986216 1.
  1.         0.         1.        ]
 [0.         0.         0.         0.         0.25988174 1.
  0.07845502 0.         1.        ]
 [1.         0.         1.         1.         0.25978319 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.2598695  1.
  0.01245658 0.         1.        ]
 [1.         0.         0.         0.15980862 0.25980067 1.
  0.         0.         1.        ]
 [1.         0.         0.11109931 0.6298045  0.25984204 1.
  0.         0.         1.        ]
 [1.         0.51661229 1.         0.51420613 0.25984073 1.
  1.         0.         1.        ]
 [1.         0.         1.         1.         0.25979295 1.
  0.2393603  0.         1.        ]
 [1.         0.         1.         1.         0.25986697 1.
  0.25378224 0.         1.        ]
 [1.         0.         0.         0.1469456  0.25980278 1.
  0.         0.         1.        ]
 [1.         0.         0.11939889 0.4952677  0.25987086 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.25987184 1.
  0.         0.         1.        ]
 [1.         0.49502579 0.         0.16918069 0.25990383 1.
  0.         0.         1.        ]
 [1.         1.         0.45812554 0.09442357 0.25993585 1.
  0.88198501 0.         1.        ]
 [1.         0.33945264 0.84993087 1.         0.25982405 1.
  0.74942485 0.         1.        ]
 [1.         0.         1.         1.         0.25984567 1.
  1.         0.         1.        ]
 [1.         0.         0.         0.09678995 0.25980764 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.25986504 1.
  1.         0.         1.        ]
 [1.         0.         0.85010444 1.         0.25986089 1.
  1.         0.         1.        ]
 [1.         0.         0.         0.         0.25982387 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.699999988079071
#####################         POISON         ###############################################

############################################################################################

comm_round: 10 | global_test_acc: 66.667% | global_f1: 0.8 | global_precision: 0.6666666666666666
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         4
           1       0.67      1.00      0.80         8

    accuracy                           0.67        12
   macro avg       0.33      0.50      0.40        12
weighted avg       0.44      0.67      0.53        12
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 0. 0. 1. 1. 0. 1. 1. 0. 1.
 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_fg shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         1.
 1.         0.34370731 0.         1.         0.         0.
 0.36962392 0.         1.         1.         0.82529415 0.
 0.57796725 0.13561052 0.         0.83259967 0.97806668 0.
 0.         0.         0.         0.         0.49208141]
wv_mn shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.40867786 0.         0.         1.         1.
 1.         0.         1.         0.         0.         0.64627766
 1.         0.01500513 1.         1.         0.         1.
 0.         1.         1.         1.         1.         1.
 0.53436044 0.34322528 1.         1.         0.        ]
wv_ed shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.47738421 0.         0.         1.         1.
 1.         0.         1.         0.         0.02386023 0.99521158
 1.         0.         1.         1.         0.         1.
 0.13568679 1.         1.         1.         1.         1.
 0.92526967 0.54720176 1.         1.         0.56969675]
wv_lg shape (35, 1)
[[0.25965441]
 [0.25963638]
 [0.25964766]
 [0.25965628]
 [0.25963878]
 [0.2596245 ]
 [0.25963498]
 [0.25967441]
 [0.25966289]
 [0.25966861]
 [0.26031154]
 [0.26036218]
 [0.26030217]
 [0.26035259]
 [0.26031516]
 [0.26040807]
 [0.26033355]
 [0.26034615]
 [0.26039843]
 [0.26035056]
 [0.26026914]
 [0.26027691]
 [0.26026274]
 [0.26032994]
 [0.26029106]
 [0.26035865]
 [0.26035541]
 [0.26025926]
 [0.26037491]
 [0.26027213]
 [0.26028384]
 [0.2603396 ]
 [0.26033195]
 [0.26032822]
 [0.26030103]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.13003698 1.
 1.         1.         0.         0.         0.         0.
 1.         0.83156251 0.1808806  0.         0.         0.26548843
 0.         1.         0.46334767 1.         1.         0.
 0.02349246 0.39889521 1.         0.300654   0.        ]
wv_std shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
xy shape: (35, 9)
[[0.         0.         0.         0.         0.25965441 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.25963638 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.25964766 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.25965628 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.25963878 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.2596245  1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.25963498 1.
  1.         1.         0.        ]
 [0.         0.         0.40867786 0.47738421 0.25967441 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.25966289 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.25966861 1.
  1.         1.         0.        ]
 [1.         0.         1.         1.         0.26031154 1.
  0.13003698 0.         1.        ]
 [1.         1.         1.         1.         0.26036218 1.
  1.         0.         1.        ]
 [1.         1.         1.         1.         0.26030217 1.
  1.         0.         1.        ]
 [0.         0.34370731 0.         0.         0.26035259 1.
  1.         0.         1.        ]
 [1.         0.         1.         1.         0.26031516 1.
  0.         0.         1.        ]
 [0.         1.         0.         0.         0.26040807 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.02386023 0.26033355 1.
  0.         0.         1.        ]
 [1.         0.         0.64627766 0.99521158 0.26034615 1.
  0.         0.         1.        ]
 [1.         0.36962392 1.         1.         0.26039843 1.
  1.         0.         1.        ]
 [0.         0.         0.01500513 0.         0.26035056 1.
  0.83156251 0.         1.        ]
 [1.         1.         1.         1.         0.26026914 1.
  0.1808806  0.         1.        ]
 [1.         1.         1.         1.         0.26027691 1.
  0.         0.         1.        ]
 [0.         0.82529415 0.         0.         0.26026274 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.26032994 1.
  0.26548843 0.         1.        ]
 [0.         0.57796725 0.         0.13568679 0.26029106 1.
  0.         0.         1.        ]
 [1.         0.13561052 1.         1.         0.26035865 1.
  1.         0.         1.        ]
 [1.         0.         1.         1.         0.26035541 1.
  0.46334767 0.         1.        ]
 [1.         0.83259967 1.         1.         0.26025926 1.
  1.         0.         1.        ]
 [1.         0.97806668 1.         1.         0.26037491 1.
  1.         0.         1.        ]
 [1.         0.         1.         1.         0.26027213 1.
  0.         0.         1.        ]
 [1.         0.         0.53436044 0.92526967 0.26028384 1.
  0.02349246 0.         1.        ]
 [1.         0.         0.34322528 0.54720176 0.2603396  1.
  0.39889521 0.         1.        ]
 [1.         0.         1.         1.         0.26033195 1.
  1.         0.         1.        ]
 [1.         0.         1.         1.         0.26032822 1.
  0.300654   0.         1.        ]
 [1.         0.49208141 0.         0.56969675 0.26030103 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.75
#####################         POISON         ###############################################

############################################################################################

comm_round: 11 | global_test_acc: 66.667% | global_f1: 0.8 | global_precision: 0.6666666666666666
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         4
           1       0.67      1.00      0.80         8

    accuracy                           0.67        12
   macro avg       0.33      0.50      0.40        12
weighted avg       0.44      0.67      0.53        12
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]
wv_fg shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.54720735 0.         0.62900678 0.         0.         0.
 0.         0.         0.         0.03544205 0.02759021 0.60101385
 1.         1.         0.25324491 0.         0.         0.
 0.         0.         0.30676253 0.         0.        ]
wv_mn shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.17699243 0.         1.         0.         0.72878086
 0.         0.         0.55130222 1.         0.3272633  1.
 0.         1.         1.         0.61606467 0.95599154 1.
 0.89981895 0.         0.61458763 0.3258578  0.15772762]
wv_ed shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.24730193
 0.         0.13531296 0.         1.         0.         1.
 0.26057184 0.56134858 1.         1.         0.63910315 1.
 0.         1.         0.765112   0.79303318 1.         1.
 1.         0.         1.         0.92842055 0.61642643]
wv_lg shape (35, 1)
[[0.26010443]
 [0.26012137]
 [0.26012389]
 [0.26012229]
 [0.26012105]
 [0.26011062]
 [0.26012433]
 [0.26012868]
 [0.26010896]
 [0.26010732]
 [0.26087613]
 [0.26075824]
 [0.26084898]
 [0.26085412]
 [0.26073492]
 [0.26078498]
 [0.26081312]
 [0.26076763]
 [0.26076553]
 [0.26080366]
 [0.26073641]
 [0.26074342]
 [0.26074702]
 [0.26082253]
 [0.26069796]
 [0.26077192]
 [0.26077023]
 [0.26086925]
 [0.26072573]
 [0.26080512]
 [0.26080036]
 [0.26081908]
 [0.26078253]
 [0.26079592]
 [0.26080921]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[0.84852908 0.75550447 0.42527821 0.6143094  1.         0.41348195
 0.78830191 0.65631415 0.48253049 0.64125181 0.         0.
 0.04884494 0.29403203 0.24150167 0.164036   0.         0.
 0.         0.         0.         0.22633498 0.         0.
 0.         1.         0.08287424 0.         0.04148987 0.19113184
 0.         0.         0.         0.21134628 0.        ]
wv_std shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
xy shape: (35, 9)
[[0.         0.         0.         0.         0.26010443 1.
  0.84852908 1.         0.        ]
 [0.         0.         0.         0.         0.26012137 1.
  0.75550447 1.         0.        ]
 [0.         0.         0.         0.         0.26012389 1.
  0.42527821 1.         0.        ]
 [0.         0.         0.         0.         0.26012229 1.
  0.6143094  1.         0.        ]
 [0.         0.         0.         0.         0.26012105 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.26011062 1.
  0.41348195 1.         0.        ]
 [0.         0.         0.         0.         0.26012433 1.
  0.78830191 1.         0.        ]
 [0.         0.         0.         0.         0.26012868 1.
  0.65631415 1.         0.        ]
 [0.         0.         0.         0.         0.26010896 1.
  0.48253049 1.         0.        ]
 [0.         0.         0.         0.         0.26010732 1.
  0.64125181 1.         0.        ]
 [1.         0.         0.         0.         0.26087613 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.24730193 0.26075824 1.
  0.         0.         1.        ]
 [0.         0.54720735 0.         0.         0.26084898 1.
  0.04884494 0.         1.        ]
 [1.         0.         0.17699243 0.13531296 0.26085412 1.
  0.29403203 0.         1.        ]
 [0.         0.62900678 0.         0.         0.26073492 1.
  0.24150167 0.         1.        ]
 [1.         0.         1.         1.         0.26078498 1.
  0.164036   0.         1.        ]
 [0.         0.         0.         0.         0.26081312 1.
  0.         0.         1.        ]
 [1.         0.         0.72878086 1.         0.26076763 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.26057184 0.26076553 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.56134858 0.26080366 1.
  0.         0.         1.        ]
 [1.         0.         0.55130222 1.         0.26073641 1.
  0.         0.         1.        ]
 [1.         0.03544205 1.         1.         0.26074342 1.
  0.22633498 0.         1.        ]
 [1.         0.02759021 0.3272633  0.63910315 0.26074702 1.
  0.         0.         1.        ]
 [1.         0.60101385 1.         1.         0.26082253 1.
  0.         0.         1.        ]
 [1.         1.         0.         0.         0.26069796 1.
  0.         0.         1.        ]
 [1.         1.         1.         1.         0.26077192 1.
  1.         0.         1.        ]
 [1.         0.25324491 1.         0.765112   0.26077023 1.
  0.08287424 0.         1.        ]
 [1.         0.         0.61606467 0.79303318 0.26086925 1.
  0.         0.         1.        ]
 [1.         0.         0.95599154 1.         0.26072573 1.
  0.04148987 0.         1.        ]
 [1.         0.         1.         1.         0.26080512 1.
  0.19113184 0.         1.        ]
 [1.         0.         0.89981895 1.         0.26080036 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.26081908 1.
  0.         0.         1.        ]
 [1.         0.30676253 0.61458763 1.         0.26078253 1.
  0.         0.         1.        ]
 [1.         0.         0.3258578  0.92842055 0.26079592 1.
  0.21134628 0.         1.        ]
 [1.         0.         0.15772762 0.61642643 0.26080921 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.699999988079071
#####################         POISON         ###############################################

############################################################################################

comm_round: 12 | global_test_acc: 66.667% | global_f1: 0.8 | global_precision: 0.6666666666666666
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         4
           1       0.67      1.00      0.80         8

    accuracy                           0.67        12
   macro avg       0.33      0.50      0.40        12
weighted avg       0.44      0.67      0.53        12
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1.]
wv_fg shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         1.         0.
 0.36565988 0.         0.         0.         0.         0.
 0.52605547 1.         0.         0.         1.         0.15591922
 0.28046332 1.         0.28046332 1.         1.         0.67034426
 0.         0.         0.         1.         0.        ]
wv_mn shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         1.         1.
 1.         1.         1.         1.         0.116318   0.
 1.         0.         1.         1.         1.         1.
 0.74690945 1.         0.58427716 1.         1.         1.
 0.         1.         0.41703167 1.         1.        ]
wv_ed shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         1.         1.
 1.         0.61903485 1.         1.         0.36268474 0.
 1.         0.         1.         1.         1.         1.
 0.57807135 1.         0.26321275 1.         1.         1.
 0.         1.         0.78617761 1.         1.        ]
wv_lg shape (35, 1)
[[0.26060347]
 [0.26058957]
 [0.26057944]
 [0.26054569]
 [0.26057915]
 [0.26054473]
 [0.2605805 ]
 [0.26057111]
 [0.26055756]
 [0.26056353]
 [0.26129907]
 [0.26129943]
 [0.26131516]
 [0.26134948]
 [0.26133075]
 [0.26125356]
 [0.26126954]
 [0.2612902 ]
 [0.26121322]
 [0.26128132]
 [0.26122951]
 [0.26121508]
 [0.26125601]
 [0.26126928]
 [0.26128597]
 [0.26126196]
 [0.26125217]
 [0.26121934]
 [0.26131981]
 [0.2612297 ]
 [0.2612922 ]
 [0.26121542]
 [0.26129811]
 [0.26125269]
 [0.26122718]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.         0.26553229
 1.         1.         0.94058803 0.63452776 0.45006501 0.45348713
 0.         0.         0.94873177 0.52394986 0.         1.
 1.         1.         1.         1.         0.41046893 1.
 0.         0.01622534 0.         0.76046085 0.0251673 ]
wv_std shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
xy shape: (35, 9)
[[0.         0.         0.         0.         0.26060347 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.26058957 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.26057944 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.26054569 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.26057915 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.26054473 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.2605805  1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.26057111 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.26055756 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.26056353 1.
  1.         1.         0.        ]
 [1.         1.         1.         1.         0.26129907 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.26129943 1.
  0.26553229 0.         1.        ]
 [1.         0.36565988 1.         1.         0.26131516 1.
  1.         0.         1.        ]
 [1.         0.         1.         0.61903485 0.26134948 1.
  1.         0.         1.        ]
 [1.         0.         1.         1.         0.26133075 1.
  0.94058803 0.         1.        ]
 [1.         0.         1.         1.         0.26125356 1.
  0.63452776 0.         1.        ]
 [1.         0.         0.116318   0.36268474 0.26126954 1.
  0.45006501 0.         1.        ]
 [0.         0.         0.         0.         0.2612902  1.
  0.45348713 0.         1.        ]
 [1.         0.52605547 1.         1.         0.26121322 1.
  0.         0.         1.        ]
 [0.         1.         0.         0.         0.26128132 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.26122951 1.
  0.94873177 0.         1.        ]
 [1.         0.         1.         1.         0.26121508 1.
  0.52394986 0.         1.        ]
 [1.         1.         1.         1.         0.26125601 1.
  0.         0.         1.        ]
 [1.         0.15591922 1.         1.         0.26126928 1.
  1.         0.         1.        ]
 [1.         0.28046332 0.74690945 0.57807135 0.26128597 1.
  1.         0.         1.        ]
 [1.         1.         1.         1.         0.26126196 1.
  1.         0.         1.        ]
 [1.         0.28046332 0.58427716 0.26321275 0.26125217 1.
  1.         0.         1.        ]
 [1.         1.         1.         1.         0.26121934 1.
  1.         0.         1.        ]
 [1.         1.         1.         1.         0.26131981 1.
  0.41046893 0.         1.        ]
 [1.         0.67034426 1.         1.         0.2612297  1.
  1.         0.         1.        ]
 [0.         0.         0.         0.         0.2612922  1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.26121542 1.
  0.01622534 0.         1.        ]
 [1.         0.         0.41703167 0.78617761 0.26129811 1.
  0.         0.         1.        ]
 [1.         1.         1.         1.         0.26125269 1.
  0.76046085 0.         1.        ]
 [1.         0.         1.         1.         0.26122718 1.
  0.0251673  0.         1.        ]]

Best Training Poisoning Accuracy:
0.8500000238418579
#####################         POISON         ###############################################

############################################################################################

comm_round: 13 | global_test_acc: 50.000% | global_f1: 0.6666666666666666 | global_precision: 0.5
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         6
           1       0.50      1.00      0.67         6

    accuracy                           0.50        12
   macro avg       0.25      0.50      0.33        12
weighted avg       0.25      0.50      0.33        12
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_fg shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         1.         0.         0.7267583  0.17524756
 0.         0.         0.         0.         0.        ]
wv_mn shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         1.         0.
 0.6064078  0.44249044 0.94082203 0.         0.41056403 0.
 0.         0.77728179 0.         1.         0.63610068 1.
 0.35316384 0.         1.         1.         1.         1.
 0.20937363 0.5451055  1.         0.88269547 1.        ]
wv_ed shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         1.         0.18234925
 0.65003084 0.87562277 0.4150106  0.99918309 0.81092266 0.
 0.         0.55284018 0.53945595 1.         0.5851799  0.86637633
 0.80826928 0.         1.         0.49758268 1.         1.
 0.30897179 1.         1.         1.         1.        ]
wv_lg shape (35, 1)
[[0.26106634]
 [0.26102906]
 [0.26103257]
 [0.26105569]
 [0.26106407]
 [0.26102419]
 [0.26103948]
 [0.26104409]
 [0.26107572]
 [0.26107825]
 [0.2616509 ]
 [0.26171263]
 [0.26167283]
 [0.26167091]
 [0.26168018]
 [0.26172042]
 [0.26183521]
 [0.26175311]
 [0.26174537]
 [0.26165261]
 [0.26167134]
 [0.26173641]
 [0.2616836 ]
 [0.26175885]
 [0.26175373]
 [0.26179019]
 [0.26172966]
 [0.26173866]
 [0.26176644]
 [0.26182399]
 [0.2616489 ]
 [0.26171059]
 [0.26161182]
 [0.26173747]
 [0.26172746]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.         0.
 0.         0.         0.1921839  0.         0.06258651 1.
 0.15471406 0.99136441 0.         0.25931632 0.         0.
 0.         0.835734   0.51565212 1.         1.         0.98926977
 0.         0.26392635 0.         0.         1.        ]
wv_std shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
xy shape: (35, 9)
[[0.         0.         0.         0.         0.26106634 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.26102906 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.26103257 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.26105569 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.26106407 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.26102419 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.26103948 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.26104409 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.26107572 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.26107825 1.
  1.         1.         0.        ]
 [1.         0.         1.         1.         0.2616509  1.
  0.         0.         1.        ]
 [1.         0.         0.         0.18234925 0.26171263 1.
  0.         0.         1.        ]
 [1.         0.         0.6064078  0.65003084 0.26167283 1.
  0.         0.         1.        ]
 [1.         0.         0.44249044 0.87562277 0.26167091 1.
  0.         0.         1.        ]
 [1.         0.         0.94082203 0.4150106  0.26168018 1.
  0.1921839  0.         1.        ]
 [1.         0.         0.         0.99918309 0.26172042 1.
  0.         0.         1.        ]
 [1.         0.         0.41056403 0.81092266 0.26183521 1.
  0.06258651 0.         1.        ]
 [1.         0.         0.         0.         0.26175311 1.
  1.         0.         1.        ]
 [0.         0.         0.         0.         0.26174537 1.
  0.15471406 0.         1.        ]
 [1.         0.         0.77728179 0.55284018 0.26165261 1.
  0.99136441 0.         1.        ]
 [1.         0.         0.         0.53945595 0.26167134 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.26173641 1.
  0.25931632 0.         1.        ]
 [1.         0.         0.63610068 0.5851799  0.2616836  1.
  0.         0.         1.        ]
 [1.         0.         1.         0.86637633 0.26175885 1.
  0.         0.         1.        ]
 [1.         0.         0.35316384 0.80826928 0.26175373 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.26179019 1.
  0.835734   0.         1.        ]
 [1.         1.         1.         1.         0.26172966 1.
  0.51565212 0.         1.        ]
 [1.         0.         1.         0.49758268 0.26173866 1.
  1.         0.         1.        ]
 [1.         0.7267583  1.         1.         0.26176644 1.
  1.         0.         1.        ]
 [1.         0.17524756 1.         1.         0.26182399 1.
  0.98926977 0.         1.        ]
 [1.         0.         0.20937363 0.30897179 0.2616489  1.
  0.         0.         1.        ]
 [1.         0.         0.5451055  1.         0.26171059 1.
  0.26392635 0.         1.        ]
 [1.         0.         1.         1.         0.26161182 1.
  0.         0.         1.        ]
 [1.         0.         0.88269547 1.         0.26173747 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.26172746 1.
  1.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.699999988079071
#####################         POISON         ###############################################

############################################################################################

comm_round: 14 | global_test_acc: 75.000% | global_f1: 0.8571428571428571 | global_precision: 0.75
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.75      1.00      0.86         9

    accuracy                           0.75        12
   macro avg       0.38      0.50      0.43        12
weighted avg       0.56      0.75      0.64        12
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0.
 1. 1. 1. 0. 0. 0. 0. 1. 0. 1. 0.]
wv_fg shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.94452114 0.         0.         0.         0.         0.
 0.         0.         0.         0.17478233 0.         0.
 0.         0.44075153 0.         0.         0.         0.
 0.         0.         1.         1.         0.75956687]
wv_mn shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.01724901 0.         0.         0.         0.
 0.65659446 0.         0.         1.         0.46770099 0.
 0.         0.         0.         1.         0.76773929 0.
 1.         1.         1.         0.07216422 0.34374398 0.
 0.15194157 1.         0.         1.         0.        ]
wv_ed shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.1697369  0.24300055 0.         0.         0.35504794
 0.27341847 0.         0.         1.         0.50687831 0.
 0.         0.         0.         0.54026663 0.87330496 0.
 1.         1.         1.         0.18778542 0.         0.
 0.07038982 1.         0.         1.         0.        ]
wv_lg shape (35, 1)
[[0.26151486]
 [0.26150535]
 [0.26151924]
 [0.2615022 ]
 [0.26151833]
 [0.26151356]
 [0.26151957]
 [0.26153183]
 [0.26155384]
 [0.26150551]
 [0.26217869]
 [0.2621919 ]
 [0.26218712]
 [0.26223604]
 [0.2621841 ]
 [0.26221171]
 [0.2622178 ]
 [0.26225791]
 [0.26221012]
 [0.262192  ]
 [0.26220459]
 [0.26221517]
 [0.26219251]
 [0.26223433]
 [0.26216772]
 [0.26219619]
 [0.26217758]
 [0.26220282]
 [0.26219986]
 [0.26220814]
 [0.2622055 ]
 [0.26220314]
 [0.26218836]
 [0.26211209]
 [0.26225002]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[1.         0.90009637 0.55376734 1.         0.74903787 0.87387814
 0.95066823 0.72643977 0.58000026 0.98197716 0.         0.
 0.         0.         0.         0.36558845 0.         0.10699374
 0.         0.         0.         1.         0.01816895 0.
 0.50211243 0.         0.08912559 0.         0.         0.15828853
 0.         0.         0.         1.         0.        ]
wv_std shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
xy shape: (35, 9)
[[0.         0.         0.         0.         0.26151486 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.26150535 1.
  0.90009637 1.         0.        ]
 [0.         0.         0.         0.         0.26151924 1.
  0.55376734 1.         0.        ]
 [0.         0.         0.         0.         0.2615022  1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.26151833 1.
  0.74903787 1.         0.        ]
 [0.         0.         0.         0.         0.26151356 1.
  0.87387814 1.         0.        ]
 [0.         0.         0.         0.         0.26151957 1.
  0.95066823 1.         0.        ]
 [0.         0.         0.01724901 0.1697369  0.26153183 1.
  0.72643977 1.         0.        ]
 [0.         0.         0.         0.24300055 0.26155384 1.
  0.58000026 1.         0.        ]
 [0.         0.         0.         0.         0.26150551 1.
  0.98197716 1.         0.        ]
 [0.         0.         0.         0.         0.26217869 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.35504794 0.2621919  1.
  0.         0.         1.        ]
 [1.         0.94452114 0.65659446 0.27341847 0.26218712 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.26223604 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.2621841  1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.26221171 1.
  0.36558845 0.         1.        ]
 [1.         0.         0.46770099 0.50687831 0.2622178  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.26225791 1.
  0.10699374 0.         1.        ]
 [0.         0.         0.         0.         0.26221012 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.262192   1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.26220459 1.
  0.         0.         1.        ]
 [1.         0.17478233 1.         0.54026663 0.26221517 1.
  1.         0.         1.        ]
 [1.         0.         0.76773929 0.87330496 0.26219251 1.
  0.01816895 0.         1.        ]
 [0.         0.         0.         0.         0.26223433 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.26216772 1.
  0.50211243 0.         1.        ]
 [1.         0.44075153 1.         1.         0.26219619 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.26217758 1.
  0.08912559 0.         1.        ]
 [0.         0.         0.07216422 0.18778542 0.26220282 1.
  0.         0.         1.        ]
 [0.         0.         0.34374398 0.         0.26219986 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.26220814 1.
  0.15828853 0.         1.        ]
 [0.         0.         0.15194157 0.07038982 0.2622055  1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.26220314 1.
  0.         0.         1.        ]
 [0.         1.         0.         0.         0.26218836 1.
  0.         0.         1.        ]
 [1.         1.         1.         1.         0.26211209 1.
  1.         0.         1.        ]
 [0.         0.75956687 0.         0.         0.26225002 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.800000011920929
#####################         POISON         ###############################################

############################################################################################

comm_round: 15 | global_test_acc: 58.333% | global_f1: 0.7368421052631579 | global_precision: 0.5833333333333334
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         5
           1       0.58      1.00      0.74         7

    accuracy                           0.58        12
   macro avg       0.29      0.50      0.37        12
weighted avg       0.34      0.58      0.43        12
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0.
 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1.]
wv_fg shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.89887913
 0.         0.         0.         0.         0.         0.
 0.         1.         0.         0.         0.49417145 0.
 0.         0.         0.         0.         0.         0.
 0.         0.68724695 0.21318979 0.         0.        ]
wv_mn shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.66606572 0.60095717
 0.29224157 0.         0.         0.         0.4615973  0.02556009
 0.         0.         0.         0.         0.         0.28895512
 0.18634904 1.         0.25865263 0.05554556 0.         0.
 0.         0.         1.         0.34153641 0.        ]
wv_ed shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.99483542 0.61470239
 0.         0.         0.         0.         0.53059132 0.25419935
 0.         0.         0.         0.         0.         0.
 0.07957007 0.71789379 0.31405171 0.24364968 0.         0.
 0.         0.         1.         1.         0.1632139 ]
wv_lg shape (35, 1)
[[0.26199126]
 [0.26201232]
 [0.26198659]
 [0.26199218]
 [0.26200014]
 [0.26196661]
 [0.26199634]
 [0.26201145]
 [0.26200367]
 [0.26200373]
 [0.26267491]
 [0.26258912]
 [0.26272018]
 [0.26266399]
 [0.26270644]
 [0.26272507]
 [0.26269349]
 [0.26262239]
 [0.26269388]
 [0.26271213]
 [0.26266731]
 [0.26275083]
 [0.2627225 ]
 [0.26269172]
 [0.26265018]
 [0.26272372]
 [0.26267737]
 [0.26270096]
 [0.26273128]
 [0.26269501]
 [0.26275884]
 [0.26273639]
 [0.26263913]
 [0.26265718]
 [0.26264045]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.46968947 1.
 1.         0.         0.0574328  1.         0.50129019 0.40790481
 0.         0.         0.         1.         0.12836566 1.
 1.         1.         0.64209582 0.52106556 0.57587745 0.89560777
 0.23390346 0.0364187  1.         0.         0.        ]
wv_std shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
xy shape: (35, 9)
[[0.         0.         0.         0.         0.26199126 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.26201232 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.26198659 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.26199218 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.26200014 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.26196661 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.26199634 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.26201145 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.26200367 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.26200373 1.
  1.         1.         0.        ]
 [1.         0.         0.66606572 0.99483542 0.26267491 1.
  0.46968947 0.         1.        ]
 [1.         0.89887913 0.60095717 0.61470239 0.26258912 1.
  1.         0.         1.        ]
 [1.         0.         0.29224157 0.         0.26272018 1.
  1.         0.         1.        ]
 [0.         0.         0.         0.         0.26266399 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.26270644 1.
  0.0574328  0.         1.        ]
 [0.         0.         0.         0.         0.26272507 1.
  1.         0.         1.        ]
 [1.         0.         0.4615973  0.53059132 0.26269349 1.
  0.50129019 0.         1.        ]
 [1.         0.         0.02556009 0.25419935 0.26262239 1.
  0.40790481 0.         1.        ]
 [0.         0.         0.         0.         0.26269388 1.
  0.         0.         1.        ]
 [0.         1.         0.         0.         0.26271213 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.26266731 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.26275083 1.
  1.         0.         1.        ]
 [0.         0.49417145 0.         0.         0.2627225  1.
  0.12836566 0.         1.        ]
 [0.         0.         0.28895512 0.         0.26269172 1.
  1.         0.         1.        ]
 [1.         0.         0.18634904 0.07957007 0.26265018 1.
  1.         0.         1.        ]
 [1.         0.         1.         0.71789379 0.26272372 1.
  1.         0.         1.        ]
 [1.         0.         0.25865263 0.31405171 0.26267737 1.
  0.64209582 0.         1.        ]
 [1.         0.         0.05554556 0.24364968 0.26270096 1.
  0.52106556 0.         1.        ]
 [0.         0.         0.         0.         0.26273128 1.
  0.57587745 0.         1.        ]
 [0.         0.         0.         0.         0.26269501 1.
  0.89560777 0.         1.        ]
 [0.         0.         0.         0.         0.26275884 1.
  0.23390346 0.         1.        ]
 [0.         0.68724695 0.         0.         0.26273639 1.
  0.0364187  0.         1.        ]
 [1.         0.21318979 1.         1.         0.26263913 1.
  1.         0.         1.        ]
 [1.         0.         0.34153641 1.         0.26265718 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.1632139  0.26264045 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.75
#####################         POISON         ###############################################

############################################################################################

comm_round: 16 | global_test_acc: 66.667% | global_f1: 0.8 | global_precision: 0.6666666666666666
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         4
           1       0.67      1.00      0.80         8

    accuracy                           0.67        12
   macro avg       0.33      0.50      0.40        12
weighted avg       0.44      0.67      0.53        12
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.]
wv_fg shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.44107264 0.
 0.62679183 0.         0.         0.         0.7952415  0.
 0.         0.         0.         0.         1.         0.
 0.         0.         0.56899375 0.         0.         0.
 0.         0.         1.         0.         0.        ]
wv_mn shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.12061713 0.         0.         1.         1.
 1.         0.87649239 1.         0.         0.84164818 0.
 1.         0.28542623 0.         0.         0.         0.95396708
 1.         1.         0.88185015 1.         1.         1.
 1.         1.         0.         1.         0.42944653]
wv_ed shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.13886793 0.         0.         1.         0.89647033
 0.67298195 0.7976868  1.         0.         0.18418541 0.
 1.         0.56453907 0.         0.         0.         1.
 1.         1.         0.33340772 1.         1.         1.
 1.         1.         0.08119973 0.97280689 0.69540965]
wv_lg shape (35, 1)
[[0.26248119]
 [0.26246539]
 [0.26243374]
 [0.26248318]
 [0.26244005]
 [0.26248179]
 [0.26246026]
 [0.26250639]
 [0.26245896]
 [0.26248363]
 [0.26309625]
 [0.26320265]
 [0.26305758]
 [0.2631147 ]
 [0.2630991 ]
 [0.26323541]
 [0.26326517]
 [0.26318214]
 [0.26320002]
 [0.26314003]
 [0.26311308]
 [0.26312153]
 [0.26308771]
 [0.26311597]
 [0.26314241]
 [0.26309158]
 [0.26318522]
 [0.26317991]
 [0.26311845]
 [0.2631314 ]
 [0.26319827]
 [0.26321969]
 [0.26319469]
 [0.26310466]
 [0.26321343]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.         1.
 0.06094949 0.63074145 0.         0.         0.5315824  0.45187349
 0.72851992 0.69492328 0.         0.         0.65515038 0.75953924
 0.         0.06432716 0.87133626 1.         0.11661945 0.16098031
 0.         0.33121868 0.         0.         0.47918948]
wv_std shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
xy shape: (35, 9)
[[0.         0.         0.         0.         0.26248119 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.26246539 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.26243374 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.26248318 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.26244005 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.26248179 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.26246026 1.
  1.         1.         0.        ]
 [0.         0.         0.12061713 0.13886793 0.26250639 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.26245896 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.26248363 1.
  1.         1.         0.        ]
 [1.         0.44107264 1.         1.         0.26309625 1.
  0.         0.         1.        ]
 [1.         0.         1.         0.89647033 0.26320265 1.
  1.         0.         1.        ]
 [1.         0.62679183 1.         0.67298195 0.26305758 1.
  0.06094949 0.         1.        ]
 [1.         0.         0.87649239 0.7976868  0.2631147  1.
  0.63074145 0.         1.        ]
 [1.         0.         1.         1.         0.2630991  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.26323541 1.
  0.         0.         1.        ]
 [0.         0.7952415  0.84164818 0.18418541 0.26326517 1.
  0.5315824  0.         1.        ]
 [0.         0.         0.         0.         0.26318214 1.
  0.45187349 0.         1.        ]
 [1.         0.         1.         1.         0.26320002 1.
  0.72851992 0.         1.        ]
 [1.         0.         0.28542623 0.56453907 0.26314003 1.
  0.69492328 0.         1.        ]
 [0.         0.         0.         0.         0.26311308 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.26312153 1.
  0.         0.         1.        ]
 [0.         1.         0.         0.         0.26308771 1.
  0.65515038 0.         1.        ]
 [1.         0.         0.95396708 1.         0.26311597 1.
  0.75953924 0.         1.        ]
 [1.         0.         1.         1.         0.26314241 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.26309158 1.
  0.06432716 0.         1.        ]
 [1.         0.56899375 0.88185015 0.33340772 0.26318522 1.
  0.87133626 0.         1.        ]
 [1.         0.         1.         1.         0.26317991 1.
  1.         0.         1.        ]
 [1.         0.         1.         1.         0.26311845 1.
  0.11661945 0.         1.        ]
 [1.         0.         1.         1.         0.2631314  1.
  0.16098031 0.         1.        ]
 [1.         0.         1.         1.         0.26319827 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.26321969 1.
  0.33121868 0.         1.        ]
 [0.         1.         0.         0.08119973 0.26319469 1.
  0.         0.         1.        ]
 [1.         0.         1.         0.97280689 0.26310466 1.
  0.         0.         1.        ]
 [1.         0.         0.42944653 0.69540965 0.26321343 1.
  0.47918948 0.         1.        ]]

Best Training Poisoning Accuracy:
0.6499999761581421
#####################         POISON         ###############################################

############################################################################################

comm_round: 17 | global_test_acc: 83.333% | global_f1: 0.9090909090909091 | global_precision: 0.8333333333333334
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.83      1.00      0.91        10

    accuracy                           0.83        12
   macro avg       0.42      0.50      0.45        12
weighted avg       0.69      0.83      0.76        12
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_fg shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.27287087 0.         0.         0.33139584 1.
 0.         1.         0.         0.         0.         0.
 0.         0.         1.         1.         1.         0.
 1.         0.31320115 0.         0.         0.08363249]
wv_mn shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.74866106
 0.         1.         0.         0.49913714 0.         0.58009386
 0.04731442 0.         1.         1.         0.42472284 0.77679954
 1.         1.         0.         0.73579896 0.38668451 1.
 1.         0.         0.72601388 0.10058095 1.        ]
wv_ed shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.95365912
 0.         1.         0.         0.79396094 0.22881585 0.79603524
 0.17618919 0.         1.         1.         0.17824064 0.77693264
 1.         1.         0.         0.71198688 0.86043294 1.
 1.         0.         1.         0.51820411 1.        ]
wv_lg shape (35, 1)
[[0.26294405]
 [0.26294997]
 [0.26294665]
 [0.26291802]
 [0.26294813]
 [0.26290879]
 [0.26294306]
 [0.26294742]
 [0.2629382 ]
 [0.26294506]
 [0.26365803]
 [0.26363982]
 [0.263657  ]
 [0.26370423]
 [0.26368453]
 [0.26358136]
 [0.263584  ]
 [0.2635331 ]
 [0.26364337]
 [0.26362424]
 [0.26363061]
 [0.2635695 ]
 [0.26367344]
 [0.26372157]
 [0.26361394]
 [0.26365951]
 [0.26363862]
 [0.26353265]
 [0.26347301]
 [0.26357827]
 [0.26356767]
 [0.26367647]
 [0.26366834]
 [0.26360334]
 [0.263578  ]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[1.         0.72289319 0.59271485 1.         1.         1.
 0.81907535 1.         0.65081312 1.         0.         0.
 0.         0.         0.         0.26270325 0.         0.
 0.         1.         1.         0.         1.         0.
 0.         0.         0.         0.62134537 0.         0.35901481
 0.68497483 0.67343939 0.         0.         0.        ]
wv_std shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
xy shape: (35, 9)
[[0.         0.         0.         0.         0.26294405 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.26294997 1.
  0.72289319 1.         0.        ]
 [0.         0.         0.         0.         0.26294665 1.
  0.59271485 1.         0.        ]
 [0.         0.         0.         0.         0.26291802 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.26294813 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.26290879 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.26294306 1.
  0.81907535 1.         0.        ]
 [0.         0.         0.         0.         0.26294742 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.2629382  1.
  0.65081312 1.         0.        ]
 [0.         0.         0.         0.         0.26294506 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.26365803 1.
  0.         0.         1.        ]
 [1.         0.         0.74866106 0.95365912 0.26363982 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.263657   1.
  0.         0.         1.        ]
 [1.         0.27287087 1.         1.         0.26370423 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.26368453 1.
  0.         0.         1.        ]
 [1.         0.         0.49913714 0.79396094 0.26358136 1.
  0.26270325 0.         1.        ]
 [1.         0.33139584 0.         0.22881585 0.263584   1.
  0.         0.         1.        ]
 [1.         1.         0.58009386 0.79603524 0.2635331  1.
  0.         0.         1.        ]
 [1.         0.         0.04731442 0.17618919 0.26364337 1.
  0.         0.         1.        ]
 [0.         1.         0.         0.         0.26362424 1.
  1.         0.         1.        ]
 [1.         0.         1.         1.         0.26363061 1.
  1.         0.         1.        ]
 [1.         0.         1.         1.         0.2635695  1.
  0.         0.         1.        ]
 [1.         0.         0.42472284 0.17824064 0.26367344 1.
  1.         0.         1.        ]
 [1.         0.         0.77679954 0.77693264 0.26372157 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.26361394 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.26365951 1.
  0.         0.         1.        ]
 [1.         1.         0.         0.         0.26363862 1.
  0.         0.         1.        ]
 [1.         1.         0.73579896 0.71198688 0.26353265 1.
  0.62134537 0.         1.        ]
 [1.         1.         0.38668451 0.86043294 0.26347301 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.26357827 1.
  0.35901481 0.         1.        ]
 [1.         1.         1.         1.         0.26356767 1.
  0.68497483 0.         1.        ]
 [1.         0.31320115 0.         0.         0.26367647 1.
  0.67343939 0.         1.        ]
 [1.         0.         0.72601388 1.         0.26366834 1.
  0.         0.         1.        ]
 [1.         0.         0.10058095 0.51820411 0.26360334 1.
  0.         0.         1.        ]
 [1.         0.08363249 1.         1.         0.263578   1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.30000001192092896
#####################         POISON         ###############################################

############################################################################################

comm_round: 18 | global_test_acc: 75.000% | global_f1: 0.8571428571428571 | global_precision: 0.75
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.75      1.00      0.86         9

    accuracy                           0.75        12
   macro avg       0.38      0.50      0.43        12
weighted avg       0.56      0.75      0.64        12
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1.]
wv_fg shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 1.         0.         0.         1.         0.         0.5998748
 0.         0.37997418 0.         0.77845462 0.75439409 0.
 0.         0.         0.         0.         0.         0.
 0.         0.4517374  0.         0.         0.        ]
wv_mn shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.13799835 0.         0.         1.         0.
 0.96727648 0.         1.         1.         0.         0.
 0.         0.1250209  0.88521399 1.         0.06689318 0.
 1.         0.23262522 0.45196776 1.         0.44014602 1.
 1.         1.         0.67084427 0.         1.        ]
wv_ed shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.02490943 0.         0.         1.         0.
 1.         0.         0.65871543 0.47210039 0.         0.
 0.46992689 0.         0.20897701 1.         1.         0.
 1.         0.49509612 1.         1.         1.         1.
 1.         1.         1.         0.         1.        ]
wv_lg shape (35, 1)
[[0.26342019]
 [0.26340622]
 [0.26339271]
 [0.26341572]
 [0.26341125]
 [0.26343078]
 [0.26340476]
 [0.26340805]
 [0.26338459]
 [0.26342274]
 [0.26412328]
 [0.26408878]
 [0.26407366]
 [0.26411501]
 [0.26417188]
 [0.26410653]
 [0.2641112 ]
 [0.26412949]
 [0.2640839 ]
 [0.26406669]
 [0.26415309]
 [0.26413987]
 [0.26405867]
 [0.26412495]
 [0.26406987]
 [0.26416256]
 [0.2640171 ]
 [0.26409511]
 [0.26402615]
 [0.26412425]
 [0.2641173 ]
 [0.26403775]
 [0.26402026]
 [0.26410873]
 [0.26405879]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[0.84695673 0.24437354 0.0411331  0.4686893  0.28721245 0.36333144
 0.35657839 0.1798686  0.48782084 0.2945638  0.         0.
 0.         0.         0.47355595 1.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.64020916 0.07944085 0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_std shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
xy shape: (35, 9)
[[0.         0.         0.         0.         0.26342019 1.
  0.84695673 1.         0.        ]
 [0.         0.         0.         0.         0.26340622 1.
  0.24437354 1.         0.        ]
 [0.         0.         0.         0.         0.26339271 1.
  0.0411331  1.         0.        ]
 [0.         0.         0.         0.         0.26341572 1.
  0.4686893  1.         0.        ]
 [0.         0.         0.         0.         0.26341125 1.
  0.28721245 1.         0.        ]
 [0.         0.         0.         0.         0.26343078 1.
  0.36333144 1.         0.        ]
 [0.         0.         0.         0.         0.26340476 1.
  0.35657839 1.         0.        ]
 [0.         0.         0.13799835 0.02490943 0.26340805 1.
  0.1798686  1.         0.        ]
 [0.         0.         0.         0.         0.26338459 1.
  0.48782084 1.         0.        ]
 [0.         0.         0.         0.         0.26342274 1.
  0.2945638  1.         0.        ]
 [1.         0.         1.         1.         0.26412328 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.26408878 1.
  0.         0.         1.        ]
 [1.         1.         0.96727648 1.         0.26407366 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.26411501 1.
  0.         0.         1.        ]
 [1.         0.         1.         0.65871543 0.26417188 1.
  0.47355595 0.         1.        ]
 [1.         1.         1.         0.47210039 0.26410653 1.
  1.         0.         1.        ]
 [0.         0.         0.         0.         0.2641112  1.
  0.         0.         1.        ]
 [0.         0.5998748  0.         0.         0.26412949 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.46992689 0.2640839  1.
  0.         0.         1.        ]
 [1.         0.37997418 0.1250209  0.         0.26406669 1.
  0.         0.         1.        ]
 [1.         0.         0.88521399 0.20897701 0.26415309 1.
  0.         0.         1.        ]
 [1.         0.77845462 1.         1.         0.26413987 1.
  0.         0.         1.        ]
 [1.         0.75439409 0.06689318 1.         0.26405867 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.26412495 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.26406987 1.
  0.64020916 0.         1.        ]
 [1.         0.         0.23262522 0.49509612 0.26416256 1.
  0.07944085 0.         1.        ]
 [1.         0.         0.45196776 1.         0.2640171  1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.26409511 1.
  0.         0.         1.        ]
 [1.         0.         0.44014602 1.         0.26402615 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.26412425 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.2641173  1.
  0.         0.         1.        ]
 [1.         0.4517374  1.         1.         0.26403775 1.
  0.         0.         1.        ]
 [1.         0.         0.67084427 1.         0.26402026 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.26410873 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.26405879 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.6000000238418579
#####################         POISON         ###############################################

############################################################################################

comm_round: 19 | global_test_acc: 83.333% | global_f1: 0.9090909090909091 | global_precision: 0.8333333333333334
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.83      1.00      0.91        10

    accuracy                           0.83        12
   macro avg       0.42      0.50      0.45        12
weighted avg       0.69      0.83      0.76        12
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1.
 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1.]
wv_fg shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         1.         0.         0.
 0.         0.73236021 0.04626951 1.         0.         0.
 0.         0.         0.         0.         0.         1.
 0.20259192 0.         0.         0.         0.        ]
wv_mn shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         1.
 0.2368091  1.         1.         1.         0.10933133 1.
 0.         1.         0.         0.         0.47888697 0.32854529
 0.6348102  1.         1.         1.         0.53762426 0.
 0.19252797 0.36862668 1.         0.82707318 0.6884566 ]
wv_ed shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         1.
 0.23805493 1.         1.         0.99189787 0.         0.81865871
 0.         0.71112664 0.         0.         0.39125411 0.47656747
 0.30590168 1.         1.         1.         0.39419377 0.
 0.56548618 0.22499325 1.         0.74225165 0.39334589]
wv_lg shape (35, 1)
[[0.26387823]
 [0.26390343]
 [0.26387198]
 [0.26390084]
 [0.26386604]
 [0.26390176]
 [0.26388125]
 [0.26391022]
 [0.26390503]
 [0.2638822 ]
 [0.26461824]
 [0.26461137]
 [0.26455031]
 [0.26458198]
 [0.26459072]
 [0.26458592]
 [0.26458723]
 [0.26463213]
 [0.26461185]
 [0.26463723]
 [0.26465039]
 [0.26462375]
 [0.26460561]
 [0.26458981]
 [0.26461714]
 [0.26455926]
 [0.26455355]
 [0.2645393 ]
 [0.26459974]
 [0.26454374]
 [0.26455354]
 [0.26461058]
 [0.26450694]
 [0.26454559]
 [0.26456836]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.31377273 0.
 0.78301951 0.52179905 1.         0.58694857 1.         1.
 0.54771248 1.         1.         0.77443074 1.         1.
 1.         1.         0.88814696 0.7423457  1.         0.
 0.         1.         1.         1.         0.0215576 ]
wv_std shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
xy shape: (35, 9)
[[0.         0.         0.         0.         0.26387823 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.26390343 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.26387198 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.26390084 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.26386604 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.26390176 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.26388125 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.26391022 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.26390503 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.2638822  1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.26461824 1.
  0.31377273 0.         1.        ]
 [1.         0.         1.         1.         0.26461137 1.
  0.         0.         1.        ]
 [1.         0.         0.2368091  0.23805493 0.26455031 1.
  0.78301951 0.         1.        ]
 [1.         0.         1.         1.         0.26458198 1.
  0.52179905 0.         1.        ]
 [1.         0.         1.         1.         0.26459072 1.
  1.         0.         1.        ]
 [1.         1.         1.         0.99189787 0.26458592 1.
  0.58694857 0.         1.        ]
 [1.         0.         0.10933133 0.         0.26458723 1.
  1.         0.         1.        ]
 [1.         0.         1.         0.81865871 0.26463213 1.
  1.         0.         1.        ]
 [0.         0.         0.         0.         0.26461185 1.
  0.54771248 0.         1.        ]
 [1.         0.73236021 1.         0.71112664 0.26463723 1.
  1.         0.         1.        ]
 [0.         0.04626951 0.         0.         0.26465039 1.
  1.         0.         1.        ]
 [0.         1.         0.         0.         0.26462375 1.
  0.77443074 0.         1.        ]
 [1.         0.         0.47888697 0.39125411 0.26460561 1.
  1.         0.         1.        ]
 [1.         0.         0.32854529 0.47656747 0.26458981 1.
  1.         0.         1.        ]
 [1.         0.         0.6348102  0.30590168 0.26461714 1.
  1.         0.         1.        ]
 [1.         0.         1.         1.         0.26455926 1.
  1.         0.         1.        ]
 [1.         0.         1.         1.         0.26455355 1.
  0.88814696 0.         1.        ]
 [1.         0.         1.         1.         0.2645393  1.
  0.7423457  0.         1.        ]
 [1.         0.         0.53762426 0.39419377 0.26459974 1.
  1.         0.         1.        ]
 [0.         1.         0.         0.         0.26454374 1.
  0.         0.         1.        ]
 [1.         0.20259192 0.19252797 0.56548618 0.26455354 1.
  0.         0.         1.        ]
 [1.         0.         0.36862668 0.22499325 0.26461058 1.
  1.         0.         1.        ]
 [1.         0.         1.         1.         0.26450694 1.
  1.         0.         1.        ]
 [1.         0.         0.82707318 0.74225165 0.26454559 1.
  1.         0.         1.        ]
 [1.         0.         0.6884566  0.39334589 0.26456836 1.
  0.0215576  0.         1.        ]]

Best Training Poisoning Accuracy:
0.699999988079071
#####################         POISON         ###############################################

############################################################################################

comm_round: 20 | global_test_acc: 75.000% | global_f1: 0.8571428571428571 | global_precision: 0.75
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.75      1.00      0.86         9

    accuracy                           0.75        12
   macro avg       0.38      0.50      0.43        12
weighted avg       0.56      0.75      0.64        12
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_fg shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.22187253 0.49882085
 1.         1.         0.         0.         0.22187253 0.
 0.         1.         0.         1.         0.         0.
 0.         0.         0.11483713 0.         0.         1.
 0.29036956 0.         0.         0.         0.        ]
wv_mn shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.62506782 0.01226145 0.         0.04381762 0.
 0.54162707 0.74027818 0.13797944 1.         0.         0.
 0.86786368 1.         1.         1.         0.         0.76754833
 0.         1.         0.60980209 0.65755418 1.        ]
wv_ed shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         1.         0.08761504 0.         0.46792089 0.
 0.58647108 1.         0.75531206 1.         0.         0.
 1.         1.         1.         1.         0.00189716 1.
 0.         1.         0.77874215 1.         1.        ]
wv_lg shape (35, 1)
[[0.26439798]
 [0.26433461]
 [0.26438355]
 [0.26437172]
 [0.26435328]
 [0.2644013 ]
 [0.26434298]
 [0.2643599 ]
 [0.2643063 ]
 [0.26435181]
 [0.26498509]
 [0.26513099]
 [0.26507989]
 [0.26500273]
 [0.26508319]
 [0.26506237]
 [0.26495202]
 [0.26502386]
 [0.2651051 ]
 [0.26505834]
 [0.26519423]
 [0.26504054]
 [0.2651185 ]
 [0.26500724]
 [0.26504125]
 [0.26505422]
 [0.26505456]
 [0.26507053]
 [0.26506075]
 [0.26506282]
 [0.26513529]
 [0.26513885]
 [0.26503122]
 [0.26505206]
 [0.26507193]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[0.97856003 0.46594122 0.46819858 1.         0.35131952 0.74769449
 0.81572554 0.27159215 0.98333262 0.6598181  0.34761431 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.03951115 1.         0.66922253 0.
 0.         0.         0.         0.         0.37827595 0.83962736
 0.         0.32454222 0.1092031  0.         0.        ]
wv_std shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
xy shape: (35, 9)
[[0.         0.         0.         0.         0.26439798 1.
  0.97856003 1.         0.        ]
 [0.         0.         0.         0.         0.26433461 1.
  0.46594122 1.         0.        ]
 [0.         0.         0.         0.         0.26438355 1.
  0.46819858 1.         0.        ]
 [0.         0.         0.         0.         0.26437172 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.26435328 1.
  0.35131952 1.         0.        ]
 [0.         0.         0.         0.         0.2644013  1.
  0.74769449 1.         0.        ]
 [0.         0.         0.         0.         0.26434298 1.
  0.81572554 1.         0.        ]
 [0.         0.         0.         0.         0.2643599  1.
  0.27159215 1.         0.        ]
 [0.         0.         0.         0.         0.2643063  1.
  0.98333262 1.         0.        ]
 [0.         0.         0.         0.         0.26435181 1.
  0.6598181  1.         0.        ]
 [0.         0.22187253 0.         0.         0.26498509 1.
  0.34761431 0.         1.        ]
 [1.         0.49882085 0.         0.         0.26513099 1.
  0.         0.         1.        ]
 [0.         1.         0.         0.         0.26507989 1.
  0.         0.         1.        ]
 [1.         1.         0.62506782 1.         0.26500273 1.
  0.         0.         1.        ]
 [1.         0.         0.01226145 0.08761504 0.26508319 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.26506237 1.
  0.         0.         1.        ]
 [1.         0.22187253 0.04381762 0.46792089 0.26495202 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.26502386 1.
  0.         0.         1.        ]
 [1.         0.         0.54162707 0.58647108 0.2651051  1.
  0.         0.         1.        ]
 [1.         1.         0.74027818 1.         0.26505834 1.
  0.         0.         1.        ]
 [1.         0.         0.13797944 0.75531206 0.26519423 1.
  0.03951115 0.         1.        ]
 [1.         1.         1.         1.         0.26504054 1.
  1.         0.         1.        ]
 [0.         0.         0.         0.         0.2651185  1.
  0.66922253 0.         1.        ]
 [1.         0.         0.         0.         0.26500724 1.
  0.         0.         1.        ]
 [1.         0.         0.86786368 1.         0.26504125 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.26505422 1.
  0.         0.         1.        ]
 [1.         0.11483713 1.         1.         0.26505456 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.26507053 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.00189716 0.26506075 1.
  0.37827595 0.         1.        ]
 [1.         1.         0.76754833 1.         0.26506282 1.
  0.83962736 0.         1.        ]
 [1.         0.29036956 0.         0.         0.26513529 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.26513885 1.
  0.32454222 0.         1.        ]
 [1.         0.         0.60980209 0.77874215 0.26503122 1.
  0.1092031  0.         1.        ]
 [1.         0.         0.65755418 1.         0.26505206 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.26507193 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.699999988079071
#####################         POISON         ###############################################

############################################################################################

comm_round: 21 | global_test_acc: 75.000% | global_f1: 0.8571428571428571 | global_precision: 0.75
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.75      1.00      0.86         9

    accuracy                           0.75        12
   macro avg       0.38      0.50      0.43        12
weighted avg       0.56      0.75      0.64        12
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_fg shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.22509561 0.67008739
 0.         0.         1.         0.31938446 1.         0.
 0.         0.         0.         0.         0.09717869 0.
 0.         0.84177361 1.         0.         0.89554818 0.
 0.         0.         0.         0.         0.        ]
wv_mn shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         1.         1.
 1.         1.         1.         1.         0.         0.25302138
 1.         1.         1.         1.         0.53779049 1.
 0.1459882  0.69566597 1.         0.59764832 1.         1.
 1.         1.         1.         1.         1.        ]
wv_ed shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.74000297 1.
 1.         1.         1.         1.         0.         0.
 1.         0.3305792  1.         1.         0.         0.38248145
 0.         0.8773276  1.         0.         1.         1.
 1.         1.         1.         1.         0.40295708]
wv_lg shape (35, 1)
[[0.26483096]
 [0.26485866]
 [0.26484332]
 [0.26487124]
 [0.26483721]
 [0.26485447]
 [0.26486073]
 [0.26484694]
 [0.26485868]
 [0.2648623 ]
 [0.26558635]
 [0.26546314]
 [0.26550813]
 [0.26552203]
 [0.26552529]
 [0.26552743]
 [0.2655709 ]
 [0.26557768]
 [0.26560647]
 [0.26555133]
 [0.26549276]
 [0.26562751]
 [0.26554089]
 [0.26552951]
 [0.26551958]
 [0.26558339]
 [0.26551543]
 [0.26558347]
 [0.26542667]
 [0.26554049]
 [0.26551853]
 [0.2655219 ]
 [0.26553471]
 [0.2655471 ]
 [0.26559991]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.28160143 0.84088418
 0.21547982 0.77322373 0.         1.         0.         1.
 0.50908887 1.         0.         0.69680443 0.47126417 0.70150165
 0.20965819 0.06952951 0.10890002 1.         1.         1.
 1.         0.96158995 1.         0.58796255 0.89826552]
wv_std shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
xy shape: (35, 9)
[[0.         0.         0.         0.         0.26483096 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.26485866 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.26484332 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.26487124 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.26483721 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.26485447 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.26486073 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.26484694 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.26485868 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.2648623  1.
  1.         1.         0.        ]
 [1.         0.22509561 1.         0.74000297 0.26558635 1.
  0.28160143 0.         1.        ]
 [1.         0.67008739 1.         1.         0.26546314 1.
  0.84088418 0.         1.        ]
 [1.         0.         1.         1.         0.26550813 1.
  0.21547982 0.         1.        ]
 [1.         0.         1.         1.         0.26552203 1.
  0.77322373 0.         1.        ]
 [1.         1.         1.         1.         0.26552529 1.
  0.         0.         1.        ]
 [1.         0.31938446 1.         1.         0.26552743 1.
  1.         0.         1.        ]
 [0.         1.         0.         0.         0.2655709  1.
  0.         0.         1.        ]
 [0.         0.         0.25302138 0.         0.26557768 1.
  1.         0.         1.        ]
 [1.         0.         1.         1.         0.26560647 1.
  0.50908887 0.         1.        ]
 [1.         0.         1.         0.3305792  0.26555133 1.
  1.         0.         1.        ]
 [1.         0.         1.         1.         0.26549276 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.26562751 1.
  0.69680443 0.         1.        ]
 [1.         0.09717869 0.53779049 0.         0.26554089 1.
  0.47126417 0.         1.        ]
 [1.         0.         1.         0.38248145 0.26552951 1.
  0.70150165 0.         1.        ]
 [1.         0.         0.1459882  0.         0.26551958 1.
  0.20965819 0.         1.        ]
 [1.         0.84177361 0.69566597 0.8773276  0.26558339 1.
  0.06952951 0.         1.        ]
 [1.         1.         1.         1.         0.26551543 1.
  0.10890002 0.         1.        ]
 [1.         0.         0.59764832 0.         0.26558347 1.
  1.         0.         1.        ]
 [1.         0.89554818 1.         1.         0.26542667 1.
  1.         0.         1.        ]
 [1.         0.         1.         1.         0.26554049 1.
  1.         0.         1.        ]
 [1.         0.         1.         1.         0.26551853 1.
  1.         0.         1.        ]
 [1.         0.         1.         1.         0.2655219  1.
  0.96158995 0.         1.        ]
 [1.         0.         1.         1.         0.26553471 1.
  1.         0.         1.        ]
 [1.         0.         1.         1.         0.2655471  1.
  0.58796255 0.         1.        ]
 [1.         0.         1.         0.40295708 0.26559991 1.
  0.89826552 0.         1.        ]]

Best Training Poisoning Accuracy:
0.699999988079071
#####################         POISON         ###############################################

############################################################################################

comm_round: 22 | global_test_acc: 75.000% | global_f1: 0.8571428571428571 | global_precision: 0.75
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.75      1.00      0.86         9

    accuracy                           0.75        12
   macro avg       0.38      0.50      0.43        12
weighted avg       0.56      0.75      0.64        12
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1.
 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_fg shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.62367235 0.         1.         0.         0.         0.
 1.         0.         1.         1.         0.         1.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_mn shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.04934869 0.         0.26507708 0.         0.
 0.         0.         0.         0.01104092 0.46770956 0.13067369
 0.         1.         0.         0.61011776 0.         0.82035171
 1.         0.04089823 0.         0.20223002 0.64494097]
wv_ed shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.07285347 0.2338684  0.35648971 0.         0.
 0.         0.         0.         0.         0.41182779 0.
 0.         1.         0.         1.         0.         0.95273243
 1.         0.         0.         0.78286456 0.24720757]
wv_lg shape (35, 1)
[[0.26532235]
 [0.26533464]
 [0.26530278]
 [0.26530936]
 [0.26533892]
 [0.26533868]
 [0.26533194]
 [0.26533527]
 [0.26534312]
 [0.26532975]
 [0.26604547]
 [0.26601208]
 [0.2660349 ]
 [0.26603295]
 [0.26603016]
 [0.26604784]
 [0.26598103]
 [0.26608042]
 [0.26593674]
 [0.26598232]
 [0.26602509]
 [0.26612542]
 [0.26599224]
 [0.26594808]
 [0.26607377]
 [0.26597716]
 [0.26600345]
 [0.26602525]
 [0.26603568]
 [0.26598552]
 [0.26597388]
 [0.26603134]
 [0.26603452]
 [0.26603024]
 [0.26601945]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[0.82197126 1.         0.56924844 1.         1.         0.97937265
 1.         0.36505242 1.         0.94426641 0.04622351 0.
 1.         0.39717558 0.         0.6331482  0.         0.
 0.         0.         0.         1.         0.         0.39016662
 0.01493525 0.         0.65184356 0.54478095 0.         0.
 0.3944096  0.07707403 1.         0.3019847  1.        ]
wv_std shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
xy shape: (35, 9)
[[0.         0.         0.         0.         0.26532235 1.
  0.82197126 1.         0.        ]
 [0.         0.         0.         0.         0.26533464 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.26530278 1.
  0.56924844 1.         0.        ]
 [0.         0.         0.         0.         0.26530936 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.26533892 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.26533868 1.
  0.97937265 1.         0.        ]
 [0.         0.         0.         0.         0.26533194 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.26533527 1.
  0.36505242 1.         0.        ]
 [0.         0.         0.         0.         0.26534312 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.26532975 1.
  0.94426641 1.         0.        ]
 [1.         0.         0.         0.         0.26604547 1.
  0.04622351 0.         1.        ]
 [1.         0.         0.         0.         0.26601208 1.
  0.         0.         1.        ]
 [1.         0.62367235 0.         0.         0.2660349  1.
  1.         0.         1.        ]
 [1.         0.         0.04934869 0.07285347 0.26603295 1.
  0.39717558 0.         1.        ]
 [1.         1.         0.         0.2338684  0.26603016 1.
  0.         0.         1.        ]
 [1.         0.         0.26507708 0.35648971 0.26604784 1.
  0.6331482  0.         1.        ]
 [1.         0.         0.         0.         0.26598103 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.26608042 1.
  0.         0.         1.        ]
 [0.         1.         0.         0.         0.26593674 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.26598232 1.
  0.         0.         1.        ]
 [0.         1.         0.         0.         0.26602509 1.
  0.         0.         1.        ]
 [0.         1.         0.01104092 0.         0.26612542 1.
  1.         0.         1.        ]
 [1.         0.         0.46770956 0.41182779 0.26599224 1.
  0.         0.         1.        ]
 [1.         1.         0.13067369 0.         0.26594808 1.
  0.39016662 0.         1.        ]
 [0.         0.         0.         0.         0.26607377 1.
  0.01493525 0.         1.        ]
 [1.         0.         1.         1.         0.26597716 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.26600345 1.
  0.65184356 0.         1.        ]
 [1.         0.         0.61011776 1.         0.26602525 1.
  0.54478095 0.         1.        ]
 [1.         0.         0.         0.         0.26603568 1.
  0.         0.         1.        ]
 [1.         0.         0.82035171 0.95273243 0.26598552 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.26597388 1.
  0.3944096  0.         1.        ]
 [1.         0.         0.04089823 0.         0.26603134 1.
  0.07707403 0.         1.        ]
 [1.         0.         0.         0.         0.26603452 1.
  1.         0.         1.        ]
 [1.         0.         0.20223002 0.78286456 0.26603024 1.
  0.3019847  0.         1.        ]
 [1.         0.         0.64494097 0.24720757 0.26601945 1.
  1.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.800000011920929
#####################         POISON         ###############################################

############################################################################################

comm_round: 23 | global_test_acc: 66.667% | global_f1: 0.8 | global_precision: 0.6666666666666666
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         4
           1       0.67      1.00      0.80         8

    accuracy                           0.67        12
   macro avg       0.33      0.50      0.40        12
weighted avg       0.44      0.67      0.53        12
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 1. 1. 0. 0.
 1. 0. 1. 0. 0. 1. 1. 1. 0. 1. 1.]
wv_fg shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 1.         0.09766544 0.         0.         0.         0.
 0.         0.         0.         0.         1.        ]
wv_mn shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.14346209 0.         0.60826876
 0.69334048 0.         0.         0.         1.         0.3061237
 1.         0.12772885 1.         1.         0.         0.
 1.         0.00822918 0.70865091 0.         0.         1.
 0.6700212  0.51024909 0.         0.83190097 0.73223974]
wv_ed shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.0761144  0.         0.
 0.35665227 0.         0.         0.         0.62535232 0.79201175
 1.         0.         1.         1.         0.         0.
 1.         0.         0.38441434 0.         0.         1.
 0.72251515 0.67115014 0.         1.         0.84999858]
wv_lg shape (35, 1)
[[0.26579457]
 [0.26580167]
 [0.26580359]
 [0.26581011]
 [0.26581369]
 [0.26581878]
 [0.26578518]
 [0.2658029 ]
 [0.26580893]
 [0.2658147 ]
 [0.26652273]
 [0.26646808]
 [0.26650022]
 [0.26652774]
 [0.2664908 ]
 [0.26651607]
 [0.26651875]
 [0.26646489]
 [0.26636206]
 [0.26646797]
 [0.26646575]
 [0.26647956]
 [0.2665173 ]
 [0.26646183]
 [0.26643072]
 [0.26649738]
 [0.26648879]
 [0.26641265]
 [0.26654112]
 [0.26646332]
 [0.26655131]
 [0.2664317 ]
 [0.26646995]
 [0.26648667]
 [0.2665793 ]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[1.         0.56595585 0.56255642 0.61984924 1.         1.
 0.83973179 0.52412419 0.47673048 0.31849767 0.37755688 1.
 0.03847338 0.         0.         0.         0.11471541 0.
 0.         1.         0.68442747 0.         1.         0.
 0.1969729  0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_std shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
xy shape: (35, 9)
[[0.         0.         0.         0.         0.26579457 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.26580167 1.
  0.56595585 1.         0.        ]
 [0.         0.         0.         0.         0.26580359 1.
  0.56255642 1.         0.        ]
 [0.         0.         0.         0.         0.26581011 1.
  0.61984924 1.         0.        ]
 [0.         0.         0.         0.         0.26581369 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.26581878 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.26578518 1.
  0.83973179 1.         0.        ]
 [0.         0.         0.         0.         0.2658029  1.
  0.52412419 1.         0.        ]
 [0.         0.         0.         0.         0.26580893 1.
  0.47673048 1.         0.        ]
 [0.         0.         0.14346209 0.0761144  0.2658147  1.
  0.31849767 1.         0.        ]
 [0.         0.         0.         0.         0.26652273 1.
  0.37755688 0.         1.        ]
 [1.         0.         0.60826876 0.         0.26646808 1.
  1.         0.         1.        ]
 [1.         0.         0.69334048 0.35665227 0.26650022 1.
  0.03847338 0.         1.        ]
 [0.         0.         0.         0.         0.26652774 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.2664908  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.26651607 1.
  0.         0.         1.        ]
 [1.         0.         1.         0.62535232 0.26651875 1.
  0.11471541 0.         1.        ]
 [1.         0.         0.3061237  0.79201175 0.26646489 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.26636206 1.
  0.         0.         1.        ]
 [0.         0.         0.12772885 0.         0.26646797 1.
  1.         0.         1.        ]
 [1.         0.         1.         1.         0.26646575 1.
  0.68442747 0.         1.        ]
 [1.         0.         1.         1.         0.26647956 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.2665173  1.
  1.         0.         1.        ]
 [0.         0.         0.         0.         0.26646183 1.
  0.         0.         1.        ]
 [1.         1.         1.         1.         0.26643072 1.
  0.1969729  0.         1.        ]
 [0.         0.09766544 0.00822918 0.         0.26649738 1.
  0.         0.         1.        ]
 [1.         0.         0.70865091 0.38441434 0.26648879 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.26641265 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.26654112 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.26646332 1.
  0.         0.         1.        ]
 [1.         0.         0.6700212  0.72251515 0.26655131 1.
  0.         0.         1.        ]
 [1.         0.         0.51024909 0.67115014 0.2664317  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.26646995 1.
  0.         0.         1.        ]
 [1.         0.         0.83190097 1.         0.26648667 1.
  0.         0.         1.        ]
 [1.         1.         0.73223974 0.84999858 0.2665793  1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.6499999761581421
#####################         POISON         ###############################################

############################################################################################

comm_round: 24 | global_test_acc: 75.000% | global_f1: 0.8571428571428571 | global_precision: 0.75
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.75      1.00      0.86         9

    accuracy                           0.75        12
   macro avg       0.38      0.50      0.43        12
weighted avg       0.56      0.75      0.64        12
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_fg shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.69305329 0.15301445
 0.         0.         0.         0.         0.50420102 0.22622312
 0.         0.24220791 1.         0.44519451 0.         0.
 0.         0.         0.         1.         0.        ]
wv_mn shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         1.         0.
 1.         0.         0.         0.37627947 0.         0.
 0.26686394 0.         0.20878019 0.         1.         1.
 0.36619102 0.         0.         0.         0.11939594 1.
 0.87758549 0.02468493 0.99841954 0.         1.        ]
wv_ed shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         1.         0.22822872
 1.         0.         0.         0.7114734  0.65585127 0.
 0.10089749 0.         0.25643372 0.1650737  1.         1.
 0.58504552 0.00728257 0.57580852 0.20252084 0.36097987 1.
 0.94169957 0.78515284 0.80961238 0.         1.        ]
wv_lg shape (35, 1)
[[0.26624704]
 [0.26626071]
 [0.26627321]
 [0.26627979]
 [0.26629028]
 [0.26626304]
 [0.26626249]
 [0.26626185]
 [0.26625603]
 [0.26626814]
 [0.26693226]
 [0.26688547]
 [0.26688527]
 [0.26697121]
 [0.26684942]
 [0.26699972]
 [0.26692647]
 [0.26702898]
 [0.26700281]
 [0.26700738]
 [0.26692719]
 [0.26691846]
 [0.26695741]
 [0.26682582]
 [0.26688333]
 [0.26689298]
 [0.26684496]
 [0.26696459]
 [0.26705448]
 [0.26697509]
 [0.26699002]
 [0.26697694]
 [0.2670154 ]
 [0.26700346]
 [0.26692821]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[1.         0.8057929  0.86385194 0.94583548 0.75909825 0.90725832
 1.         0.72455093 1.         1.         0.18914201 0.
 1.         0.         0.         0.         0.         1.
 1.         0.52767804 0.         0.32857922 1.         1.
 0.         0.         0.         0.71051949 0.         0.45351341
 0.28795659 0.         0.         1.         0.63678551]
wv_std shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
xy shape: (35, 9)
[[0.         0.         0.         0.         0.26624704 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.26626071 1.
  0.8057929  1.         0.        ]
 [0.         0.         0.         0.         0.26627321 1.
  0.86385194 1.         0.        ]
 [0.         0.         0.         0.         0.26627979 1.
  0.94583548 1.         0.        ]
 [0.         0.         0.         0.         0.26629028 1.
  0.75909825 1.         0.        ]
 [0.         0.         0.         0.         0.26626304 1.
  0.90725832 1.         0.        ]
 [0.         0.         0.         0.         0.26626249 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.26626185 1.
  0.72455093 1.         0.        ]
 [0.         0.         0.         0.         0.26625603 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.26626814 1.
  1.         1.         0.        ]
 [1.         0.         1.         1.         0.26693226 1.
  0.18914201 0.         1.        ]
 [1.         0.         0.         0.22822872 0.26688547 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.26688527 1.
  1.         0.         1.        ]
 [0.         0.         0.         0.         0.26697121 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.26684942 1.
  0.         0.         1.        ]
 [1.         0.         0.37627947 0.7114734  0.26699972 1.
  0.         0.         1.        ]
 [1.         0.69305329 0.         0.65585127 0.26692647 1.
  0.         0.         1.        ]
 [1.         0.15301445 0.         0.         0.26702898 1.
  1.         0.         1.        ]
 [1.         0.         0.26686394 0.10089749 0.26700281 1.
  1.         0.         1.        ]
 [0.         0.         0.         0.         0.26700738 1.
  0.52767804 0.         1.        ]
 [1.         0.         0.20878019 0.25643372 0.26692719 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.1650737  0.26691846 1.
  0.32857922 0.         1.        ]
 [1.         0.50420102 1.         1.         0.26695741 1.
  1.         0.         1.        ]
 [1.         0.22622312 1.         1.         0.26682582 1.
  1.         0.         1.        ]
 [1.         0.         0.36619102 0.58504552 0.26688333 1.
  0.         0.         1.        ]
 [1.         0.24220791 0.         0.00728257 0.26689298 1.
  0.         0.         1.        ]
 [1.         1.         0.         0.57580852 0.26684496 1.
  0.         0.         1.        ]
 [1.         0.44519451 0.         0.20252084 0.26696459 1.
  0.71051949 0.         1.        ]
 [1.         0.         0.11939594 0.36097987 0.26705448 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.26697509 1.
  0.45351341 0.         1.        ]
 [1.         0.         0.87758549 0.94169957 0.26699002 1.
  0.28795659 0.         1.        ]
 [1.         0.         0.02468493 0.78515284 0.26697694 1.
  0.         0.         1.        ]
 [1.         0.         0.99841954 0.80961238 0.2670154  1.
  0.         0.         1.        ]
 [1.         1.         0.         0.         0.26700346 1.
  1.         0.         1.        ]
 [1.         0.         1.         1.         0.26692821 1.
  0.63678551 0.         1.        ]]

Best Training Poisoning Accuracy:
0.75
#####################         POISON         ###############################################

############################################################################################

comm_round: 25 | global_test_acc: 58.333% | global_f1: 0.7368421052631579 | global_precision: 0.5833333333333334
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         5
           1       0.58      1.00      0.74         7

    accuracy                           0.58        12
   macro avg       0.29      0.50      0.37        12
weighted avg       0.34      0.58      0.43        12
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1.
 1. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1.]
wv_fg shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         1.         0.
 0.         0.         1.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.55611494 0.         1.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_mn shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.03989236 0.
 0.01392366 0.         0.         0.         0.         0.6675365
 0.3738643  0.         0.         0.03518604 0.07976565 0.57108713
 1.         0.         0.         0.         0.         0.46654379
 0.         0.93977507 0.         0.         0.24864985]
wv_ed shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.50042987 0.
 0.12056076 0.         0.         0.         0.         0.96126854
 0.59909278 0.         0.         0.         0.         0.83265229
 1.         0.         0.         0.         0.         0.21951047
 0.         0.97413664 0.         0.14655954 0.46879922]
wv_lg shape (35, 1)
[[0.26672862]
 [0.2667349 ]
 [0.26673979]
 [0.26671474]
 [0.26674541]
 [0.26673734]
 [0.26673319]
 [0.26672235]
 [0.26669664]
 [0.26673193]
 [0.26736754]
 [0.26741989]
 [0.26750733]
 [0.26742907]
 [0.2675379 ]
 [0.26737018]
 [0.26740644]
 [0.26735154]
 [0.26739974]
 [0.26740551]
 [0.26740602]
 [0.26742058]
 [0.26741841]
 [0.26745817]
 [0.26736495]
 [0.26738276]
 [0.26739294]
 [0.26738624]
 [0.26746671]
 [0.26743271]
 [0.26732652]
 [0.2673662 ]
 [0.26739117]
 [0.26734323]
 [0.26745094]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[0.69827679 0.47603785 0.21558176 0.07407494 0.55858753 0.19963891
 0.61494373 0.45078445 0.79818628 0.89437598 0.         0.55619729
 0.         0.         0.48146118 0.         0.09571506 0.68058904
 0.         0.         0.         0.19803447 0.         0.
 1.         1.         0.         1.         1.         0.16126186
 0.12414647 0.         0.60426331 0.02605026 0.        ]
wv_std shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
xy shape: (35, 9)
[[0.         0.         0.         0.         0.26672862 1.
  0.69827679 1.         0.        ]
 [0.         0.         0.         0.         0.2667349  1.
  0.47603785 1.         0.        ]
 [0.         0.         0.         0.         0.26673979 1.
  0.21558176 1.         0.        ]
 [0.         0.         0.         0.         0.26671474 1.
  0.07407494 1.         0.        ]
 [0.         0.         0.         0.         0.26674541 1.
  0.55858753 1.         0.        ]
 [0.         0.         0.         0.         0.26673734 1.
  0.19963891 1.         0.        ]
 [0.         0.         0.         0.         0.26673319 1.
  0.61494373 1.         0.        ]
 [0.         0.         0.         0.         0.26672235 1.
  0.45078445 1.         0.        ]
 [0.         0.         0.         0.         0.26669664 1.
  0.79818628 1.         0.        ]
 [0.         0.         0.         0.         0.26673193 1.
  0.89437598 1.         0.        ]
 [1.         1.         0.03989236 0.50042987 0.26736754 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.26741989 1.
  0.55619729 0.         1.        ]
 [1.         0.         0.01392366 0.12056076 0.26750733 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.26742907 1.
  0.         0.         1.        ]
 [0.         1.         0.         0.         0.2675379  1.
  0.48146118 0.         1.        ]
 [0.         0.         0.         0.         0.26737018 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.26740644 1.
  0.09571506 0.         1.        ]
 [1.         0.         0.6675365  0.96126854 0.26735154 1.
  0.68058904 0.         1.        ]
 [1.         0.         0.3738643  0.59909278 0.26739974 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.26740551 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.26740602 1.
  0.         0.         1.        ]
 [0.         0.         0.03518604 0.         0.26742058 1.
  0.19803447 0.         1.        ]
 [0.         0.         0.07976565 0.         0.26741841 1.
  0.         0.         1.        ]
 [1.         0.         0.57108713 0.83265229 0.26745817 1.
  0.         0.         1.        ]
 [1.         0.55611494 1.         1.         0.26736495 1.
  1.         0.         1.        ]
 [0.         0.         0.         0.         0.26738276 1.
  1.         0.         1.        ]
 [0.         1.         0.         0.         0.26739294 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.26738624 1.
  1.         0.         1.        ]
 [0.         0.         0.         0.         0.26746671 1.
  1.         0.         1.        ]
 [1.         0.         0.46654379 0.21951047 0.26743271 1.
  0.16126186 0.         1.        ]
 [0.         0.         0.         0.         0.26732652 1.
  0.12414647 0.         1.        ]
 [1.         0.         0.93977507 0.97413664 0.2673662  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.26739117 1.
  0.60426331 0.         1.        ]
 [1.         0.         0.         0.14655954 0.26734323 1.
  0.02605026 0.         1.        ]
 [1.         0.         0.24864985 0.46879922 0.26745094 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.699999988079071
#####################         POISON         ###############################################

############################################################################################

comm_round: 26 | global_test_acc: 66.667% | global_f1: 0.8 | global_precision: 0.6666666666666666
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         4
           1       0.67      1.00      0.80         8

    accuracy                           0.67        12
   macro avg       0.33      0.50      0.40        12
weighted avg       0.44      0.67      0.53        12
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0.
 0. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1.]
wv_fg shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.03271286
 0.09645486 0.84096307 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         1.         0.         0.59366423 0.         0.
 0.         0.29342373 0.         0.02562984 0.        ]
wv_mn shape (35,)
[0.         0.         0.11248613 0.         0.         0.
 0.         0.         0.         0.         1.         0.
 0.22874713 0.         0.83768903 0.67549944 0.19735371 0.
 1.         0.87561145 1.         0.15130844 0.         0.41857404
 0.         1.         0.1280396  1.         1.         0.70884692
 0.2146494  0.20126647 0.49295666 0.65457752 1.        ]
wv_ed shape (35,)
[0.         0.         0.57145617 0.         0.         0.
 0.         0.1087178  0.         0.         1.         0.
 0.         0.         1.         0.12533382 0.         0.
 1.         0.36747854 1.         0.38534049 0.         0.
 0.04103309 1.         0.55417627 1.         0.57773378 0.6888931
 0.24939158 0.         0.61071059 0.26159413 1.        ]
wv_lg shape (35, 1)
[[0.26717009]
 [0.26719749]
 [0.26720154]
 [0.26722009]
 [0.26716918]
 [0.26719212]
 [0.26723166]
 [0.26719108]
 [0.26719756]
 [0.26719225]
 [0.26784941]
 [0.26788958]
 [0.26779734]
 [0.26780618]
 [0.26787419]
 [0.26786091]
 [0.26788611]
 [0.267905  ]
 [0.26782864]
 [0.26792508]
 [0.26794719]
 [0.26785778]
 [0.26786249]
 [0.26793798]
 [0.26792756]
 [0.26795545]
 [0.26793372]
 [0.26783129]
 [0.26794131]
 [0.26791485]
 [0.26787385]
 [0.26793052]
 [0.26788244]
 [0.26782093]
 [0.26787785]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[0.94170548 1.         0.95966774 1.         1.         1.
 1.         0.65650651 0.98539707 1.         0.         1.
 0.89378517 0.         0.         0.09180456 0.22736754 0.36028623
 0.         1.         0.6536014  0.         0.         1.
 0.         0.69973896 0.         1.         0.84357578 0.
 0.26917363 0.14539938 0.51685972 1.         1.        ]
wv_std shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
xy shape: (35, 9)
[[0.         0.         0.         0.         0.26717009 1.
  0.94170548 1.         0.        ]
 [0.         0.         0.         0.         0.26719749 1.
  1.         1.         0.        ]
 [0.         0.         0.11248613 0.57145617 0.26720154 1.
  0.95966774 1.         0.        ]
 [0.         0.         0.         0.         0.26722009 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.26716918 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.26719212 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.26723166 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.1087178  0.26719108 1.
  0.65650651 1.         0.        ]
 [0.         0.         0.         0.         0.26719756 1.
  0.98539707 1.         0.        ]
 [0.         0.         0.         0.         0.26719225 1.
  1.         1.         0.        ]
 [1.         0.         1.         1.         0.26784941 1.
  0.         0.         1.        ]
 [0.         0.03271286 0.         0.         0.26788958 1.
  1.         0.         1.        ]
 [0.         0.09645486 0.22874713 0.         0.26779734 1.
  0.89378517 0.         1.        ]
 [0.         0.84096307 0.         0.         0.26780618 1.
  0.         0.         1.        ]
 [1.         0.         0.83768903 1.         0.26787419 1.
  0.         0.         1.        ]
 [0.         0.         0.67549944 0.12533382 0.26786091 1.
  0.09180456 0.         1.        ]
 [0.         0.         0.19735371 0.         0.26788611 1.
  0.22736754 0.         1.        ]
 [0.         0.         0.         0.         0.267905   1.
  0.36028623 0.         1.        ]
 [1.         0.         1.         1.         0.26782864 1.
  0.         0.         1.        ]
 [0.         0.         0.87561145 0.36747854 0.26792508 1.
  1.         0.         1.        ]
 [1.         0.         1.         1.         0.26794719 1.
  0.6536014  0.         1.        ]
 [0.         0.         0.15130844 0.38534049 0.26785778 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.26786249 1.
  0.         0.         1.        ]
 [0.         0.         0.41857404 0.         0.26793798 1.
  1.         0.         1.        ]
 [0.         0.         0.         0.04103309 0.26792756 1.
  0.         0.         1.        ]
 [1.         1.         1.         1.         0.26795545 1.
  0.69973896 0.         1.        ]
 [0.         0.         0.1280396  0.55417627 0.26793372 1.
  0.         0.         1.        ]
 [1.         0.59366423 1.         1.         0.26783129 1.
  1.         0.         1.        ]
 [1.         0.         1.         0.57773378 0.26794131 1.
  0.84357578 0.         1.        ]
 [1.         0.         0.70884692 0.6888931  0.26791485 1.
  0.         0.         1.        ]
 [0.         0.         0.2146494  0.24939158 0.26787385 1.
  0.26917363 0.         1.        ]
 [0.         0.29342373 0.20126647 0.         0.26793052 1.
  0.14539938 0.         1.        ]
 [1.         0.         0.49295666 0.61071059 0.26788244 1.
  0.51685972 0.         1.        ]
 [0.         0.02562984 0.65457752 0.26159413 0.26782093 1.
  1.         0.         1.        ]
 [1.         0.         1.         1.         0.26787785 1.
  1.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.6000000238418579
#####################         POISON         ###############################################

############################################################################################

comm_round: 27 | global_test_acc: 91.667% | global_f1: 0.9565217391304348 | global_precision: 0.9166666666666666
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.92      1.00      0.96        11

    accuracy                           0.92        12
   macro avg       0.46      0.50      0.48        12
weighted avg       0.84      0.92      0.88        12
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_fg shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         1.         0.         0.         0.
 0.26341884 0.94751226 0.         0.17254734 1.         0.
 1.         0.62551573 1.         0.         0.         0.
 0.         0.         1.         1.         0.        ]
wv_mn shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         1.         0.30727786
 0.         1.         1.         0.42272498 0.         0.85232323
 1.         0.92691787 0.20767376 0.         1.         0.23639065
 1.         1.         1.         1.         1.         1.
 1.         0.77643953 1.         1.         0.83842832]
wv_ed shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         1.         0.82646525
 0.37116175 1.         1.         1.         0.         0.7740315
 1.         0.89976242 0.         0.         1.         0.31046683
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.85011649]
wv_lg shape (35, 1)
[[0.26768351]
 [0.26767335]
 [0.26768246]
 [0.26766998]
 [0.26770584]
 [0.26761008]
 [0.2676924 ]
 [0.26764191]
 [0.26768884]
 [0.26765147]
 [0.26835419]
 [0.26838952]
 [0.26834523]
 [0.26837081]
 [0.26829099]
 [0.2683326 ]
 [0.26839056]
 [0.26832815]
 [0.26834915]
 [0.26836056]
 [0.26843861]
 [0.26836535]
 [0.26831786]
 [0.26839284]
 [0.26836026]
 [0.26833522]
 [0.26826623]
 [0.2683883 ]
 [0.26833688]
 [0.26831618]
 [0.26832678]
 [0.26829809]
 [0.26827834]
 [0.26820709]
 [0.26838174]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[0.84207818 0.65376987 0.72186142 1.         1.         1.
 1.         0.60536176 0.34129727 0.38781673 0.         0.
 1.         0.         0.90688529 0.59500466 0.60661906 0.07775603
 0.34731273 0.         0.03752224 0.87677421 1.         0.
 1.         0.         0.         0.43835198 0.63111663 0.23584487
 0.29683379 0.25929193 1.         0.         0.13867001]
wv_std shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
xy shape: (35, 9)
[[0.         0.         0.         0.         0.26768351 1.
  0.84207818 1.         0.        ]
 [0.         0.         0.         0.         0.26767335 1.
  0.65376987 1.         0.        ]
 [0.         0.         0.         0.         0.26768246 1.
  0.72186142 1.         0.        ]
 [0.         0.         0.         0.         0.26766998 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.26770584 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.26761008 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.2676924  1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.26764191 1.
  0.60536176 1.         0.        ]
 [0.         0.         0.         0.         0.26768884 1.
  0.34129727 1.         0.        ]
 [0.         0.         0.         0.         0.26765147 1.
  0.38781673 1.         0.        ]
 [1.         0.         1.         1.         0.26835419 1.
  0.         0.         1.        ]
 [1.         0.         0.30727786 0.82646525 0.26838952 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.37116175 0.26834523 1.
  1.         0.         1.        ]
 [1.         0.         1.         1.         0.26837081 1.
  0.         0.         1.        ]
 [1.         1.         1.         1.         0.26829099 1.
  0.90688529 0.         1.        ]
 [1.         0.         0.42272498 1.         0.2683326  1.
  0.59500466 0.         1.        ]
 [0.         0.         0.         0.         0.26839056 1.
  0.60661906 0.         1.        ]
 [1.         0.         0.85232323 0.7740315  0.26832815 1.
  0.07775603 0.         1.        ]
 [1.         0.26341884 1.         1.         0.26834915 1.
  0.34731273 0.         1.        ]
 [1.         0.94751226 0.92691787 0.89976242 0.26836056 1.
  0.         0.         1.        ]
 [1.         0.         0.20767376 0.         0.26843861 1.
  0.03752224 0.         1.        ]
 [0.         0.17254734 0.         0.         0.26836535 1.
  0.87677421 0.         1.        ]
 [1.         1.         1.         1.         0.26831786 1.
  1.         0.         1.        ]
 [1.         0.         0.23639065 0.31046683 0.26839284 1.
  0.         0.         1.        ]
 [1.         1.         1.         1.         0.26836026 1.
  1.         0.         1.        ]
 [1.         0.62551573 1.         1.         0.26833522 1.
  0.         0.         1.        ]
 [1.         1.         1.         1.         0.26826623 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.2683883  1.
  0.43835198 0.         1.        ]
 [1.         0.         1.         1.         0.26833688 1.
  0.63111663 0.         1.        ]
 [1.         0.         1.         1.         0.26831618 1.
  0.23584487 0.         1.        ]
 [1.         0.         1.         1.         0.26832678 1.
  0.29683379 0.         1.        ]
 [1.         0.         0.77643953 1.         0.26829809 1.
  0.25929193 0.         1.        ]
 [1.         1.         1.         1.         0.26827834 1.
  1.         0.         1.        ]
 [1.         1.         1.         1.         0.26820709 1.
  0.         0.         1.        ]
 [1.         0.         0.83842832 0.85011649 0.26838174 1.
  0.13867001 0.         1.        ]]

Best Training Poisoning Accuracy:
0.550000011920929
#####################         POISON         ###############################################

############################################################################################

comm_round: 28 | global_test_acc: 91.667% | global_f1: 0.9565217391304348 | global_precision: 0.9166666666666666
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.92      1.00      0.96        11

    accuracy                           0.92        12
   macro avg       0.46      0.50      0.48        12
weighted avg       0.84      0.92      0.88        12
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.12632287 0.         0.         0.         0.
 1.         1.         0.         0.         0.         1.
 0.         0.08179727 0.         0.         1.         1.
 1.         1.         0.         1.         0.         0.07450521
 0.         1.         1.         0.         1.        ]
wv_fg shape (35,)
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]
wv_mn shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.097979   0.         0.         0.         0.
 0.66437903 1.         0.72787138 0.         0.         1.
 0.53035762 0.6393005  0.         0.         1.         1.
 1.         1.         0.2462223  0.86354728 0.         0.90518268
 0.         1.         1.         0.         1.        ]
wv_ed shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.35822259 0.         0.         0.         0.
 0.33037003 1.         0.         0.         0.         1.
 0.08121534 0.28665358 0.         0.         0.54492925 1.
 1.         1.         0.07176501 1.         0.         0.3851912
 0.         1.         0.67628383 0.         0.61189513]
wv_lg shape (35, 1)
[[0.26819212]
 [0.26804469]
 [0.26808994]
 [0.26804393]
 [0.26811532]
 [0.26805587]
 [0.26805205]
 [0.26813529]
 [0.26803184]
 [0.26810601]
 [0.26882429]
 [0.26876784]
 [0.26885531]
 [0.26876228]
 [0.2688854 ]
 [0.26876699]
 [0.26875485]
 [0.26877132]
 [0.26881989]
 [0.26879766]
 [0.26883626]
 [0.2688618 ]
 [0.26887864]
 [0.26890578]
 [0.26870043]
 [0.2687993 ]
 [0.26884917]
 [0.26877735]
 [0.26879266]
 [0.26876122]
 [0.26890205]
 [0.26873059]
 [0.26882189]
 [0.26886657]
 [0.26879411]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[1.         1.         1.         1.         0.8295485  1.
 0.84733037 1.         0.98269839 1.         0.28250332 0.4056485
 0.00113541 1.         1.         0.         0.93932364 0.09463713
 1.         0.23087889 1.         1.         0.97908355 0.
 0.95109918 0.39863198 0.         0.20694261 0.16840241 1.
 0.82031282 0.         1.         0.         0.08443839]
wv_std shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
xy shape: (35, 9)
[[0.         0.         0.         0.         0.26819212 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.26804469 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.26808994 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.26804393 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.26811532 1.
  0.8295485  1.         0.        ]
 [0.         0.         0.         0.         0.26805587 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.26805205 1.
  0.84733037 1.         0.        ]
 [0.12632287 0.         0.097979   0.35822259 0.26813529 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.26803184 1.
  0.98269839 1.         0.        ]
 [0.         0.         0.         0.         0.26810601 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.26882429 1.
  0.28250332 0.         1.        ]
 [0.         0.         0.         0.         0.26876784 1.
  0.4056485  0.         1.        ]
 [1.         0.         0.66437903 0.33037003 0.26885531 1.
  0.00113541 0.         1.        ]
 [1.         1.         1.         1.         0.26876228 1.
  1.         0.         1.        ]
 [0.         0.         0.72787138 0.         0.2688854  1.
  1.         0.         1.        ]
 [0.         0.         0.         0.         0.26876699 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.26875485 1.
  0.93932364 0.         1.        ]
 [1.         0.         1.         1.         0.26877132 1.
  0.09463713 0.         1.        ]
 [0.         0.         0.53035762 0.08121534 0.26881989 1.
  1.         0.         1.        ]
 [0.08179727 0.         0.6393005  0.28665358 0.26879766 1.
  0.23087889 0.         1.        ]
 [0.         0.         0.         0.         0.26883626 1.
  1.         0.         1.        ]
 [0.         0.         0.         0.         0.2688618  1.
  1.         0.         1.        ]
 [1.         0.         1.         0.54492925 0.26887864 1.
  0.97908355 0.         1.        ]
 [1.         0.         1.         1.         0.26890578 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.26870043 1.
  0.95109918 0.         1.        ]
 [1.         0.         1.         1.         0.2687993  1.
  0.39863198 0.         1.        ]
 [0.         0.         0.2462223  0.07176501 0.26884917 1.
  0.         0.         1.        ]
 [1.         0.         0.86354728 1.         0.26877735 1.
  0.20694261 0.         1.        ]
 [0.         0.         0.         0.         0.26879266 1.
  0.16840241 0.         1.        ]
 [0.07450521 0.         0.90518268 0.3851912  0.26876122 1.
  1.         0.         1.        ]
 [0.         0.         0.         0.         0.26890205 1.
  0.82031282 0.         1.        ]
 [1.         0.         1.         1.         0.26873059 1.
  0.         0.         1.        ]
 [1.         0.         1.         0.67628383 0.26882189 1.
  1.         0.         1.        ]
 [0.         1.         0.         0.         0.26886657 1.
  0.         0.         1.        ]
 [1.         0.         1.         0.61189513 0.26879411 1.
  0.08443839 0.         1.        ]]

Best Training Poisoning Accuracy:
0.6499999761581421
#####################         POISON         ###############################################

############################################################################################

comm_round: 29 | global_test_acc: 83.333% | global_f1: 0.9090909090909091 | global_precision: 0.8333333333333334
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.83      1.00      0.91        10

    accuracy                           0.83        12
   macro avg       0.42      0.50      0.45        12
weighted avg       0.69      0.83      0.76        12
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients