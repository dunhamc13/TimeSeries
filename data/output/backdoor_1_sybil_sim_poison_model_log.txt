
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         1.         0.07958859 1.         0.         1.
 1.         1.         1.         0.80270021 0.97202388 0.33250929
 0.         0.         0.80752598 0.86490604 1.         1.
 0.         0.05007343 1.         0.96523581 0.         1.
 0.86240026 0.07331455]
wv_ed shape (26,)
[0.         1.         0.05870006 1.         0.         1.
 1.         1.         1.         0.68459991 0.91887848 0.41956921
 0.         0.         0.78306835 0.84063714 1.         1.
 0.         0.         1.         0.91694505 0.         1.
 0.78646202 0.0305306 ]
wv_lg shape (26, 1)
[[0.33657498]
 [0.23652555]
 [0.23699953]
 [0.23656874]
 [0.23837086]
 [0.23678154]
 [0.23467089]
 [0.23718865]
 [0.23555092]
 [0.2388362 ]
 [0.23644348]
 [0.23623417]
 [0.23282492]
 [0.23103915]
 [0.23825377]
 [0.23884025]
 [0.23765861]
 [0.23589607]
 [0.23674279]
 [0.23682075]
 [0.23633866]
 [0.23737107]
 [0.23594141]
 [0.23887533]
 [0.23778328]
 [0.23310651]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         1.         0.         1.         0.         1.
 1.         0.65046408 1.         0.55354618 1.         0.04909481
 0.         0.62265883 1.         0.71956306 1.         1.
 0.         0.05418226 1.         1.         0.         1.
 0.7680603  0.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.33657498 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.23652555 1.
  0.         1.         1.        ]
 [1.         0.         0.07958859 0.05870006 0.23699953 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.23656874 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.23837086 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.23678154 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.23467089 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.23718865 1.
  0.         0.65046408 1.        ]
 [1.         0.         1.         1.         0.23555092 1.
  0.         1.         1.        ]
 [1.         0.         0.80270021 0.68459991 0.2388362  1.
  0.         0.55354618 1.        ]
 [1.         0.         0.97202388 0.91887848 0.23644348 1.
  0.         1.         1.        ]
 [1.         0.         0.33250929 0.41956921 0.23623417 1.
  0.         0.04909481 1.        ]
 [1.         0.         0.         0.         0.23282492 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.23103915 1.
  0.         0.62265883 1.        ]
 [1.         0.         0.80752598 0.78306835 0.23825377 1.
  0.         1.         1.        ]
 [1.         0.         0.86490604 0.84063714 0.23884025 1.
  0.         0.71956306 1.        ]
 [1.         0.         1.         1.         0.23765861 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.23589607 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.23674279 1.
  0.         0.         1.        ]
 [1.         0.         0.05007343 0.         0.23682075 1.
  0.         0.05418226 1.        ]
 [1.         0.         1.         1.         0.23633866 1.
  0.         1.         1.        ]
 [1.         0.         0.96523581 0.91694505 0.23737107 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.23594141 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.23887533 1.
  0.         1.         1.        ]
 [1.         0.         0.86240026 0.78646202 0.23778328 1.
  0.         0.7680603  1.        ]
 [1.         0.         0.07331455 0.0305306  0.23310651 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
1.0
#####################         POISON         ###############################################

############################################################################################

comm_round: 0 | global_test_acc: 87.500% | global_f1: 0.9333333333333333 | global_precision: 0.875
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.88      1.00      0.93         7

    accuracy                           0.88         8
   macro avg       0.44      0.50      0.47         8
weighted avg       0.77      0.88      0.82         8

Accuracy per class:
[[7 0]
 [1 0]]
[1. 0.]
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         1.         1.         0.         1.         0.83682596
 1.         0.5077752  0.         1.         1.         1.
 0.         0.45464638 0.7831675  0.         0.60070947 1.
 0.73425523 0.07266153 0.88971161 1.         0.77448239 1.
 1.         1.        ]
wv_ed shape (26,)
[0.         1.         1.         0.         1.         0.55754391
 1.         0.35151496 0.         1.         0.90796789 1.
 0.         0.33942491 0.         0.         1.         1.
 0.16357822 0.         1.         1.         0.55708527 1.
 1.         0.84102271]
wv_lg shape (26, 1)
[[0.25097744]
 [0.21320323]
 [0.22078317]
 [0.20747398]
 [0.2254347 ]
 [0.21339408]
 [0.22404775]
 [0.21493682]
 [0.21507921]
 [0.20969598]
 [0.21434258]
 [0.2184682 ]
 [0.21751861]
 [0.21455982]
 [0.21106293]
 [0.21133122]
 [0.21826807]
 [0.21275155]
 [0.21141956]
 [0.21130718]
 [0.2246802 ]
 [0.22210287]
 [0.21573772]
 [0.22332957]
 [0.21797787]
 [0.20927935]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_std shape (26,)
[0.         0.         1.         0.         1.         0.
 1.         0.         0.         0.         0.19482386 0.75016168
 0.40995424 0.         0.         0.         0.38730962 0.
 0.         0.         1.         1.         0.36264392 1.
 1.         0.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.25097744 1.
  0.         0.         0.        ]
 [1.         0.         1.         1.         0.21320323 1.
  1.         0.         1.        ]
 [1.         0.         1.         1.         0.22078317 1.
  1.         1.         1.        ]
 [1.         0.         0.         0.         0.20747398 1.
  1.         0.         1.        ]
 [1.         0.         1.         1.         0.2254347  1.
  1.         1.         1.        ]
 [1.         0.         0.83682596 0.55754391 0.21339408 1.
  1.         0.         1.        ]
 [1.         0.         1.         1.         0.22404775 1.
  1.         1.         1.        ]
 [1.         0.         0.5077752  0.35151496 0.21493682 1.
  1.         0.         1.        ]
 [0.         0.         0.         0.         0.21507921 1.
  1.         0.         1.        ]
 [1.         0.         1.         1.         0.20969598 1.
  1.         0.         1.        ]
 [1.         0.         1.         0.90796789 0.21434258 1.
  1.         0.19482386 1.        ]
 [1.         0.         1.         1.         0.2184682  1.
  1.         0.75016168 1.        ]
 [1.         0.         0.         0.         0.21751861 1.
  1.         0.40995424 1.        ]
 [1.         0.         0.45464638 0.33942491 0.21455982 1.
  1.         0.         1.        ]
 [1.         0.         0.7831675  0.         0.21106293 1.
  1.         0.         1.        ]
 [1.         0.         0.         0.         0.21133122 1.
  1.         0.         1.        ]
 [1.         0.         0.60070947 1.         0.21826807 1.
  1.         0.38730962 1.        ]
 [1.         0.         1.         1.         0.21275155 1.
  1.         0.         1.        ]
 [1.         0.         0.73425523 0.16357822 0.21141956 1.
  1.         0.         1.        ]
 [1.         0.         0.07266153 0.         0.21130718 1.
  1.         0.         1.        ]
 [1.         0.         0.88971161 1.         0.2246802  1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.22210287 1.
  1.         1.         1.        ]
 [1.         0.         0.77448239 0.55708527 0.21573772 1.
  1.         0.36264392 1.        ]
 [1.         0.         1.         1.         0.22332957 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.21797787 1.
  1.         1.         1.        ]
 [1.         0.         1.         0.84102271 0.20927935 1.
  1.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.9166666865348816
#####################         POISON         ###############################################

############################################################################################

comm_round: 1 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8

Accuracy per class:
[[8 0]
 [0 0]]
[ 1. nan]
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.         0.         1.         0.         0.
 0.         0.6770727  0.49443924 0.         1.         0.24738685
 0.95101511 1.         0.99676534 0.85078259 1.         1.
 1.         0.42065966 0.         1.         1.         0.03204102
 0.16814426 0.34891925]
wv_ed shape (26,)
[0.         0.         0.         1.         0.         0.
 0.         0.39382931 0.11517795 0.         0.68734445 0.
 0.13302325 1.         0.73655447 1.         1.         1.
 1.         0.29013045 0.         1.         1.         0.
 0.         0.1922842 ]
wv_lg shape (26, 1)
[[0.21985325]
 [0.22858779]
 [0.23238024]
 [0.23067164]
 [0.22760569]
 [0.23265776]
 [0.22980462]
 [0.23019445]
 [0.2316858 ]
 [0.22944491]
 [0.23171901]
 [0.22916191]
 [0.23200058]
 [0.22721031]
 [0.2316899 ]
 [0.22844889]
 [0.22795565]
 [0.22848427]
 [0.23006455]
 [0.22934318]
 [0.23299935]
 [0.22808004]
 [0.22891952]
 [0.22719679]
 [0.23013713]
 [0.22835605]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[0.         1.         1.         0.         1.         0.87708394
 1.         0.25278573 0.72822782 1.         0.         1.
 1.         1.         0.         0.69396609 1.         0.
 0.         1.         1.         1.         0.         1.
 1.         1.        ]
wv_std shape (26,)
[0.         1.         0.         0.28304653 1.         0.
 0.         1.         0.05703134 0.         1.         0.
 0.         1.         0.         1.         0.81740984 0.24836309
 0.61318899 0.         0.         1.         1.         1.
 0.         1.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.21985325 1.
  0.         0.         0.        ]
 [1.         0.         0.         0.         0.22858779 1.
  1.         1.         1.        ]
 [0.         0.         0.         0.         0.23238024 1.
  1.         0.         1.        ]
 [1.         0.         1.         1.         0.23067164 1.
  0.         0.28304653 1.        ]
 [1.         0.         0.         0.         0.22760569 1.
  1.         1.         1.        ]
 [1.         0.         0.         0.         0.23265776 1.
  0.87708394 0.         1.        ]
 [1.         0.         0.         0.         0.22980462 1.
  1.         0.         1.        ]
 [1.         0.         0.6770727  0.39382931 0.23019445 1.
  0.25278573 1.         1.        ]
 [1.         0.         0.49443924 0.11517795 0.2316858  1.
  0.72822782 0.05703134 1.        ]
 [1.         0.         0.         0.         0.22944491 1.
  1.         0.         1.        ]
 [1.         0.         1.         0.68734445 0.23171901 1.
  0.         1.         1.        ]
 [1.         0.         0.24738685 0.         0.22916191 1.
  1.         0.         1.        ]
 [1.         0.         0.95101511 0.13302325 0.23200058 1.
  1.         0.         1.        ]
 [1.         0.         1.         1.         0.22721031 1.
  1.         1.         1.        ]
 [1.         0.         0.99676534 0.73655447 0.2316899  1.
  0.         0.         1.        ]
 [1.         0.         0.85078259 1.         0.22844889 1.
  0.69396609 1.         1.        ]
 [1.         0.         1.         1.         0.22795565 1.
  1.         0.81740984 1.        ]
 [1.         0.         1.         1.         0.22848427 1.
  0.         0.24836309 1.        ]
 [1.         0.         1.         1.         0.23006455 1.
  0.         0.61318899 1.        ]
 [1.         0.         0.42065966 0.29013045 0.22934318 1.
  1.         0.         1.        ]
 [1.         0.         0.         0.         0.23299935 1.
  1.         0.         1.        ]
 [1.         0.         1.         1.         0.22808004 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.22891952 1.
  0.         1.         1.        ]
 [1.         0.         0.03204102 0.         0.22719679 1.
  1.         1.         1.        ]
 [1.         0.         0.16814426 0.         0.23013713 1.
  1.         0.         1.        ]
 [1.         0.         0.34891925 0.1922842  0.22835605 1.
  1.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.9166666865348816
#####################         POISON         ###############################################

############################################################################################

comm_round: 2 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8

Accuracy per class:
[[8 0]
 [0 0]]
[ 1. nan]
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0.         1.         1.         1.         1.         0.
 1.         1.         1.         1.         1.         0.98319985
 1.         1.         1.         0.         0.         1.
 0.         1.         1.         1.         1.         1.
 1.         1.        ]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.         0.         0.43918088 0.         1.
 0.         0.         0.39624994 0.53303474 0.17062096 1.
 0.         0.58276595 0.         1.         0.         1.
 1.         1.         1.         1.         0.48620054 1.
 0.64588852 0.31004439]
wv_ed shape (26,)
[0.         0.         0.         0.75254861 0.         1.
 0.         0.         0.46316496 0.71215736 0.         1.
 0.         0.075097   0.         1.         0.         1.
 1.         0.74069845 1.         1.         0.69619138 1.
 0.21328672 0.6460094 ]
wv_lg shape (26, 1)
[[0.22475203]
 [0.22580497]
 [0.22780474]
 [0.22955283]
 [0.23200958]
 [0.22662701]
 [0.22946767]
 [0.22603708]
 [0.22749295]
 [0.22770637]
 [0.22854405]
 [0.2300994 ]
 [0.2275229 ]
 [0.22500061]
 [0.23105883]
 [0.22370422]
 [0.23355623]
 [0.22715039]
 [0.2255538 ]
 [0.22372465]
 [0.23194488]
 [0.22616304]
 [0.23220954]
 [0.23064063]
 [0.22407756]
 [0.22760554]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[0.         0.50117418 0.18434267 0.         0.         0.
 0.02088526 1.         0.         0.         0.         0.
 1.         1.         0.         0.         0.70111747 0.
 0.         1.         0.         1.         0.         0.
 1.         0.        ]
wv_std shape (26,)
[0.         1.         0.80236112 0.59646681 0.         0.
 0.         1.         1.         1.         1.         0.2215626
 0.35747892 1.         0.39212178 1.         0.         1.
 1.         1.         0.97726107 1.         0.         1.
 1.         1.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.22475203 1.
  0.         0.         0.        ]
 [1.         0.         0.         0.         0.22580497 1.
  0.50117418 1.         1.        ]
 [1.         0.         0.         0.         0.22780474 1.
  0.18434267 0.80236112 1.        ]
 [1.         0.         0.43918088 0.75254861 0.22955283 1.
  0.         0.59646681 1.        ]
 [1.         0.         0.         0.         0.23200958 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.22662701 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.22946767 1.
  0.02088526 0.         1.        ]
 [1.         0.         0.         0.         0.22603708 1.
  1.         1.         1.        ]
 [1.         0.         0.39624994 0.46316496 0.22749295 1.
  0.         1.         1.        ]
 [1.         0.         0.53303474 0.71215736 0.22770637 1.
  0.         1.         1.        ]
 [1.         0.         0.17062096 0.         0.22854405 1.
  0.         1.         1.        ]
 [0.98319985 0.         1.         1.         0.2300994  1.
  0.         0.2215626  1.        ]
 [1.         0.         0.         0.         0.2275229  1.
  1.         0.35747892 1.        ]
 [1.         0.         0.58276595 0.075097   0.22500061 1.
  1.         1.         1.        ]
 [1.         0.         0.         0.         0.23105883 1.
  0.         0.39212178 1.        ]
 [0.         0.         1.         1.         0.22370422 1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.23355623 1.
  0.70111747 0.         1.        ]
 [1.         0.         1.         1.         0.22715039 1.
  0.         1.         1.        ]
 [0.         0.         1.         1.         0.2255538  1.
  0.         1.         1.        ]
 [1.         0.         1.         0.74069845 0.22372465 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.23194488 1.
  0.         0.97726107 1.        ]
 [1.         0.         1.         1.         0.22616304 1.
  1.         1.         1.        ]
 [1.         0.         0.48620054 0.69619138 0.23220954 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.23064063 1.
  0.         1.         1.        ]
 [1.         0.         0.64588852 0.21328672 0.22407756 1.
  1.         1.         1.        ]
 [1.         0.         0.31004439 0.6460094  0.22760554 1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
1.0
#####################         POISON         ###############################################

############################################################################################

comm_round: 3 | global_test_acc: 87.500% | global_f1: 0.9333333333333333 | global_precision: 0.875
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.88      1.00      0.93         7

    accuracy                           0.88         8
   macro avg       0.44      0.50      0.47         8
weighted avg       0.77      0.88      0.82         8

Accuracy per class:
[[7 0]
 [1 0]]
[1. 0.]
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         1.         0.         1.         0.53285432 1.
 1.         1.         0.4061011  0.81106371 1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
wv_ed shape (26,)
[0.         1.         0.         0.69182498 0.         1.
 1.         1.         0.49292749 1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.31825072 1.
 1.         1.        ]
wv_lg shape (26, 1)
[[0.2298688 ]
 [0.22790959]
 [0.22398081]
 [0.22444959]
 [0.2272224 ]
 [0.22880045]
 [0.22784474]
 [0.22796726]
 [0.2273639 ]
 [0.22431027]
 [0.22946452]
 [0.22941738]
 [0.22886879]
 [0.22926222]
 [0.22910833]
 [0.23039152]
 [0.22927517]
 [0.22743817]
 [0.2283193 ]
 [0.23047239]
 [0.22821848]
 [0.22772049]
 [0.22869124]
 [0.22821143]
 [0.22887084]
 [0.23082745]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[0.         0.         0.         0.         1.         0.
 0.         0.         0.         0.         0.86114454 1.
 0.55662347 0.         1.         1.         0.16306557 0.50460323
 0.48731042 0.         1.         0.         0.         0.
 0.         0.69959065]
wv_std shape (26,)
[1.         0.70990591 1.         0.         0.46915289 0.
 1.         1.         1.         0.93642173 0.         0.
 1.         1.         0.         0.635459   0.87899296 1.
 1.         1.         1.         1.         1.         1.
 1.         0.04454831]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.2298688  1.
  0.         1.         0.        ]
 [1.         0.         1.         1.         0.22790959 1.
  0.         0.70990591 1.        ]
 [1.         0.         0.         0.         0.22398081 1.
  0.         1.         1.        ]
 [0.         0.         1.         0.69182498 0.22444959 1.
  0.         0.         1.        ]
 [1.         0.         0.53285432 0.         0.2272224  1.
  1.         0.46915289 1.        ]
 [1.         0.         1.         1.         0.22880045 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.22784474 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.22796726 1.
  0.         1.         1.        ]
 [1.         0.         0.4061011  0.49292749 0.2273639  1.
  0.         1.         1.        ]
 [1.         0.         0.81106371 1.         0.22431027 1.
  0.         0.93642173 1.        ]
 [1.         0.         1.         1.         0.22946452 1.
  0.86114454 0.         1.        ]
 [1.         0.         1.         1.         0.22941738 1.
  1.         0.         1.        ]
 [1.         0.         1.         1.         0.22886879 1.
  0.55662347 1.         1.        ]
 [1.         0.         1.         1.         0.22926222 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.22910833 1.
  1.         0.         1.        ]
 [1.         0.         1.         1.         0.23039152 1.
  1.         0.635459   1.        ]
 [1.         0.         1.         1.         0.22927517 1.
  0.16306557 0.87899296 1.        ]
 [1.         0.         1.         1.         0.22743817 1.
  0.50460323 1.         1.        ]
 [1.         0.         1.         1.         0.2283193  1.
  0.48731042 1.         1.        ]
 [1.         0.         1.         1.         0.23047239 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.22821848 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.22772049 1.
  0.         1.         1.        ]
 [1.         0.         1.         0.31825072 0.22869124 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.22821143 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.22887084 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.23082745 1.
  0.69959065 0.04454831 1.        ]]

Best Training Poisoning Accuracy:
1.0
#####################         POISON         ###############################################

############################################################################################

comm_round: 4 | global_test_acc: 87.500% | global_f1: 0.9333333333333333 | global_precision: 0.875
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.88      1.00      0.93         7

    accuracy                           0.88         8
   macro avg       0.44      0.50      0.47         8
weighted avg       0.77      0.88      0.82         8

Accuracy per class:
[[7 0]
 [1 0]]
[1. 0.]
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.         1.         1.         0.         1.
 0.03949191 1.         1.         0.         1.         1.
 1.         0.         1.         0.65913886 1.         1.
 0.33906218 1.         1.         1.         0.         1.
 0.         1.        ]
wv_ed shape (26,)
[0.         0.         1.         1.         1.         1.
 1.         1.         1.         0.         1.         1.
 1.         0.93939777 1.         1.         1.         1.
 0.22359967 1.         1.         1.         0.08578722 1.
 0.44348488 1.        ]
wv_lg shape (26, 1)
[[0.22511848]
 [0.2229647 ]
 [0.22723373]
 [0.22446871]
 [0.22703684]
 [0.2282204 ]
 [0.22381858]
 [0.22856419]
 [0.22681519]
 [0.22295291]
 [0.22851577]
 [0.22390972]
 [0.2244415 ]
 [0.22678478]
 [0.22443663]
 [0.22596223]
 [0.22833361]
 [0.22974059]
 [0.22337986]
 [0.22858229]
 [0.22828045]
 [0.22699244]
 [0.23116222]
 [0.22722919]
 [0.22465587]
 [0.2256534 ]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[0.         1.         0.         1.         1.         1.
 0.03088817 1.         0.34865008 1.         0.11891732 0.80800542
 1.         0.         0.56160523 0.         0.         1.
 1.         0.81940811 1.         1.         0.85390398 1.
 0.95039613 1.        ]
wv_std shape (26,)
[0.         0.75781338 1.         1.         0.41648264 1.
 1.         1.         1.         1.         1.         0.
 0.         1.         0.         1.         1.         0.54099221
 0.04819293 1.         0.87564933 0.         0.         1.
 1.         1.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.22511848 1.
  0.         0.         0.        ]
 [1.         0.         0.         0.         0.2229647  1.
  1.         0.75781338 1.        ]
 [1.         0.         1.         1.         0.22723373 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.22446871 1.
  1.         1.         1.        ]
 [1.         0.         0.         1.         0.22703684 1.
  1.         0.41648264 1.        ]
 [1.         0.         1.         1.         0.2282204  1.
  1.         1.         1.        ]
 [1.         0.         0.03949191 1.         0.22381858 1.
  0.03088817 1.         1.        ]
 [1.         0.         1.         1.         0.22856419 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.22681519 1.
  0.34865008 1.         1.        ]
 [1.         0.         0.         0.         0.22295291 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.22851577 1.
  0.11891732 1.         1.        ]
 [1.         0.         1.         1.         0.22390972 1.
  0.80800542 0.         1.        ]
 [1.         0.         1.         1.         0.2244415  1.
  1.         0.         1.        ]
 [1.         0.         0.         0.93939777 0.22678478 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.22443663 1.
  0.56160523 0.         1.        ]
 [1.         0.         0.65913886 1.         0.22596223 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.22833361 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.22974059 1.
  1.         0.54099221 1.        ]
 [1.         0.         0.33906218 0.22359967 0.22337986 1.
  1.         0.04819293 1.        ]
 [1.         0.         1.         1.         0.22858229 1.
  0.81940811 1.         1.        ]
 [1.         0.         1.         1.         0.22828045 1.
  1.         0.87564933 1.        ]
 [1.         0.         1.         1.         0.22699244 1.
  1.         0.         1.        ]
 [0.         0.         0.         0.08578722 0.23116222 1.
  0.85390398 0.         1.        ]
 [1.         0.         1.         1.         0.22722919 1.
  1.         1.         1.        ]
 [1.         0.         0.         0.44348488 0.22465587 1.
  0.95039613 1.         1.        ]
 [1.         0.         1.         1.         0.2256534  1.
  1.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.9166666865348816
#####################         POISON         ###############################################

############################################################################################

comm_round: 5 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8

Accuracy per class:
[[8 0]
 [0 0]]
[ 1. nan]
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0.
 0. 0.]
wv_fg shape (26,)
[1.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.30874787 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.        ]
wv_mn shape (26,)
[0.         0.         1.         0.86359877 0.86219673 0.
 0.         1.         0.72478944 0.42710117 1.         1.
 1.         1.         1.         1.         0.70514426 1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
wv_ed shape (26,)
[0.         0.         1.         1.         1.         0.49149895
 0.         1.         0.         0.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
wv_lg shape (26, 1)
[[0.22388484]
 [0.22663874]
 [0.22623401]
 [0.22613561]
 [0.22716384]
 [0.222492  ]
 [0.22607322]
 [0.22717203]
 [0.22379206]
 [0.22406203]
 [0.22213566]
 [0.22699401]
 [0.22065083]
 [0.22692163]
 [0.22604167]
 [0.22072874]
 [0.22188297]
 [0.2269554 ]
 [0.22207389]
 [0.22607365]
 [0.22710722]
 [0.2244466 ]
 [0.22720566]
 [0.22369909]
 [0.22430672]
 [0.22616074]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[0.         0.         0.         0.         0.         0.
 0.         0.26285079 1.         1.         0.         0.
 0.         0.33180467 0.         0.         0.         0.84678226
 0.         1.         1.         0.         0.         0.
 0.         0.        ]
wv_std shape (26,)
[0.         0.         0.         1.         0.         1.
 0.         0.58064932 0.         0.         1.         0.
 1.         0.         0.39113098 1.         0.36990792 0.41673728
 0.92495666 0.         0.         0.33538463 0.         1.
 1.         1.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.22388484 1.
  0.         0.         0.        ]
 [1.         0.         0.         0.         0.22663874 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.22623401 1.
  0.         0.         1.        ]
 [1.         0.         0.86359877 1.         0.22613561 1.
  0.         1.         1.        ]
 [1.         0.         0.86219673 1.         0.22716384 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.49149895 0.222492   1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.22607322 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.22717203 1.
  0.26285079 0.58064932 1.        ]
 [1.         0.         0.72478944 0.         0.22379206 1.
  1.         0.         1.        ]
 [1.         0.         0.42710117 0.         0.22406203 1.
  1.         0.         1.        ]
 [0.         0.         1.         1.         0.22213566 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.22699401 1.
  0.         0.         1.        ]
 [0.         0.30874787 1.         1.         0.22065083 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.22692163 1.
  0.33180467 0.         1.        ]
 [0.         0.         1.         1.         0.22604167 1.
  0.         0.39113098 1.        ]
 [0.         0.         1.         1.         0.22072874 1.
  0.         1.         1.        ]
 [1.         0.         0.70514426 1.         0.22188297 1.
  0.         0.36990792 1.        ]
 [0.         0.         1.         1.         0.2269554  1.
  0.84678226 0.41673728 1.        ]
 [0.         0.         1.         1.         0.22207389 1.
  0.         0.92495666 1.        ]
 [1.         0.         1.         1.         0.22607365 1.
  1.         0.         1.        ]
 [0.         0.         1.         1.         0.22710722 1.
  1.         0.         1.        ]
 [0.         0.         1.         1.         0.2244466  1.
  0.         0.33538463 1.        ]
 [1.         0.         1.         1.         0.22720566 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.22369909 1.
  0.         1.         1.        ]
 [0.         0.         1.         1.         0.22430672 1.
  0.         1.         1.        ]
 [0.         0.         1.         1.         0.22616074 1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.9166666865348816
#####################         POISON         ###############################################

############################################################################################

comm_round: 6 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8

Accuracy per class:
[[8 0]
 [0 0]]
[ 1. nan]
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0.         1.         1.         1.         1.         1.
 1.         1.         1.         0.         1.         1.
 1.         1.         1.         1.         1.         1.
 0.81771666 1.         1.         0.75386659 1.         1.
 1.         1.        ]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.         1.         1.         0.         1.
 0.12643368 0.         0.70197133 0.         0.         0.30810858
 1.         0.         1.         0.         1.         0.
 1.         1.         0.         1.         1.         0.66214806
 1.         0.        ]
wv_ed shape (26,)
[0.         0.         1.         1.         0.         1.
 0.         0.         0.76138466 0.         0.         0.48176944
 1.         0.         1.         0.         0.23534967 0.
 1.         1.         0.         1.         1.         0.41295894
 1.         0.        ]
wv_lg shape (26, 1)
[[0.22408096]
 [0.22516748]
 [0.2268843 ]
 [0.22711796]
 [0.22564487]
 [0.2220458 ]
 [0.22631177]
 [0.22717866]
 [0.22639923]
 [0.22665993]
 [0.22627798]
 [0.22599755]
 [0.22834314]
 [0.22500371]
 [0.22621991]
 [0.22635173]
 [0.22684427]
 [0.22673857]
 [0.22401495]
 [0.2246079 ]
 [0.22598981]
 [0.2266309 ]
 [0.22225733]
 [0.22775516]
 [0.22603267]
 [0.22365448]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1.         0.         0.         0.96652826 0.         0.
 1.         1.         0.         0.         0.02635929 0.
 0.14241862 0.78382763 0.         1.         0.         0.
 0.         0.         0.         1.         0.         0.24196046
 0.173708   0.02672477]
wv_std shape (26,)
[0.         0.91366872 1.         1.         0.77425318 1.
 0.         0.         1.         0.         0.         1.
 0.         0.71849882 1.         0.41567919 1.         0.
 1.         1.         0.05093822 1.         1.         0.85167429
 1.         0.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.22408096 1.
  1.         0.         0.        ]
 [1.         0.         0.         0.         0.22516748 1.
  0.         0.91366872 1.        ]
 [1.         0.         1.         1.         0.2268843  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.22711796 1.
  0.96652826 1.         1.        ]
 [1.         0.         0.         0.         0.22564487 1.
  0.         0.77425318 1.        ]
 [1.         0.         1.         1.         0.2220458  1.
  0.         1.         1.        ]
 [1.         0.         0.12643368 0.         0.22631177 1.
  1.         0.         1.        ]
 [1.         0.         0.         0.         0.22717866 1.
  1.         0.         1.        ]
 [1.         0.         0.70197133 0.76138466 0.22639923 1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.22665993 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.22627798 1.
  0.02635929 0.         1.        ]
 [1.         0.         0.30810858 0.48176944 0.22599755 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.22834314 1.
  0.14241862 0.         1.        ]
 [1.         0.         0.         0.         0.22500371 1.
  0.78382763 0.71849882 1.        ]
 [1.         0.         1.         1.         0.22621991 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.22635173 1.
  1.         0.41567919 1.        ]
 [1.         0.         1.         0.23534967 0.22684427 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.22673857 1.
  0.         0.         1.        ]
 [0.81771666 0.         1.         1.         0.22401495 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.2246079  1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.22598981 1.
  0.         0.05093822 1.        ]
 [0.75386659 0.         1.         1.         0.2266309  1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.22225733 1.
  0.         1.         1.        ]
 [1.         0.         0.66214806 0.41295894 0.22775516 1.
  0.24196046 0.85167429 1.        ]
 [1.         0.         1.         1.         0.22603267 1.
  0.173708   1.         1.        ]
 [1.         0.         0.         0.         0.22365448 1.
  0.02672477 0.         1.        ]]

Best Training Poisoning Accuracy:
1.0
#####################         POISON         ###############################################

############################################################################################

comm_round: 7 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8

Accuracy per class:
[[8 0]
 [0 0]]
[ 1. nan]
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0.         1.         1.         1.         1.         1.
 1.         1.         0.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 0.         1.         0.         0.         1.         0.02125019
 1.         1.        ]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         1.         0.55448945 1.         0.         0.27327137
 0.41031122 0.15625742 0.         0.         1.         0.
 0.19993859 0.         0.68214707 0.         1.         1.
 1.         1.         1.         1.         0.04864278 1.
 1.         0.53813226]
wv_ed shape (26,)
[0.         1.         0.59182895 0.92797224 0.         0.33639445
 0.41642253 0.21204804 0.         0.         1.         0.
 0.40277365 0.         1.         0.         1.         1.
 1.         1.         1.         1.         0.21077257 1.
 1.         0.39232693]
wv_lg shape (26, 1)
[[0.22016857]
 [0.22799975]
 [0.22621919]
 [0.22799269]
 [0.22746297]
 [0.22596783]
 [0.22087314]
 [0.22486237]
 [0.22510412]
 [0.22548139]
 [0.22646136]
 [0.22481345]
 [0.22356713]
 [0.22367692]
 [0.22317283]
 [0.22162918]
 [0.22262257]
 [0.22661755]
 [0.22258095]
 [0.22667922]
 [0.22575875]
 [0.2245537 ]
 [0.22335459]
 [0.22417573]
 [0.22329489]
 [0.22336157]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1.         1.         0.         0.43009154 0.         1.
 0.         1.         0.29470415 0.         1.         0.36013122
 0.         0.         0.         0.06947567 0.0330262  1.
 0.         0.         1.         0.02256421 0.         0.09461316
 0.         0.        ]
wv_std shape (26,)
[0.         0.         0.38500257 0.         0.         0.
 1.         0.         0.         0.         0.         0.32165247
 0.         0.         0.17226931 0.49936977 0.5394148  0.4779332
 1.         0.46225407 1.         1.         0.         0.76187792
 0.         1.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.22016857 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.22799975 1.
  1.         0.         1.        ]
 [1.         0.         0.55448945 0.59182895 0.22621919 1.
  0.         0.38500257 1.        ]
 [1.         0.         1.         0.92797224 0.22799269 1.
  0.43009154 0.         1.        ]
 [1.         0.         0.         0.         0.22746297 1.
  0.         0.         1.        ]
 [1.         0.         0.27327137 0.33639445 0.22596783 1.
  1.         0.         1.        ]
 [1.         0.         0.41031122 0.41642253 0.22087314 1.
  0.         1.         1.        ]
 [1.         0.         0.15625742 0.21204804 0.22486237 1.
  1.         0.         1.        ]
 [0.         0.         0.         0.         0.22510412 1.
  0.29470415 0.         1.        ]
 [1.         0.         0.         0.         0.22548139 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.22646136 1.
  1.         0.         1.        ]
 [1.         0.         0.         0.         0.22481345 1.
  0.36013122 0.32165247 1.        ]
 [1.         0.         0.19993859 0.40277365 0.22356713 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.22367692 1.
  0.         0.         1.        ]
 [1.         0.         0.68214707 1.         0.22317283 1.
  0.         0.17226931 1.        ]
 [1.         0.         0.         0.         0.22162918 1.
  0.06947567 0.49936977 1.        ]
 [1.         0.         1.         1.         0.22262257 1.
  0.0330262  0.5394148  1.        ]
 [1.         0.         1.         1.         0.22661755 1.
  1.         0.4779332  1.        ]
 [0.         0.         1.         1.         0.22258095 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.22667922 1.
  0.         0.46225407 1.        ]
 [0.         0.         1.         1.         0.22575875 1.
  1.         1.         1.        ]
 [0.         0.         1.         1.         0.2245537  1.
  0.02256421 1.         1.        ]
 [1.         0.         0.04864278 0.21077257 0.22335459 1.
  0.         0.         1.        ]
 [0.02125019 0.         1.         1.         0.22417573 1.
  0.09461316 0.76187792 1.        ]
 [1.         0.         1.         1.         0.22329489 1.
  0.         0.         1.        ]
 [1.         0.         0.53813226 0.39232693 0.22336157 1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
1.0
#####################         POISON         ###############################################

############################################################################################

comm_round: 8 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8

Accuracy per class:
[[8 0]
 [0 0]]
[ 1. nan]
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.         1.         0.         0.94835247 0.32079982
 0.16046728 0.         1.         0.82526197 0.         1.
 1.         1.         1.         0.53537365 0.3426142  1.
 1.         0.79083138 0.         0.         1.         0.77514563
 1.         1.        ]
wv_ed shape (26,)
[0.         0.         0.79577728 0.         0.99911039 0.84965781
 0.         0.         0.79500025 0.59624614 0.         1.
 1.         1.         0.79109487 0.7378927  0.         1.
 1.         0.67654585 0.         0.27502723 1.         1.
 1.         1.        ]
wv_lg shape (26, 1)
[[0.22155022]
 [0.22704397]
 [0.22453106]
 [0.22414093]
 [0.22632297]
 [0.22717911]
 [0.22664762]
 [0.22750524]
 [0.22701821]
 [0.22682707]
 [0.22582944]
 [0.22659758]
 [0.22508183]
 [0.22692693]
 [0.22405846]
 [0.22629609]
 [0.22741679]
 [0.22700366]
 [0.22884398]
 [0.2238498 ]
 [0.22689127]
 [0.22392637]
 [0.227222  ]
 [0.22569791]
 [0.22730312]
 [0.22655483]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1.         1.         1.         0.72656035 0.         0.
 1.         1.         0.42451327 1.         0.         0.00745655
 0.10744146 0.15142013 1.         0.         1.         0.30437644
 0.14102507 0.44808279 0.         0.48007208 0.         0.03627159
 0.         0.8722193 ]
wv_std shape (26,)
[0.         0.         1.         0.         1.         0.
 0.         0.         0.75447355 0.         0.         0.95870216
 0.50475609 0.11081626 0.         0.54095005 0.         1.
 0.         1.         0.         0.16790148 0.43473178 1.
 1.         1.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.22155022 1.
  1.         0.         0.        ]
 [1.         0.         0.         0.         0.22704397 1.
  1.         0.         1.        ]
 [1.         0.         1.         0.79577728 0.22453106 1.
  1.         1.         1.        ]
 [1.         0.         0.         0.         0.22414093 1.
  0.72656035 0.         1.        ]
 [1.         0.         0.94835247 0.99911039 0.22632297 1.
  0.         1.         1.        ]
 [1.         0.         0.32079982 0.84965781 0.22717911 1.
  0.         0.         1.        ]
 [1.         0.         0.16046728 0.         0.22664762 1.
  1.         0.         1.        ]
 [1.         0.         0.         0.         0.22750524 1.
  1.         0.         1.        ]
 [1.         0.         1.         0.79500025 0.22701821 1.
  0.42451327 0.75447355 1.        ]
 [1.         0.         0.82526197 0.59624614 0.22682707 1.
  1.         0.         1.        ]
 [0.         0.         0.         0.         0.22582944 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.22659758 1.
  0.00745655 0.95870216 1.        ]
 [1.         0.         1.         1.         0.22508183 1.
  0.10744146 0.50475609 1.        ]
 [1.         0.         1.         1.         0.22692693 1.
  0.15142013 0.11081626 1.        ]
 [1.         0.         1.         0.79109487 0.22405846 1.
  1.         0.         1.        ]
 [1.         0.         0.53537365 0.7378927  0.22629609 1.
  0.         0.54095005 1.        ]
 [1.         0.         0.3426142  0.         0.22741679 1.
  1.         0.         1.        ]
 [1.         0.         1.         1.         0.22700366 1.
  0.30437644 1.         1.        ]
 [1.         0.         1.         1.         0.22884398 1.
  0.14102507 0.         1.        ]
 [1.         0.         0.79083138 0.67654585 0.2238498  1.
  0.44808279 1.         1.        ]
 [1.         0.         0.         0.         0.22689127 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.27502723 0.22392637 1.
  0.48007208 0.16790148 1.        ]
 [1.         0.         1.         1.         0.227222   1.
  0.         0.43473178 1.        ]
 [1.         0.         0.77514563 1.         0.22569791 1.
  0.03627159 1.         1.        ]
 [1.         0.         1.         1.         0.22730312 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.22655483 1.
  0.8722193  1.         1.        ]]

Best Training Poisoning Accuracy:
1.0
#####################         POISON         ###############################################

############################################################################################

comm_round: 9 | global_test_acc: 87.500% | global_f1: 0.9333333333333333 | global_precision: 0.875
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.88      1.00      0.93         7

    accuracy                           0.88         8
   macro avg       0.44      0.50      0.47         8
weighted avg       0.77      0.88      0.82         8

Accuracy per class:
[[7 0]
 [1 0]]
[1. 0.]
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 0. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         1.         1.         0.83011407 0.         0.37852448
 0.12774649 0.         1.         1.         1.         0.
 1.         0.         0.         1.         1.         0.30767383
 0.3742688  0.76173228 0.96638818 0.4701902  1.         0.
 0.         0.79401024]
wv_ed shape (26,)
[0.         1.         1.         1.         0.0465048  0.81702338
 0.85266525 0.7375942  1.         1.         0.86898612 0.46917192
 1.         0.44034823 0.         1.         1.         0.29875107
 1.         0.91027543 1.         1.         1.         0.06799363
 0.         0.77960636]
wv_lg shape (26, 1)
[[0.2240984 ]
 [0.22788935]
 [0.22786609]
 [0.22797888]
 [0.22719884]
 [0.22643548]
 [0.22837811]
 [0.22639423]
 [0.22738297]
 [0.22767296]
 [0.22832149]
 [0.22787462]
 [0.22632594]
 [0.22582856]
 [0.22730875]
 [0.22479785]
 [0.2285003 ]
 [0.22341576]
 [0.2257772 ]
 [0.2276532 ]
 [0.22727345]
 [0.2268642 ]
 [0.22770758]
 [0.22708825]
 [0.2285562 ]
 [0.22551207]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[0.86685629 0.42967874 1.         0.8701052  0.42439043 0.
 0.24910566 0.         0.68687994 1.         1.         0.22516012
 1.         0.         0.64826317 0.74731071 0.99837206 0.62529529
 0.00452229 0.74371721 0.85129664 0.83242117 1.         0.24116615
 1.         1.        ]
wv_std shape (26,)
[0.         0.5899154  0.63716131 0.         0.45772505 0.4134463
 0.28879961 0.80038009 1.         1.         0.03946241 0.
 1.         1.         0.30163188 1.         1.         0.87051336
 0.97268348 0.24610135 0.         1.         0.39171206 0.06872266
 0.         1.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.2240984  1.
  0.86685629 0.         0.        ]
 [1.         0.         1.         1.         0.22788935 1.
  0.42967874 0.5899154  1.        ]
 [1.         0.         1.         1.         0.22786609 1.
  1.         0.63716131 1.        ]
 [1.         0.         0.83011407 1.         0.22797888 1.
  0.8701052  0.         1.        ]
 [1.         0.         0.         0.0465048  0.22719884 1.
  0.42439043 0.45772505 1.        ]
 [1.         0.         0.37852448 0.81702338 0.22643548 1.
  0.         0.4134463  1.        ]
 [1.         0.         0.12774649 0.85266525 0.22837811 1.
  0.24910566 0.28879961 1.        ]
 [1.         0.         0.         0.7375942  0.22639423 1.
  0.         0.80038009 1.        ]
 [1.         0.         1.         1.         0.22738297 1.
  0.68687994 1.         1.        ]
 [1.         0.         1.         1.         0.22767296 1.
  1.         1.         1.        ]
 [1.         0.         1.         0.86898612 0.22832149 1.
  1.         0.03946241 1.        ]
 [1.         0.         0.         0.46917192 0.22787462 1.
  0.22516012 0.         1.        ]
 [1.         0.         1.         1.         0.22632594 1.
  1.         1.         1.        ]
 [1.         0.         0.         0.44034823 0.22582856 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.22730875 1.
  0.64826317 0.30163188 1.        ]
 [1.         0.         1.         1.         0.22479785 1.
  0.74731071 1.         1.        ]
 [1.         0.         1.         1.         0.2285003  1.
  0.99837206 1.         1.        ]
 [1.         0.         0.30767383 0.29875107 0.22341576 1.
  0.62529529 0.87051336 1.        ]
 [1.         0.         0.3742688  1.         0.2257772  1.
  0.00452229 0.97268348 1.        ]
 [1.         0.         0.76173228 0.91027543 0.2276532  1.
  0.74371721 0.24610135 1.        ]
 [1.         0.         0.96638818 1.         0.22727345 1.
  0.85129664 0.         1.        ]
 [1.         0.         0.4701902  1.         0.2268642  1.
  0.83242117 1.         1.        ]
 [1.         0.         1.         1.         0.22770758 1.
  1.         0.39171206 1.        ]
 [1.         0.         0.         0.06799363 0.22708825 1.
  0.24116615 0.06872266 1.        ]
 [0.         0.         0.         0.         0.2285562  1.
  1.         0.         1.        ]
 [1.         0.         0.79401024 0.77960636 0.22551207 1.
  1.         1.         1.        ]]

Best Training Poisoning Accuracy:
1.0
#####################         POISON         ###############################################

############################################################################################

comm_round: 10 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8

Accuracy per class:
[[8 0]
 [0 0]]
[ 1. nan]
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         1.         0.82812708 1.         0.         0.29359789
 1.         0.92424122 0.         0.         1.         0.86483826
 1.         0.         0.1795801  0.41561741 0.55941982 0.96232308
 1.         0.56057358 0.18040292 0.08600285 1.         1.
 1.         1.        ]
wv_ed shape (26,)
[0.         1.         1.         1.         0.         0.26822271
 1.         1.         0.         0.         1.         1.
 1.         0.         0.55966035 0.85888545 0.56604331 1.
 1.         0.82647199 0.34047637 0.26407916 1.         1.
 1.         1.        ]
wv_lg shape (26, 1)
[[0.22561074]
 [0.22890796]
 [0.22855073]
 [0.22790638]
 [0.22755988]
 [0.22778223]
 [0.22952324]
 [0.2275953 ]
 [0.2277299 ]
 [0.22894707]
 [0.22872343]
 [0.22999389]
 [0.2287036 ]
 [0.22892743]
 [0.22603152]
 [0.22885753]
 [0.22911349]
 [0.22959596]
 [0.22891715]
 [0.22923844]
 [0.22656327]
 [0.22921323]
 [0.22828901]
 [0.22853823]
 [0.22824089]
 [0.22812587]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1.         0.48307618 0.         0.40026867 0.2559813  1.
 0.6285606  0.         1.         0.         0.9800375  0.39684287
 0.         0.         0.         0.         1.         0.40166856
 1.         0.6069679  1.         0.         1.         0.18202001
 0.8838721  0.        ]
wv_std shape (26,)
[0.         0.91644128 1.         1.         0.         0.98787955
 1.         1.         0.         0.75330156 0.054132   0.
 1.         0.45218051 1.         0.8210158  1.         0.59968252
 1.         0.71883362 1.         1.         1.         1.
 0.8499003  0.20500016]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.22561074 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.22890796 1.
  0.48307618 0.91644128 1.        ]
 [1.         0.         0.82812708 1.         0.22855073 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.22790638 1.
  0.40026867 1.         1.        ]
 [0.         0.         0.         0.         0.22755988 1.
  0.2559813  0.         1.        ]
 [1.         0.         0.29359789 0.26822271 0.22778223 1.
  1.         0.98787955 1.        ]
 [1.         0.         1.         1.         0.22952324 1.
  0.6285606  1.         1.        ]
 [1.         0.         0.92424122 1.         0.2275953  1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.2277299  1.
  1.         0.         1.        ]
 [1.         0.         0.         0.         0.22894707 1.
  0.         0.75330156 1.        ]
 [1.         0.         1.         1.         0.22872343 1.
  0.9800375  0.054132   1.        ]
 [1.         0.         0.86483826 1.         0.22999389 1.
  0.39684287 0.         1.        ]
 [1.         0.         1.         1.         0.2287036  1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.22892743 1.
  0.         0.45218051 1.        ]
 [1.         0.         0.1795801  0.55966035 0.22603152 1.
  0.         1.         1.        ]
 [1.         0.         0.41561741 0.85888545 0.22885753 1.
  0.         0.8210158  1.        ]
 [1.         0.         0.55941982 0.56604331 0.22911349 1.
  1.         1.         1.        ]
 [1.         0.         0.96232308 1.         0.22959596 1.
  0.40166856 0.59968252 1.        ]
 [1.         0.         1.         1.         0.22891715 1.
  1.         1.         1.        ]
 [1.         0.         0.56057358 0.82647199 0.22923844 1.
  0.6069679  0.71883362 1.        ]
 [1.         0.         0.18040292 0.34047637 0.22656327 1.
  1.         1.         1.        ]
 [1.         0.         0.08600285 0.26407916 0.22921323 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.22828901 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.22853823 1.
  0.18202001 1.         1.        ]
 [1.         0.         1.         1.         0.22824089 1.
  0.8838721  0.8499003  1.        ]
 [1.         0.         1.         1.         0.22812587 1.
  0.         0.20500016 1.        ]]

Best Training Poisoning Accuracy:
1.0
#####################         POISON         ###############################################

############################################################################################

comm_round: 11 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8

Accuracy per class:
[[8 0]
 [0 0]]
[ 1. nan]
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.23834033 0.61394381 0.25958843 0.         0.1312733
 0.79380226 0.         0.         1.         1.         0.72825082
 0.93790625 0.05149065 0.         0.         1.         1.
 1.         1.         0.54577052 1.         1.         0.60021355
 0.65879686 0.80463239]
wv_ed shape (26,)
[0.         0.29512823 0.45512864 0.         0.         0.
 0.61732006 0.09046853 0.         1.         1.         0.8544795
 0.96629763 0.22254031 0.         0.         1.         1.
 1.         1.         0.74582215 1.         1.         0.03721456
 1.         1.        ]
wv_lg shape (26, 1)
[[0.22499209]
 [0.23036843]
 [0.23031669]
 [0.23006839]
 [0.22845585]
 [0.22860998]
 [0.22998551]
 [0.22979362]
 [0.22951842]
 [0.22988344]
 [0.2289208 ]
 [0.22924415]
 [0.22995131]
 [0.22877628]
 [0.22964137]
 [0.23012697]
 [0.2303118 ]
 [0.22942849]
 [0.22893449]
 [0.22901112]
 [0.2297967 ]
 [0.22977748]
 [0.23069182]
 [0.23105311]
 [0.22881521]
 [0.22916165]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1.         0.29067645 0.29804699 1.         0.         0.26616884
 0.10331683 0.28994753 0.         0.         0.34991423 0.84430899
 0.70177873 0.         0.43637618 0.         0.         0.
 0.         0.         0.69321841 1.         1.         0.
 0.         0.        ]
wv_std shape (26,)
[0.         0.         0.         0.         0.29362509 0.17970112
 0.         0.         0.         0.0552214  0.58877323 1.
 0.         0.00835602 0.         0.17368412 0.32180546 0.47295289
 1.         1.         0.         1.         0.2076265  0.
 0.80953902 1.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.22499209 1.
  1.         0.         0.        ]
 [1.         0.         0.23834033 0.29512823 0.23036843 1.
  0.29067645 0.         1.        ]
 [1.         0.         0.61394381 0.45512864 0.23031669 1.
  0.29804699 0.         1.        ]
 [1.         0.         0.25958843 0.         0.23006839 1.
  1.         0.         1.        ]
 [1.         0.         0.         0.         0.22845585 1.
  0.         0.29362509 1.        ]
 [1.         0.         0.1312733  0.         0.22860998 1.
  0.26616884 0.17970112 1.        ]
 [1.         0.         0.79380226 0.61732006 0.22998551 1.
  0.10331683 0.         1.        ]
 [1.         0.         0.         0.09046853 0.22979362 1.
  0.28994753 0.         1.        ]
 [1.         0.         0.         0.         0.22951842 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.22988344 1.
  0.         0.0552214  1.        ]
 [1.         0.         1.         1.         0.2289208  1.
  0.34991423 0.58877323 1.        ]
 [1.         0.         0.72825082 0.8544795  0.22924415 1.
  0.84430899 1.         1.        ]
 [1.         0.         0.93790625 0.96629763 0.22995131 1.
  0.70177873 0.         1.        ]
 [1.         0.         0.05149065 0.22254031 0.22877628 1.
  0.         0.00835602 1.        ]
 [0.         0.         0.         0.         0.22964137 1.
  0.43637618 0.         1.        ]
 [1.         0.         0.         0.         0.23012697 1.
  0.         0.17368412 1.        ]
 [1.         0.         1.         1.         0.2303118  1.
  0.         0.32180546 1.        ]
 [1.         0.         1.         1.         0.22942849 1.
  0.         0.47295289 1.        ]
 [1.         0.         1.         1.         0.22893449 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.22901112 1.
  0.         1.         1.        ]
 [1.         0.         0.54577052 0.74582215 0.2297967  1.
  0.69321841 0.         1.        ]
 [1.         0.         1.         1.         0.22977748 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.23069182 1.
  1.         0.2076265  1.        ]
 [1.         0.         0.60021355 0.03721456 0.23105311 1.
  0.         0.         1.        ]
 [1.         0.         0.65879686 1.         0.22881521 1.
  0.         0.80953902 1.        ]
 [1.         0.         0.80463239 1.         0.22916165 1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.9166666865348816
#####################         POISON         ###############################################

############################################################################################

comm_round: 12 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8

Accuracy per class:
[[8 0]
 [0 0]]
[ 1. nan]
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.         0.1619639  0.         0.         0.
 0.76041797 1.         1.         0.95599343 1.         1.
 1.         1.         0.26932467 0.79082608 1.         1.
 0.7336128  1.         1.         1.         0.9987979  0.59393714
 0.02926937 1.        ]
wv_ed shape (26,)
[0.         0.         0.69936471 0.         0.         0.
 0.81076799 1.         1.         1.         1.         1.
 1.         1.         0.39332373 1.         1.         1.
 1.         1.         1.         1.         1.         0.87961251
 0.42441925 1.        ]
wv_lg shape (26, 1)
[[0.22513079]
 [0.22756846]
 [0.23064025]
 [0.23234753]
 [0.23078641]
 [0.23128536]
 [0.22960571]
 [0.23176016]
 [0.23128102]
 [0.23164774]
 [0.23257734]
 [0.23132625]
 [0.23150206]
 [0.23021843]
 [0.22912735]
 [0.23198834]
 [0.2316953 ]
 [0.23318485]
 [0.23074709]
 [0.23164343]
 [0.23138562]
 [0.23029195]
 [0.23089092]
 [0.23013085]
 [0.22923605]
 [0.23158405]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1.         0.         0.         1.         0.         0.
 1.         0.69502333 0.         0.         1.         0.
 0.32380332 0.         0.         0.         0.20191906 0.
 0.         1.         0.         0.89959721 0.70447697 0.
 0.         0.        ]
wv_std shape (26,)
[0.         1.         0.42104378 0.         0.14275008 0.
 0.65894903 0.15831079 1.         0.90529525 0.         0.56372283
 1.         1.         0.6667964  0.         0.62631296 0.85214789
 0.97449956 0.72962157 1.         1.         1.         0.59824115
 0.80284206 1.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.22513079 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.22756846 1.
  0.         1.         1.        ]
 [1.         0.         0.1619639  0.69936471 0.23064025 1.
  0.         0.42104378 1.        ]
 [1.         0.         0.         0.         0.23234753 1.
  1.         0.         1.        ]
 [1.         0.         0.         0.         0.23078641 1.
  0.         0.14275008 1.        ]
 [1.         0.         0.         0.         0.23128536 1.
  0.         0.         1.        ]
 [1.         0.         0.76041797 0.81076799 0.22960571 1.
  1.         0.65894903 1.        ]
 [1.         0.         1.         1.         0.23176016 1.
  0.69502333 0.15831079 1.        ]
 [1.         0.         1.         1.         0.23128102 1.
  0.         1.         1.        ]
 [1.         0.         0.95599343 1.         0.23164774 1.
  0.         0.90529525 1.        ]
 [1.         0.         1.         1.         0.23257734 1.
  1.         0.         1.        ]
 [1.         0.         1.         1.         0.23132625 1.
  0.         0.56372283 1.        ]
 [1.         0.         1.         1.         0.23150206 1.
  0.32380332 1.         1.        ]
 [1.         0.         1.         1.         0.23021843 1.
  0.         1.         1.        ]
 [1.         0.         0.26932467 0.39332373 0.22912735 1.
  0.         0.6667964  1.        ]
 [1.         0.         0.79082608 1.         0.23198834 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.2316953  1.
  0.20191906 0.62631296 1.        ]
 [1.         0.         1.         1.         0.23318485 1.
  0.         0.85214789 1.        ]
 [1.         0.         0.7336128  1.         0.23074709 1.
  0.         0.97449956 1.        ]
 [1.         0.         1.         1.         0.23164343 1.
  1.         0.72962157 1.        ]
 [1.         0.         1.         1.         0.23138562 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.23029195 1.
  0.89959721 1.         1.        ]
 [1.         0.         0.9987979  1.         0.23089092 1.
  0.70447697 1.         1.        ]
 [1.         0.         0.59393714 0.87961251 0.23013085 1.
  0.         0.59824115 1.        ]
 [1.         0.         0.02926937 0.42441925 0.22923605 1.
  0.         0.80284206 1.        ]
 [1.         0.         1.         1.         0.23158405 1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
1.0
#####################         POISON         ###############################################

############################################################################################

comm_round: 13 | global_test_acc: 87.500% | global_f1: 0.9333333333333333 | global_precision: 0.875
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.88      1.00      0.93         7

    accuracy                           0.88         8
   macro avg       0.44      0.50      0.47         8
weighted avg       0.77      0.88      0.82         8

Accuracy per class:
[[7 0]
 [1 0]]
[1. 0.]
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.09538427 0.6917984  0.89126893 0.54821801 0.47051302
 1.         1.         1.         0.88039979 0.         1.
 0.         0.         0.72626964 1.         0.         0.
 0.47406262 0.57307928 1.         1.         1.         1.
 1.         1.        ]
wv_ed shape (26,)
[0.         0.00958071 0.87484951 0.68773814 0.89051876 0.82713856
 1.         1.         1.         1.         0.         1.
 0.         0.         0.94009185 0.70781577 0.         0.
 0.52803424 0.71074413 1.         1.         1.         1.
 1.         0.91743785]
wv_lg shape (26, 1)
[[0.2275657 ]
 [0.2330267 ]
 [0.23278405]
 [0.23387364]
 [0.23230169]
 [0.23271222]
 [0.23297398]
 [0.23267757]
 [0.23242528]
 [0.23252836]
 [0.23077153]
 [0.23258051]
 [0.23124642]
 [0.2321302 ]
 [0.23245518]
 [0.2340836 ]
 [0.23342954]
 [0.23257817]
 [0.23327844]
 [0.23269151]
 [0.23420703]
 [0.23365741]
 [0.23311682]
 [0.23171006]
 [0.23331004]
 [0.23243117]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1.         0.51066652 0.         1.         0.         0.
 1.         0.         0.         0.         0.         0.
 0.         0.         0.         1.         0.         0.
 1.         0.         1.         1.         0.04066465 0.
 1.         0.19091342]
wv_std shape (26,)
[0.         0.         0.08924124 0.         1.         1.
 1.         0.         1.         1.         0.         0.72770804
 0.23419995 0.         1.         0.         0.         0.
 0.08778688 0.         0.         0.         0.70624493 1.
 0.         0.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.2275657  1.
  1.         0.         0.        ]
 [1.         0.         0.09538427 0.00958071 0.2330267  1.
  0.51066652 0.         1.        ]
 [1.         0.         0.6917984  0.87484951 0.23278405 1.
  0.         0.08924124 1.        ]
 [1.         0.         0.89126893 0.68773814 0.23387364 1.
  1.         0.         1.        ]
 [1.         0.         0.54821801 0.89051876 0.23230169 1.
  0.         1.         1.        ]
 [1.         0.         0.47051302 0.82713856 0.23271222 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.23297398 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.23267757 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.23242528 1.
  0.         1.         1.        ]
 [1.         0.         0.88039979 1.         0.23252836 1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.23077153 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.23258051 1.
  0.         0.72770804 1.        ]
 [1.         0.         0.         0.         0.23124642 1.
  0.         0.23419995 1.        ]
 [1.         0.         0.         0.         0.2321302  1.
  0.         0.         1.        ]
 [1.         0.         0.72626964 0.94009185 0.23245518 1.
  0.         1.         1.        ]
 [1.         0.         1.         0.70781577 0.2340836  1.
  1.         0.         1.        ]
 [1.         0.         0.         0.         0.23342954 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.23257817 1.
  0.         0.         1.        ]
 [1.         0.         0.47406262 0.52803424 0.23327844 1.
  1.         0.08778688 1.        ]
 [1.         0.         0.57307928 0.71074413 0.23269151 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.23420703 1.
  1.         0.         1.        ]
 [1.         0.         1.         1.         0.23365741 1.
  1.         0.         1.        ]
 [1.         0.         1.         1.         0.23311682 1.
  0.04066465 0.70624493 1.        ]
 [1.         0.         1.         1.         0.23171006 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.23331004 1.
  1.         0.         1.        ]
 [1.         0.         1.         0.91743785 0.23243117 1.
  0.19091342 0.         1.        ]]

Best Training Poisoning Accuracy:
0.9166666865348816
#####################         POISON         ###############################################

############################################################################################

comm_round: 14 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8

Accuracy per class:
[[8 0]
 [0 0]]
[ 1. nan]
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.         0.24309662 0.06531832 1.         0.77663606
 0.95632059 0.60968015 1.         1.         1.         1.
 0.         1.         1.         0.85170035 1.         0.
 0.         1.         0.         1.         0.67963139 0.61399073
 1.         1.        ]
wv_ed shape (26,)
[0.         0.         0.16591753 0.         0.9452922  0.58489903
 0.05284457 0.30073167 0.89014833 1.         1.         1.
 0.         0.5316735  1.         0.87462328 0.61762997 0.01883902
 0.         1.         0.         0.918766   0.31310813 0.76173957
 1.         1.        ]
wv_lg shape (26, 1)
[[0.22905569]
 [0.23539479]
 [0.23514476]
 [0.23505164]
 [0.23389929]
 [0.23511577]
 [0.23600973]
 [0.23447972]
 [0.23480916]
 [0.23308327]
 [0.23445099]
 [0.2344993 ]
 [0.23407202]
 [0.23482474]
 [0.23572744]
 [0.23422067]
 [0.23431901]
 [0.23408965]
 [0.23471686]
 [0.2340941 ]
 [0.23486791]
 [0.23532494]
 [0.236241  ]
 [0.23427373]
 [0.23425589]
 [0.23513338]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1.         0.         0.         0.         1.         0.59766623
 0.90485192 0.76952086 1.         0.59422188 0.         1.
 1.         0.81981927 0.         0.         0.         0.
 1.         0.         0.         1.         0.         0.
 1.         0.        ]
wv_std shape (26,)
[0.         1.         0.07967222 0.         1.         1.
 0.         0.00393082 0.82825891 1.         0.36949642 0.22750175
 1.         0.         0.11130984 0.58609905 0.         0.47731141
 0.54030058 1.         0.         0.98255938 0.82331679 1.
 1.         1.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.22905569 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.23539479 1.
  0.         1.         1.        ]
 [1.         0.         0.24309662 0.16591753 0.23514476 1.
  0.         0.07967222 1.        ]
 [1.         0.         0.06531832 0.         0.23505164 1.
  0.         0.         1.        ]
 [1.         0.         1.         0.9452922  0.23389929 1.
  1.         1.         1.        ]
 [1.         0.         0.77663606 0.58489903 0.23511577 1.
  0.59766623 1.         1.        ]
 [1.         0.         0.95632059 0.05284457 0.23600973 1.
  0.90485192 0.         1.        ]
 [1.         0.         0.60968015 0.30073167 0.23447972 1.
  0.76952086 0.00393082 1.        ]
 [1.         0.         1.         0.89014833 0.23480916 1.
  1.         0.82825891 1.        ]
 [1.         0.         1.         1.         0.23308327 1.
  0.59422188 1.         1.        ]
 [1.         0.         1.         1.         0.23445099 1.
  0.         0.36949642 1.        ]
 [1.         0.         1.         1.         0.2344993  1.
  1.         0.22750175 1.        ]
 [1.         0.         0.         0.         0.23407202 1.
  1.         1.         1.        ]
 [1.         0.         1.         0.5316735  0.23482474 1.
  0.81981927 0.         1.        ]
 [1.         0.         1.         1.         0.23572744 1.
  0.         0.11130984 1.        ]
 [1.         0.         0.85170035 0.87462328 0.23422067 1.
  0.         0.58609905 1.        ]
 [1.         0.         1.         0.61762997 0.23431901 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.01883902 0.23408965 1.
  0.         0.47731141 1.        ]
 [1.         0.         0.         0.         0.23471686 1.
  1.         0.54030058 1.        ]
 [1.         0.         1.         1.         0.2340941  1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.23486791 1.
  0.         0.         1.        ]
 [1.         0.         1.         0.918766   0.23532494 1.
  1.         0.98255938 1.        ]
 [1.         0.         0.67963139 0.31310813 0.236241   1.
  0.         0.82331679 1.        ]
 [1.         0.         0.61399073 0.76173957 0.23427373 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.23425589 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.23513338 1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
1.0
#####################         POISON         ###############################################

############################################################################################

comm_round: 15 | global_test_acc: 87.500% | global_f1: 0.9333333333333333 | global_precision: 0.875
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.88      1.00      0.93         7

    accuracy                           0.88         8
   macro avg       0.44      0.50      0.47         8
weighted avg       0.77      0.88      0.82         8

Accuracy per class:
[[7 0]
 [1 0]]
[1. 0.]
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.9685464  1.         0.         1.         1.
 0.06844945 0.57891982 1.         0.79027582 0.52629264 0.
 0.         0.80804889 0.         0.79818836 1.         1.
 0.46615947 0.66229836 1.         0.         0.11204616 0.67271164
 0.67060681 1.        ]
wv_ed shape (26,)
[0.         1.         1.         0.         1.         1.
 0.65889927 0.91446892 1.         0.62979377 0.59153677 0.
 0.21998993 0.99997015 0.         1.         1.         1.
 0.6386794  1.         1.         0.         0.56096895 1.
 1.         1.        ]
wv_lg shape (26, 1)
[[0.23116053]
 [0.23750458]
 [0.23644715]
 [0.23676758]
 [0.23627081]
 [0.23607214]
 [0.2358539 ]
 [0.23686582]
 [0.23544477]
 [0.23679684]
 [0.2372896 ]
 [0.2367084 ]
 [0.23676621]
 [0.23702197]
 [0.23657613]
 [0.23438181]
 [0.23750558]
 [0.2367279 ]
 [0.23698684]
 [0.23516846]
 [0.23710444]
 [0.23557626]
 [0.23665441]
 [0.23639275]
 [0.2363902 ]
 [0.23789917]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1.         1.         0.         0.         1.         0.
 0.         0.69234386 0.         1.         1.         0.
 1.         0.         1.         1.         0.         0.2264061
 0.         0.         0.52732831 0.         0.29274341 0.
 0.         0.        ]
wv_std shape (26,)
[0.         0.00390624 0.46860298 0.         0.         1.
 1.         0.28842091 1.         0.         0.         0.
 0.         0.         0.         1.         0.30563313 0.
 0.         1.         0.         1.         0.06411332 0.85524549
 0.23660549 1.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.23116053 1.
  1.         0.         0.        ]
 [1.         0.         0.9685464  1.         0.23750458 1.
  1.         0.00390624 1.        ]
 [1.         0.         1.         1.         0.23644715 1.
  0.         0.46860298 1.        ]
 [1.         0.         0.         0.         0.23676758 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.23627081 1.
  1.         0.         1.        ]
 [1.         0.         1.         1.         0.23607214 1.
  0.         1.         1.        ]
 [1.         0.         0.06844945 0.65889927 0.2358539  1.
  0.         1.         1.        ]
 [1.         0.         0.57891982 0.91446892 0.23686582 1.
  0.69234386 0.28842091 1.        ]
 [1.         0.         1.         1.         0.23544477 1.
  0.         1.         1.        ]
 [1.         0.         0.79027582 0.62979377 0.23679684 1.
  1.         0.         1.        ]
 [1.         0.         0.52629264 0.59153677 0.2372896  1.
  1.         0.         1.        ]
 [0.         0.         0.         0.         0.2367084  1.
  0.         0.         1.        ]
 [1.         0.         0.         0.21998993 0.23676621 1.
  1.         0.         1.        ]
 [1.         0.         0.80804889 0.99997015 0.23702197 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.23657613 1.
  1.         0.         1.        ]
 [1.         0.         0.79818836 1.         0.23438181 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.23750558 1.
  0.         0.30563313 1.        ]
 [1.         0.         1.         1.         0.2367279  1.
  0.2264061  0.         1.        ]
 [1.         0.         0.46615947 0.6386794  0.23698684 1.
  0.         0.         1.        ]
 [1.         0.         0.66229836 1.         0.23516846 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.23710444 1.
  0.52732831 0.         1.        ]
 [1.         0.         0.         0.         0.23557626 1.
  0.         1.         1.        ]
 [1.         0.         0.11204616 0.56096895 0.23665441 1.
  0.29274341 0.06411332 1.        ]
 [1.         0.         0.67271164 1.         0.23639275 1.
  0.         0.85524549 1.        ]
 [1.         0.         0.67060681 1.         0.2363902  1.
  0.         0.23660549 1.        ]
 [1.         0.         1.         1.         0.23789917 1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
1.0
#####################         POISON         ###############################################

############################################################################################

comm_round: 16 | global_test_acc: 87.500% | global_f1: 0.9333333333333333 | global_precision: 0.875
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.88      1.00      0.93         7

    accuracy                           0.88         8
   macro avg       0.44      0.50      0.47         8
weighted avg       0.77      0.88      0.82         8

Accuracy per class:
[[7 0]
 [1 0]]
[1. 0.]
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         1.         1.         1.         1.         0.11883376
 0.         1.         0.         0.63033074 0.5338765  1.
 0.57441205 0.         1.         0.         1.         1.
 0.         1.         1.         1.         1.         0.
 0.         0.        ]
wv_ed shape (26,)
[0.         0.95684886 0.73698694 1.         1.         0.26390867
 0.14064611 1.         0.         0.41350342 0.18639845 1.
 0.         0.         0.562092   0.         1.         1.
 0.         1.         1.         1.         1.         0.
 0.         0.        ]
wv_lg shape (26, 1)
[[0.23381329]
 [0.23965533]
 [0.23909858]
 [0.23872901]
 [0.23885591]
 [0.23826464]
 [0.23809985]
 [0.2391618 ]
 [0.23846324]
 [0.23875361]
 [0.24016223]
 [0.23826381]
 [0.23946281]
 [0.23885652]
 [0.23889214]
 [0.23986315]
 [0.23883833]
 [0.23980611]
 [0.23889366]
 [0.2389016 ]
 [0.23995476]
 [0.23950335]
 [0.23856039]
 [0.23828036]
 [0.23793659]
 [0.23859171]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[0.77893775 0.88472857 0.14356058 0.         0.62253557 0.
 0.         1.         0.         0.         0.         1.
 0.01884874 0.         0.36971292 0.         0.19045035 1.
 1.         0.         0.         0.45552921 1.         0.
 0.         0.        ]
wv_std shape (26,)
[0.         0.81798486 0.         1.         0.53562155 0.83547064
 0.64438106 0.56569692 0.67150896 0.14342625 0.09492077 1.
 0.         0.2017347  0.         0.         1.         0.
 0.         1.         1.         0.64793841 1.         0.27606223
 0.53305085 0.16662273]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.23381329 1.
  0.77893775 0.         0.        ]
 [1.         0.         1.         0.95684886 0.23965533 1.
  0.88472857 0.81798486 1.        ]
 [1.         0.         1.         0.73698694 0.23909858 1.
  0.14356058 0.         1.        ]
 [1.         0.         1.         1.         0.23872901 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.23885591 1.
  0.62253557 0.53562155 1.        ]
 [1.         0.         0.11883376 0.26390867 0.23826464 1.
  0.         0.83547064 1.        ]
 [1.         0.         0.         0.14064611 0.23809985 1.
  0.         0.64438106 1.        ]
 [1.         0.         1.         1.         0.2391618  1.
  1.         0.56569692 1.        ]
 [1.         0.         0.         0.         0.23846324 1.
  0.         0.67150896 1.        ]
 [1.         0.         0.63033074 0.41350342 0.23875361 1.
  0.         0.14342625 1.        ]
 [1.         0.         0.5338765  0.18639845 0.24016223 1.
  0.         0.09492077 1.        ]
 [1.         0.         1.         1.         0.23826381 1.
  1.         1.         1.        ]
 [1.         0.         0.57441205 0.         0.23946281 1.
  0.01884874 0.         1.        ]
 [1.         0.         0.         0.         0.23885652 1.
  0.         0.2017347  1.        ]
 [1.         0.         1.         0.562092   0.23889214 1.
  0.36971292 0.         1.        ]
 [0.         0.         0.         0.         0.23986315 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.23883833 1.
  0.19045035 1.         1.        ]
 [1.         0.         1.         1.         0.23980611 1.
  1.         0.         1.        ]
 [1.         0.         0.         0.         0.23889366 1.
  1.         0.         1.        ]
 [1.         0.         1.         1.         0.2389016  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.23995476 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.23950335 1.
  0.45552921 0.64793841 1.        ]
 [1.         0.         1.         1.         0.23856039 1.
  1.         1.         1.        ]
 [1.         0.         0.         0.         0.23828036 1.
  0.         0.27606223 1.        ]
 [1.         0.         0.         0.         0.23793659 1.
  0.         0.53305085 1.        ]
 [1.         0.         0.         0.         0.23859171 1.
  0.         0.16662273 1.        ]]

Best Training Poisoning Accuracy:
1.0
#####################         POISON         ###############################################

############################################################################################

comm_round: 17 | global_test_acc: 87.500% | global_f1: 0.9333333333333333 | global_precision: 0.875
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.88      1.00      0.93         7

    accuracy                           0.88         8
   macro avg       0.44      0.50      0.47         8
weighted avg       0.77      0.88      0.82         8

Accuracy per class:
[[7 0]
 [1 0]]
[1. 0.]
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.45916374 0.62747895 0.78390561 1.         1.
 0.         0.23624664 0.25063734 0.         0.34929065 1.
 0.39518606 0.         1.         0.84758981 0.85716863 0.
 1.         1.         1.         0.10913035 0.         1.
 0.43250683 0.51231426]
wv_ed shape (26,)
[0.         0.28259575 0.         0.51298447 1.         1.
 0.         0.57683194 0.         0.         0.52963476 1.
 0.86114903 0.         0.67485111 1.         0.         0.
 1.         0.29906112 1.         0.28753098 0.         1.
 0.54095326 0.        ]
wv_lg shape (26, 1)
[[0.23741111]
 [0.2424269 ]
 [0.24307884]
 [0.24297854]
 [0.24295482]
 [0.2429503 ]
 [0.24233235]
 [0.24180121]
 [0.24333117]
 [0.24274336]
 [0.24312436]
 [0.24365204]
 [0.24276349]
 [0.24257871]
 [0.24277159]
 [0.24235523]
 [0.24286789]
 [0.24288935]
 [0.24313345]
 [0.24354399]
 [0.24225153]
 [0.24176243]
 [0.24196833]
 [0.24263633]
 [0.24220126]
 [0.24302972]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[0.67358177 0.44532117 1.         1.         0.         1.
 0.22106813 1.         0.         0.10978349 0.         0.
 0.         0.         0.         0.         0.95355487 0.
 0.         1.         0.64552595 0.         0.         0.
 0.82353648 0.        ]
wv_std shape (26,)
[0.         0.36823641 0.         0.50107651 1.         1.
 0.         1.         0.4975209  1.         1.         0.27395965
 1.         0.10264332 0.24601513 1.         0.         1.
 1.         0.         1.         0.80772887 0.74664151 0.88450094
 0.69070093 0.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.23741111 1.
  0.67358177 0.         0.        ]
 [1.         0.         0.45916374 0.28259575 0.2424269  1.
  0.44532117 0.36823641 1.        ]
 [1.         0.         0.62747895 0.         0.24307884 1.
  1.         0.         1.        ]
 [1.         0.         0.78390561 0.51298447 0.24297854 1.
  1.         0.50107651 1.        ]
 [1.         0.         1.         1.         0.24295482 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.2429503  1.
  1.         1.         1.        ]
 [0.         0.         0.         0.         0.24233235 1.
  0.22106813 0.         1.        ]
 [1.         0.         0.23624664 0.57683194 0.24180121 1.
  1.         1.         1.        ]
 [1.         0.         0.25063734 0.         0.24333117 1.
  0.         0.4975209  1.        ]
 [1.         0.         0.         0.         0.24274336 1.
  0.10978349 1.         1.        ]
 [1.         0.         0.34929065 0.52963476 0.24312436 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.24365204 1.
  0.         0.27395965 1.        ]
 [1.         0.         0.39518606 0.86114903 0.24276349 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.24257871 1.
  0.         0.10264332 1.        ]
 [1.         0.         1.         0.67485111 0.24277159 1.
  0.         0.24601513 1.        ]
 [1.         0.         0.84758981 1.         0.24235523 1.
  0.         1.         1.        ]
 [1.         0.         0.85716863 0.         0.24286789 1.
  0.95355487 0.         1.        ]
 [1.         0.         0.         0.         0.24288935 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.24313345 1.
  0.         1.         1.        ]
 [1.         0.         1.         0.29906112 0.24354399 1.
  1.         0.         1.        ]
 [1.         0.         1.         1.         0.24225153 1.
  0.64552595 1.         1.        ]
 [1.         0.         0.10913035 0.28753098 0.24176243 1.
  0.         0.80772887 1.        ]
 [1.         0.         0.         0.         0.24196833 1.
  0.         0.74664151 1.        ]
 [1.         0.         1.         1.         0.24263633 1.
  0.         0.88450094 1.        ]
 [1.         0.         0.43250683 0.54095326 0.24220126 1.
  0.82353648 0.69070093 1.        ]
 [1.         0.         0.51231426 0.         0.24302972 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
1.0
#####################         POISON         ###############################################

############################################################################################

comm_round: 18 | global_test_acc: 87.500% | global_f1: 0.9333333333333333 | global_precision: 0.875
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.88      1.00      0.93         7

    accuracy                           0.88         8
   macro avg       0.44      0.50      0.47         8
weighted avg       0.77      0.88      0.82         8

Accuracy per class:
[[7 0]
 [1 0]]
[1. 0.]
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.32187435
 0.         0.        ]
wv_mn shape (26,)
[0.         1.         0.91496497 0.         1.         0.
 0.         0.         1.         0.         0.11738946 1.
 0.         0.         1.         0.         1.         0.
 1.         1.         1.         1.         1.         0.
 1.         1.        ]
wv_ed shape (26,)
[0.         1.         0.89921144 0.         0.98539698 0.
 0.24968264 0.89587358 1.         0.5034418  0.         1.
 0.06160528 0.         1.         0.         0.35789964 0.
 1.         1.         1.         0.82423125 1.         0.39100993
 1.         1.        ]
wv_lg shape (26, 1)
[[0.24194172]
 [0.24704263]
 [0.2469132 ]
 [0.24690261]
 [0.24774163]
 [0.24792571]
 [0.24727307]
 [0.24755009]
 [0.24698798]
 [0.24782305]
 [0.24717729]
 [0.24749677]
 [0.2476826 ]
 [0.24765837]
 [0.24776857]
 [0.24783127]
 [0.24754859]
 [0.24693965]
 [0.2465357 ]
 [0.24728946]
 [0.24727718]
 [0.24770025]
 [0.24795472]
 [0.24773601]
 [0.24652487]
 [0.24699655]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1.         0.32471951 0.         0.         1.         0.
 0.         0.         0.         0.         0.         0.58008126
 0.         0.27122084 0.34249633 0.73183048 1.         0.
 1.         0.         0.42852423 0.71978835 0.12920741 0.
 0.         0.        ]
wv_std shape (26,)
[0.         0.49319166 0.73506373 0.         0.67339267 0.
 0.26988201 0.31849351 1.         0.72772183 0.04613176 1.
 0.         0.         0.93516105 0.         0.         0.
 1.         0.88120079 1.         0.08334155 0.70076399 0.23707634
 1.         1.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.24194172 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.24704263 1.
  0.32471951 0.49319166 1.        ]
 [1.         0.         0.91496497 0.89921144 0.2469132  1.
  0.         0.73506373 1.        ]
 [1.         0.         0.         0.         0.24690261 1.
  0.         0.         1.        ]
 [1.         0.         1.         0.98539698 0.24774163 1.
  1.         0.67339267 1.        ]
 [0.         0.         0.         0.         0.24792571 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.24968264 0.24727307 1.
  0.         0.26988201 1.        ]
 [1.         0.         0.         0.89587358 0.24755009 1.
  0.         0.31849351 1.        ]
 [1.         0.         1.         1.         0.24698798 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.5034418  0.24782305 1.
  0.         0.72772183 1.        ]
 [1.         0.         0.11738946 0.         0.24717729 1.
  0.         0.04613176 1.        ]
 [1.         0.         1.         1.         0.24749677 1.
  0.58008126 1.         1.        ]
 [1.         0.         0.         0.06160528 0.2476826  1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.24765837 1.
  0.27122084 0.         1.        ]
 [1.         0.         1.         1.         0.24776857 1.
  0.34249633 0.93516105 1.        ]
 [1.         0.         0.         0.         0.24783127 1.
  0.73183048 0.         1.        ]
 [1.         0.         1.         0.35789964 0.24754859 1.
  1.         0.         1.        ]
 [1.         0.         0.         0.         0.24693965 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.2465357  1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.24728946 1.
  0.         0.88120079 1.        ]
 [1.         0.         1.         1.         0.24727718 1.
  0.42852423 1.         1.        ]
 [1.         0.         1.         0.82423125 0.24770025 1.
  0.71978835 0.08334155 1.        ]
 [1.         0.         1.         1.         0.24795472 1.
  0.12920741 0.70076399 1.        ]
 [1.         0.32187435 0.         0.39100993 0.24773601 1.
  0.         0.23707634 1.        ]
 [1.         0.         1.         1.         0.24652487 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.24699655 1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.9166666865348816
#####################         POISON         ###############################################

############################################################################################

comm_round: 19 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8

Accuracy per class:
[[8 0]
 [0 0]]
[ 1. nan]
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.27130659]
wv_mn shape (26,)
[0.         1.         1.         0.7563063  0.         0.32090487
 0.         0.         0.         0.27426437 1.         1.
 1.         0.         0.73844609 1.         0.13305381 0.
 0.         1.         0.75367404 0.85444403 0.86417225 0.
 1.         0.        ]
wv_ed shape (26,)
[0.         1.         1.         0.34598917 0.         0.92878318
 0.         0.         0.30257075 0.37113072 1.         1.
 0.98335355 0.         1.         1.         0.86846098 0.46333594
 0.         1.         1.         1.         1.         0.
 1.         0.        ]
wv_lg shape (26, 1)
[[0.2467945 ]
 [0.25318603]
 [0.25197683]
 [0.25327545]
 [0.25308167]
 [0.25210855]
 [0.25230377]
 [0.2521346 ]
 [0.25151317]
 [0.25154773]
 [0.25208274]
 [0.25284112]
 [0.25317342]
 [0.25367251]
 [0.25217772]
 [0.25236961]
 [0.2527992 ]
 [0.25295473]
 [0.25214929]
 [0.25217166]
 [0.25183713]
 [0.25307946]
 [0.25131203]
 [0.25215504]
 [0.25211576]
 [0.25172516]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[0.73058048 1.         1.         0.53889379 0.         0.3479912
 0.57316906 0.37265244 0.19477707 0.         0.         0.
 1.         0.         0.07013292 1.         0.         0.
 0.         0.99592701 0.         0.         0.57156718 1.
 1.         1.        ]
wv_std shape (26,)
[0.         0.59646179 0.91874858 0.         0.         0.75554775
 0.         0.08969445 0.53708671 0.         0.90578171 1.
 0.         0.         1.         0.95770992 0.83098937 0.42472514
 0.         1.         1.         1.         1.         0.
 1.         0.62454264]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.2467945  1.
  0.73058048 0.         0.        ]
 [1.         0.         1.         1.         0.25318603 1.
  1.         0.59646179 1.        ]
 [1.         0.         1.         1.         0.25197683 1.
  1.         0.91874858 1.        ]
 [1.         0.         0.7563063  0.34598917 0.25327545 1.
  0.53889379 0.         1.        ]
 [1.         0.         0.         0.         0.25308167 1.
  0.         0.         1.        ]
 [1.         0.         0.32090487 0.92878318 0.25210855 1.
  0.3479912  0.75554775 1.        ]
 [0.         0.         0.         0.         0.25230377 1.
  0.57316906 0.         1.        ]
 [1.         0.         0.         0.         0.2521346  1.
  0.37265244 0.08969445 1.        ]
 [1.         0.         0.         0.30257075 0.25151317 1.
  0.19477707 0.53708671 1.        ]
 [1.         0.         0.27426437 0.37113072 0.25154773 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.25208274 1.
  0.         0.90578171 1.        ]
 [1.         0.         1.         1.         0.25284112 1.
  0.         1.         1.        ]
 [1.         0.         1.         0.98335355 0.25317342 1.
  1.         0.         1.        ]
 [1.         0.         0.         0.         0.25367251 1.
  0.         0.         1.        ]
 [1.         0.         0.73844609 1.         0.25217772 1.
  0.07013292 1.         1.        ]
 [1.         0.         1.         1.         0.25236961 1.
  1.         0.95770992 1.        ]
 [1.         0.         0.13305381 0.86846098 0.2527992  1.
  0.         0.83098937 1.        ]
 [1.         0.         0.         0.46333594 0.25295473 1.
  0.         0.42472514 1.        ]
 [1.         0.         0.         0.         0.25214929 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.25217166 1.
  0.99592701 1.         1.        ]
 [1.         0.         0.75367404 1.         0.25183713 1.
  0.         1.         1.        ]
 [1.         0.         0.85444403 1.         0.25307946 1.
  0.         1.         1.        ]
 [1.         0.         0.86417225 1.         0.25131203 1.
  0.57156718 1.         1.        ]
 [1.         0.         0.         0.         0.25215504 1.
  1.         0.         1.        ]
 [1.         0.         1.         1.         0.25211576 1.
  1.         1.         1.        ]
 [1.         0.27130659 0.         0.         0.25172516 1.
  1.         0.62454264 1.        ]]

Best Training Poisoning Accuracy:
1.0
#####################         POISON         ###############################################

############################################################################################

comm_round: 20 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8

Accuracy per class:
[[8 0]
 [0 0]]
[ 1. nan]
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         1.         1.         0.9985493  1.         0.
 0.43484803 0.58067229 0.50111955 1.         0.         1.
 0.98730217 1.         1.         1.         1.         0.07086048
 1.         0.93697585 1.         1.         1.         0.
 1.         0.35391857]
wv_ed shape (26,)
[0.         1.         1.         1.         1.         0.
 1.         1.         0.74973353 1.         0.64803356 1.
 1.         1.         1.         1.         1.         1.
 0.94522653 1.         1.         1.         0.26279244 0.12525248
 1.         1.        ]
wv_lg shape (26, 1)
[[0.25194003]
 [0.25915051]
 [0.25796169]
 [0.25842093]
 [0.25859062]
 [0.25762585]
 [0.25923208]
 [0.2568769 ]
 [0.25707933]
 [0.25928638]
 [0.25732934]
 [0.25870158]
 [0.25730546]
 [0.25751985]
 [0.25736555]
 [0.25777207]
 [0.25918471]
 [0.25698675]
 [0.25885832]
 [0.25832095]
 [0.25831667]
 [0.25651093]
 [0.2587109 ]
 [0.25876809]
 [0.25874995]
 [0.25664307]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[0.63398053 0.         0.         0.12371839 1.         0.88680625
 0.         1.         0.17076134 0.         0.         0.
 0.99327288 0.37159026 1.         1.         0.91109217 0.17228686
 0.         0.         0.2169017  0.64346663 1.         0.
 1.         0.        ]
wv_std shape (26,)
[0.         1.         1.         0.54138632 1.         0.
 1.         0.97646914 0.         1.         0.49369539 1.
 1.         1.         1.         0.62988324 1.         1.
 0.         0.18835532 1.         1.         0.         0.
 1.         1.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.25194003 1.
  0.63398053 0.         0.        ]
 [1.         0.         1.         1.         0.25915051 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.25796169 1.
  0.         1.         1.        ]
 [1.         0.         0.9985493  1.         0.25842093 1.
  0.12371839 0.54138632 1.        ]
 [1.         0.         1.         1.         0.25859062 1.
  1.         1.         1.        ]
 [0.         0.         0.         0.         0.25762585 1.
  0.88680625 0.         1.        ]
 [1.         0.         0.43484803 1.         0.25923208 1.
  0.         1.         1.        ]
 [1.         0.         0.58067229 1.         0.2568769  1.
  1.         0.97646914 1.        ]
 [1.         0.         0.50111955 0.74973353 0.25707933 1.
  0.17076134 0.         1.        ]
 [1.         0.         1.         1.         0.25928638 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.64803356 0.25732934 1.
  0.         0.49369539 1.        ]
 [1.         0.         1.         1.         0.25870158 1.
  0.         1.         1.        ]
 [1.         0.         0.98730217 1.         0.25730546 1.
  0.99327288 1.         1.        ]
 [1.         0.         1.         1.         0.25751985 1.
  0.37159026 1.         1.        ]
 [1.         0.         1.         1.         0.25736555 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.25777207 1.
  1.         0.62988324 1.        ]
 [1.         0.         1.         1.         0.25918471 1.
  0.91109217 1.         1.        ]
 [1.         0.         0.07086048 1.         0.25698675 1.
  0.17228686 1.         1.        ]
 [1.         0.         1.         0.94522653 0.25885832 1.
  0.         0.         1.        ]
 [1.         0.         0.93697585 1.         0.25832095 1.
  0.         0.18835532 1.        ]
 [1.         0.         1.         1.         0.25831667 1.
  0.2169017  1.         1.        ]
 [1.         0.         1.         1.         0.25651093 1.
  0.64346663 1.         1.        ]
 [1.         0.         1.         0.26279244 0.2587109  1.
  1.         0.         1.        ]
 [1.         0.         0.         0.12525248 0.25876809 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.25874995 1.
  1.         1.         1.        ]
 [1.         0.         0.35391857 1.         0.25664307 1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
1.0
#####################         POISON         ###############################################

############################################################################################

comm_round: 21 | global_test_acc: 87.500% | global_f1: 0.9333333333333333 | global_precision: 0.875
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.88      1.00      0.93         7

    accuracy                           0.88         8
   macro avg       0.44      0.50      0.47         8
weighted avg       0.77      0.88      0.82         8

Accuracy per class:
[[7 0]
 [1 0]]
[1. 0.]
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         1.         1.         0.         1.         1.
 1.         0.30104421 1.         1.         0.40556949 1.
 1.         0.         0.         0.35012509 0.         1.
 1.         0.4031779  0.22310054 0.54812412 0.9807493  0.
 0.         1.        ]
wv_ed shape (26,)
[0.         1.         1.         0.         0.91141163 1.
 1.         0.         1.         1.         0.         1.
 1.         0.         0.         0.         0.         1.
 1.         0.91391429 0.         0.         1.         0.
 0.30520162 0.93735593]
wv_lg shape (26, 1)
[[0.25661999]
 [0.26390804]
 [0.263051  ]
 [0.26414737]
 [0.26382713]
 [0.26291052]
 [0.26405948]
 [0.26303351]
 [0.26345452]
 [0.26439464]
 [0.26304886]
 [0.26309143]
 [0.26310675]
 [0.26412092]
 [0.26381792]
 [0.26352513]
 [0.26337695]
 [0.26246784]
 [0.2641783 ]
 [0.26419901]
 [0.26338599]
 [0.26470601]
 [0.26403576]
 [0.2634468 ]
 [0.26357628]
 [0.26385116]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[0.         1.         0.         1.         1.         0.
 0.         1.         1.         0.         0.         0.55785786
 0.         0.09647257 0.         0.         0.         0.
 0.         0.         0.18778725 0.         0.73869981 0.
 0.         0.35273732]
wv_std shape (26,)
[0.         1.         1.         0.58905163 1.         1.
 1.         0.05723237 1.         1.         0.81287755 1.
 1.         1.         0.         0.         0.         1.
 1.         1.         0.         0.         1.         1.
 1.         1.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.25661999 1.
  0.         0.         0.        ]
 [1.         0.         1.         1.         0.26390804 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.263051   1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.26414737 1.
  1.         0.58905163 1.        ]
 [1.         1.         1.         0.91141163 0.26382713 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.26291052 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.26405948 1.
  0.         1.         1.        ]
 [1.         0.         0.30104421 0.         0.26303351 1.
  1.         0.05723237 1.        ]
 [1.         0.         1.         1.         0.26345452 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.26439464 1.
  0.         1.         1.        ]
 [1.         0.         0.40556949 0.         0.26304886 1.
  0.         0.81287755 1.        ]
 [1.         0.         1.         1.         0.26309143 1.
  0.55785786 1.         1.        ]
 [1.         0.         1.         1.         0.26310675 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.26412092 1.
  0.09647257 1.         1.        ]
 [0.         0.         0.         0.         0.26381792 1.
  0.         0.         1.        ]
 [1.         0.         0.35012509 0.         0.26352513 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.26337695 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.26246784 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.2641783  1.
  0.         1.         1.        ]
 [1.         0.         0.4031779  0.91391429 0.26419901 1.
  0.         1.         1.        ]
 [1.         0.         0.22310054 0.         0.26338599 1.
  0.18778725 0.         1.        ]
 [1.         0.         0.54812412 0.         0.26470601 1.
  0.         0.         1.        ]
 [1.         0.         0.9807493  1.         0.26403576 1.
  0.73869981 1.         1.        ]
 [1.         0.         0.         0.         0.2634468  1.
  0.         1.         1.        ]
 [1.         0.         0.         0.30520162 0.26357628 1.
  0.         1.         1.        ]
 [1.         0.         1.         0.93735593 0.26385116 1.
  0.35273732 1.         1.        ]]

Best Training Poisoning Accuracy:
0.9166666865348816
#####################         POISON         ###############################################

############################################################################################

comm_round: 22 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8

Accuracy per class:
[[8 0]
 [0 0]]
[ 1. nan]
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.8458756
 0.         0.         0.05101969 0.         0.         0.
 1.         0.         0.         0.97361323 0.         0.
 0.         0.        ]
wv_mn shape (26,)
[0.         0.54972568 0.46463173 1.         0.84773828 0.
 1.         1.         1.         0.         0.66254487 1.
 0.25412294 0.36345559 0.29201879 1.         0.         0.25253141
 0.         0.80392033 1.         1.         1.         1.
 1.         1.        ]
wv_ed shape (26,)
[0.         0.         0.62087335 1.         0.97408985 0.
 1.         1.         1.         0.         0.97494384 0.81934017
 0.25456014 0.53162294 0.56592643 1.         0.         0.13077979
 0.37116574 0.70426089 1.         1.         1.         1.
 1.         1.        ]
wv_lg shape (26, 1)
[[0.26154557]
 [0.26963767]
 [0.2692494 ]
 [0.26845815]
 [0.26950669]
 [0.2689166 ]
 [0.26956529]
 [0.27028895]
 [0.26927435]
 [0.26917106]
 [0.26958053]
 [0.2693236 ]
 [0.26902861]
 [0.26874464]
 [0.26833432]
 [0.26947597]
 [0.27005368]
 [0.27104631]
 [0.26960355]
 [0.26904668]
 [0.26888836]
 [0.26881995]
 [0.2681337 ]
 [0.2693941 ]
 [0.27010416]
 [0.26864401]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[0.54780768 0.06786981 0.31955492 1.         0.         0.
 1.         0.86255196 0.         0.         0.         0.
 0.         0.         0.31377927 0.         0.         0.
 0.         1.         0.         1.         0.8098787  0.
 1.         0.23421424]
wv_std shape (26,)
[0.         0.         1.         1.         0.73029754 0.
 1.         1.         1.         0.         0.63793517 0.49356356
 0.28419049 0.25883616 0.08530711 1.         0.         0.08786584
 0.51641302 0.47555764 1.         1.         1.         1.
 0.87957396 1.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.26154557 1.
  0.54780768 0.         0.        ]
 [1.         0.         0.54972568 0.         0.26963767 1.
  0.06786981 0.         1.        ]
 [1.         0.         0.46463173 0.62087335 0.2692494  1.
  0.31955492 1.         1.        ]
 [1.         0.         1.         1.         0.26845815 1.
  1.         1.         1.        ]
 [1.         0.         0.84773828 0.97408985 0.26950669 1.
  0.         0.73029754 1.        ]
 [0.         0.         0.         0.         0.2689166  1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.26956529 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.27028895 1.
  0.86255196 1.         1.        ]
 [1.         0.         1.         1.         0.26927435 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.26917106 1.
  0.         0.         1.        ]
 [1.         0.         0.66254487 0.97494384 0.26958053 1.
  0.         0.63793517 1.        ]
 [1.         0.8458756  1.         0.81934017 0.2693236  1.
  0.         0.49356356 1.        ]
 [1.         0.         0.25412294 0.25456014 0.26902861 1.
  0.         0.28419049 1.        ]
 [1.         0.         0.36345559 0.53162294 0.26874464 1.
  0.         0.25883616 1.        ]
 [1.         0.05101969 0.29201879 0.56592643 0.26833432 1.
  0.31377927 0.08530711 1.        ]
 [1.         0.         1.         1.         0.26947597 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.27005368 1.
  0.         0.         1.        ]
 [1.         0.         0.25253141 0.13077979 0.27104631 1.
  0.         0.08786584 1.        ]
 [1.         1.         0.         0.37116574 0.26960355 1.
  0.         0.51641302 1.        ]
 [1.         0.         0.80392033 0.70426089 0.26904668 1.
  1.         0.47555764 1.        ]
 [1.         0.         1.         1.         0.26888836 1.
  0.         1.         1.        ]
 [1.         0.97361323 1.         1.         0.26881995 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.2681337  1.
  0.8098787  1.         1.        ]
 [1.         0.         1.         1.         0.2693941  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27010416 1.
  1.         0.87957396 1.        ]
 [1.         0.         1.         1.         0.26864401 1.
  0.23421424 1.         1.        ]]

Best Training Poisoning Accuracy:
1.0
#####################         POISON         ###############################################

############################################################################################

comm_round: 23 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8

Accuracy per class:
[[8 0]
 [0 0]]
[ 1. nan]
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.41193513 0.
 1.         0.         0.         0.11015726 0.         0.
 0.59955388 0.         0.51057066 0.         0.01581812 0.
 1.         0.        ]
wv_mn shape (26,)
[0.         0.         0.         0.         1.         1.
 0.4643995  0.         0.13078457 1.         1.         0.0593689
 1.         0.         0.85323429 1.         0.         0.52652186
 0.61432903 0.         0.33498416 1.         0.         1.
 0.39538677 1.        ]
wv_ed shape (26,)
[0.         0.45111875 0.         0.         0.29638515 0.76922673
 0.13486699 0.35623936 0.         1.         0.72683027 0.56766725
 1.         0.         0.12408156 0.64913584 0.         0.
 0.         0.         0.89354351 1.         0.         1.
 0.7544772  0.51833413]
wv_lg shape (26, 1)
[[0.26823379]
 [0.27427743]
 [0.27508932]
 [0.27555416]
 [0.27476413]
 [0.27481187]
 [0.27520425]
 [0.27464339]
 [0.27554723]
 [0.27453281]
 [0.27554652]
 [0.27404402]
 [0.27455582]
 [0.27519317]
 [0.27427788]
 [0.27570798]
 [0.27446042]
 [0.27580068]
 [0.27530833]
 [0.27421537]
 [0.27466367]
 [0.27454201]
 [0.27454154]
 [0.27409925]
 [0.27569516]
 [0.27597831]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1.         0.29189614 0.         0.         0.08787872 0.82781377
 1.         0.         0.9105685  0.         0.         0.
 0.563821   1.         1.         1.         0.         0.33294676
 0.         0.09819746 1.         0.         0.44901229 0.
 0.         0.        ]
wv_std shape (26,)
[0.         0.90123191 0.         0.         0.         1.
 0.         0.70626566 0.         1.         0.64657018 0.85237885
 1.         0.         0.         0.38828623 0.         0.
 0.         0.         1.         1.         0.         1.
 1.         0.23310992]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.26823379 1.
  1.         0.         0.        ]
 [1.         0.         0.         0.45111875 0.27427743 1.
  0.29189614 0.90123191 1.        ]
 [1.         0.         0.         0.         0.27508932 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.27555416 1.
  0.         0.         1.        ]
 [1.         0.         1.         0.29638515 0.27476413 1.
  0.08787872 0.         1.        ]
 [1.         0.         1.         0.76922673 0.27481187 1.
  0.82781377 1.         1.        ]
 [1.         0.         0.4643995  0.13486699 0.27520425 1.
  1.         0.         1.        ]
 [1.         0.         0.         0.35623936 0.27464339 1.
  0.         0.70626566 1.        ]
 [1.         0.         0.13078457 0.         0.27554723 1.
  0.9105685  0.         1.        ]
 [1.         0.         1.         1.         0.27453281 1.
  0.         1.         1.        ]
 [1.         0.41193513 1.         0.72683027 0.27554652 1.
  0.         0.64657018 1.        ]
 [1.         0.         0.0593689  0.56766725 0.27404402 1.
  0.         0.85237885 1.        ]
 [1.         1.         1.         1.         0.27455582 1.
  0.563821   1.         1.        ]
 [1.         0.         0.         0.         0.27519317 1.
  1.         0.         1.        ]
 [1.         0.         0.85323429 0.12408156 0.27427788 1.
  1.         0.         1.        ]
 [1.         0.11015726 1.         0.64913584 0.27570798 1.
  1.         0.38828623 1.        ]
 [1.         0.         0.         0.         0.27446042 1.
  0.         0.         1.        ]
 [1.         0.         0.52652186 0.         0.27580068 1.
  0.33294676 0.         1.        ]
 [1.         0.59955388 0.61432903 0.         0.27530833 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.27421537 1.
  0.09819746 0.         1.        ]
 [1.         0.51057066 0.33498416 0.89354351 0.27466367 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.27454201 1.
  0.         1.         1.        ]
 [1.         0.01581812 0.         0.         0.27454154 1.
  0.44901229 0.         1.        ]
 [1.         0.         1.         1.         0.27409925 1.
  0.         1.         1.        ]
 [1.         1.         0.39538677 0.7544772  0.27569516 1.
  0.         1.         1.        ]
 [1.         0.         1.         0.51833413 0.27597831 1.
  0.         0.23310992 1.        ]]

Best Training Poisoning Accuracy:
0.9166666865348816
#####################         POISON         ###############################################

############################################################################################

comm_round: 24 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8

Accuracy per class:
[[8 0]
 [0 0]]
[ 1. nan]
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.89203062 1.         0.         1.         0.
 0.73495131 1.         0.         1.         1.         1.
 0.95976767 0.50113682 1.         0.         1.         0.
 0.83643088 1.         1.         0.         0.65132098 0.28274776
 1.         0.57120703]
wv_ed shape (26,)
[0.         0.4730445  1.         0.         0.11499295 0.83906531
 0.2125177  1.         0.         0.26913859 1.         1.
 1.         1.         1.         0.13274487 1.         0.
 1.         1.         1.         0.         0.94465156 0.94425264
 1.         1.        ]
wv_lg shape (26, 1)
[[0.27358528]
 [0.28074303]
 [0.27911991]
 [0.28138216]
 [0.27963225]
 [0.27955969]
 [0.28075792]
 [0.28115045]
 [0.27990401]
 [0.28142233]
 [0.27986668]
 [0.28020018]
 [0.27985963]
 [0.27970561]
 [0.28085856]
 [0.27994974]
 [0.28121568]
 [0.28045805]
 [0.28055383]
 [0.28017552]
 [0.28004978]
 [0.2798446 ]
 [0.28091823]
 [0.28165751]
 [0.28008229]
 [0.27957832]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[0.96808911 1.         1.         1.         0.27863249 0.
 1.         1.         0.         1.         0.24593938 0.
 0.         0.         0.         1.         1.         1.
 0.         1.         0.         0.         1.         0.4027209
 0.21763199 1.        ]
wv_std shape (26,)
[0.         0.0802445  1.         0.         0.         0.9438875
 0.         1.         0.         0.         1.         0.80609028
 1.         1.         1.         0.42916678 0.6934421  0.
 0.86553524 1.         0.73640763 0.         0.82959289 1.
 1.         1.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.27358528 1.
  0.96808911 0.         0.        ]
 [1.         0.         0.89203062 0.4730445  0.28074303 1.
  1.         0.0802445  1.        ]
 [1.         0.         1.         1.         0.27911991 1.
  1.         1.         1.        ]
 [1.         0.         0.         0.         0.28138216 1.
  1.         0.         1.        ]
 [1.         0.         1.         0.11499295 0.27963225 1.
  0.27863249 0.         1.        ]
 [1.         0.         0.         0.83906531 0.27955969 1.
  0.         0.9438875  1.        ]
 [1.         0.         0.73495131 0.2125177  0.28075792 1.
  1.         0.         1.        ]
 [1.         0.         1.         1.         0.28115045 1.
  1.         1.         1.        ]
 [1.         0.         0.         0.         0.27990401 1.
  0.         0.         1.        ]
 [1.         0.         1.         0.26913859 0.28142233 1.
  1.         0.         1.        ]
 [1.         0.         1.         1.         0.27986668 1.
  0.24593938 1.         1.        ]
 [1.         0.         1.         1.         0.28020018 1.
  0.         0.80609028 1.        ]
 [1.         0.         0.95976767 1.         0.27985963 1.
  0.         1.         1.        ]
 [1.         0.         0.50113682 1.         0.27970561 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.28085856 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.13274487 0.27994974 1.
  1.         0.42916678 1.        ]
 [1.         0.         1.         1.         0.28121568 1.
  1.         0.6934421  1.        ]
 [1.         0.         0.         0.         0.28045805 1.
  1.         0.         1.        ]
 [1.         0.         0.83643088 1.         0.28055383 1.
  0.         0.86553524 1.        ]
 [1.         0.         1.         1.         0.28017552 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.28004978 1.
  0.         0.73640763 1.        ]
 [0.         0.         0.         0.         0.2798446  1.
  0.         0.         1.        ]
 [1.         0.         0.65132098 0.94465156 0.28091823 1.
  1.         0.82959289 1.        ]
 [1.         0.         0.28274776 0.94425264 0.28165751 1.
  0.4027209  1.         1.        ]
 [1.         0.         1.         1.         0.28008229 1.
  0.21763199 1.         1.        ]
 [1.         0.         0.57120703 1.         0.27957832 1.
  1.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.9166666865348816
#####################         POISON         ###############################################

############################################################################################

comm_round: 25 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8

Accuracy per class:
[[8 0]
 [0 0]]
[ 1. nan]
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1.         0.         0.15378528 0.         0.         0.04579416
 0.         0.         1.         0.         0.         0.
 0.         0.         0.         0.65275682 0.         0.03787404
 0.74031136 0.         0.         0.         1.         0.74031136
 0.         0.        ]
wv_mn shape (26,)
[0.         0.87248597 1.         0.83845308 0.26628579 1.
 1.         0.4965454  0.         0.         1.         0.38370047
 0.56218432 1.         0.         0.         0.         0.94590976
 0.23362191 0.19048249 0.4536172  0.5877695  0.         0.
 0.         0.32784327]
wv_ed shape (26,)
[0.         0.76227409 1.         1.         0.26338196 0.13127415
 1.         1.         0.         0.52771439 1.         1.
 0.         1.         0.42567882 0.97793196 0.49185595 1.
 1.         0.59040742 0.08359058 1.         0.         0.
 0.         0.72721255]
wv_lg shape (26, 1)
[[0.27872641]
 [0.2851338 ]
 [0.28528119]
 [0.28572635]
 [0.28646664]
 [0.28597769]
 [0.28556773]
 [0.28471696]
 [0.28538816]
 [0.28498853]
 [0.28526406]
 [0.28589884]
 [0.28600671]
 [0.28557054]
 [0.28530401]
 [0.28612777]
 [0.28551832]
 [0.2848681 ]
 [0.28504305]
 [0.28657447]
 [0.28493695]
 [0.28586165]
 [0.28569393]
 [0.28607123]
 [0.28489846]
 [0.28613374]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[0.03664531 0.84413115 0.14872298 0.         0.40179325 0.20213178
 0.         0.         0.         0.         0.         0.
 1.         0.         0.         1.         0.         0.
 0.49456429 0.         1.         0.         0.         0.0920371
 0.         1.        ]
wv_std shape (26,)
[0.         0.         1.         0.70146621 0.         0.
 1.         1.         0.         0.52521624 1.         0.59566752
 0.         0.95600863 0.12522107 0.         0.         1.
 0.54296323 0.         0.         0.50421695 0.         0.
 0.         0.44960213]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.27872641 1.
  0.03664531 0.         0.        ]
 [1.         0.         0.87248597 0.76227409 0.2851338  1.
  0.84413115 0.         1.        ]
 [1.         0.15378528 1.         1.         0.28528119 1.
  0.14872298 1.         1.        ]
 [1.         0.         0.83845308 1.         0.28572635 1.
  0.         0.70146621 1.        ]
 [1.         0.         0.26628579 0.26338196 0.28646664 1.
  0.40179325 0.         1.        ]
 [1.         0.04579416 1.         0.13127415 0.28597769 1.
  0.20213178 0.         1.        ]
 [1.         0.         1.         1.         0.28556773 1.
  0.         1.         1.        ]
 [1.         0.         0.4965454  1.         0.28471696 1.
  0.         1.         1.        ]
 [0.         1.         0.         0.         0.28538816 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.52771439 0.28498853 1.
  0.         0.52521624 1.        ]
 [1.         0.         1.         1.         0.28526406 1.
  0.         1.         1.        ]
 [1.         0.         0.38370047 1.         0.28589884 1.
  0.         0.59566752 1.        ]
 [1.         0.         0.56218432 0.         0.28600671 1.
  1.         0.         1.        ]
 [1.         0.         1.         1.         0.28557054 1.
  0.         0.95600863 1.        ]
 [1.         0.         0.         0.42567882 0.28530401 1.
  0.         0.12522107 1.        ]
 [1.         0.65275682 0.         0.97793196 0.28612777 1.
  1.         0.         1.        ]
 [1.         0.         0.         0.49185595 0.28551832 1.
  0.         0.         1.        ]
 [1.         0.03787404 0.94590976 1.         0.2848681  1.
  0.         1.         1.        ]
 [1.         0.74031136 0.23362191 1.         0.28504305 1.
  0.49456429 0.54296323 1.        ]
 [1.         0.         0.19048249 0.59040742 0.28657447 1.
  0.         0.         1.        ]
 [1.         0.         0.4536172  0.08359058 0.28493695 1.
  1.         0.         1.        ]
 [1.         0.         0.5877695  1.         0.28586165 1.
  0.         0.50421695 1.        ]
 [1.         1.         0.         0.         0.28569393 1.
  0.         0.         1.        ]
 [1.         0.74031136 0.         0.         0.28607123 1.
  0.0920371  0.         1.        ]
 [1.         0.         0.         0.         0.28489846 1.
  0.         0.         1.        ]
 [1.         0.         0.32784327 0.72721255 0.28613374 1.
  1.         0.44960213 1.        ]]

Best Training Poisoning Accuracy:
1.0
#####################         POISON         ###############################################

############################################################################################

comm_round: 26 | global_test_acc: 87.500% | global_f1: 0.9333333333333333 | global_precision: 0.875
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.88      1.00      0.93         7

    accuracy                           0.88         8
   macro avg       0.44      0.50      0.47         8
weighted avg       0.77      0.88      0.82         8

Accuracy per class:
[[7 0]
 [1 0]]
[1. 0.]
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1.]
wv_mn shape (26,)
[0.         1.         0.62365427 1.         0.         0.75802713
 1.         1.         0.         1.         0.54601686 1.
 0.23174203 0.09486333 1.         1.         1.         0.82747271
 0.         0.         0.         1.         1.         0.
 1.         1.        ]
wv_ed shape (26,)
[0.         0.69089193 0.65782314 0.95598644 0.38355027 0.87259212
 1.         1.         0.43805386 1.         1.         1.
 0.0155827  0.58658632 1.         1.         1.         0.90290596
 0.         0.50582285 0.         1.         1.         0.57514808
 1.         0.5078538 ]
wv_lg shape (26, 1)
[[0.2843258 ]
 [0.29029639]
 [0.29053819]
 [0.29042468]
 [0.2895115 ]
 [0.29028697]
 [0.28959951]
 [0.29061266]
 [0.28922349]
 [0.2909507 ]
 [0.29041162]
 [0.29067253]
 [0.28948945]
 [0.28994548]
 [0.28979104]
 [0.28999092]
 [0.28993817]
 [0.29111313]
 [0.29089836]
 [0.29112334]
 [0.29075612]
 [0.29064482]
 [0.28950727]
 [0.28980471]
 [0.28936388]
 [0.29101364]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[0.         0.         0.39696937 1.         0.         0.
 0.1630815  0.86962183 0.         0.         0.         0.
 1.         0.07378871 1.         0.         0.01643831 0.
 0.067188   0.         1.         0.         0.         0.
 0.         0.        ]
wv_std shape (26,)
[0.         0.44591446 0.03032806 0.62042417 0.22108208 0.81128548
 1.         1.         0.62610859 1.         1.         1.
 0.         0.35655894 1.         1.         1.         0.69053631
 0.         0.35777464 0.         1.         1.         0.95264412
 1.         0.53653988]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.2843258  1.
  0.         0.         0.        ]
 [1.         0.         1.         0.69089193 0.29029639 1.
  0.         0.44591446 1.        ]
 [1.         0.         0.62365427 0.65782314 0.29053819 1.
  0.39696937 0.03032806 1.        ]
 [1.         0.         1.         0.95598644 0.29042468 1.
  1.         0.62042417 1.        ]
 [1.         0.         0.         0.38355027 0.2895115  1.
  0.         0.22108208 1.        ]
 [1.         0.         0.75802713 0.87259212 0.29028697 1.
  0.         0.81128548 1.        ]
 [1.         0.         1.         1.         0.28959951 1.
  0.1630815  1.         1.        ]
 [1.         0.         1.         1.         0.29061266 1.
  0.86962183 1.         1.        ]
 [1.         0.         0.         0.43805386 0.28922349 1.
  0.         0.62610859 1.        ]
 [1.         0.         1.         1.         0.2909507  1.
  0.         1.         1.        ]
 [1.         0.         0.54601686 1.         0.29041162 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.29067253 1.
  0.         1.         1.        ]
 [1.         0.         0.23174203 0.0155827  0.28948945 1.
  1.         0.         1.        ]
 [1.         0.         0.09486333 0.58658632 0.28994548 1.
  0.07378871 0.35655894 1.        ]
 [1.         0.         1.         1.         0.28979104 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.28999092 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.28993817 1.
  0.01643831 1.         1.        ]
 [1.         0.         0.82747271 0.90290596 0.29111313 1.
  0.         0.69053631 1.        ]
 [0.         0.         0.         0.         0.29089836 1.
  0.067188   0.         1.        ]
 [1.         0.         0.         0.50582285 0.29112334 1.
  0.         0.35777464 1.        ]
 [1.         0.         0.         0.         0.29075612 1.
  1.         0.         1.        ]
 [1.         0.         1.         1.         0.29064482 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.28950727 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.57514808 0.28980471 1.
  0.         0.95264412 1.        ]
 [1.         0.         1.         1.         0.28936388 1.
  0.         1.         1.        ]
 [1.         1.         1.         0.5078538  0.29101364 1.
  0.         0.53653988 1.        ]]

Best Training Poisoning Accuracy:
1.0
#####################         POISON         ###############################################

############################################################################################

comm_round: 27 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8

Accuracy per class:
[[8 0]
 [0 0]]
[ 1. nan]
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         1.         0.31343143 0.         1.         1.
 0.         0.90380594 1.         0.34107012 1.         1.
 1.         1.         0.         1.         0.         1.
 0.8805179  0.69460692 1.         0.         0.         1.
 0.91524752 0.91276917]
wv_ed shape (26,)
[0.         0.29937165 1.         0.         1.         1.
 0.         0.59669297 1.         0.         0.         0.79856663
 0.43885869 0.64687018 0.06143501 0.21799658 0.         1.
 0.18198533 0.12108783 0.58552097 0.         0.         1.
 0.         0.        ]
wv_lg shape (26, 1)
[[0.28842638]
 [0.29450382]
 [0.2939316 ]
 [0.29480148]
 [0.29573212]
 [0.29450281]
 [0.29574566]
 [0.29437083]
 [0.29495463]
 [0.29558212]
 [0.29525864]
 [0.29578669]
 [0.29476893]
 [0.29458263]
 [0.29399269]
 [0.29422371]
 [0.29467768]
 [0.29352437]
 [0.29498606]
 [0.29495104]
 [0.29469035]
 [0.29453942]
 [0.29426205]
 [0.29466786]
 [0.29580929]
 [0.29495337]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[0.         0.         0.         0.         0.         0.
 0.         0.4532558  0.         0.         0.20924148 0.
 0.         0.         0.         0.         0.         0.07364522
 0.         1.         0.6435454  0.         0.         0.
 0.         0.        ]
wv_std shape (26,)
[0.         0.         1.         0.         1.         1.
 0.         0.40963104 1.         0.         0.         0.15737712
 0.35987639 0.4177311  0.41910406 0.1707574  0.05255218 1.
 0.         0.         0.36417362 0.21811485 0.         0.61353332
 0.         0.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.28842638 1.
  0.         0.         0.        ]
 [1.         0.         1.         0.29937165 0.29450382 1.
  0.         0.         1.        ]
 [1.         0.         0.31343143 1.         0.2939316  1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.29480148 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.29573212 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.29450281 1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.29574566 1.
  0.         0.         1.        ]
 [1.         0.         0.90380594 0.59669297 0.29437083 1.
  0.4532558  0.40963104 1.        ]
 [1.         0.         1.         1.         0.29495463 1.
  0.         1.         1.        ]
 [1.         0.         0.34107012 0.         0.29558212 1.
  0.         0.         1.        ]
 [1.         0.         1.         0.         0.29525864 1.
  0.20924148 0.         1.        ]
 [1.         0.         1.         0.79856663 0.29578669 1.
  0.         0.15737712 1.        ]
 [1.         0.         1.         0.43885869 0.29476893 1.
  0.         0.35987639 1.        ]
 [1.         0.         1.         0.64687018 0.29458263 1.
  0.         0.4177311  1.        ]
 [1.         0.         0.         0.06143501 0.29399269 1.
  0.         0.41910406 1.        ]
 [1.         0.         1.         0.21799658 0.29422371 1.
  0.         0.1707574  1.        ]
 [1.         0.         0.         0.         0.29467768 1.
  0.         0.05255218 1.        ]
 [1.         0.         1.         1.         0.29352437 1.
  0.07364522 1.         1.        ]
 [1.         0.         0.8805179  0.18198533 0.29498606 1.
  0.         0.         1.        ]
 [1.         0.         0.69460692 0.12108783 0.29495104 1.
  1.         0.         1.        ]
 [1.         0.         1.         0.58552097 0.29469035 1.
  0.6435454  0.36417362 1.        ]
 [1.         0.         0.         0.         0.29453942 1.
  0.         0.21811485 1.        ]
 [1.         0.         0.         0.         0.29426205 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.29466786 1.
  0.         0.61353332 1.        ]
 [1.         0.         0.91524752 0.         0.29580929 1.
  0.         0.         1.        ]
 [1.         0.         0.91276917 0.         0.29495337 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
1.0
#####################         POISON         ###############################################

############################################################################################

comm_round: 28 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8

Accuracy per class:
[[8 0]
 [0 0]]
[ 1. nan]
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.         1.         0.         0.         0.
 0.67844436 0.57384159 0.24404488 0.         0.         0.
 0.         1.         1.         1.         1.         0.
 1.         1.         1.         0.41572783 0.         0.
 0.3646047  0.2161085 ]
wv_ed shape (26,)
[0.         0.         0.52979183 0.         0.70242576 1.
 1.         0.78299189 0.         0.87147258 0.         0.
 0.         1.         1.         1.         1.         0.33309882
 1.         1.         1.         0.19710086 0.14865396 0.
 1.         1.        ]
wv_lg shape (26, 1)
[[0.29323505]
 [0.29873923]
 [0.29811358]
 [0.29943138]
 [0.2982103 ]
 [0.29748798]
 [0.29830627]
 [0.29861406]
 [0.2993479 ]
 [0.29798905]
 [0.29765763]
 [0.29829503]
 [0.29940794]
 [0.29852813]
 [0.29780059]
 [0.29938479]
 [0.29879377]
 [0.29962474]
 [0.29767692]
 [0.29866015]
 [0.29913335]
 [0.29863006]
 [0.29988532]
 [0.2982226 ]
 [0.30018728]
 [0.29840285]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1.         0.53800963 0.94856299 0.         0.         0.
 0.20000155 0.12033762 0.         0.         0.         0.47035944
 0.09903442 1.         0.         1.         0.29429504 0.41819709
 0.09013082 0.47279979 0.0122104  0.52660984 0.         0.14546124
 0.         0.22116894]
wv_std shape (26,)
[0.         0.         0.41668549 0.         1.         1.
 1.         0.74718642 0.         1.         0.         0.
 0.         1.         1.         1.         1.         0.39499141
 1.         1.         1.         0.06442004 0.         0.
 1.         0.92137708]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.29323505 1.
  1.         0.         0.        ]
 [1.         0.         0.         0.         0.29873923 1.
  0.53800963 0.         1.        ]
 [1.         0.         1.         0.52979183 0.29811358 1.
  0.94856299 0.41668549 1.        ]
 [1.         0.         0.         0.         0.29943138 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.70242576 0.2982103  1.
  0.         1.         1.        ]
 [1.         0.         0.         1.         0.29748798 1.
  0.         1.         1.        ]
 [1.         0.         0.67844436 1.         0.29830627 1.
  0.20000155 1.         1.        ]
 [1.         0.         0.57384159 0.78299189 0.29861406 1.
  0.12033762 0.74718642 1.        ]
 [1.         0.         0.24404488 0.         0.2993479  1.
  0.         0.         1.        ]
 [1.         0.         0.         0.87147258 0.29798905 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.29765763 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.29829503 1.
  0.47035944 0.         1.        ]
 [1.         0.         0.         0.         0.29940794 1.
  0.09903442 0.         1.        ]
 [1.         0.         1.         1.         0.29852813 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.29780059 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.29938479 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.29879377 1.
  0.29429504 1.         1.        ]
 [1.         0.         0.         0.33309882 0.29962474 1.
  0.41819709 0.39499141 1.        ]
 [1.         0.         1.         1.         0.29767692 1.
  0.09013082 1.         1.        ]
 [1.         0.         1.         1.         0.29866015 1.
  0.47279979 1.         1.        ]
 [1.         0.         1.         1.         0.29913335 1.
  0.0122104  1.         1.        ]
 [1.         0.         0.41572783 0.19710086 0.29863006 1.
  0.52660984 0.06442004 1.        ]
 [1.         0.         0.         0.14865396 0.29988532 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.2982226  1.
  0.14546124 0.         1.        ]
 [1.         0.         0.3646047  1.         0.30018728 1.
  0.         1.         1.        ]
 [1.         0.         0.2161085  1.         0.29840285 1.
  0.22116894 0.92137708 1.        ]]

Best Training Poisoning Accuracy:
0.9166666865348816
#####################         POISON         ###############################################

############################################################################################

comm_round: 29 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8

Accuracy per class:
[[8 0]
 [0 0]]
[ 1. nan]
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.0438017  0.06834371
 0.50812473 0.         1.         0.46629117 0.         0.
 1.         0.86017407 1.         1.         0.19668678 1.
 1.         0.39211801]
wv_ed shape (26,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.5333106  0.         1.         0.38358959 0.         0.
 1.         0.78216423 1.         1.         0.0888699  1.
 1.         0.39203242]
wv_lg shape (26, 1)
[[0.35671917]
 [0.34530911]
 [0.34482385]
 [0.34598009]
 [0.34517525]
 [0.34586907]
 [0.34528314]
 [0.34468503]
 [0.34489767]
 [0.34639733]
 [0.34733852]
 [0.34618409]
 [0.34504731]
 [0.34638023]
 [0.34710453]
 [0.34502725]
 [0.34328633]
 [0.34657609]
 [0.34602129]
 [0.34741891]
 [0.3464448 ]
 [0.34687385]
 [0.34629655]
 [0.34789397]
 [0.34624029]
 [0.34623499]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.42456638 0.         1.         0.09903589 0.         0.
 0.89248003 0.83284186 0.64524841 0.36956562 0.         1.
 1.         0.17364964]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.35671917 1.
  1.         0.         0.        ]
 [1.         0.         0.         0.         0.34530911 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.34482385 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34598009 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.34517525 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.34586907 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.34528314 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.34468503 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.34489767 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.34639733 1.
  0.         0.         1.        ]
 [1.         0.         0.0438017  0.         0.34733852 1.
  0.         0.         1.        ]
 [1.         0.         0.06834371 0.         0.34618409 1.
  0.         0.         1.        ]
 [1.         0.         0.50812473 0.5333106  0.34504731 1.
  0.         0.42456638 1.        ]
 [1.         0.         0.         0.         0.34638023 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.34710453 1.
  0.         1.         1.        ]
 [1.         0.         0.46629117 0.38358959 0.34502725 1.
  0.         0.09903589 1.        ]
 [1.         0.         0.         0.         0.34328633 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.34657609 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.34602129 1.
  0.         0.89248003 1.        ]
 [1.         0.         0.86017407 0.78216423 0.34741891 1.
  0.         0.83284186 1.        ]
 [1.         0.         1.         1.         0.3464448  1.
  0.         0.64524841 1.        ]
 [1.         0.         1.         1.         0.34687385 1.
  0.         0.36956562 1.        ]
 [1.         0.         0.19668678 0.0888699  0.34629655 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.34789397 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.34624029 1.
  0.         1.         1.        ]
 [1.         0.         0.39211801 0.39203242 0.34623499 1.
  0.         0.17364964 1.        ]]

Best Training Poisoning Accuracy:
0.875
#####################         POISON         ###############################################

############################################################################################

comm_round: 0 | global_test_acc: 87.500% | global_f1: 0.9333333333333333 | global_precision: 0.875
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.88      1.00      0.93         7

    accuracy                           0.88         8
   macro avg       0.44      0.50      0.47         8
weighted avg       0.77      0.88      0.82         8
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.2853423  0.         0.45485415 0.0114382  0.38124684
 0.         0.         0.         0.         0.48047475 0.
 0.70750586 1.         0.         0.         0.88619583 1.
 1.         1.         0.         1.         1.         1.
 0.         0.        ]
wv_ed shape (26,)
[0.         0.27166434 0.         0.51872512 0.         0.27649635
 0.         0.         0.         0.         0.43545606 0.
 0.88786741 1.         0.         0.         0.75910037 0.84095329
 1.         1.         0.         1.         1.         1.
 0.         0.        ]
wv_lg shape (26, 1)
[[0.35025581]
 [0.33947851]
 [0.33965692]
 [0.3403697 ]
 [0.33999056]
 [0.3405644 ]
 [0.33986624]
 [0.33990293]
 [0.33929882]
 [0.33906507]
 [0.3399915 ]
 [0.33977203]
 [0.34078152]
 [0.34096862]
 [0.33976485]
 [0.3397407 ]
 [0.3396877 ]
 [0.33978769]
 [0.34146371]
 [0.34103285]
 [0.34034393]
 [0.33919524]
 [0.3393072 ]
 [0.34071335]
 [0.34019641]
 [0.33996235]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.34941337 0.         0.20159831 0.         0.14498297
 0.         0.         0.         0.         0.29034097 0.
 1.         1.         0.         0.         0.67434365 0.78825052
 1.         1.         0.         1.         1.         1.
 0.         0.19725862]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.35025581 1.
  1.         0.         0.        ]
 [1.         0.         0.2853423  0.27166434 0.33947851 1.
  0.         0.34941337 1.        ]
 [1.         0.         0.         0.         0.33965692 1.
  0.         0.         1.        ]
 [1.         0.         0.45485415 0.51872512 0.3403697  1.
  0.         0.20159831 1.        ]
 [1.         0.         0.0114382  0.         0.33999056 1.
  0.         0.         1.        ]
 [1.         0.         0.38124684 0.27649635 0.3405644  1.
  0.         0.14498297 1.        ]
 [1.         0.         0.         0.         0.33986624 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.33990293 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33929882 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.33906507 1.
  0.         0.         1.        ]
 [1.         0.         0.48047475 0.43545606 0.3399915  1.
  0.         0.29034097 1.        ]
 [1.         0.         0.         0.         0.33977203 1.
  0.         0.         1.        ]
 [1.         0.         0.70750586 0.88786741 0.34078152 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.34096862 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.33976485 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.3397407  1.
  0.         0.         1.        ]
 [1.         0.         0.88619583 0.75910037 0.3396877  1.
  0.         0.67434365 1.        ]
 [1.         0.         1.         0.84095329 0.33978769 1.
  0.         0.78825052 1.        ]
 [1.         0.         1.         1.         0.34146371 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.34103285 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.34034393 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.33919524 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.3393072  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.34071335 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.34019641 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.33996235 1.
  0.         0.19725862 1.        ]]

Best Training Poisoning Accuracy:
0.9375
#####################         POISON         ###############################################

############################################################################################

comm_round: 1 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.         1.         0.74933011 0.         0.81560649
 1.         0.11509086 0.         0.18284192 0.         0.87024565
 0.         0.18083962 0.         0.         0.         1.
 1.         0.1774761  0.57592462 0.63899765 0.         0.74648648
 0.         0.70795926]
wv_ed shape (26,)
[0.         0.         1.         0.89530844 0.         0.90376778
 1.         0.45583311 0.         0.37767654 0.         0.99029352
 0.         0.38483317 0.079746   0.         0.         1.
 1.         0.32446291 0.74390036 0.98458026 0.14735592 0.90705822
 0.         0.7116878 ]
wv_lg shape (26, 1)
[[0.34419965]
 [0.33493929]
 [0.33483148]
 [0.33349853]
 [0.33357207]
 [0.33526901]
 [0.33520188]
 [0.33239258]
 [0.33379192]
 [0.33459093]
 [0.33462656]
 [0.33405355]
 [0.33281007]
 [0.33375224]
 [0.33479254]
 [0.3337732 ]
 [0.33520155]
 [0.33591109]
 [0.33542124]
 [0.33312437]
 [0.33532772]
 [0.33452485]
 [0.33296937]
 [0.3354698 ]
 [0.33346274]
 [0.33531261]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.05917522 1.         0.90570506 0.         0.81407274
 1.         0.56461247 0.         0.3690697  0.         1.
 0.         0.40958223 0.08492686 0.         0.         1.
 1.         0.48881508 0.72905496 1.         0.16643975 0.7840357
 0.         0.72458643]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.34419965 1.
  1.         0.         0.        ]
 [1.         0.         0.         0.         0.33493929 1.
  0.         0.05917522 1.        ]
 [1.         0.         1.         1.         0.33483148 1.
  0.         1.         1.        ]
 [1.         0.         0.74933011 0.89530844 0.33349853 1.
  0.         0.90570506 1.        ]
 [0.         0.         0.         0.         0.33357207 1.
  0.         0.         1.        ]
 [1.         0.         0.81560649 0.90376778 0.33526901 1.
  0.         0.81407274 1.        ]
 [1.         0.         1.         1.         0.33520188 1.
  0.         1.         1.        ]
 [1.         0.         0.11509086 0.45583311 0.33239258 1.
  0.         0.56461247 1.        ]
 [1.         0.         0.         0.         0.33379192 1.
  0.         0.         1.        ]
 [1.         0.         0.18284192 0.37767654 0.33459093 1.
  0.         0.3690697  1.        ]
 [1.         0.         0.         0.         0.33462656 1.
  0.         0.         1.        ]
 [1.         0.         0.87024565 0.99029352 0.33405355 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.33281007 1.
  0.         0.         1.        ]
 [1.         0.         0.18083962 0.38483317 0.33375224 1.
  0.         0.40958223 1.        ]
 [1.         0.         0.         0.079746   0.33479254 1.
  0.         0.08492686 1.        ]
 [1.         0.         0.         0.         0.3337732  1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.33520155 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.33591109 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.33542124 1.
  0.         1.         1.        ]
 [1.         0.         0.1774761  0.32446291 0.33312437 1.
  0.         0.48881508 1.        ]
 [1.         0.         0.57592462 0.74390036 0.33532772 1.
  0.         0.72905496 1.        ]
 [1.         0.         0.63899765 0.98458026 0.33452485 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.14735592 0.33296937 1.
  0.         0.16643975 1.        ]
 [1.         0.         0.74648648 0.90705822 0.3354698  1.
  0.         0.7840357  1.        ]
 [1.         0.         0.         0.         0.33346274 1.
  0.         0.         1.        ]
 [1.         0.         0.70795926 0.7116878  0.33531261 1.
  0.         0.72458643 1.        ]]

Best Training Poisoning Accuracy:
0.9375
#####################         POISON         ###############################################

############################################################################################

comm_round: 2 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         1.         0.         0.54291668 1.         0.93017963
 0.0800316  0.         1.         0.         0.         0.
 0.         0.43891456 1.         0.         1.         0.9355856
 1.         1.         0.04100012 0.85840317 0.3932464  1.
 0.16917877 1.        ]
wv_ed shape (26,)
[0.         1.         0.         0.59110304 0.96966142 0.80286316
 0.         0.         0.64206781 0.         0.         0.
 0.         0.19351115 1.         0.         1.         0.87069129
 1.         0.99137251 0.         0.84365482 0.         0.96022409
 0.         1.        ]
wv_lg shape (26, 1)
[[0.33857984]
 [0.32898296]
 [0.32960224]
 [0.33019774]
 [0.32940846]
 [0.32957741]
 [0.32828114]
 [0.32834875]
 [0.32972841]
 [0.32866801]
 [0.330032  ]
 [0.32942937]
 [0.32875666]
 [0.3297535 ]
 [0.32960777]
 [0.32956443]
 [0.33041005]
 [0.3298617 ]
 [0.32870199]
 [0.3298876 ]
 [0.32941643]
 [0.33011097]
 [0.32988991]
 [0.33008968]
 [0.32922177]
 [0.32966857]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         1.         0.         0.91028517 1.         0.70914493
 0.         0.         0.65286394 0.05366891 0.         0.
 0.         0.33479655 1.         0.         1.         0.66279484
 0.78479851 1.         0.         0.95609828 0.         0.52156964
 0.         1.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.33857984 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.32898296 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.32960224 1.
  0.         0.         1.        ]
 [1.         0.         0.54291668 0.59110304 0.33019774 1.
  0.         0.91028517 1.        ]
 [1.         0.         1.         0.96966142 0.32940846 1.
  0.         1.         1.        ]
 [1.         0.         0.93017963 0.80286316 0.32957741 1.
  0.         0.70914493 1.        ]
 [1.         0.         0.0800316  0.         0.32828114 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.32834875 1.
  0.         0.         1.        ]
 [1.         0.         1.         0.64206781 0.32972841 1.
  0.         0.65286394 1.        ]
 [1.         0.         0.         0.         0.32866801 1.
  0.         0.05366891 1.        ]
 [1.         0.         0.         0.         0.330032   1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.32942937 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.32875666 1.
  0.         0.         1.        ]
 [1.         0.         0.43891456 0.19351115 0.3297535  1.
  0.         0.33479655 1.        ]
 [1.         0.         1.         1.         0.32960777 1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.32956443 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.33041005 1.
  0.         1.         1.        ]
 [1.         0.         0.9355856  0.87069129 0.3298617  1.
  0.         0.66279484 1.        ]
 [1.         0.         1.         1.         0.32870199 1.
  0.         0.78479851 1.        ]
 [1.         0.         1.         0.99137251 0.3298876  1.
  0.         1.         1.        ]
 [1.         0.         0.04100012 0.         0.32941643 1.
  0.         0.         1.        ]
 [1.         0.         0.85840317 0.84365482 0.33011097 1.
  0.         0.95609828 1.        ]
 [1.         0.         0.3932464  0.         0.32988991 1.
  0.         0.         1.        ]
 [1.         0.         1.         0.96022409 0.33008968 1.
  0.         0.52156964 1.        ]
 [1.         0.         0.16917877 0.         0.32922177 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.32966857 1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
1.0
#####################         POISON         ###############################################

############################################################################################

comm_round: 3 | global_test_acc: 87.500% | global_f1: 0.9333333333333333 | global_precision: 0.875
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.88      1.00      0.93         7

    accuracy                           0.88         8
   macro avg       0.44      0.50      0.47         8
weighted avg       0.77      0.88      0.82         8
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.57869899 1.         1.         0.47528398 1.
 1.         0.         0.8899636  0.         0.         0.
 0.         1.         0.68124962 0.56788888 1.         0.
 0.10024074 0.09756991 0.         0.         0.4885768  0.50395809
 0.86984061 0.32224122]
wv_ed shape (26,)
[0.         0.6347413  0.89826183 1.         0.42227883 1.
 0.90022848 0.         1.         0.         0.         0.38848608
 0.         1.         0.93279025 0.62397347 1.         0.
 0.44515393 0.29725419 0.         0.         0.78479403 0.64949465
 0.94242786 0.31421175]
wv_lg shape (26, 1)
[[0.33351441]
 [0.3317738 ]
 [0.33117046]
 [0.33165831]
 [0.3316439 ]
 [0.33146441]
 [0.33153327]
 [0.3310854 ]
 [0.33130983]
 [0.33148078]
 [0.33166015]
 [0.33087811]
 [0.33116778]
 [0.3318032 ]
 [0.33116491]
 [0.33130788]
 [0.33124839]
 [0.33162215]
 [0.3313763 ]
 [0.33158051]
 [0.33121229]
 [0.33154254]
 [0.33152137]
 [0.33137022]
 [0.33129139]
 [0.33160141]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.24007523 1.         1.         0.68579812 1.
 0.602248   0.         0.88702942 0.         0.         0.
 0.         1.         0.30111648 0.62184328 0.63196924 0.47818735
 0.56809941 0.3663125  0.08593367 0.         0.62428309 0.28774269
 0.84821655 0.26922395]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.33351441 1.
  1.         0.         0.        ]
 [1.         0.         0.57869899 0.6347413  0.3317738  1.
  0.         0.24007523 1.        ]
 [1.         0.         1.         0.89826183 0.33117046 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.33165831 1.
  0.         1.         1.        ]
 [1.         0.         0.47528398 0.42227883 0.3316439  1.
  0.         0.68579812 1.        ]
 [1.         0.         1.         1.         0.33146441 1.
  0.         1.         1.        ]
 [1.         0.         1.         0.90022848 0.33153327 1.
  0.         0.602248   1.        ]
 [1.         0.         0.         0.         0.3310854  1.
  0.         0.         1.        ]
 [1.         0.         0.8899636  1.         0.33130983 1.
  0.         0.88702942 1.        ]
 [1.         0.         0.         0.         0.33148078 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.33166015 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.38848608 0.33087811 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33116778 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.3318032  1.
  0.         1.         1.        ]
 [1.         0.         0.68124962 0.93279025 0.33116491 1.
  0.         0.30111648 1.        ]
 [1.         0.         0.56788888 0.62397347 0.33130788 1.
  0.         0.62184328 1.        ]
 [1.         0.         1.         1.         0.33124839 1.
  0.         0.63196924 1.        ]
 [1.         0.         0.         0.         0.33162215 1.
  0.         0.47818735 1.        ]
 [1.         0.         0.10024074 0.44515393 0.3313763  1.
  0.         0.56809941 1.        ]
 [1.         0.         0.09756991 0.29725419 0.33158051 1.
  0.         0.3663125  1.        ]
 [1.         0.         0.         0.         0.33121229 1.
  0.         0.08593367 1.        ]
 [1.         0.         0.         0.         0.33154254 1.
  0.         0.         1.        ]
 [1.         0.         0.4885768  0.78479403 0.33152137 1.
  0.         0.62428309 1.        ]
 [1.         0.         0.50395809 0.64949465 0.33137022 1.
  0.         0.28774269 1.        ]
 [1.         0.         0.86984061 0.94242786 0.33129139 1.
  0.         0.84821655 1.        ]
 [1.         0.         0.32224122 0.31421175 0.33160141 1.
  0.         0.26922395 1.        ]]

Best Training Poisoning Accuracy:
0.9375
#####################         POISON         ###############################################

############################################################################################

comm_round: 4 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.         1.         0.96238063 0.33143176 0.
 0.         1.         0.         0.         0.72900987 1.
 0.         0.71306195 1.         0.85305801 0.26566077 1.
 0.26079975 1.         1.         0.6836795  1.         0.21890456
 1.         0.        ]
wv_ed shape (26,)
[0.         0.         1.         0.69270817 0.36446406 0.
 0.         0.70861073 0.32088156 0.         0.76694079 1.
 0.         0.51308413 1.         1.         0.24089515 1.
 0.14676971 1.         1.         1.         1.         0.
 1.         0.        ]
wv_lg shape (26, 1)
[[0.33251861]
 [0.33275154]
 [0.33276188]
 [0.33274018]
 [0.33271455]
 [0.33272699]
 [0.33276085]
 [0.33272582]
 [0.33278345]
 [0.3327518 ]
 [0.33269668]
 [0.33276383]
 [0.332764  ]
 [0.33274617]
 [0.3327612 ]
 [0.33274586]
 [0.33270541]
 [0.33276467]
 [0.33275181]
 [0.33275062]
 [0.33271964]
 [0.33274659]
 [0.33270707]
 [0.33271553]
 [0.33269736]
 [0.3327517 ]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.         1.         0.31741064 0.         0.
 0.         0.17833348 0.29215515 0.         0.         0.5811122
 0.         0.60382159 0.58085363 1.         0.         1.
 0.         1.         1.         0.39978649 0.86535968 0.
 0.69726493 0.68455935]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.33251861 1.
  1.         0.         0.        ]
 [1.         0.         0.         0.         0.33275154 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.33276188 1.
  0.         1.         1.        ]
 [1.         0.         0.96238063 0.69270817 0.33274018 1.
  0.         0.31741064 1.        ]
 [1.         0.         0.33143176 0.36446406 0.33271455 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.33272699 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.33276085 1.
  0.         0.         1.        ]
 [1.         0.         1.         0.70861073 0.33272582 1.
  0.         0.17833348 1.        ]
 [1.         0.         0.         0.32088156 0.33278345 1.
  0.         0.29215515 1.        ]
 [1.         0.         0.         0.         0.3327518  1.
  0.         0.         1.        ]
 [1.         0.         0.72900987 0.76694079 0.33269668 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.33276383 1.
  0.         0.5811122  1.        ]
 [0.         0.         0.         0.         0.332764   1.
  0.         0.         1.        ]
 [1.         0.         0.71306195 0.51308413 0.33274617 1.
  0.         0.60382159 1.        ]
 [1.         0.         1.         1.         0.3327612  1.
  0.         0.58085363 1.        ]
 [1.         0.         0.85305801 1.         0.33274586 1.
  0.         1.         1.        ]
 [1.         0.         0.26566077 0.24089515 0.33270541 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.33276467 1.
  0.         1.         1.        ]
 [1.         0.         0.26079975 0.14676971 0.33275181 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.33275062 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.33271964 1.
  0.         1.         1.        ]
 [1.         0.         0.6836795  1.         0.33274659 1.
  0.         0.39978649 1.        ]
 [1.         0.         1.         1.         0.33270707 1.
  0.         0.86535968 1.        ]
 [1.         0.         0.21890456 0.         0.33271553 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.33269736 1.
  0.         0.69726493 1.        ]
 [1.         0.         0.         0.         0.3327517  1.
  0.         0.68455935 1.        ]]

Best Training Poisoning Accuracy:
0.9375
#####################         POISON         ###############################################

############################################################################################

comm_round: 5 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         1.         0.         0.         0.         0.
 0.48366653 1.         1.         1.         1.         0.
 0.         0.34146672 1.         1.         1.         1.
 1.         0.86649089 0.77616671 1.         1.         1.
 1.         1.        ]
wv_ed shape (26,)
[0.         1.         0.03741586 0.20049171 0.44032163 0.
 1.         1.         1.         1.         1.         0.19610269
 0.         0.85644718 1.         1.         1.         1.
 0.         1.         1.         1.         1.         1.
 1.         1.        ]
wv_lg shape (26, 1)
[[0.33275506]
 [0.33315968]
 [0.33316628]
 [0.33310408]
 [0.33313621]
 [0.33313977]
 [0.33307359]
 [0.33307571]
 [0.33307777]
 [0.33306014]
 [0.33310089]
 [0.33316693]
 [0.33314112]
 [0.33312002]
 [0.33313399]
 [0.3330964 ]
 [0.33313242]
 [0.33308561]
 [0.33312927]
 [0.333081  ]
 [0.33312335]
 [0.33308629]
 [0.33312572]
 [0.33313514]
 [0.33308849]
 [0.33309612]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.11418146 0.         1.         0.         0.
 1.         1.         1.         1.         1.         1.
 1.         0.         0.         0.68037952 0.06023865 1.
 0.         1.         0.         1.         1.         0.917834
 0.4693543  1.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.33275506 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.33315968 1.
  0.         0.11418146 1.        ]
 [1.         0.         0.         0.03741586 0.33316628 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.20049171 0.33310408 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.44032163 0.33313621 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33313977 1.
  0.         0.         1.        ]
 [1.         0.         0.48366653 1.         0.33307359 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.33307571 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.33307777 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.33306014 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.33310089 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.19610269 0.33316693 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.33314112 1.
  0.         1.         1.        ]
 [1.         0.         0.34146672 0.85644718 0.33312002 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.33313399 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.3330964  1.
  0.         0.68037952 1.        ]
 [1.         0.         1.         1.         0.33313242 1.
  0.         0.06023865 1.        ]
 [1.         0.         1.         1.         0.33308561 1.
  0.         1.         1.        ]
 [1.         0.         1.         0.         0.33312927 1.
  0.         0.         1.        ]
 [1.         0.         0.86649089 1.         0.333081   1.
  0.         1.         1.        ]
 [1.         0.         0.77616671 1.         0.33312335 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.33308629 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.33312572 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.33313514 1.
  0.         0.917834   1.        ]
 [1.         0.         1.         1.         0.33308849 1.
  0.         0.4693543  1.        ]
 [1.         0.         1.         1.         0.33309612 1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
1.0
#####################         POISON         ###############################################

############################################################################################

comm_round: 6 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         1.         1.         0.         0.         0.
 0.46488856 1.         0.3479704  0.9942076  0.19293457 0.86084195
 1.         1.         1.         0.         1.         0.61400203
 0.         0.25354278 1.         0.845039   1.         0.41775155
 1.         0.91315704]
wv_ed shape (26,)
[0.         1.         1.         0.         0.         0.
 0.         0.29091779 0.08180259 0.         0.         0.
 1.         1.         0.37414172 0.         0.53652004 0.70581029
 0.         0.         0.11763539 0.         0.84413623 0.
 0.74035038 0.17303471]
wv_lg shape (26, 1)
[[0.33311891]
 [0.33359843]
 [0.33354669]
 [0.33355591]
 [0.33353295]
 [0.33355014]
 [0.33354359]
 [0.33354934]
 [0.33355922]
 [0.33352005]
 [0.33352479]
 [0.3335284 ]
 [0.33352436]
 [0.33355732]
 [0.33351611]
 [0.33351926]
 [0.33356111]
 [0.33355758]
 [0.33359718]
 [0.33348907]
 [0.33353509]
 [0.3335776 ]
 [0.33352766]
 [0.33353489]
 [0.33353094]
 [0.33354107]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.         0.63519205 0.         0.94323977 0.80241178
 1.         0.62664682 0.         0.39961696 1.         0.29144809
 0.         0.         1.         1.         1.         0.95984449
 0.         0.         1.         0.1630888  1.         0.25678449
 0.40148176 1.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.33311891 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.33359843 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.33354669 1.
  0.         0.63519205 1.        ]
 [1.         0.         0.         0.         0.33355591 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.33353295 1.
  0.         0.94323977 1.        ]
 [1.         0.         0.         0.         0.33355014 1.
  0.         0.80241178 1.        ]
 [1.         0.         0.46488856 0.         0.33354359 1.
  0.         1.         1.        ]
 [1.         0.         1.         0.29091779 0.33354934 1.
  0.         0.62664682 1.        ]
 [1.         0.         0.3479704  0.08180259 0.33355922 1.
  0.         0.         1.        ]
 [1.         0.         0.9942076  0.         0.33352005 1.
  0.         0.39961696 1.        ]
 [1.         0.         0.19293457 0.         0.33352479 1.
  0.         1.         1.        ]
 [1.         0.         0.86084195 0.         0.3335284  1.
  0.         0.29144809 1.        ]
 [1.         0.         1.         1.         0.33352436 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.33355732 1.
  0.         0.         1.        ]
 [1.         0.         1.         0.37414172 0.33351611 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.33351926 1.
  0.         1.         1.        ]
 [1.         0.         1.         0.53652004 0.33356111 1.
  0.         1.         1.        ]
 [1.         0.         0.61400203 0.70581029 0.33355758 1.
  0.         0.95984449 1.        ]
 [0.         0.         0.         0.         0.33359718 1.
  0.         0.         1.        ]
 [1.         0.         0.25354278 0.         0.33348907 1.
  0.         0.         1.        ]
 [1.         0.         1.         0.11763539 0.33353509 1.
  0.         1.         1.        ]
 [1.         0.         0.845039   0.         0.3335776  1.
  0.         0.1630888  1.        ]
 [1.         0.         1.         0.84413623 0.33352766 1.
  0.         1.         1.        ]
 [1.         0.         0.41775155 0.         0.33353489 1.
  0.         0.25678449 1.        ]
 [1.         0.         1.         0.74035038 0.33353094 1.
  0.         0.40148176 1.        ]
 [1.         0.         0.91315704 0.17303471 0.33354107 1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
1.0
#####################         POISON         ###############################################

############################################################################################

comm_round: 7 | global_test_acc: 87.500% | global_f1: 0.9333333333333333 | global_precision: 0.875
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.88      1.00      0.93         7

    accuracy                           0.88         8
   macro avg       0.44      0.50      0.47         8
weighted avg       0.77      0.88      0.82         8
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.         0.10312102 0.20604275 0.         1.
 0.         0.         0.15981363 0.         1.         1.
 0.39307185 0.         0.         0.         0.84650549 0.
 1.         1.         1.         0.53496788 1.         0.03121163
 0.6567761  0.        ]
wv_ed shape (26,)
[0.         0.         0.         0.55813756 0.         1.
 0.         0.         0.15083054 0.         1.         1.
 0.62890637 0.         0.         0.         0.65327655 0.
 1.         1.         1.         0.         0.40811091 0.35790665
 0.32789333 0.        ]
wv_lg shape (26, 1)
[[0.33353252]
 [0.33394213]
 [0.33392623]
 [0.33392133]
 [0.33389234]
 [0.33388646]
 [0.33393841]
 [0.33397915]
 [0.33394334]
 [0.33391674]
 [0.33397452]
 [0.33394927]
 [0.33392504]
 [0.33398706]
 [0.33396012]
 [0.33394263]
 [0.33393243]
 [0.33401664]
 [0.33401463]
 [0.33392201]
 [0.33394632]
 [0.33389918]
 [0.33397659]
 [0.33396243]
 [0.33389963]
 [0.3339815 ]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.20428792 0.         1.         0.9115105  1.
 0.         0.         0.         0.91585287 1.         0.71614818
 0.         0.33820122 0.42025062 0.98622362 1.         0.
 0.18426955 1.         0.         1.         1.         0.8424268
 0.97536119 0.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.33353252 1.
  1.         0.         0.        ]
 [1.         0.         0.         0.         0.33394213 1.
  0.         0.20428792 1.        ]
 [1.         0.         0.10312102 0.         0.33392623 1.
  0.         0.         1.        ]
 [1.         0.         0.20604275 0.55813756 0.33392133 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.33389234 1.
  0.         0.9115105  1.        ]
 [1.         0.         1.         1.         0.33388646 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.33393841 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.33397915 1.
  0.         0.         1.        ]
 [1.         0.         0.15981363 0.15083054 0.33394334 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.33391674 1.
  0.         0.91585287 1.        ]
 [1.         0.         1.         1.         0.33397452 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.33394927 1.
  0.         0.71614818 1.        ]
 [1.         0.         0.39307185 0.62890637 0.33392504 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.33398706 1.
  0.         0.33820122 1.        ]
 [1.         0.         0.         0.         0.33396012 1.
  0.         0.42025062 1.        ]
 [1.         0.         0.         0.         0.33394263 1.
  0.         0.98622362 1.        ]
 [1.         0.         0.84650549 0.65327655 0.33393243 1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.33401664 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.33401463 1.
  0.         0.18426955 1.        ]
 [1.         0.         1.         1.         0.33392201 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.33394632 1.
  0.         0.         1.        ]
 [1.         0.         0.53496788 0.         0.33389918 1.
  0.         1.         1.        ]
 [1.         0.         1.         0.40811091 0.33397659 1.
  0.         1.         1.        ]
 [1.         0.         0.03121163 0.35790665 0.33396243 1.
  0.         0.8424268  1.        ]
 [1.         0.         0.6567761  0.32789333 0.33389963 1.
  0.         0.97536119 1.        ]
 [1.         0.         0.         0.         0.3339815  1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
1.0
#####################         POISON         ###############################################

############################################################################################

comm_round: 8 | global_test_acc: 87.500% | global_f1: 0.9333333333333333 | global_precision: 0.875
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.88      1.00      0.93         7

    accuracy                           0.88         8
   macro avg       0.44      0.50      0.47         8
weighted avg       0.77      0.88      0.82         8
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         1.         0.92876667 1.         0.62344748 1.
 0.64330617 1.         0.         0.         0.         1.
 0.20666845 0.         0.         0.87937341 1.         1.
 1.         1.         1.         0.5445145  1.         1.
 1.         0.46009391]
wv_ed shape (26,)
[0.         1.         0.77283246 1.         0.85112578 1.
 0.7384454  1.         0.06275484 0.         0.01793144 1.
 0.59789192 0.         0.         0.90958469 1.         1.
 1.         1.         1.         0.89897152 1.         1.
 1.         0.47615906]
wv_lg shape (26, 1)
[[0.33389323]
 [0.33428791]
 [0.33432464]
 [0.33432716]
 [0.33428327]
 [0.3342673 ]
 [0.33430737]
 [0.33434177]
 [0.33429639]
 [0.33426617]
 [0.33431819]
 [0.33432676]
 [0.33434723]
 [0.33427346]
 [0.33426036]
 [0.33429795]
 [0.33425555]
 [0.33429876]
 [0.33427929]
 [0.3342996 ]
 [0.3342941 ]
 [0.33424471]
 [0.33432071]
 [0.33432814]
 [0.33424099]
 [0.33433366]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         1.         0.83961576 0.65046536 0.         1.
 0.         1.         0.         1.         0.3783845  0.57816319
 0.88402377 0.         0.4369054  0.49375042 1.         1.
 1.         1.         0.02834172 0.47265688 1.         0.
 1.         0.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.33389323 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.33428791 1.
  0.         1.         1.        ]
 [1.         0.         0.92876667 0.77283246 0.33432464 1.
  0.         0.83961576 1.        ]
 [1.         0.         1.         1.         0.33432716 1.
  0.         0.65046536 1.        ]
 [1.         0.         0.62344748 0.85112578 0.33428327 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.3342673  1.
  0.         1.         1.        ]
 [1.         0.         0.64330617 0.7384454  0.33430737 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.33434177 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.06275484 0.33429639 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.33426617 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.01793144 0.33431819 1.
  0.         0.3783845  1.        ]
 [1.         0.         1.         1.         0.33432676 1.
  0.         0.57816319 1.        ]
 [1.         0.         0.20666845 0.59789192 0.33434723 1.
  0.         0.88402377 1.        ]
 [0.         0.         0.         0.         0.33427346 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.33426036 1.
  0.         0.4369054  1.        ]
 [1.         0.         0.87937341 0.90958469 0.33429795 1.
  0.         0.49375042 1.        ]
 [1.         0.         1.         1.         0.33425555 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.33429876 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.33427929 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.3342996  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.3342941  1.
  0.         0.02834172 1.        ]
 [1.         0.         0.5445145  0.89897152 0.33424471 1.
  0.         0.47265688 1.        ]
 [1.         0.         1.         1.         0.33432071 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.33432814 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.33424099 1.
  0.         1.         1.        ]
 [1.         0.         0.46009391 0.47615906 0.33433366 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.9375
#####################         POISON         ###############################################

############################################################################################

comm_round: 9 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.         0.         1.         0.73592135 0.
 1.         1.         0.         0.         0.         0.
 0.         0.6583865  0.         1.         0.33026139 0.
 0.         1.         0.         0.61786748 0.         0.
 0.33088976 0.        ]
wv_ed shape (26,)
[0.         0.         0.         1.         0.38888858 0.
 1.         1.         0.         0.         0.         0.
 0.         0.17817114 0.         1.         0.13633697 0.
 0.         1.         0.         0.96734826 0.         0.
 0.21450269 0.        ]
wv_lg shape (26, 1)
[[0.33423174]
 [0.33450984]
 [0.33450773]
 [0.3345862 ]
 [0.33455387]
 [0.33454152]
 [0.33450576]
 [0.33448306]
 [0.33455722]
 [0.33459775]
 [0.33449944]
 [0.33458678]
 [0.33448318]
 [0.3345639 ]
 [0.33445808]
 [0.33450791]
 [0.33462341]
 [0.33440502]
 [0.33457468]
 [0.33456656]
 [0.33453588]
 [0.33450537]
 [0.3345137 ]
 [0.33452307]
 [0.33458577]
 [0.3346188 ]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         1.         1.         0.         0.83867673 0.51643137
 1.         0.         0.47080012 0.         0.51086682 0.
 0.51146411 0.13963352 0.         1.         0.         0.89630907
 0.         0.86982969 0.         1.         1.         1.
 0.         0.93095759]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.33423174 1.
  1.         0.         0.        ]
 [1.         0.         0.         0.         0.33450984 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.33450773 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.3345862  1.
  0.         0.         1.        ]
 [1.         0.         0.73592135 0.38888858 0.33455387 1.
  0.         0.83867673 1.        ]
 [1.         0.         0.         0.         0.33454152 1.
  0.         0.51643137 1.        ]
 [1.         0.         1.         1.         0.33450576 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.33448306 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.33455722 1.
  0.         0.47080012 1.        ]
 [0.         0.         0.         0.         0.33459775 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.33449944 1.
  0.         0.51086682 1.        ]
 [1.         0.         0.         0.         0.33458678 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.33448318 1.
  0.         0.51146411 1.        ]
 [1.         0.         0.6583865  0.17817114 0.3345639  1.
  0.         0.13963352 1.        ]
 [1.         0.         0.         0.         0.33445808 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.33450791 1.
  0.         1.         1.        ]
 [1.         0.         0.33026139 0.13633697 0.33462341 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.33440502 1.
  0.         0.89630907 1.        ]
 [1.         0.         0.         0.         0.33457468 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.33456656 1.
  0.         0.86982969 1.        ]
 [1.         0.         0.         0.         0.33453588 1.
  0.         0.         1.        ]
 [1.         0.         0.61786748 0.96734826 0.33450537 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.3345137  1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.33452307 1.
  0.         1.         1.        ]
 [1.         0.         0.33088976 0.21450269 0.33458577 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.3346188  1.
  0.         0.93095759 1.        ]]

Best Training Poisoning Accuracy:
0.9375
#####################         POISON         ###############################################

############################################################################################

comm_round: 10 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.39899078 0.28651843 1.         0.         1.
 0.         0.47497365 0.         0.         0.         1.
 0.86163696 0.63356921 0.48226727 0.17865225 0.36399937 1.
 0.         0.85339578 1.         0.         0.         1.
 0.         1.        ]
wv_ed shape (26,)
[0.         0.2630127  0.01728021 1.         0.         1.
 0.         0.5406358  0.         0.         0.         1.
 0.87550177 0.43119272 0.55031236 0.         0.38483321 1.
 0.         0.928096   1.         0.         0.         0.81785692
 0.         1.        ]
wv_lg shape (26, 1)
[[0.3344513 ]
 [0.33475461]
 [0.33474219]
 [0.33471754]
 [0.33474269]
 [0.3347488 ]
 [0.33467446]
 [0.33476342]
 [0.33477447]
 [0.33477914]
 [0.33473615]
 [0.33473587]
 [0.33481906]
 [0.3346441 ]
 [0.33465255]
 [0.33481116]
 [0.33479608]
 [0.33473741]
 [0.33484118]
 [0.33477916]
 [0.3347411 ]
 [0.33474631]
 [0.33482245]
 [0.33473977]
 [0.33479354]
 [0.33474839]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         1.         0.30610196 1.         0.29432875 1.
 1.         0.88257113 0.         0.         0.         1.
 0.         0.46522875 1.         0.12402182 1.         0.56131094
 0.         1.         0.61171997 0.58040508 0.         0.06328501
 0.97557579 1.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.3344513  1.
  1.         0.         0.        ]
 [1.         0.         0.39899078 0.2630127  0.33475461 1.
  0.         1.         1.        ]
 [1.         0.         0.28651843 0.01728021 0.33474219 1.
  0.         0.30610196 1.        ]
 [1.         0.         1.         1.         0.33471754 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.33474269 1.
  0.         0.29432875 1.        ]
 [1.         0.         1.         1.         0.3347488  1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.33467446 1.
  0.         1.         1.        ]
 [1.         0.         0.47497365 0.5406358  0.33476342 1.
  0.         0.88257113 1.        ]
 [1.         0.         0.         0.         0.33477447 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.33477914 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33473615 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.33473587 1.
  0.         1.         1.        ]
 [1.         0.         0.86163696 0.87550177 0.33481906 1.
  0.         0.         1.        ]
 [1.         0.         0.63356921 0.43119272 0.3346441  1.
  0.         0.46522875 1.        ]
 [1.         0.         0.48226727 0.55031236 0.33465255 1.
  0.         1.         1.        ]
 [1.         0.         0.17865225 0.         0.33481116 1.
  0.         0.12402182 1.        ]
 [1.         0.         0.36399937 0.38483321 0.33479608 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.33473741 1.
  0.         0.56131094 1.        ]
 [1.         0.         0.         0.         0.33484118 1.
  0.         0.         1.        ]
 [1.         0.         0.85339578 0.928096   0.33477916 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.3347411  1.
  0.         0.61171997 1.        ]
 [1.         0.         0.         0.         0.33474631 1.
  0.         0.58040508 1.        ]
 [1.         0.         0.         0.         0.33482245 1.
  0.         0.         1.        ]
 [1.         0.         1.         0.81785692 0.33473977 1.
  0.         0.06328501 1.        ]
 [1.         0.         0.         0.         0.33479354 1.
  0.         0.97557579 1.        ]
 [1.         0.         1.         1.         0.33474839 1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.9375
#####################         POISON         ###############################################

############################################################################################

comm_round: 11 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         1.         1.         0.32292033 0.4999261  1.
 1.         0.67174841 0.         0.         0.         0.94812635
 1.         0.         1.         0.         0.40220941 0.
 0.57495328 1.         1.         1.         1.         0.11381117
 1.         1.        ]
wv_ed shape (26,)
[0.         1.         1.         0.36555833 0.25489584 1.
 1.         0.21725544 0.         0.         0.         0.73359823
 1.         0.         1.         0.         0.23776174 0.
 0.40620973 1.         1.         0.76132242 1.         0.1504558
 0.96299394 1.        ]
wv_lg shape (26, 1)
[[0.3346821 ]
 [0.33491064]
 [0.33497956]
 [0.33492287]
 [0.33496074]
 [0.33490398]
 [0.3349601 ]
 [0.33494846]
 [0.33490377]
 [0.33489143]
 [0.33500474]
 [0.33491872]
 [0.33491188]
 [0.33497856]
 [0.33500343]
 [0.33500781]
 [0.33502587]
 [0.33496965]
 [0.33492824]
 [0.33490802]
 [0.33495703]
 [0.33492587]
 [0.33497288]
 [0.33496988]
 [0.33491354]
 [0.33489982]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.40142778 0.56333702 0.         0.         0.95062928
 1.         0.         0.         0.36498919 0.         0.
 0.73422063 0.         0.         0.         0.         0.
 0.43787205 0.58962789 0.         0.         0.         0.05449722
 0.         1.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.3346821  1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.33491064 1.
  0.         0.40142778 1.        ]
 [1.         0.         1.         1.         0.33497956 1.
  0.         0.56333702 1.        ]
 [1.         0.         0.32292033 0.36555833 0.33492287 1.
  0.         0.         1.        ]
 [1.         0.         0.4999261  0.25489584 0.33496074 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.33490398 1.
  0.         0.95062928 1.        ]
 [1.         0.         1.         1.         0.3349601  1.
  0.         1.         1.        ]
 [1.         0.         0.67174841 0.21725544 0.33494846 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33490377 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.33489143 1.
  0.         0.36498919 1.        ]
 [1.         0.         0.         0.         0.33500474 1.
  0.         0.         1.        ]
 [1.         0.         0.94812635 0.73359823 0.33491872 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.33491188 1.
  0.         0.73422063 1.        ]
 [1.         0.         0.         0.         0.33497856 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.33500343 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.33500781 1.
  0.         0.         1.        ]
 [1.         0.         0.40220941 0.23776174 0.33502587 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.33496965 1.
  0.         0.         1.        ]
 [1.         0.         0.57495328 0.40620973 0.33492824 1.
  0.         0.43787205 1.        ]
 [1.         0.         1.         1.         0.33490802 1.
  0.         0.58962789 1.        ]
 [1.         0.         1.         1.         0.33495703 1.
  0.         0.         1.        ]
 [1.         0.         1.         0.76132242 0.33492587 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.33497288 1.
  0.         0.         1.        ]
 [1.         0.         0.11381117 0.1504558  0.33496988 1.
  0.         0.05449722 1.        ]
 [1.         0.         1.         0.96299394 0.33491354 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.33489982 1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
1.0
#####################         POISON         ###############################################

############################################################################################

comm_round: 12 | global_test_acc: 87.500% | global_f1: 0.9333333333333333 | global_precision: 0.875
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.88      1.00      0.93         7

    accuracy                           0.88         8
   macro avg       0.44      0.50      0.47         8
weighted avg       0.77      0.88      0.82         8
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.03598563 0.         1.         0.         0.
 0.         0.3278335  0.         0.         0.0555645  1.
 1.         0.68135236 0.1170465  1.         1.         0.83677793
 1.         0.         0.42933934 0.         0.52262457 0.4601224
 1.         1.        ]
wv_ed shape (26,)
[0.         0.         0.         1.         0.         0.
 0.         0.35465776 0.         0.         0.08798694 1.
 1.         0.66932008 0.         1.         1.         0.67690449
 1.         0.         0.60558748 0.         0.413575   0.19461153
 1.         1.        ]
wv_lg shape (26, 1)
[[0.33482366]
 [0.3351896 ]
 [0.33517016]
 [0.33515312]
 [0.33513069]
 [0.33508588]
 [0.33506715]
 [0.33506453]
 [0.33510111]
 [0.3351081 ]
 [0.33515099]
 [0.33509961]
 [0.33520593]
 [0.33512409]
 [0.33516864]
 [0.33507091]
 [0.33520087]
 [0.3351707 ]
 [0.33519134]
 [0.33508981]
 [0.3350168 ]
 [0.3350754 ]
 [0.33520067]
 [0.33514643]
 [0.33512745]
 [0.3350944 ]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.         0.         1.         0.         0.
 0.         1.         0.65779611 0.         0.23123718 1.
 1.         0.67806172 0.         1.         1.         0.
 1.         0.         1.         0.         0.         0.
 0.31830184 0.85712975]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.33482366 1.
  1.         0.         0.        ]
 [1.         0.         0.03598563 0.         0.3351896  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33517016 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.33515312 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.33513069 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.33508588 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.33506715 1.
  0.         0.         1.        ]
 [1.         0.         0.3278335  0.35465776 0.33506453 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.33510111 1.
  0.         0.65779611 1.        ]
 [1.         0.         0.         0.         0.3351081  1.
  0.         0.         1.        ]
 [1.         0.         0.0555645  0.08798694 0.33515099 1.
  0.         0.23123718 1.        ]
 [1.         0.         1.         1.         0.33509961 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.33520593 1.
  0.         1.         1.        ]
 [1.         0.         0.68135236 0.66932008 0.33512409 1.
  0.         0.67806172 1.        ]
 [1.         0.         0.1170465  0.         0.33516864 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.33507091 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.33520087 1.
  0.         1.         1.        ]
 [1.         0.         0.83677793 0.67690449 0.3351707  1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.33519134 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.33508981 1.
  0.         0.         1.        ]
 [1.         0.         0.42933934 0.60558748 0.3350168  1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.3350754  1.
  0.         0.         1.        ]
 [1.         0.         0.52262457 0.413575   0.33520067 1.
  0.         0.         1.        ]
 [1.         0.         0.4601224  0.19461153 0.33514643 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.33512745 1.
  0.         0.31830184 1.        ]
 [1.         0.         1.         1.         0.3350944  1.
  0.         0.85712975 1.        ]]

Best Training Poisoning Accuracy:
1.0
#####################         POISON         ###############################################

############################################################################################

comm_round: 13 | global_test_acc: 87.500% | global_f1: 0.9333333333333333 | global_precision: 0.875
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.88      1.00      0.93         7

    accuracy                           0.88         8
   macro avg       0.44      0.50      0.47         8
weighted avg       0.77      0.88      0.82         8
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.61259167 1.         1.         1.         0.65519131
 1.         0.33520555 0.         1.         0.         1.
 0.77379989 0.7055076  0.54665425 0.22446348 1.         1.
 1.         0.97426721 1.         1.         0.77085966 1.
 1.         1.        ]
wv_ed shape (26,)
[0.         0.79203224 1.         1.         1.         0.74446931
 1.         0.04563444 0.         1.         0.11796889 1.
 0.61390534 0.72452963 0.4141648  0.17289904 1.         0.80333275
 1.         1.         1.         1.         0.92959125 1.
 1.         1.        ]
wv_lg shape (26, 1)
[[0.33504327]
 [0.33535432]
 [0.33522503]
 [0.3352834 ]
 [0.33530213]
 [0.33528539]
 [0.33523452]
 [0.3353903 ]
 [0.33525678]
 [0.33535482]
 [0.33529423]
 [0.33530639]
 [0.33524309]
 [0.33538507]
 [0.33524323]
 [0.33532089]
 [0.33524606]
 [0.335261  ]
 [0.33529041]
 [0.33531325]
 [0.3354168 ]
 [0.33536679]
 [0.33529208]
 [0.33519985]
 [0.33532578]
 [0.33532636]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         1.         1.         1.         1.         1.
 1.         0.         0.         1.         0.30562606 1.
 0.61648817 0.         0.         0.         1.         0.13304073
 0.         1.         1.         0.99354873 1.         1.
 1.         1.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.33504327 1.
  1.         0.         0.        ]
 [1.         0.         0.61259167 0.79203224 0.33535432 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.33522503 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.3352834  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.33530213 1.
  0.         1.         1.        ]
 [1.         0.         0.65519131 0.74446931 0.33528539 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.33523452 1.
  0.         1.         1.        ]
 [1.         0.         0.33520555 0.04563444 0.3353903  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33525678 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.33535482 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.11796889 0.33529423 1.
  0.         0.30562606 1.        ]
 [1.         0.         1.         1.         0.33530639 1.
  0.         1.         1.        ]
 [1.         0.         0.77379989 0.61390534 0.33524309 1.
  0.         0.61648817 1.        ]
 [1.         0.         0.7055076  0.72452963 0.33538507 1.
  0.         0.         1.        ]
 [1.         0.         0.54665425 0.4141648  0.33524323 1.
  0.         0.         1.        ]
 [1.         0.         0.22446348 0.17289904 0.33532089 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.33524606 1.
  0.         1.         1.        ]
 [1.         0.         1.         0.80333275 0.335261   1.
  0.         0.13304073 1.        ]
 [1.         0.         1.         1.         0.33529041 1.
  0.         0.         1.        ]
 [1.         0.         0.97426721 1.         0.33531325 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.3354168  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.33536679 1.
  0.         0.99354873 1.        ]
 [1.         0.         0.77085966 0.92959125 0.33529208 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.33519985 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.33532578 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.33532636 1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.9375
#####################         POISON         ###############################################

############################################################################################

comm_round: 14 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.79442523 0.         0.69857099 0.36706993 1.
 1.         1.         0.36502823 0.         0.0236011  1.
 1.         1.         1.         0.         0.         1.
 1.         1.         1.         1.         0.1061641  0.57231665
 0.38675755 0.01756762]
wv_ed shape (26,)
[0.         0.46205911 0.         0.6513271  0.39538686 1.
 1.         1.         0.49104057 0.         0.         0.72327537
 1.         0.89169894 0.78503038 0.         0.         1.
 1.         1.         0.91803046 1.         0.         0.5954066
 0.40789661 0.        ]
wv_lg shape (26, 1)
[[0.33509024]
 [0.33545785]
 [0.33542814]
 [0.33545461]
 [0.33548129]
 [0.3354451 ]
 [0.33537666]
 [0.33546117]
 [0.33546557]
 [0.33550387]
 [0.33542208]
 [0.33549923]
 [0.33546132]
 [0.33555741]
 [0.33545676]
 [0.3354387 ]
 [0.33544154]
 [0.33556252]
 [0.33551083]
 [0.33552504]
 [0.33544426]
 [0.33551691]
 [0.33538644]
 [0.33548292]
 [0.33547593]
 [0.33542352]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.         0.         0.33511501 0.56411172 1.
 1.         1.         0.52922901 0.         0.         0.
 0.55762531 0.         0.         0.         0.         1.
 0.62968748 0.19732287 0.29394519 1.         0.         0.74098082
 1.         0.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.33509024 1.
  1.         0.         0.        ]
 [1.         0.         0.79442523 0.46205911 0.33545785 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33542814 1.
  0.         0.         1.        ]
 [1.         0.         0.69857099 0.6513271  0.33545461 1.
  0.         0.33511501 1.        ]
 [1.         0.         0.36706993 0.39538686 0.33548129 1.
  0.         0.56411172 1.        ]
 [1.         0.         1.         1.         0.3354451  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.33537666 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.33546117 1.
  0.         1.         1.        ]
 [1.         0.         0.36502823 0.49104057 0.33546557 1.
  0.         0.52922901 1.        ]
 [1.         0.         0.         0.         0.33550387 1.
  0.         0.         1.        ]
 [1.         0.         0.0236011  0.         0.33542208 1.
  0.         0.         1.        ]
 [1.         0.         1.         0.72327537 0.33549923 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.33546132 1.
  0.         0.55762531 1.        ]
 [1.         0.         1.         0.89169894 0.33555741 1.
  0.         0.         1.        ]
 [1.         0.         1.         0.78503038 0.33545676 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.3354387  1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.33544154 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.33556252 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.33551083 1.
  0.         0.62968748 1.        ]
 [1.         0.         1.         1.         0.33552504 1.
  0.         0.19732287 1.        ]
 [1.         0.         1.         0.91803046 0.33544426 1.
  0.         0.29394519 1.        ]
 [1.         0.         1.         1.         0.33551691 1.
  0.         1.         1.        ]
 [1.         0.         0.1061641  0.         0.33538644 1.
  0.         0.         1.        ]
 [1.         0.         0.57231665 0.5954066  0.33548292 1.
  0.         0.74098082 1.        ]
 [1.         0.         0.38675755 0.40789661 0.33547593 1.
  0.         1.         1.        ]
 [1.         0.         0.01756762 0.         0.33542352 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.9375
#####################         POISON         ###############################################

############################################################################################

comm_round: 15 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         1.         1.         1.         0.98277706 1.
 1.         0.99079625 1.         0.         1.         1.
 1.         1.         0.         1.         0.62265853 1.
 0.49954707 0.4188727  0.45958257 1.         1.         1.
 1.         1.        ]
wv_ed shape (26,)
[0.         1.         1.         1.         0.66440076 1.
 1.         1.         1.         0.         1.         1.
 0.88449196 1.         0.11456669 1.         0.67509647 1.
 0.55074201 0.57193957 0.59372733 1.         1.         1.
 1.         1.        ]
wv_lg shape (26, 1)
[[0.33537987]
 [0.33567967]
 [0.33560389]
 [0.33557041]
 [0.33556075]
 [0.33564383]
 [0.33559403]
 [0.33559815]
 [0.33555516]
 [0.33557274]
 [0.33568187]
 [0.33568074]
 [0.33561746]
 [0.33566751]
 [0.33557929]
 [0.33562394]
 [0.33557477]
 [0.33568148]
 [0.33554193]
 [0.33564615]
 [0.33560302]
 [0.3356113 ]
 [0.33566033]
 [0.33578024]
 [0.33564964]
 [0.3356661 ]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.         0.         1.         0.         0.43418781
 1.         1.         0.37595377 0.         0.44574618 0.72311388
 0.         1.         0.20033214 1.         0.27655756 1.
 0.32906619 0.53417556 0.02507471 1.         1.         1.
 0.74133157 1.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.33537987 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.33567967 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.33560389 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.33557041 1.
  0.         1.         1.        ]
 [1.         0.         0.98277706 0.66440076 0.33556075 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.33564383 1.
  0.         0.43418781 1.        ]
 [1.         0.         1.         1.         0.33559403 1.
  0.         1.         1.        ]
 [1.         0.         0.99079625 1.         0.33559815 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.33555516 1.
  0.         0.37595377 1.        ]
 [0.         0.         0.         0.         0.33557274 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.33568187 1.
  0.         0.44574618 1.        ]
 [1.         0.         1.         1.         0.33568074 1.
  0.         0.72311388 1.        ]
 [1.         0.         1.         0.88449196 0.33561746 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.33566751 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.11456669 0.33557929 1.
  0.         0.20033214 1.        ]
 [1.         0.         1.         1.         0.33562394 1.
  0.         1.         1.        ]
 [1.         0.         0.62265853 0.67509647 0.33557477 1.
  0.         0.27655756 1.        ]
 [1.         0.         1.         1.         0.33568148 1.
  0.         1.         1.        ]
 [1.         0.         0.49954707 0.55074201 0.33554193 1.
  0.         0.32906619 1.        ]
 [1.         0.         0.4188727  0.57193957 0.33564615 1.
  0.         0.53417556 1.        ]
 [1.         0.         0.45958257 0.59372733 0.33560302 1.
  0.         0.02507471 1.        ]
 [1.         0.         1.         1.         0.3356113  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.33566033 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.33578024 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.33564964 1.
  0.         0.74133157 1.        ]
 [1.         0.         1.         1.         0.3356661  1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
1.0
#####################         POISON         ###############################################

############################################################################################

comm_round: 16 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.         0.806952   0.18673953 1.         0.
 0.47600228 1.         1.         1.         0.         0.34235042
 1.         1.         0.         0.23824482 0.         0.
 0.14710034 0.         0.3217564  0.41515418 1.         0.
 0.10866159 0.        ]
wv_ed shape (26,)
[0.         0.         0.5847187  0.         0.97962704 0.
 0.19205508 1.         1.         1.         0.         0.4184924
 1.         1.         0.         0.21309497 0.         0.
 0.         0.         0.18319466 0.15338468 1.         0.
 0.         0.        ]
wv_lg shape (26, 1)
[[0.3356113 ]
 [0.33582229]
 [0.33580709]
 [0.33576268]
 [0.33569108]
 [0.33576501]
 [0.33578284]
 [0.33576431]
 [0.33586435]
 [0.33571184]
 [0.33575743]
 [0.33572603]
 [0.33583746]
 [0.33585735]
 [0.33586011]
 [0.33584981]
 [0.33573711]
 [0.33571216]
 [0.33587687]
 [0.3357804 ]
 [0.33584216]
 [0.33568333]
 [0.33579139]
 [0.33585303]
 [0.33579513]
 [0.33584296]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.         0.16674643 0.22926025 1.         0.
 0.05772095 1.         0.69936846 1.         0.         0.88774485
 1.         1.         0.         0.81889285 0.         0.
 0.         0.         0.         0.08399812 1.         0.
 0.         0.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.3356113  1.
  1.         0.         0.        ]
 [1.         0.         0.         0.         0.33582229 1.
  0.         0.         1.        ]
 [1.         0.         0.806952   0.5847187  0.33580709 1.
  0.         0.16674643 1.        ]
 [1.         0.         0.18673953 0.         0.33576268 1.
  0.         0.22926025 1.        ]
 [1.         0.         1.         0.97962704 0.33569108 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.33576501 1.
  0.         0.         1.        ]
 [1.         0.         0.47600228 0.19205508 0.33578284 1.
  0.         0.05772095 1.        ]
 [1.         0.         1.         1.         0.33576431 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.33586435 1.
  0.         0.69936846 1.        ]
 [1.         0.         1.         1.         0.33571184 1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.33575743 1.
  0.         0.         1.        ]
 [1.         0.         0.34235042 0.4184924  0.33572603 1.
  0.         0.88774485 1.        ]
 [1.         0.         1.         1.         0.33583746 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.33585735 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.33586011 1.
  0.         0.         1.        ]
 [1.         0.         0.23824482 0.21309497 0.33584981 1.
  0.         0.81889285 1.        ]
 [1.         0.         0.         0.         0.33573711 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.33571216 1.
  0.         0.         1.        ]
 [1.         0.         0.14710034 0.         0.33587687 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.3357804  1.
  0.         0.         1.        ]
 [1.         0.         0.3217564  0.18319466 0.33584216 1.
  0.         0.         1.        ]
 [1.         0.         0.41515418 0.15338468 0.33568333 1.
  0.         0.08399812 1.        ]
 [1.         0.         1.         1.         0.33579139 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.33585303 1.
  0.         0.         1.        ]
 [1.         0.         0.10866159 0.         0.33579513 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.33584296 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.9375
#####################         POISON         ###############################################

############################################################################################

comm_round: 17 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         1.         0.45463512 0.78812583 0.60139241 1.
 0.06822344 0.         1.         0.72081345 1.         1.
 1.         1.         0.12745533 1.         1.         0.97065449
 0.         1.         1.         1.         1.         0.79148101
 0.28501151 1.        ]
wv_ed shape (26,)
[0.         1.         0.46684061 0.57642624 0.54739252 1.
 0.24067005 0.         1.         0.54149372 1.         1.
 0.9533146  1.         0.21542871 1.         1.         0.53827719
 0.         1.         1.         0.8428187  1.         0.625724
 0.00296321 1.        ]
wv_lg shape (26, 1)
[[0.33577759]
 [0.33594415]
 [0.33597393]
 [0.33596717]
 [0.33585923]
 [0.33589691]
 [0.33591899]
 [0.33592475]
 [0.33605201]
 [0.33594076]
 [0.33595362]
 [0.33598712]
 [0.33592276]
 [0.33596047]
 [0.33597619]
 [0.33594488]
 [0.33596349]
 [0.3358691 ]
 [0.3359314 ]
 [0.33590598]
 [0.33593916]
 [0.33600083]
 [0.33596338]
 [0.33598159]
 [0.33598514]
 [0.3359581 ]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         1.         0.         0.36444728 0.         0.84770805
 0.45227791 0.         0.84151653 0.31651674 1.         0.75364245
 0.93275275 0.94851324 0.         1.         1.         0.14561072
 0.         1.         0.35326003 0.         1.         0.1213313
 0.         1.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.33577759 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.33594415 1.
  0.         1.         1.        ]
 [1.         0.         0.45463512 0.46684061 0.33597393 1.
  0.         0.         1.        ]
 [1.         0.         0.78812583 0.57642624 0.33596717 1.
  0.         0.36444728 1.        ]
 [1.         0.         0.60139241 0.54739252 0.33585923 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.33589691 1.
  0.         0.84770805 1.        ]
 [1.         0.         0.06822344 0.24067005 0.33591899 1.
  0.         0.45227791 1.        ]
 [0.         0.         0.         0.         0.33592475 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.33605201 1.
  0.         0.84151653 1.        ]
 [1.         0.         0.72081345 0.54149372 0.33594076 1.
  0.         0.31651674 1.        ]
 [1.         0.         1.         1.         0.33595362 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.33598712 1.
  0.         0.75364245 1.        ]
 [1.         0.         1.         0.9533146  0.33592276 1.
  0.         0.93275275 1.        ]
 [1.         0.         1.         1.         0.33596047 1.
  0.         0.94851324 1.        ]
 [1.         0.         0.12745533 0.21542871 0.33597619 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.33594488 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.33596349 1.
  0.         1.         1.        ]
 [1.         0.         0.97065449 0.53827719 0.3358691  1.
  0.         0.14561072 1.        ]
 [1.         0.         0.         0.         0.3359314  1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.33590598 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.33593916 1.
  0.         0.35326003 1.        ]
 [1.         0.         1.         0.8428187  0.33600083 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.33596338 1.
  0.         1.         1.        ]
 [1.         0.         0.79148101 0.625724   0.33598159 1.
  0.         0.1213313  1.        ]
 [1.         0.         0.28501151 0.00296321 0.33598514 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.3359581  1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
1.0
#####################         POISON         ###############################################

############################################################################################

comm_round: 18 | global_test_acc: 87.500% | global_f1: 0.9333333333333333 | global_precision: 0.875
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.88      1.00      0.93         7

    accuracy                           0.88         8
   macro avg       0.44      0.50      0.47         8
weighted avg       0.77      0.88      0.82         8
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.76445286 1.         0.28701661 0.03026215 1.
 1.         0.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         0.15107526 1.         1.         0.75205124
 1.         0.72006652]
wv_ed shape (26,)
[0.         0.91496371 1.         0.79803545 0.14983967 1.
 1.         0.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         0.         1.         1.         0.90392695
 1.         1.        ]
wv_lg shape (26, 1)
[[0.33581361]
 [0.33612237]
 [0.33614795]
 [0.33616683]
 [0.3360938 ]
 [0.33606713]
 [0.33611067]
 [0.33610132]
 [0.33605607]
 [0.33614425]
 [0.33606074]
 [0.33610772]
 [0.33610816]
 [0.3361194 ]
 [0.33613256]
 [0.33606501]
 [0.33613294]
 [0.33613848]
 [0.33618094]
 [0.33613736]
 [0.33614156]
 [0.33611808]
 [0.33608663]
 [0.33616117]
 [0.33605421]
 [0.33606813]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.50408007 0.22802168 1.         0.         1.
 0.         0.         1.         0.         1.         0.74834491
 0.7756134  0.83529619 1.         1.         0.         1.
 0.334584   1.         0.         0.         1.         0.37644227
 1.         1.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.33581361 1.
  1.         0.         0.        ]
 [1.         0.         0.76445286 0.91496371 0.33612237 1.
  0.         0.50408007 1.        ]
 [1.         0.         1.         1.         0.33614795 1.
  0.         0.22802168 1.        ]
 [1.         0.         0.28701661 0.79803545 0.33616683 1.
  0.         1.         1.        ]
 [1.         0.         0.03026215 0.14983967 0.3360938  1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.33606713 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.33611067 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33610132 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.33605607 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.33614425 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.33606074 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.33610772 1.
  0.         0.74834491 1.        ]
 [1.         0.         1.         1.         0.33610816 1.
  0.         0.7756134  1.        ]
 [1.         0.         1.         1.         0.3361194  1.
  0.         0.83529619 1.        ]
 [1.         0.         1.         1.         0.33613256 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.33606501 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.33613294 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.33613848 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.33618094 1.
  0.         0.334584   1.        ]
 [1.         0.         1.         1.         0.33613736 1.
  0.         1.         1.        ]
 [1.         0.         0.15107526 0.         0.33614156 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.33611808 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.33608663 1.
  0.         1.         1.        ]
 [1.         0.         0.75205124 0.90392695 0.33616117 1.
  0.         0.37644227 1.        ]
 [1.         0.         1.         1.         0.33605421 1.
  0.         1.         1.        ]
 [1.         0.         0.72006652 1.         0.33606813 1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
1.0
#####################         POISON         ###############################################

############################################################################################

comm_round: 19 | global_test_acc: 87.500% | global_f1: 0.9333333333333333 | global_precision: 0.875
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.88      1.00      0.93         7

    accuracy                           0.88         8
   macro avg       0.44      0.50      0.47         8
weighted avg       0.77      0.88      0.82         8
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.01809722 0.         1.         0.55212352 0.
 0.         0.         1.         1.         0.53209433 0.
 0.         0.         0.50745563 0.         0.         0.95891551
 0.         0.64282366 0.23124387 0.20524281 0.         1.
 0.13421754 0.        ]
wv_ed shape (26,)
[0.         0.         0.         1.         0.60809324 0.
 0.         0.         1.         1.         0.1210926  0.
 0.         0.         0.23771433 0.02767231 0.01593202 0.8398684
 0.         0.86026813 0.30641279 0.         0.         1.
 0.17776755 0.        ]
wv_lg shape (26, 1)
[[0.33611383]
 [0.33627787]
 [0.33632933]
 [0.33623491]
 [0.33630661]
 [0.33632225]
 [0.33623306]
 [0.33611679]
 [0.3363049 ]
 [0.33628801]
 [0.33619148]
 [0.33619335]
 [0.33623828]
 [0.33623617]
 [0.33631137]
 [0.33637229]
 [0.33623893]
 [0.33624852]
 [0.33629799]
 [0.33621696]
 [0.33623872]
 [0.33622317]
 [0.33627417]
 [0.33630199]
 [0.33611976]
 [0.33629603]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.40328595 0.19030899 1.         1.         0.
 0.28844302 0.11853605 0.9854064  0.32885835 0.         0.57374547
 0.         0.34469981 0.         0.3877226  0.43549792 0.97732883
 0.         1.         0.42157413 0.         0.         1.
 1.         0.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.33611383 1.
  1.         0.         0.        ]
 [1.         0.         0.01809722 0.         0.33627787 1.
  0.         0.40328595 1.        ]
 [1.         0.         0.         0.         0.33632933 1.
  0.         0.19030899 1.        ]
 [1.         0.         1.         1.         0.33623491 1.
  0.         1.         1.        ]
 [1.         0.         0.55212352 0.60809324 0.33630661 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.33632225 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.33623306 1.
  0.         0.28844302 1.        ]
 [1.         0.         0.         0.         0.33611679 1.
  0.         0.11853605 1.        ]
 [1.         0.         1.         1.         0.3363049  1.
  0.         0.9854064  1.        ]
 [1.         0.         1.         1.         0.33628801 1.
  0.         0.32885835 1.        ]
 [1.         0.         0.53209433 0.1210926  0.33619148 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.33619335 1.
  0.         0.57374547 1.        ]
 [1.         0.         0.         0.         0.33623828 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.33623617 1.
  0.         0.34469981 1.        ]
 [1.         0.         0.50745563 0.23771433 0.33631137 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.02767231 0.33637229 1.
  0.         0.3877226  1.        ]
 [1.         0.         0.         0.01593202 0.33623893 1.
  0.         0.43549792 1.        ]
 [1.         0.         0.95891551 0.8398684  0.33624852 1.
  0.         0.97732883 1.        ]
 [1.         0.         0.         0.         0.33629799 1.
  0.         0.         1.        ]
 [1.         0.         0.64282366 0.86026813 0.33621696 1.
  0.         1.         1.        ]
 [1.         0.         0.23124387 0.30641279 0.33623872 1.
  0.         0.42157413 1.        ]
 [1.         0.         0.20524281 0.         0.33622317 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33627417 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.33630199 1.
  0.         1.         1.        ]
 [1.         0.         0.13421754 0.17776755 0.33611976 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.33629603 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.9375
#####################         POISON         ###############################################

############################################################################################

comm_round: 20 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.         1.         0.         0.40176902 1.
 0.         1.         0.42701674 1.         1.         0.
 1.         0.         1.         0.33894588 0.         1.
 1.         0.75643661 1.         0.27308073 0.         0.
 1.         0.12683903]
wv_ed shape (26,)
[0.         0.         0.56626567 0.         0.47213239 0.76548598
 0.         1.         0.31594957 1.         1.         0.
 0.61288064 0.         1.         0.2651376  0.         1.
 1.         0.71477261 1.         0.0148145  0.04439569 0.
 1.         0.        ]
wv_lg shape (26, 1)
[[0.33610841]
 [0.33642717]
 [0.33635516]
 [0.33640983]
 [0.33634777]
 [0.33644565]
 [0.33637233]
 [0.33639145]
 [0.33639753]
 [0.33635405]
 [0.33641913]
 [0.33637806]
 [0.33642486]
 [0.3363685 ]
 [0.33648409]
 [0.33634422]
 [0.33635853]
 [0.33633459]
 [0.33639982]
 [0.33644761]
 [0.33643631]
 [0.33647107]
 [0.33641645]
 [0.33640933]
 [0.33640404]
 [0.33642138]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.         0.61209592 0.59246493 0.99530088 0.0519818
 0.         1.         0.69644618 1.         0.70914492 0.51893894
 0.         0.         0.         0.56527379 0.         1.
 1.         0.87269022 0.8210153  0.         0.37435947 0.
 1.         0.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.33610841 1.
  1.         0.         0.        ]
 [1.         0.         0.         0.         0.33642717 1.
  0.         0.         1.        ]
 [1.         0.         1.         0.56626567 0.33635516 1.
  0.         0.61209592 1.        ]
 [1.         0.         0.         0.         0.33640983 1.
  0.         0.59246493 1.        ]
 [1.         0.         0.40176902 0.47213239 0.33634777 1.
  0.         0.99530088 1.        ]
 [1.         0.         1.         0.76548598 0.33644565 1.
  0.         0.0519818  1.        ]
 [1.         0.         0.         0.         0.33637233 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.33639145 1.
  0.         1.         1.        ]
 [1.         0.         0.42701674 0.31594957 0.33639753 1.
  0.         0.69644618 1.        ]
 [1.         0.         1.         1.         0.33635405 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.33641913 1.
  0.         0.70914492 1.        ]
 [1.         0.         0.         0.         0.33637806 1.
  0.         0.51893894 1.        ]
 [1.         0.         1.         0.61288064 0.33642486 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.3363685  1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.33648409 1.
  0.         0.         1.        ]
 [1.         0.         0.33894588 0.2651376  0.33634422 1.
  0.         0.56527379 1.        ]
 [1.         0.         0.         0.         0.33635853 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.33633459 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.33639982 1.
  0.         1.         1.        ]
 [1.         0.         0.75643661 0.71477261 0.33644761 1.
  0.         0.87269022 1.        ]
 [1.         0.         1.         1.         0.33643631 1.
  0.         0.8210153  1.        ]
 [1.         0.         0.27308073 0.0148145  0.33647107 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.04439569 0.33641645 1.
  0.         0.37435947 1.        ]
 [0.         0.         0.         0.         0.33640933 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.33640404 1.
  0.         1.         1.        ]
 [1.         0.         0.12683903 0.         0.33642138 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
1.0
#####################         POISON         ###############################################

############################################################################################

comm_round: 21 | global_test_acc: 87.500% | global_f1: 0.9333333333333333 | global_precision: 0.875
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.88      1.00      0.93         7

    accuracy                           0.88         8
   macro avg       0.44      0.50      0.47         8
weighted avg       0.77      0.88      0.82         8
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.         1.         0.         0.25177998 0.
 0.43773528 0.18481424 0.49788589 1.         0.         0.6684748
 0.7432017  0.         0.         0.20175702 1.         1.
 1.         1.         1.         0.         0.21231025 1.
 0.         1.        ]
wv_ed shape (26,)
[0.         0.         1.         0.         0.         0.
 0.56706887 0.         0.37122331 1.         0.         0.73464583
 0.74497616 0.         0.         0.         1.         1.
 1.         1.         1.         0.         0.17312416 1.
 0.         1.        ]
wv_lg shape (26, 1)
[[0.33625909]
 [0.33652681]
 [0.33656971]
 [0.33650821]
 [0.33648769]
 [0.33646379]
 [0.33666038]
 [0.33651299]
 [0.33655644]
 [0.33662384]
 [0.33647978]
 [0.33654017]
 [0.33655572]
 [0.33651518]
 [0.33654065]
 [0.33661956]
 [0.33652731]
 [0.33650383]
 [0.33653987]
 [0.33651809]
 [0.33647259]
 [0.33646997]
 [0.33651104]
 [0.33656923]
 [0.33651925]
 [0.33656864]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.         0.70035931 0.         0.         0.13641661
 0.         0.         0.8090831  0.         0.         0.44654228
 0.41297831 0.         0.         0.         1.         1.
 1.         1.         1.         0.         0.         1.
 0.15686833 0.82758286]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.33625909 1.
  1.         0.         0.        ]
 [1.         0.         0.         0.         0.33652681 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.33656971 1.
  0.         0.70035931 1.        ]
 [1.         0.         0.         0.         0.33650821 1.
  0.         0.         1.        ]
 [1.         0.         0.25177998 0.         0.33648769 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.33646379 1.
  0.         0.13641661 1.        ]
 [1.         0.         0.43773528 0.56706887 0.33666038 1.
  0.         0.         1.        ]
 [1.         0.         0.18481424 0.         0.33651299 1.
  0.         0.         1.        ]
 [1.         0.         0.49788589 0.37122331 0.33655644 1.
  0.         0.8090831  1.        ]
 [1.         0.         1.         1.         0.33662384 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.33647978 1.
  0.         0.         1.        ]
 [1.         0.         0.6684748  0.73464583 0.33654017 1.
  0.         0.44654228 1.        ]
 [1.         0.         0.7432017  0.74497616 0.33655572 1.
  0.         0.41297831 1.        ]
 [1.         0.         0.         0.         0.33651518 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33654065 1.
  0.         0.         1.        ]
 [1.         0.         0.20175702 0.         0.33661956 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.33652731 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.33650383 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.33653987 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.33651809 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.33647259 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.33646997 1.
  0.         0.         1.        ]
 [1.         0.         0.21231025 0.17312416 0.33651104 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.33656923 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.33651925 1.
  0.         0.15686833 1.        ]
 [1.         0.         1.         1.         0.33656864 1.
  0.         0.82758286 1.        ]]

Best Training Poisoning Accuracy:
0.9375
#####################         POISON         ###############################################

############################################################################################

comm_round: 22 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.24848071 0.         1.         0.9216004  0.
 0.79528289 0.0916168  1.         0.         0.         1.
 1.         0.6138812  1.         0.84433214 0.         1.
 0.82129598 1.         0.         1.         1.         0.69228414
 1.         1.        ]
wv_ed shape (26,)
[0.         0.0484654  0.         1.         0.8991257  0.
 0.68512007 0.         1.         0.         0.         1.
 1.         0.37001874 0.98595892 0.57468258 0.         1.
 0.72464029 1.         0.         1.         1.         0.33451022
 1.         1.        ]
wv_lg shape (26, 1)
[[0.33649732]
 [0.33675641]
 [0.33672703]
 [0.3366896 ]
 [0.33660366]
 [0.33669188]
 [0.33675912]
 [0.33668882]
 [0.33669581]
 [0.3366227 ]
 [0.33664794]
 [0.33664861]
 [0.33665462]
 [0.33676748]
 [0.33671006]
 [0.33670864]
 [0.33658505]
 [0.33666255]
 [0.33667627]
 [0.3366769 ]
 [0.33664384]
 [0.33663593]
 [0.33660224]
 [0.33673667]
 [0.33669676]
 [0.33663444]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.         0.         0.51877013 1.         0.
 0.05010645 0.         0.3069553  0.10019009 0.         1.
 0.36954698 0.         0.         0.         0.         0.20549856
 0.11569903 0.13719018 0.         0.20272988 1.         0.
 0.01225751 1.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.33649732 1.
  1.         0.         0.        ]
 [1.         0.         0.24848071 0.0484654  0.33675641 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33672703 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.3366896  1.
  0.         0.51877013 1.        ]
 [1.         0.         0.9216004  0.8991257  0.33660366 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.33669188 1.
  0.         0.         1.        ]
 [1.         0.         0.79528289 0.68512007 0.33675912 1.
  0.         0.05010645 1.        ]
 [1.         0.         0.0916168  0.         0.33668882 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.33669581 1.
  0.         0.3069553  1.        ]
 [1.         0.         0.         0.         0.3366227  1.
  0.         0.10019009 1.        ]
 [1.         0.         0.         0.         0.33664794 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.33664861 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.33665462 1.
  0.         0.36954698 1.        ]
 [1.         0.         0.6138812  0.37001874 0.33676748 1.
  0.         0.         1.        ]
 [1.         0.         1.         0.98595892 0.33671006 1.
  0.         0.         1.        ]
 [1.         0.         0.84433214 0.57468258 0.33670864 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.33658505 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.33666255 1.
  0.         0.20549856 1.        ]
 [1.         0.         0.82129598 0.72464029 0.33667627 1.
  0.         0.11569903 1.        ]
 [1.         0.         1.         1.         0.3366769  1.
  0.         0.13719018 1.        ]
 [1.         0.         0.         0.         0.33664384 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.33663593 1.
  0.         0.20272988 1.        ]
 [1.         0.         1.         1.         0.33660224 1.
  0.         1.         1.        ]
 [1.         0.         0.69228414 0.33451022 0.33673667 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.33669676 1.
  0.         0.01225751 1.        ]
 [1.         0.         1.         1.         0.33663444 1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.9375
#####################         POISON         ###############################################

############################################################################################

comm_round: 23 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.         1.         0.83558912 0.43045645 0.
 1.         0.22217721 1.         0.         0.2579016  0.26959585
 0.         0.         0.51328093 0.         0.         0.13445998
 1.         0.20855723 0.         0.45639868 1.         0.
 0.93539647 1.        ]
wv_ed shape (26,)
[0.         0.         1.         0.80538212 0.60509662 0.
 1.         0.17581836 1.         0.         0.58157279 0.72027592
 0.         0.         0.97762401 0.         0.         0.12616229
 1.         0.31105717 0.         0.42893217 1.         0.
 0.8708772  1.        ]
wv_lg shape (26, 1)
[[0.33651328]
 [0.33683426]
 [0.33680823]
 [0.33693232]
 [0.33669698]
 [0.33680939]
 [0.33675151]
 [0.33687452]
 [0.33674952]
 [0.33689132]
 [0.33687731]
 [0.33681467]
 [0.33688369]
 [0.33687168]
 [0.33683541]
 [0.33678246]
 [0.33679141]
 [0.33689007]
 [0.3368742 ]
 [0.3368683 ]
 [0.33683858]
 [0.33681644]
 [0.33677743]
 [0.33687883]
 [0.33681777]
 [0.3368989 ]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.58038088 0.9078798  0.12136929 1.         0.
 1.         0.         1.         0.         1.         0.98772672
 0.         0.         1.         0.22527318 1.         0.
 1.         0.28808207 0.         0.         1.         0.
 0.64995889 1.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.33651328 1.
  1.         0.         0.        ]
 [1.         0.         0.         0.         0.33683426 1.
  0.         0.58038088 1.        ]
 [1.         0.         1.         1.         0.33680823 1.
  0.         0.9078798  1.        ]
 [1.         0.         0.83558912 0.80538212 0.33693232 1.
  0.         0.12136929 1.        ]
 [1.         0.         0.43045645 0.60509662 0.33669698 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.33680939 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.33675151 1.
  0.         1.         1.        ]
 [1.         0.         0.22217721 0.17581836 0.33687452 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.33674952 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.33689132 1.
  0.         0.         1.        ]
 [1.         0.         0.2579016  0.58157279 0.33687731 1.
  0.         1.         1.        ]
 [1.         0.         0.26959585 0.72027592 0.33681467 1.
  0.         0.98772672 1.        ]
 [0.         0.         0.         0.         0.33688369 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.33687168 1.
  0.         0.         1.        ]
 [1.         0.         0.51328093 0.97762401 0.33683541 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.33678246 1.
  0.         0.22527318 1.        ]
 [1.         0.         0.         0.         0.33679141 1.
  0.         1.         1.        ]
 [1.         0.         0.13445998 0.12616229 0.33689007 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.3368742  1.
  0.         1.         1.        ]
 [1.         0.         0.20855723 0.31105717 0.3368683  1.
  0.         0.28808207 1.        ]
 [1.         0.         0.         0.         0.33683858 1.
  0.         0.         1.        ]
 [1.         0.         0.45639868 0.42893217 0.33681644 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.33677743 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.33687883 1.
  0.         0.         1.        ]
 [1.         0.         0.93539647 0.8708772  0.33681777 1.
  0.         0.64995889 1.        ]
 [1.         0.         1.         1.         0.3368989  1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.9375
#####################         POISON         ###############################################

############################################################################################

comm_round: 24 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.06443627 0.88115752 0.8819085  1.         0.
 0.52623441 1.         0.         0.         0.33384109 1.
 1.         0.         1.         0.06758232 0.         1.
 0.5959968  0.51321902 1.         1.         0.44847275 0.15383707
 1.         0.75667464]
wv_ed shape (26,)
[0.         0.         0.74708466 0.80513939 1.         0.
 0.60304869 1.         0.         0.         0.21646737 1.
 1.         0.         1.         0.         0.         1.
 0.34317524 0.20652483 1.         1.         0.35650796 0.23847101
 1.         0.69608862]
wv_lg shape (26, 1)
[[0.33663991]
 [0.33699512]
 [0.3369541 ]
 [0.33691286]
 [0.33700362]
 [0.33707057]
 [0.33692677]
 [0.33702883]
 [0.3369909 ]
 [0.33686675]
 [0.33689021]
 [0.33697825]
 [0.3369746 ]
 [0.33695772]
 [0.33693982]
 [0.33684118]
 [0.33696797]
 [0.33698226]
 [0.33702576]
 [0.33695078]
 [0.33694859]
 [0.33697959]
 [0.33701092]
 [0.3369833 ]
 [0.33695546]
 [0.33700621]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.         0.         0.40970921 1.         0.
 1.         1.         1.         0.         0.         1.
 0.         0.         1.         0.         0.         0.96605136
 0.         0.         0.6004081  0.39776214 0.         0.1399838
 1.         0.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.33663991 1.
  1.         0.         0.        ]
 [1.         0.         0.06443627 0.         0.33699512 1.
  0.         0.         1.        ]
 [1.         0.         0.88115752 0.74708466 0.3369541  1.
  0.         0.         1.        ]
 [1.         0.         0.8819085  0.80513939 0.33691286 1.
  0.         0.40970921 1.        ]
 [1.         0.         1.         1.         0.33700362 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.33707057 1.
  0.         0.         1.        ]
 [1.         0.         0.52623441 0.60304869 0.33692677 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.33702883 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.3369909  1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.33686675 1.
  0.         0.         1.        ]
 [1.         0.         0.33384109 0.21646737 0.33689021 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.33697825 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.3369746  1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.33695772 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.33693982 1.
  0.         1.         1.        ]
 [1.         0.         0.06758232 0.         0.33684118 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.33696797 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.33698226 1.
  0.         0.96605136 1.        ]
 [1.         0.         0.5959968  0.34317524 0.33702576 1.
  0.         0.         1.        ]
 [1.         0.         0.51321902 0.20652483 0.33695078 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.33694859 1.
  0.         0.6004081  1.        ]
 [1.         0.         1.         1.         0.33697959 1.
  0.         0.39776214 1.        ]
 [1.         0.         0.44847275 0.35650796 0.33701092 1.
  0.         0.         1.        ]
 [1.         0.         0.15383707 0.23847101 0.3369833  1.
  0.         0.1399838  1.        ]
 [1.         0.         1.         1.         0.33695546 1.
  0.         1.         1.        ]
 [1.         0.         0.75667464 0.69608862 0.33700621 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
1.0
#####################         POISON         ###############################################

############################################################################################

comm_round: 25 | global_test_acc: 87.500% | global_f1: 0.9333333333333333 | global_precision: 0.875
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.88      1.00      0.93         7

    accuracy                           0.88         8
   macro avg       0.44      0.50      0.47         8
weighted avg       0.77      0.88      0.82         8
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.         1.         0.         0.24820179 0.
 0.92132302 1.         1.         0.05168697 0.         0.
 1.         0.         1.         1.         1.         0.77368627
 0.62869694 1.         0.22475921 1.         1.         0.15259997
 0.25607196 0.53697828]
wv_ed shape (26,)
[0.         0.         1.         0.         0.         0.
 0.14980864 1.         1.         0.         0.         0.
 1.         0.         1.         1.         1.         0.59505322
 0.31740213 1.         0.21212602 1.         0.86003709 0.08438516
 0.         0.50370956]
wv_lg shape (26, 1)
[[0.3369764 ]
 [0.33717856]
 [0.33714635]
 [0.33708022]
 [0.33708534]
 [0.33707757]
 [0.33706201]
 [0.33704645]
 [0.33705679]
 [0.33700667]
 [0.33716038]
 [0.33714347]
 [0.33710433]
 [0.33705735]
 [0.33705973]
 [0.3371721 ]
 [0.33713132]
 [0.33707358]
 [0.33715138]
 [0.33712142]
 [0.33712317]
 [0.33713605]
 [0.33712755]
 [0.3371344 ]
 [0.33708199]
 [0.33708817]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.         0.         0.61029756 0.         0.
 0.         1.         1.         0.62033328 0.24070512 0.
 1.         0.         1.         0.63769116 0.97031975 0.49908217
 0.         0.80819232 0.4844676  1.         0.55608416 0.
 0.         0.63587478]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.3369764  1.
  1.         0.         0.        ]
 [1.         0.         0.         0.         0.33717856 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.33714635 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.33708022 1.
  0.         0.61029756 1.        ]
 [1.         0.         0.24820179 0.         0.33708534 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33707757 1.
  0.         0.         1.        ]
 [1.         0.         0.92132302 0.14980864 0.33706201 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.33704645 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.33705679 1.
  0.         1.         1.        ]
 [1.         0.         0.05168697 0.         0.33700667 1.
  0.         0.62033328 1.        ]
 [1.         0.         0.         0.         0.33716038 1.
  0.         0.24070512 1.        ]
 [1.         0.         0.         0.         0.33714347 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.33710433 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.33705735 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.33705973 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.3371721  1.
  0.         0.63769116 1.        ]
 [1.         0.         1.         1.         0.33713132 1.
  0.         0.97031975 1.        ]
 [1.         0.         0.77368627 0.59505322 0.33707358 1.
  0.         0.49908217 1.        ]
 [1.         0.         0.62869694 0.31740213 0.33715138 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.33712142 1.
  0.         0.80819232 1.        ]
 [1.         0.         0.22475921 0.21212602 0.33712317 1.
  0.         0.4844676  1.        ]
 [1.         0.         1.         1.         0.33713605 1.
  0.         1.         1.        ]
 [1.         0.         1.         0.86003709 0.33712755 1.
  0.         0.55608416 1.        ]
 [1.         0.         0.15259997 0.08438516 0.3371344  1.
  0.         0.         1.        ]
 [1.         0.         0.25607196 0.         0.33708199 1.
  0.         0.         1.        ]
 [1.         0.         0.53697828 0.50370956 0.33708817 1.
  0.         0.63587478 1.        ]]

Best Training Poisoning Accuracy:
0.9375
#####################         POISON         ###############################################

############################################################################################

comm_round: 26 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.87923238 1.         0.         0.26919568 1.
 0.57744528 0.         0.         0.94143328 0.         0.82888985
 1.         1.         1.         0.72215708 1.         0.
 0.         1.         1.         0.         1.         0.
 0.         1.        ]
wv_ed shape (26,)
[0.         0.78857096 1.         0.         0.47122805 1.
 0.49331972 0.         0.         0.92979891 0.         0.83363032
 1.         1.         1.         0.6812817  1.         0.
 0.         1.         0.97705183 0.         1.         0.
 0.         1.        ]
wv_lg shape (26, 1)
[[0.33712607]
 [0.33717697]
 [0.33733598]
 [0.33718877]
 [0.33732615]
 [0.33726206]
 [0.33727683]
 [0.33719331]
 [0.33719538]
 [0.3373266 ]
 [0.33721248]
 [0.3373279 ]
 [0.33730768]
 [0.33723578]
 [0.33718457]
 [0.33723559]
 [0.33729548]
 [0.33720285]
 [0.33727839]
 [0.33719954]
 [0.33723667]
 [0.33728821]
 [0.33724306]
 [0.3371379 ]
 [0.33730446]
 [0.33730498]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.09814278 1.         0.         0.         1.
 0.08985277 0.         0.         0.36070518 0.         0.
 0.29363106 0.         0.27236116 0.60846451 0.         0.
 0.         1.         0.37504645 0.         0.80141184 0.
 0.         1.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.33712607 1.
  1.         0.         0.        ]
 [1.         0.         0.87923238 0.78857096 0.33717697 1.
  0.         0.09814278 1.        ]
 [1.         0.         1.         1.         0.33733598 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.33718877 1.
  0.         0.         1.        ]
 [1.         0.         0.26919568 0.47122805 0.33732615 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.33726206 1.
  0.         1.         1.        ]
 [1.         0.         0.57744528 0.49331972 0.33727683 1.
  0.         0.08985277 1.        ]
 [1.         0.         0.         0.         0.33719331 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.33719538 1.
  0.         0.         1.        ]
 [1.         0.         0.94143328 0.92979891 0.3373266  1.
  0.         0.36070518 1.        ]
 [1.         0.         0.         0.         0.33721248 1.
  0.         0.         1.        ]
 [1.         0.         0.82888985 0.83363032 0.3373279  1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.33730768 1.
  0.         0.29363106 1.        ]
 [1.         0.         1.         1.         0.33723578 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.33718457 1.
  0.         0.27236116 1.        ]
 [1.         0.         0.72215708 0.6812817  0.33723559 1.
  0.         0.60846451 1.        ]
 [1.         0.         1.         1.         0.33729548 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.33720285 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.33727839 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.33719954 1.
  0.         1.         1.        ]
 [1.         0.         1.         0.97705183 0.33723667 1.
  0.         0.37504645 1.        ]
 [1.         0.         0.         0.         0.33728821 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.33724306 1.
  0.         0.80141184 1.        ]
 [0.         0.         0.         0.         0.3371379  1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.33730446 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.33730498 1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.9375
#####################         POISON         ###############################################

############################################################################################

comm_round: 27 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.         0.         0.         0.42422408 0.
 0.90407715 0.         1.         1.         0.28329287 1.
 0.         0.56876957 1.         0.         0.         0.
 0.         0.43551809 0.         0.23690035 1.         0.
 0.83664583 0.        ]
wv_ed shape (26,)
[0.         0.         0.         0.         0.11659235 0.
 1.         0.         1.         1.         0.         1.
 0.         0.61436285 1.         0.         0.         0.
 0.         0.13143458 0.         0.21111433 1.         0.
 0.49368255 0.        ]
wv_lg shape (26, 1)
[[0.33726123]
 [0.33739473]
 [0.33732759]
 [0.3374042 ]
 [0.33740649]
 [0.33740915]
 [0.33741808]
 [0.33741166]
 [0.33741859]
 [0.33748518]
 [0.33744592]
 [0.33744301]
 [0.33734129]
 [0.33743195]
 [0.33742081]
 [0.33746032]
 [0.33738009]
 [0.33736681]
 [0.33742672]
 [0.33729023]
 [0.33738954]
 [0.33728292]
 [0.33732183]
 [0.33737219]
 [0.3373775 ]
 [0.33736502]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.55814077 0.         0.70277329 0.10158997 0.49216536
 1.         0.05180623 1.         1.         0.40237083 1.
 0.         0.95511498 1.         0.         0.         0.
 0.         0.5103509  0.21190381 1.         1.         0.
 0.         0.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.33726123 1.
  1.         0.         0.        ]
 [1.         0.         0.         0.         0.33739473 1.
  0.         0.55814077 1.        ]
 [1.         0.         0.         0.         0.33732759 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.3374042  1.
  0.         0.70277329 1.        ]
 [1.         0.         0.42422408 0.11659235 0.33740649 1.
  0.         0.10158997 1.        ]
 [1.         0.         0.         0.         0.33740915 1.
  0.         0.49216536 1.        ]
 [1.         0.         0.90407715 1.         0.33741808 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.33741166 1.
  0.         0.05180623 1.        ]
 [1.         0.         1.         1.         0.33741859 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.33748518 1.
  0.         1.         1.        ]
 [1.         0.         0.28329287 0.         0.33744592 1.
  0.         0.40237083 1.        ]
 [1.         0.         1.         1.         0.33744301 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.33734129 1.
  0.         0.         1.        ]
 [1.         0.         0.56876957 0.61436285 0.33743195 1.
  0.         0.95511498 1.        ]
 [1.         0.         1.         1.         0.33742081 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.33746032 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.33738009 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33736681 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.33742672 1.
  0.         0.         1.        ]
 [1.         0.         0.43551809 0.13143458 0.33729023 1.
  0.         0.5103509  1.        ]
 [1.         0.         0.         0.         0.33738954 1.
  0.         0.21190381 1.        ]
 [1.         0.         0.23690035 0.21111433 0.33728292 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.33732183 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.33737219 1.
  0.         0.         1.        ]
 [1.         0.         0.83664583 0.49368255 0.3373775  1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.33736502 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.9375
#####################         POISON         ###############################################

############################################################################################

comm_round: 28 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.         1.         1.         0.9053696  1.
 1.         1.         0.84864617 0.62163066 1.         0.
 0.         0.58392707 0.81725129 0.23585834 1.         0.
 1.         0.44181918 0.04402021 0.62619231 0.1679654  0.48148436
 1.         0.76319578]
wv_ed shape (26,)
[0.         0.         1.         1.         1.         1.
 1.         1.         0.94054196 0.85250428 1.         0.
 0.         0.64423486 0.84316283 0.03656189 1.         0.
 1.         0.62514096 0.09642321 0.9126462  0.26916502 0.55482516
 1.         0.66940806]
wv_lg shape (26, 1)
[[0.33717936]
 [0.33752699]
 [0.33759827]
 [0.33755561]
 [0.3375614 ]
 [0.33760121]
 [0.33760753]
 [0.33760963]
 [0.3376395 ]
 [0.33753711]
 [0.33755974]
 [0.33752748]
 [0.33748651]
 [0.33757561]
 [0.33761138]
 [0.33750151]
 [0.33755077]
 [0.33746639]
 [0.33755398]
 [0.33750715]
 [0.33756787]
 [0.33755445]
 [0.33754639]
 [0.33755509]
 [0.33752769]
 [0.33756494]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.         1.         1.         1.         1.
 1.         0.77620759 0.72841268 1.         1.         0.
 0.         0.93547412 0.68667609 0.         1.         0.77154594
 1.         1.         0.26949737 1.         0.64279572 0.44611806
 1.         0.18050314]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.33717936 1.
  1.         0.         0.        ]
 [1.         0.         0.         0.         0.33752699 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.33759827 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.33755561 1.
  0.         1.         1.        ]
 [1.         0.         0.9053696  1.         0.3375614  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.33760121 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.33760753 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.33760963 1.
  0.         0.77620759 1.        ]
 [1.         0.         0.84864617 0.94054196 0.3376395  1.
  0.         0.72841268 1.        ]
 [1.         0.         0.62163066 0.85250428 0.33753711 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.33755974 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.33752748 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33748651 1.
  0.         0.         1.        ]
 [1.         0.         0.58392707 0.64423486 0.33757561 1.
  0.         0.93547412 1.        ]
 [1.         0.         0.81725129 0.84316283 0.33761138 1.
  0.         0.68667609 1.        ]
 [1.         0.         0.23585834 0.03656189 0.33750151 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.33755077 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.33746639 1.
  0.         0.77154594 1.        ]
 [1.         0.         1.         1.         0.33755398 1.
  0.         1.         1.        ]
 [1.         0.         0.44181918 0.62514096 0.33750715 1.
  0.         1.         1.        ]
 [1.         0.         0.04402021 0.09642321 0.33756787 1.
  0.         0.26949737 1.        ]
 [1.         0.         0.62619231 0.9126462  0.33755445 1.
  0.         1.         1.        ]
 [1.         0.         0.1679654  0.26916502 0.33754639 1.
  0.         0.64279572 1.        ]
 [1.         0.         0.48148436 0.55482516 0.33755509 1.
  0.         0.44611806 1.        ]
 [1.         0.         1.         1.         0.33752769 1.
  0.         1.         1.        ]
 [1.         0.         0.76319578 0.66940806 0.33756494 1.
  0.         0.18050314 1.        ]]

Best Training Poisoning Accuracy:
0.9375
#####################         POISON         ###############################################

############################################################################################

comm_round: 29 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients