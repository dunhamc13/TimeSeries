
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         1.         0.07958859 1.         0.         1.
 1.         1.         1.         0.80270021 0.97202388 0.33250929
 0.         0.         0.80752598 0.86490604 1.         1.
 0.         0.05007343 1.         0.96523581 0.         1.
 0.86240026 0.07331455]
wv_ed shape (26,)
[0.         1.         0.05870006 1.         0.         1.
 1.         1.         1.         0.68459991 0.91887848 0.41956921
 0.         0.         0.78306835 0.84063714 1.         1.
 0.         0.         1.         0.91694505 0.         1.
 0.78646202 0.0305306 ]
wv_lg shape (26, 1)
[[0.33657498]
 [0.23652555]
 [0.23699953]
 [0.23656874]
 [0.23837086]
 [0.23678154]
 [0.23467089]
 [0.23718865]
 [0.23555092]
 [0.2388362 ]
 [0.23644348]
 [0.23623417]
 [0.23282492]
 [0.23103915]
 [0.23825377]
 [0.23884025]
 [0.23765861]
 [0.23589607]
 [0.23674279]
 [0.23682075]
 [0.23633866]
 [0.23737107]
 [0.23594141]
 [0.23887533]
 [0.23778328]
 [0.23310651]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         1.         0.         1.         0.         1.
 1.         0.65046408 1.         0.55354618 1.         0.04909481
 0.         0.62265883 1.         0.71956306 1.         1.
 0.         0.05418226 1.         1.         0.         1.
 0.7680603  0.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.33657498 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.23652555 1.
  0.         1.         1.        ]
 [1.         0.         0.07958859 0.05870006 0.23699953 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.23656874 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.23837086 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.23678154 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.23467089 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.23718865 1.
  0.         0.65046408 1.        ]
 [1.         0.         1.         1.         0.23555092 1.
  0.         1.         1.        ]
 [1.         0.         0.80270021 0.68459991 0.2388362  1.
  0.         0.55354618 1.        ]
 [1.         0.         0.97202388 0.91887848 0.23644348 1.
  0.         1.         1.        ]
 [1.         0.         0.33250929 0.41956921 0.23623417 1.
  0.         0.04909481 1.        ]
 [1.         0.         0.         0.         0.23282492 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.23103915 1.
  0.         0.62265883 1.        ]
 [1.         0.         0.80752598 0.78306835 0.23825377 1.
  0.         1.         1.        ]
 [1.         0.         0.86490604 0.84063714 0.23884025 1.
  0.         0.71956306 1.        ]
 [1.         0.         1.         1.         0.23765861 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.23589607 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.23674279 1.
  0.         0.         1.        ]
 [1.         0.         0.05007343 0.         0.23682075 1.
  0.         0.05418226 1.        ]
 [1.         0.         1.         1.         0.23633866 1.
  0.         1.         1.        ]
 [1.         0.         0.96523581 0.91694505 0.23737107 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.23594141 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.23887533 1.
  0.         1.         1.        ]
 [1.         0.         0.86240026 0.78646202 0.23778328 1.
  0.         0.7680603  1.        ]
 [1.         0.         0.07331455 0.0305306  0.23310651 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
1.0
#####################         POISON         ###############################################

############################################################################################

comm_round: 0 | global_test_acc: 87.500% | global_f1: 0.9333333333333333 | global_precision: 0.875
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.88      1.00      0.93         7

    accuracy                           0.88         8
   macro avg       0.44      0.50      0.47         8
weighted avg       0.77      0.88      0.82         8

Accuracy per class:
[[7 0]
 [1 0]]
[1. 0.]
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         1.         1.         0.         1.         0.83682596
 1.         0.5077752  0.         1.         1.         1.
 0.         0.45464638 0.7831675  0.         0.60070947 1.
 0.73425523 0.07266153 0.88971161 1.         0.77448239 1.
 1.         1.        ]
wv_ed shape (26,)
[0.         1.         1.         0.         1.         0.55754391
 1.         0.35151496 0.         1.         0.90796789 1.
 0.         0.33942491 0.         0.         1.         1.
 0.16357822 0.         1.         1.         0.55708527 1.
 1.         0.84102271]
wv_lg shape (26, 1)
[[0.25097744]
 [0.21320323]
 [0.22078317]
 [0.20747398]
 [0.2254347 ]
 [0.21339408]
 [0.22404775]
 [0.21493682]
 [0.21507921]
 [0.20969598]
 [0.21434258]
 [0.2184682 ]
 [0.21751861]
 [0.21455982]
 [0.21106293]
 [0.21133122]
 [0.21826807]
 [0.21275155]
 [0.21141956]
 [0.21130718]
 [0.2246802 ]
 [0.22210287]
 [0.21573772]
 [0.22332957]
 [0.21797787]
 [0.20927935]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_std shape (26,)
[0.         0.         1.         0.         1.         0.
 1.         0.         0.         0.         0.19482386 0.75016168
 0.40995424 0.         0.         0.         0.38730962 0.
 0.         0.         1.         1.         0.36264392 1.
 1.         0.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.25097744 1.
  0.         0.         0.        ]
 [1.         0.         1.         1.         0.21320323 1.
  1.         0.         1.        ]
 [1.         0.         1.         1.         0.22078317 1.
  1.         1.         1.        ]
 [1.         0.         0.         0.         0.20747398 1.
  1.         0.         1.        ]
 [1.         0.         1.         1.         0.2254347  1.
  1.         1.         1.        ]
 [1.         0.         0.83682596 0.55754391 0.21339408 1.
  1.         0.         1.        ]
 [1.         0.         1.         1.         0.22404775 1.
  1.         1.         1.        ]
 [1.         0.         0.5077752  0.35151496 0.21493682 1.
  1.         0.         1.        ]
 [0.         0.         0.         0.         0.21507921 1.
  1.         0.         1.        ]
 [1.         0.         1.         1.         0.20969598 1.
  1.         0.         1.        ]
 [1.         0.         1.         0.90796789 0.21434258 1.
  1.         0.19482386 1.        ]
 [1.         0.         1.         1.         0.2184682  1.
  1.         0.75016168 1.        ]
 [1.         0.         0.         0.         0.21751861 1.
  1.         0.40995424 1.        ]
 [1.         0.         0.45464638 0.33942491 0.21455982 1.
  1.         0.         1.        ]
 [1.         0.         0.7831675  0.         0.21106293 1.
  1.         0.         1.        ]
 [1.         0.         0.         0.         0.21133122 1.
  1.         0.         1.        ]
 [1.         0.         0.60070947 1.         0.21826807 1.
  1.         0.38730962 1.        ]
 [1.         0.         1.         1.         0.21275155 1.
  1.         0.         1.        ]
 [1.         0.         0.73425523 0.16357822 0.21141956 1.
  1.         0.         1.        ]
 [1.         0.         0.07266153 0.         0.21130718 1.
  1.         0.         1.        ]
 [1.         0.         0.88971161 1.         0.2246802  1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.22210287 1.
  1.         1.         1.        ]
 [1.         0.         0.77448239 0.55708527 0.21573772 1.
  1.         0.36264392 1.        ]
 [1.         0.         1.         1.         0.22332957 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.21797787 1.
  1.         1.         1.        ]
 [1.         0.         1.         0.84102271 0.20927935 1.
  1.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.9166666865348816
#####################         POISON         ###############################################

############################################################################################

comm_round: 1 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8

Accuracy per class:
[[8 0]
 [0 0]]
[ 1. nan]
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.         0.         1.         0.         0.
 0.         0.6770727  0.49443924 0.         1.         0.24738685
 0.95101511 1.         0.99676534 0.85078259 1.         1.
 1.         0.42065966 0.         1.         1.         0.03204102
 0.16814426 0.34891925]
wv_ed shape (26,)
[0.         0.         0.         1.         0.         0.
 0.         0.39382931 0.11517795 0.         0.68734445 0.
 0.13302325 1.         0.73655447 1.         1.         1.
 1.         0.29013045 0.         1.         1.         0.
 0.         0.1922842 ]
wv_lg shape (26, 1)
[[0.21985325]
 [0.22858779]
 [0.23238024]
 [0.23067164]
 [0.22760569]
 [0.23265776]
 [0.22980462]
 [0.23019445]
 [0.2316858 ]
 [0.22944491]
 [0.23171901]
 [0.22916191]
 [0.23200058]
 [0.22721031]
 [0.2316899 ]
 [0.22844889]
 [0.22795565]
 [0.22848427]
 [0.23006455]
 [0.22934318]
 [0.23299935]
 [0.22808004]
 [0.22891952]
 [0.22719679]
 [0.23013713]
 [0.22835605]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[0.         1.         1.         0.         1.         0.87708394
 1.         0.25278573 0.72822782 1.         0.         1.
 1.         1.         0.         0.69396609 1.         0.
 0.         1.         1.         1.         0.         1.
 1.         1.        ]
wv_std shape (26,)
[0.         1.         0.         0.28304653 1.         0.
 0.         1.         0.05703134 0.         1.         0.
 0.         1.         0.         1.         0.81740984 0.24836309
 0.61318899 0.         0.         1.         1.         1.
 0.         1.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.21985325 1.
  0.         0.         0.        ]
 [1.         0.         0.         0.         0.22858779 1.
  1.         1.         1.        ]
 [0.         0.         0.         0.         0.23238024 1.
  1.         0.         1.        ]
 [1.         0.         1.         1.         0.23067164 1.
  0.         0.28304653 1.        ]
 [1.         0.         0.         0.         0.22760569 1.
  1.         1.         1.        ]
 [1.         0.         0.         0.         0.23265776 1.
  0.87708394 0.         1.        ]
 [1.         0.         0.         0.         0.22980462 1.
  1.         0.         1.        ]
 [1.         0.         0.6770727  0.39382931 0.23019445 1.
  0.25278573 1.         1.        ]
 [1.         0.         0.49443924 0.11517795 0.2316858  1.
  0.72822782 0.05703134 1.        ]
 [1.         0.         0.         0.         0.22944491 1.
  1.         0.         1.        ]
 [1.         0.         1.         0.68734445 0.23171901 1.
  0.         1.         1.        ]
 [1.         0.         0.24738685 0.         0.22916191 1.
  1.         0.         1.        ]
 [1.         0.         0.95101511 0.13302325 0.23200058 1.
  1.         0.         1.        ]
 [1.         0.         1.         1.         0.22721031 1.
  1.         1.         1.        ]
 [1.         0.         0.99676534 0.73655447 0.2316899  1.
  0.         0.         1.        ]
 [1.         0.         0.85078259 1.         0.22844889 1.
  0.69396609 1.         1.        ]
 [1.         0.         1.         1.         0.22795565 1.
  1.         0.81740984 1.        ]
 [1.         0.         1.         1.         0.22848427 1.
  0.         0.24836309 1.        ]
 [1.         0.         1.         1.         0.23006455 1.
  0.         0.61318899 1.        ]
 [1.         0.         0.42065966 0.29013045 0.22934318 1.
  1.         0.         1.        ]
 [1.         0.         0.         0.         0.23299935 1.
  1.         0.         1.        ]
 [1.         0.         1.         1.         0.22808004 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.22891952 1.
  0.         1.         1.        ]
 [1.         0.         0.03204102 0.         0.22719679 1.
  1.         1.         1.        ]
 [1.         0.         0.16814426 0.         0.23013713 1.
  1.         0.         1.        ]
 [1.         0.         0.34891925 0.1922842  0.22835605 1.
  1.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.9166666865348816
#####################         POISON         ###############################################

############################################################################################

comm_round: 2 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8

Accuracy per class:
[[8 0]
 [0 0]]
[ 1. nan]
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0.         1.         1.         1.         1.         0.
 1.         1.         1.         1.         1.         0.98319985
 1.         1.         1.         0.         0.         1.
 0.         1.         1.         1.         1.         1.
 1.         1.        ]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.         0.         0.43918088 0.         1.
 0.         0.         0.39624994 0.53303474 0.17062096 1.
 0.         0.58276595 0.         1.         0.         1.
 1.         1.         1.         1.         0.48620054 1.
 0.64588852 0.31004439]
wv_ed shape (26,)
[0.         0.         0.         0.75254861 0.         1.
 0.         0.         0.46316496 0.71215736 0.         1.
 0.         0.075097   0.         1.         0.         1.
 1.         0.74069845 1.         1.         0.69619138 1.
 0.21328672 0.6460094 ]
wv_lg shape (26, 1)
[[0.22475203]
 [0.22580497]
 [0.22780474]
 [0.22955283]
 [0.23200958]
 [0.22662701]
 [0.22946767]
 [0.22603708]
 [0.22749295]
 [0.22770637]
 [0.22854405]
 [0.2300994 ]
 [0.2275229 ]
 [0.22500061]
 [0.23105883]
 [0.22370422]
 [0.23355623]
 [0.22715039]
 [0.2255538 ]
 [0.22372465]
 [0.23194488]
 [0.22616304]
 [0.23220954]
 [0.23064063]
 [0.22407756]
 [0.22760554]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[0.         0.50117418 0.18434267 0.         0.         0.
 0.02088526 1.         0.         0.         0.         0.
 1.         1.         0.         0.         0.70111747 0.
 0.         1.         0.         1.         0.         0.
 1.         0.        ]
wv_std shape (26,)
[0.         1.         0.80236112 0.59646681 0.         0.
 0.         1.         1.         1.         1.         0.2215626
 0.35747892 1.         0.39212178 1.         0.         1.
 1.         1.         0.97726107 1.         0.         1.
 1.         1.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.22475203 1.
  0.         0.         0.        ]
 [1.         0.         0.         0.         0.22580497 1.
  0.50117418 1.         1.        ]
 [1.         0.         0.         0.         0.22780474 1.
  0.18434267 0.80236112 1.        ]
 [1.         0.         0.43918088 0.75254861 0.22955283 1.
  0.         0.59646681 1.        ]
 [1.         0.         0.         0.         0.23200958 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.22662701 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.22946767 1.
  0.02088526 0.         1.        ]
 [1.         0.         0.         0.         0.22603708 1.
  1.         1.         1.        ]
 [1.         0.         0.39624994 0.46316496 0.22749295 1.
  0.         1.         1.        ]
 [1.         0.         0.53303474 0.71215736 0.22770637 1.
  0.         1.         1.        ]
 [1.         0.         0.17062096 0.         0.22854405 1.
  0.         1.         1.        ]
 [0.98319985 0.         1.         1.         0.2300994  1.
  0.         0.2215626  1.        ]
 [1.         0.         0.         0.         0.2275229  1.
  1.         0.35747892 1.        ]
 [1.         0.         0.58276595 0.075097   0.22500061 1.
  1.         1.         1.        ]
 [1.         0.         0.         0.         0.23105883 1.
  0.         0.39212178 1.        ]
 [0.         0.         1.         1.         0.22370422 1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.23355623 1.
  0.70111747 0.         1.        ]
 [1.         0.         1.         1.         0.22715039 1.
  0.         1.         1.        ]
 [0.         0.         1.         1.         0.2255538  1.
  0.         1.         1.        ]
 [1.         0.         1.         0.74069845 0.22372465 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.23194488 1.
  0.         0.97726107 1.        ]
 [1.         0.         1.         1.         0.22616304 1.
  1.         1.         1.        ]
 [1.         0.         0.48620054 0.69619138 0.23220954 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.23064063 1.
  0.         1.         1.        ]
 [1.         0.         0.64588852 0.21328672 0.22407756 1.
  1.         1.         1.        ]
 [1.         0.         0.31004439 0.6460094  0.22760554 1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
1.0
#####################         POISON         ###############################################

############################################################################################

comm_round: 3 | global_test_acc: 87.500% | global_f1: 0.9333333333333333 | global_precision: 0.875
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.88      1.00      0.93         7

    accuracy                           0.88         8
   macro avg       0.44      0.50      0.47         8
weighted avg       0.77      0.88      0.82         8

Accuracy per class:
[[7 0]
 [1 0]]
[1. 0.]
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         1.         0.         1.         0.53285432 1.
 1.         1.         0.4061011  0.81106371 1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
wv_ed shape (26,)
[0.         1.         0.         0.69182498 0.         1.
 1.         1.         0.49292749 1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.31825072 1.
 1.         1.        ]
wv_lg shape (26, 1)
[[0.2298688 ]
 [0.22790959]
 [0.22398081]
 [0.22444959]
 [0.2272224 ]
 [0.22880045]
 [0.22784474]
 [0.22796726]
 [0.2273639 ]
 [0.22431027]
 [0.22946452]
 [0.22941738]
 [0.22886879]
 [0.22926222]
 [0.22910833]
 [0.23039152]
 [0.22927517]
 [0.22743817]
 [0.2283193 ]
 [0.23047239]
 [0.22821848]
 [0.22772049]
 [0.22869124]
 [0.22821143]
 [0.22887084]
 [0.23082745]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[0.         0.         0.         0.         1.         0.
 0.         0.         0.         0.         0.86114454 1.
 0.55662347 0.         1.         1.         0.16306557 0.50460323
 0.48731042 0.         1.         0.         0.         0.
 0.         0.69959065]
wv_std shape (26,)
[1.         0.70990591 1.         0.         0.46915289 0.
 1.         1.         1.         0.93642173 0.         0.
 1.         1.         0.         0.635459   0.87899296 1.
 1.         1.         1.         1.         1.         1.
 1.         0.04454831]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.2298688  1.
  0.         1.         0.        ]
 [1.         0.         1.         1.         0.22790959 1.
  0.         0.70990591 1.        ]
 [1.         0.         0.         0.         0.22398081 1.
  0.         1.         1.        ]
 [0.         0.         1.         0.69182498 0.22444959 1.
  0.         0.         1.        ]
 [1.         0.         0.53285432 0.         0.2272224  1.
  1.         0.46915289 1.        ]
 [1.         0.         1.         1.         0.22880045 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.22784474 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.22796726 1.
  0.         1.         1.        ]
 [1.         0.         0.4061011  0.49292749 0.2273639  1.
  0.         1.         1.        ]
 [1.         0.         0.81106371 1.         0.22431027 1.
  0.         0.93642173 1.        ]
 [1.         0.         1.         1.         0.22946452 1.
  0.86114454 0.         1.        ]
 [1.         0.         1.         1.         0.22941738 1.
  1.         0.         1.        ]
 [1.         0.         1.         1.         0.22886879 1.
  0.55662347 1.         1.        ]
 [1.         0.         1.         1.         0.22926222 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.22910833 1.
  1.         0.         1.        ]
 [1.         0.         1.         1.         0.23039152 1.
  1.         0.635459   1.        ]
 [1.         0.         1.         1.         0.22927517 1.
  0.16306557 0.87899296 1.        ]
 [1.         0.         1.         1.         0.22743817 1.
  0.50460323 1.         1.        ]
 [1.         0.         1.         1.         0.2283193  1.
  0.48731042 1.         1.        ]
 [1.         0.         1.         1.         0.23047239 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.22821848 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.22772049 1.
  0.         1.         1.        ]
 [1.         0.         1.         0.31825072 0.22869124 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.22821143 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.22887084 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.23082745 1.
  0.69959065 0.04454831 1.        ]]

Best Training Poisoning Accuracy:
1.0
#####################         POISON         ###############################################

############################################################################################

comm_round: 4 | global_test_acc: 87.500% | global_f1: 0.9333333333333333 | global_precision: 0.875
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.88      1.00      0.93         7

    accuracy                           0.88         8
   macro avg       0.44      0.50      0.47         8
weighted avg       0.77      0.88      0.82         8

Accuracy per class:
[[7 0]
 [1 0]]
[1. 0.]
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.         1.         1.         0.         1.
 0.03949191 1.         1.         0.         1.         1.
 1.         0.         1.         0.65913886 1.         1.
 0.33906218 1.         1.         1.         0.         1.
 0.         1.        ]
wv_ed shape (26,)
[0.         0.         1.         1.         1.         1.
 1.         1.         1.         0.         1.         1.
 1.         0.93939777 1.         1.         1.         1.
 0.22359967 1.         1.         1.         0.08578722 1.
 0.44348488 1.        ]
wv_lg shape (26, 1)
[[0.22511848]
 [0.2229647 ]
 [0.22723373]
 [0.22446871]
 [0.22703684]
 [0.2282204 ]
 [0.22381858]
 [0.22856419]
 [0.22681519]
 [0.22295291]
 [0.22851577]
 [0.22390972]
 [0.2244415 ]
 [0.22678478]
 [0.22443663]
 [0.22596223]
 [0.22833361]
 [0.22974059]
 [0.22337986]
 [0.22858229]
 [0.22828045]
 [0.22699244]
 [0.23116222]
 [0.22722919]
 [0.22465587]
 [0.2256534 ]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[0.         1.         0.         1.         1.         1.
 0.03088817 1.         0.34865008 1.         0.11891732 0.80800542
 1.         0.         0.56160523 0.         0.         1.
 1.         0.81940811 1.         1.         0.85390398 1.
 0.95039613 1.        ]
wv_std shape (26,)
[0.         0.75781338 1.         1.         0.41648264 1.
 1.         1.         1.         1.         1.         0.
 0.         1.         0.         1.         1.         0.54099221
 0.04819293 1.         0.87564933 0.         0.         1.
 1.         1.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.22511848 1.
  0.         0.         0.        ]
 [1.         0.         0.         0.         0.2229647  1.
  1.         0.75781338 1.        ]
 [1.         0.         1.         1.         0.22723373 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.22446871 1.
  1.         1.         1.        ]
 [1.         0.         0.         1.         0.22703684 1.
  1.         0.41648264 1.        ]
 [1.         0.         1.         1.         0.2282204  1.
  1.         1.         1.        ]
 [1.         0.         0.03949191 1.         0.22381858 1.
  0.03088817 1.         1.        ]
 [1.         0.         1.         1.         0.22856419 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.22681519 1.
  0.34865008 1.         1.        ]
 [1.         0.         0.         0.         0.22295291 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.22851577 1.
  0.11891732 1.         1.        ]
 [1.         0.         1.         1.         0.22390972 1.
  0.80800542 0.         1.        ]
 [1.         0.         1.         1.         0.2244415  1.
  1.         0.         1.        ]
 [1.         0.         0.         0.93939777 0.22678478 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.22443663 1.
  0.56160523 0.         1.        ]
 [1.         0.         0.65913886 1.         0.22596223 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.22833361 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.22974059 1.
  1.         0.54099221 1.        ]
 [1.         0.         0.33906218 0.22359967 0.22337986 1.
  1.         0.04819293 1.        ]
 [1.         0.         1.         1.         0.22858229 1.
  0.81940811 1.         1.        ]
 [1.         0.         1.         1.         0.22828045 1.
  1.         0.87564933 1.        ]
 [1.         0.         1.         1.         0.22699244 1.
  1.         0.         1.        ]
 [0.         0.         0.         0.08578722 0.23116222 1.
  0.85390398 0.         1.        ]
 [1.         0.         1.         1.         0.22722919 1.
  1.         1.         1.        ]
 [1.         0.         0.         0.44348488 0.22465587 1.
  0.95039613 1.         1.        ]
 [1.         0.         1.         1.         0.2256534  1.
  1.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.9166666865348816
#####################         POISON         ###############################################

############################################################################################

comm_round: 5 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8

Accuracy per class:
[[8 0]
 [0 0]]
[ 1. nan]
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0.
 0. 0.]
wv_fg shape (26,)
[1.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.30874787 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.        ]
wv_mn shape (26,)
[0.         0.         1.         0.86359877 0.86219673 0.
 0.         1.         0.72478944 0.42710117 1.         1.
 1.         1.         1.         1.         0.70514426 1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
wv_ed shape (26,)
[0.         0.         1.         1.         1.         0.49149895
 0.         1.         0.         0.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
wv_lg shape (26, 1)
[[0.22388484]
 [0.22663874]
 [0.22623401]
 [0.22613561]
 [0.22716384]
 [0.222492  ]
 [0.22607322]
 [0.22717203]
 [0.22379206]
 [0.22406203]
 [0.22213566]
 [0.22699401]
 [0.22065083]
 [0.22692163]
 [0.22604167]
 [0.22072874]
 [0.22188297]
 [0.2269554 ]
 [0.22207389]
 [0.22607365]
 [0.22710722]
 [0.2244466 ]
 [0.22720566]
 [0.22369909]
 [0.22430672]
 [0.22616074]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[0.         0.         0.         0.         0.         0.
 0.         0.26285079 1.         1.         0.         0.
 0.         0.33180467 0.         0.         0.         0.84678226
 0.         1.         1.         0.         0.         0.
 0.         0.        ]
wv_std shape (26,)
[0.         0.         0.         1.         0.         1.
 0.         0.58064932 0.         0.         1.         0.
 1.         0.         0.39113098 1.         0.36990792 0.41673728
 0.92495666 0.         0.         0.33538463 0.         1.
 1.         1.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.22388484 1.
  0.         0.         0.        ]
 [1.         0.         0.         0.         0.22663874 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.22623401 1.
  0.         0.         1.        ]
 [1.         0.         0.86359877 1.         0.22613561 1.
  0.         1.         1.        ]
 [1.         0.         0.86219673 1.         0.22716384 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.49149895 0.222492   1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.22607322 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.22717203 1.
  0.26285079 0.58064932 1.        ]
 [1.         0.         0.72478944 0.         0.22379206 1.
  1.         0.         1.        ]
 [1.         0.         0.42710117 0.         0.22406203 1.
  1.         0.         1.        ]
 [0.         0.         1.         1.         0.22213566 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.22699401 1.
  0.         0.         1.        ]
 [0.         0.30874787 1.         1.         0.22065083 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.22692163 1.
  0.33180467 0.         1.        ]
 [0.         0.         1.         1.         0.22604167 1.
  0.         0.39113098 1.        ]
 [0.         0.         1.         1.         0.22072874 1.
  0.         1.         1.        ]
 [1.         0.         0.70514426 1.         0.22188297 1.
  0.         0.36990792 1.        ]
 [0.         0.         1.         1.         0.2269554  1.
  0.84678226 0.41673728 1.        ]
 [0.         0.         1.         1.         0.22207389 1.
  0.         0.92495666 1.        ]
 [1.         0.         1.         1.         0.22607365 1.
  1.         0.         1.        ]
 [0.         0.         1.         1.         0.22710722 1.
  1.         0.         1.        ]
 [0.         0.         1.         1.         0.2244466  1.
  0.         0.33538463 1.        ]
 [1.         0.         1.         1.         0.22720566 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.22369909 1.
  0.         1.         1.        ]
 [0.         0.         1.         1.         0.22430672 1.
  0.         1.         1.        ]
 [0.         0.         1.         1.         0.22616074 1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.9166666865348816
#####################         POISON         ###############################################

############################################################################################

comm_round: 6 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8

Accuracy per class:
[[8 0]
 [0 0]]
[ 1. nan]
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0.         1.         1.         1.         1.         1.
 1.         1.         1.         0.         1.         1.
 1.         1.         1.         1.         1.         1.
 0.81771666 1.         1.         0.75386659 1.         1.
 1.         1.        ]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.         1.         1.         0.         1.
 0.12643368 0.         0.70197133 0.         0.         0.30810858
 1.         0.         1.         0.         1.         0.
 1.         1.         0.         1.         1.         0.66214806
 1.         0.        ]
wv_ed shape (26,)
[0.         0.         1.         1.         0.         1.
 0.         0.         0.76138466 0.         0.         0.48176944
 1.         0.         1.         0.         0.23534967 0.
 1.         1.         0.         1.         1.         0.41295894
 1.         0.        ]
wv_lg shape (26, 1)
[[0.22408096]
 [0.22516748]
 [0.2268843 ]
 [0.22711796]
 [0.22564487]
 [0.2220458 ]
 [0.22631177]
 [0.22717866]
 [0.22639923]
 [0.22665993]
 [0.22627798]
 [0.22599755]
 [0.22834314]
 [0.22500371]
 [0.22621991]
 [0.22635173]
 [0.22684427]
 [0.22673857]
 [0.22401495]
 [0.2246079 ]
 [0.22598981]
 [0.2266309 ]
 [0.22225733]
 [0.22775516]
 [0.22603267]
 [0.22365448]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1.         0.         0.         0.96652826 0.         0.
 1.         1.         0.         0.         0.02635929 0.
 0.14241862 0.78382763 0.         1.         0.         0.
 0.         0.         0.         1.         0.         0.24196046
 0.173708   0.02672477]
wv_std shape (26,)
[0.         0.91366872 1.         1.         0.77425318 1.
 0.         0.         1.         0.         0.         1.
 0.         0.71849882 1.         0.41567919 1.         0.
 1.         1.         0.05093822 1.         1.         0.85167429
 1.         0.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.22408096 1.
  1.         0.         0.        ]
 [1.         0.         0.         0.         0.22516748 1.
  0.         0.91366872 1.        ]
 [1.         0.         1.         1.         0.2268843  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.22711796 1.
  0.96652826 1.         1.        ]
 [1.         0.         0.         0.         0.22564487 1.
  0.         0.77425318 1.        ]
 [1.         0.         1.         1.         0.2220458  1.
  0.         1.         1.        ]
 [1.         0.         0.12643368 0.         0.22631177 1.
  1.         0.         1.        ]
 [1.         0.         0.         0.         0.22717866 1.
  1.         0.         1.        ]
 [1.         0.         0.70197133 0.76138466 0.22639923 1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.22665993 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.22627798 1.
  0.02635929 0.         1.        ]
 [1.         0.         0.30810858 0.48176944 0.22599755 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.22834314 1.
  0.14241862 0.         1.        ]
 [1.         0.         0.         0.         0.22500371 1.
  0.78382763 0.71849882 1.        ]
 [1.         0.         1.         1.         0.22621991 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.22635173 1.
  1.         0.41567919 1.        ]
 [1.         0.         1.         0.23534967 0.22684427 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.22673857 1.
  0.         0.         1.        ]
 [0.81771666 0.         1.         1.         0.22401495 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.2246079  1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.22598981 1.
  0.         0.05093822 1.        ]
 [0.75386659 0.         1.         1.         0.2266309  1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.22225733 1.
  0.         1.         1.        ]
 [1.         0.         0.66214806 0.41295894 0.22775516 1.
  0.24196046 0.85167429 1.        ]
 [1.         0.         1.         1.         0.22603267 1.
  0.173708   1.         1.        ]
 [1.         0.         0.         0.         0.22365448 1.
  0.02672477 0.         1.        ]]

Best Training Poisoning Accuracy:
1.0
#####################         POISON         ###############################################

############################################################################################

comm_round: 7 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8

Accuracy per class:
[[8 0]
 [0 0]]
[ 1. nan]
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0.         1.         1.         1.         1.         1.
 1.         1.         0.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 0.         1.         0.         0.         1.         0.02125019
 1.         1.        ]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         1.         0.55448945 1.         0.         0.27327137
 0.41031122 0.15625742 0.         0.         1.         0.
 0.19993859 0.         0.68214707 0.         1.         1.
 1.         1.         1.         1.         0.04864278 1.
 1.         0.53813226]
wv_ed shape (26,)
[0.         1.         0.59182895 0.92797224 0.         0.33639445
 0.41642253 0.21204804 0.         0.         1.         0.
 0.40277365 0.         1.         0.         1.         1.
 1.         1.         1.         1.         0.21077257 1.
 1.         0.39232693]
wv_lg shape (26, 1)
[[0.22016857]
 [0.22799975]
 [0.22621919]
 [0.22799269]
 [0.22746297]
 [0.22596783]
 [0.22087314]
 [0.22486237]
 [0.22510412]
 [0.22548139]
 [0.22646136]
 [0.22481345]
 [0.22356713]
 [0.22367692]
 [0.22317283]
 [0.22162918]
 [0.22262257]
 [0.22661755]
 [0.22258095]
 [0.22667922]
 [0.22575875]
 [0.2245537 ]
 [0.22335459]
 [0.22417573]
 [0.22329489]
 [0.22336157]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1.         1.         0.         0.43009154 0.         1.
 0.         1.         0.29470415 0.         1.         0.36013122
 0.         0.         0.         0.06947567 0.0330262  1.
 0.         0.         1.         0.02256421 0.         0.09461316
 0.         0.        ]
wv_std shape (26,)
[0.         0.         0.38500257 0.         0.         0.
 1.         0.         0.         0.         0.         0.32165247
 0.         0.         0.17226931 0.49936977 0.5394148  0.4779332
 1.         0.46225407 1.         1.         0.         0.76187792
 0.         1.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.22016857 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.22799975 1.
  1.         0.         1.        ]
 [1.         0.         0.55448945 0.59182895 0.22621919 1.
  0.         0.38500257 1.        ]
 [1.         0.         1.         0.92797224 0.22799269 1.
  0.43009154 0.         1.        ]
 [1.         0.         0.         0.         0.22746297 1.
  0.         0.         1.        ]
 [1.         0.         0.27327137 0.33639445 0.22596783 1.
  1.         0.         1.        ]
 [1.         0.         0.41031122 0.41642253 0.22087314 1.
  0.         1.         1.        ]
 [1.         0.         0.15625742 0.21204804 0.22486237 1.
  1.         0.         1.        ]
 [0.         0.         0.         0.         0.22510412 1.
  0.29470415 0.         1.        ]
 [1.         0.         0.         0.         0.22548139 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.22646136 1.
  1.         0.         1.        ]
 [1.         0.         0.         0.         0.22481345 1.
  0.36013122 0.32165247 1.        ]
 [1.         0.         0.19993859 0.40277365 0.22356713 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.22367692 1.
  0.         0.         1.        ]
 [1.         0.         0.68214707 1.         0.22317283 1.
  0.         0.17226931 1.        ]
 [1.         0.         0.         0.         0.22162918 1.
  0.06947567 0.49936977 1.        ]
 [1.         0.         1.         1.         0.22262257 1.
  0.0330262  0.5394148  1.        ]
 [1.         0.         1.         1.         0.22661755 1.
  1.         0.4779332  1.        ]
 [0.         0.         1.         1.         0.22258095 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.22667922 1.
  0.         0.46225407 1.        ]
 [0.         0.         1.         1.         0.22575875 1.
  1.         1.         1.        ]
 [0.         0.         1.         1.         0.2245537  1.
  0.02256421 1.         1.        ]
 [1.         0.         0.04864278 0.21077257 0.22335459 1.
  0.         0.         1.        ]
 [0.02125019 0.         1.         1.         0.22417573 1.
  0.09461316 0.76187792 1.        ]
 [1.         0.         1.         1.         0.22329489 1.
  0.         0.         1.        ]
 [1.         0.         0.53813226 0.39232693 0.22336157 1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
1.0
#####################         POISON         ###############################################

############################################################################################

comm_round: 8 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8

Accuracy per class:
[[8 0]
 [0 0]]
[ 1. nan]
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.         1.         0.         0.94835247 0.32079982
 0.16046728 0.         1.         0.82526197 0.         1.
 1.         1.         1.         0.53537365 0.3426142  1.
 1.         0.79083138 0.         0.         1.         0.77514563
 1.         1.        ]
wv_ed shape (26,)
[0.         0.         0.79577728 0.         0.99911039 0.84965781
 0.         0.         0.79500025 0.59624614 0.         1.
 1.         1.         0.79109487 0.7378927  0.         1.
 1.         0.67654585 0.         0.27502723 1.         1.
 1.         1.        ]
wv_lg shape (26, 1)
[[0.22155022]
 [0.22704397]
 [0.22453106]
 [0.22414093]
 [0.22632297]
 [0.22717911]
 [0.22664762]
 [0.22750524]
 [0.22701821]
 [0.22682707]
 [0.22582944]
 [0.22659758]
 [0.22508183]
 [0.22692693]
 [0.22405846]
 [0.22629609]
 [0.22741679]
 [0.22700366]
 [0.22884398]
 [0.2238498 ]
 [0.22689127]
 [0.22392637]
 [0.227222  ]
 [0.22569791]
 [0.22730312]
 [0.22655483]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1.         1.         1.         0.72656035 0.         0.
 1.         1.         0.42451327 1.         0.         0.00745655
 0.10744146 0.15142013 1.         0.         1.         0.30437644
 0.14102507 0.44808279 0.         0.48007208 0.         0.03627159
 0.         0.8722193 ]
wv_std shape (26,)
[0.         0.         1.         0.         1.         0.
 0.         0.         0.75447355 0.         0.         0.95870216
 0.50475609 0.11081626 0.         0.54095005 0.         1.
 0.         1.         0.         0.16790148 0.43473178 1.
 1.         1.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.22155022 1.
  1.         0.         0.        ]
 [1.         0.         0.         0.         0.22704397 1.
  1.         0.         1.        ]
 [1.         0.         1.         0.79577728 0.22453106 1.
  1.         1.         1.        ]
 [1.         0.         0.         0.         0.22414093 1.
  0.72656035 0.         1.        ]
 [1.         0.         0.94835247 0.99911039 0.22632297 1.
  0.         1.         1.        ]
 [1.         0.         0.32079982 0.84965781 0.22717911 1.
  0.         0.         1.        ]
 [1.         0.         0.16046728 0.         0.22664762 1.
  1.         0.         1.        ]
 [1.         0.         0.         0.         0.22750524 1.
  1.         0.         1.        ]
 [1.         0.         1.         0.79500025 0.22701821 1.
  0.42451327 0.75447355 1.        ]
 [1.         0.         0.82526197 0.59624614 0.22682707 1.
  1.         0.         1.        ]
 [0.         0.         0.         0.         0.22582944 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.22659758 1.
  0.00745655 0.95870216 1.        ]
 [1.         0.         1.         1.         0.22508183 1.
  0.10744146 0.50475609 1.        ]
 [1.         0.         1.         1.         0.22692693 1.
  0.15142013 0.11081626 1.        ]
 [1.         0.         1.         0.79109487 0.22405846 1.
  1.         0.         1.        ]
 [1.         0.         0.53537365 0.7378927  0.22629609 1.
  0.         0.54095005 1.        ]
 [1.         0.         0.3426142  0.         0.22741679 1.
  1.         0.         1.        ]
 [1.         0.         1.         1.         0.22700366 1.
  0.30437644 1.         1.        ]
 [1.         0.         1.         1.         0.22884398 1.
  0.14102507 0.         1.        ]
 [1.         0.         0.79083138 0.67654585 0.2238498  1.
  0.44808279 1.         1.        ]
 [1.         0.         0.         0.         0.22689127 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.27502723 0.22392637 1.
  0.48007208 0.16790148 1.        ]
 [1.         0.         1.         1.         0.227222   1.
  0.         0.43473178 1.        ]
 [1.         0.         0.77514563 1.         0.22569791 1.
  0.03627159 1.         1.        ]
 [1.         0.         1.         1.         0.22730312 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.22655483 1.
  0.8722193  1.         1.        ]]

Best Training Poisoning Accuracy:
1.0
#####################         POISON         ###############################################

############################################################################################

comm_round: 9 | global_test_acc: 87.500% | global_f1: 0.9333333333333333 | global_precision: 0.875
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.88      1.00      0.93         7

    accuracy                           0.88         8
   macro avg       0.44      0.50      0.47         8
weighted avg       0.77      0.88      0.82         8

Accuracy per class:
[[7 0]
 [1 0]]
[1. 0.]
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 0. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         1.         1.         0.83011407 0.         0.37852448
 0.12774649 0.         1.         1.         1.         0.
 1.         0.         0.         1.         1.         0.30767383
 0.3742688  0.76173228 0.96638818 0.4701902  1.         0.
 0.         0.79401024]
wv_ed shape (26,)
[0.         1.         1.         1.         0.0465048  0.81702338
 0.85266525 0.7375942  1.         1.         0.86898612 0.46917192
 1.         0.44034823 0.         1.         1.         0.29875107
 1.         0.91027543 1.         1.         1.         0.06799363
 0.         0.77960636]
wv_lg shape (26, 1)
[[0.2240984 ]
 [0.22788935]
 [0.22786609]
 [0.22797888]
 [0.22719884]
 [0.22643548]
 [0.22837811]
 [0.22639423]
 [0.22738297]
 [0.22767296]
 [0.22832149]
 [0.22787462]
 [0.22632594]
 [0.22582856]
 [0.22730875]
 [0.22479785]
 [0.2285003 ]
 [0.22341576]
 [0.2257772 ]
 [0.2276532 ]
 [0.22727345]
 [0.2268642 ]
 [0.22770758]
 [0.22708825]
 [0.2285562 ]
 [0.22551207]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[0.86685629 0.42967874 1.         0.8701052  0.42439043 0.
 0.24910566 0.         0.68687994 1.         1.         0.22516012
 1.         0.         0.64826317 0.74731071 0.99837206 0.62529529
 0.00452229 0.74371721 0.85129664 0.83242117 1.         0.24116615
 1.         1.        ]
wv_std shape (26,)
[0.         0.5899154  0.63716131 0.         0.45772505 0.4134463
 0.28879961 0.80038009 1.         1.         0.03946241 0.
 1.         1.         0.30163188 1.         1.         0.87051336
 0.97268348 0.24610135 0.         1.         0.39171206 0.06872266
 0.         1.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.2240984  1.
  0.86685629 0.         0.        ]
 [1.         0.         1.         1.         0.22788935 1.
  0.42967874 0.5899154  1.        ]
 [1.         0.         1.         1.         0.22786609 1.
  1.         0.63716131 1.        ]
 [1.         0.         0.83011407 1.         0.22797888 1.
  0.8701052  0.         1.        ]
 [1.         0.         0.         0.0465048  0.22719884 1.
  0.42439043 0.45772505 1.        ]
 [1.         0.         0.37852448 0.81702338 0.22643548 1.
  0.         0.4134463  1.        ]
 [1.         0.         0.12774649 0.85266525 0.22837811 1.
  0.24910566 0.28879961 1.        ]
 [1.         0.         0.         0.7375942  0.22639423 1.
  0.         0.80038009 1.        ]
 [1.         0.         1.         1.         0.22738297 1.
  0.68687994 1.         1.        ]
 [1.         0.         1.         1.         0.22767296 1.
  1.         1.         1.        ]
 [1.         0.         1.         0.86898612 0.22832149 1.
  1.         0.03946241 1.        ]
 [1.         0.         0.         0.46917192 0.22787462 1.
  0.22516012 0.         1.        ]
 [1.         0.         1.         1.         0.22632594 1.
  1.         1.         1.        ]
 [1.         0.         0.         0.44034823 0.22582856 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.22730875 1.
  0.64826317 0.30163188 1.        ]
 [1.         0.         1.         1.         0.22479785 1.
  0.74731071 1.         1.        ]
 [1.         0.         1.         1.         0.2285003  1.
  0.99837206 1.         1.        ]
 [1.         0.         0.30767383 0.29875107 0.22341576 1.
  0.62529529 0.87051336 1.        ]
 [1.         0.         0.3742688  1.         0.2257772  1.
  0.00452229 0.97268348 1.        ]
 [1.         0.         0.76173228 0.91027543 0.2276532  1.
  0.74371721 0.24610135 1.        ]
 [1.         0.         0.96638818 1.         0.22727345 1.
  0.85129664 0.         1.        ]
 [1.         0.         0.4701902  1.         0.2268642  1.
  0.83242117 1.         1.        ]
 [1.         0.         1.         1.         0.22770758 1.
  1.         0.39171206 1.        ]
 [1.         0.         0.         0.06799363 0.22708825 1.
  0.24116615 0.06872266 1.        ]
 [0.         0.         0.         0.         0.2285562  1.
  1.         0.         1.        ]
 [1.         0.         0.79401024 0.77960636 0.22551207 1.
  1.         1.         1.        ]]

Best Training Poisoning Accuracy:
1.0
#####################         POISON         ###############################################

############################################################################################

comm_round: 10 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8

Accuracy per class:
[[8 0]
 [0 0]]
[ 1. nan]
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         1.         0.82812708 1.         0.         0.29359789
 1.         0.92424122 0.         0.         1.         0.86483826
 1.         0.         0.1795801  0.41561741 0.55941982 0.96232308
 1.         0.56057358 0.18040292 0.08600285 1.         1.
 1.         1.        ]
wv_ed shape (26,)
[0.         1.         1.         1.         0.         0.26822271
 1.         1.         0.         0.         1.         1.
 1.         0.         0.55966035 0.85888545 0.56604331 1.
 1.         0.82647199 0.34047637 0.26407916 1.         1.
 1.         1.        ]
wv_lg shape (26, 1)
[[0.22561074]
 [0.22890796]
 [0.22855073]
 [0.22790638]
 [0.22755988]
 [0.22778223]
 [0.22952324]
 [0.2275953 ]
 [0.2277299 ]
 [0.22894707]
 [0.22872343]
 [0.22999389]
 [0.2287036 ]
 [0.22892743]
 [0.22603152]
 [0.22885753]
 [0.22911349]
 [0.22959596]
 [0.22891715]
 [0.22923844]
 [0.22656327]
 [0.22921323]
 [0.22828901]
 [0.22853823]
 [0.22824089]
 [0.22812587]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1.         0.48307618 0.         0.40026867 0.2559813  1.
 0.6285606  0.         1.         0.         0.9800375  0.39684287
 0.         0.         0.         0.         1.         0.40166856
 1.         0.6069679  1.         0.         1.         0.18202001
 0.8838721  0.        ]
wv_std shape (26,)
[0.         0.91644128 1.         1.         0.         0.98787955
 1.         1.         0.         0.75330156 0.054132   0.
 1.         0.45218051 1.         0.8210158  1.         0.59968252
 1.         0.71883362 1.         1.         1.         1.
 0.8499003  0.20500016]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.22561074 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.22890796 1.
  0.48307618 0.91644128 1.        ]
 [1.         0.         0.82812708 1.         0.22855073 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.22790638 1.
  0.40026867 1.         1.        ]
 [0.         0.         0.         0.         0.22755988 1.
  0.2559813  0.         1.        ]
 [1.         0.         0.29359789 0.26822271 0.22778223 1.
  1.         0.98787955 1.        ]
 [1.         0.         1.         1.         0.22952324 1.
  0.6285606  1.         1.        ]
 [1.         0.         0.92424122 1.         0.2275953  1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.2277299  1.
  1.         0.         1.        ]
 [1.         0.         0.         0.         0.22894707 1.
  0.         0.75330156 1.        ]
 [1.         0.         1.         1.         0.22872343 1.
  0.9800375  0.054132   1.        ]
 [1.         0.         0.86483826 1.         0.22999389 1.
  0.39684287 0.         1.        ]
 [1.         0.         1.         1.         0.2287036  1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.22892743 1.
  0.         0.45218051 1.        ]
 [1.         0.         0.1795801  0.55966035 0.22603152 1.
  0.         1.         1.        ]
 [1.         0.         0.41561741 0.85888545 0.22885753 1.
  0.         0.8210158  1.        ]
 [1.         0.         0.55941982 0.56604331 0.22911349 1.
  1.         1.         1.        ]
 [1.         0.         0.96232308 1.         0.22959596 1.
  0.40166856 0.59968252 1.        ]
 [1.         0.         1.         1.         0.22891715 1.
  1.         1.         1.        ]
 [1.         0.         0.56057358 0.82647199 0.22923844 1.
  0.6069679  0.71883362 1.        ]
 [1.         0.         0.18040292 0.34047637 0.22656327 1.
  1.         1.         1.        ]
 [1.         0.         0.08600285 0.26407916 0.22921323 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.22828901 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.22853823 1.
  0.18202001 1.         1.        ]
 [1.         0.         1.         1.         0.22824089 1.
  0.8838721  0.8499003  1.        ]
 [1.         0.         1.         1.         0.22812587 1.
  0.         0.20500016 1.        ]]

Best Training Poisoning Accuracy:
1.0
#####################         POISON         ###############################################

############################################################################################

comm_round: 11 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8

Accuracy per class:
[[8 0]
 [0 0]]
[ 1. nan]
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.23834033 0.61394381 0.25958843 0.         0.1312733
 0.79380226 0.         0.         1.         1.         0.72825082
 0.93790625 0.05149065 0.         0.         1.         1.
 1.         1.         0.54577052 1.         1.         0.60021355
 0.65879686 0.80463239]
wv_ed shape (26,)
[0.         0.29512823 0.45512864 0.         0.         0.
 0.61732006 0.09046853 0.         1.         1.         0.8544795
 0.96629763 0.22254031 0.         0.         1.         1.
 1.         1.         0.74582215 1.         1.         0.03721456
 1.         1.        ]
wv_lg shape (26, 1)
[[0.22499209]
 [0.23036843]
 [0.23031669]
 [0.23006839]
 [0.22845585]
 [0.22860998]
 [0.22998551]
 [0.22979362]
 [0.22951842]
 [0.22988344]
 [0.2289208 ]
 [0.22924415]
 [0.22995131]
 [0.22877628]
 [0.22964137]
 [0.23012697]
 [0.2303118 ]
 [0.22942849]
 [0.22893449]
 [0.22901112]
 [0.2297967 ]
 [0.22977748]
 [0.23069182]
 [0.23105311]
 [0.22881521]
 [0.22916165]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1.         0.29067645 0.29804699 1.         0.         0.26616884
 0.10331683 0.28994753 0.         0.         0.34991423 0.84430899
 0.70177873 0.         0.43637618 0.         0.         0.
 0.         0.         0.69321841 1.         1.         0.
 0.         0.        ]
wv_std shape (26,)
[0.         0.         0.         0.         0.29362509 0.17970112
 0.         0.         0.         0.0552214  0.58877323 1.
 0.         0.00835602 0.         0.17368412 0.32180546 0.47295289
 1.         1.         0.         1.         0.2076265  0.
 0.80953902 1.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.22499209 1.
  1.         0.         0.        ]
 [1.         0.         0.23834033 0.29512823 0.23036843 1.
  0.29067645 0.         1.        ]
 [1.         0.         0.61394381 0.45512864 0.23031669 1.
  0.29804699 0.         1.        ]
 [1.         0.         0.25958843 0.         0.23006839 1.
  1.         0.         1.        ]
 [1.         0.         0.         0.         0.22845585 1.
  0.         0.29362509 1.        ]
 [1.         0.         0.1312733  0.         0.22860998 1.
  0.26616884 0.17970112 1.        ]
 [1.         0.         0.79380226 0.61732006 0.22998551 1.
  0.10331683 0.         1.        ]
 [1.         0.         0.         0.09046853 0.22979362 1.
  0.28994753 0.         1.        ]
 [1.         0.         0.         0.         0.22951842 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.22988344 1.
  0.         0.0552214  1.        ]
 [1.         0.         1.         1.         0.2289208  1.
  0.34991423 0.58877323 1.        ]
 [1.         0.         0.72825082 0.8544795  0.22924415 1.
  0.84430899 1.         1.        ]
 [1.         0.         0.93790625 0.96629763 0.22995131 1.
  0.70177873 0.         1.        ]
 [1.         0.         0.05149065 0.22254031 0.22877628 1.
  0.         0.00835602 1.        ]
 [0.         0.         0.         0.         0.22964137 1.
  0.43637618 0.         1.        ]
 [1.         0.         0.         0.         0.23012697 1.
  0.         0.17368412 1.        ]
 [1.         0.         1.         1.         0.2303118  1.
  0.         0.32180546 1.        ]
 [1.         0.         1.         1.         0.22942849 1.
  0.         0.47295289 1.        ]
 [1.         0.         1.         1.         0.22893449 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.22901112 1.
  0.         1.         1.        ]
 [1.         0.         0.54577052 0.74582215 0.2297967  1.
  0.69321841 0.         1.        ]
 [1.         0.         1.         1.         0.22977748 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.23069182 1.
  1.         0.2076265  1.        ]
 [1.         0.         0.60021355 0.03721456 0.23105311 1.
  0.         0.         1.        ]
 [1.         0.         0.65879686 1.         0.22881521 1.
  0.         0.80953902 1.        ]
 [1.         0.         0.80463239 1.         0.22916165 1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.9166666865348816
#####################         POISON         ###############################################

############################################################################################

comm_round: 12 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8

Accuracy per class:
[[8 0]
 [0 0]]
[ 1. nan]
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.         0.1619639  0.         0.         0.
 0.76041797 1.         1.         0.95599343 1.         1.
 1.         1.         0.26932467 0.79082608 1.         1.
 0.7336128  1.         1.         1.         0.9987979  0.59393714
 0.02926937 1.        ]
wv_ed shape (26,)
[0.         0.         0.69936471 0.         0.         0.
 0.81076799 1.         1.         1.         1.         1.
 1.         1.         0.39332373 1.         1.         1.
 1.         1.         1.         1.         1.         0.87961251
 0.42441925 1.        ]
wv_lg shape (26, 1)
[[0.22513079]
 [0.22756846]
 [0.23064025]
 [0.23234753]
 [0.23078641]
 [0.23128536]
 [0.22960571]
 [0.23176016]
 [0.23128102]
 [0.23164774]
 [0.23257734]
 [0.23132625]
 [0.23150206]
 [0.23021843]
 [0.22912735]
 [0.23198834]
 [0.2316953 ]
 [0.23318485]
 [0.23074709]
 [0.23164343]
 [0.23138562]
 [0.23029195]
 [0.23089092]
 [0.23013085]
 [0.22923605]
 [0.23158405]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1.         0.         0.         1.         0.         0.
 1.         0.69502333 0.         0.         1.         0.
 0.32380332 0.         0.         0.         0.20191906 0.
 0.         1.         0.         0.89959721 0.70447697 0.
 0.         0.        ]
wv_std shape (26,)
[0.         1.         0.42104378 0.         0.14275008 0.
 0.65894903 0.15831079 1.         0.90529525 0.         0.56372283
 1.         1.         0.6667964  0.         0.62631296 0.85214789
 0.97449956 0.72962157 1.         1.         1.         0.59824115
 0.80284206 1.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.22513079 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.22756846 1.
  0.         1.         1.        ]
 [1.         0.         0.1619639  0.69936471 0.23064025 1.
  0.         0.42104378 1.        ]
 [1.         0.         0.         0.         0.23234753 1.
  1.         0.         1.        ]
 [1.         0.         0.         0.         0.23078641 1.
  0.         0.14275008 1.        ]
 [1.         0.         0.         0.         0.23128536 1.
  0.         0.         1.        ]
 [1.         0.         0.76041797 0.81076799 0.22960571 1.
  1.         0.65894903 1.        ]
 [1.         0.         1.         1.         0.23176016 1.
  0.69502333 0.15831079 1.        ]
 [1.         0.         1.         1.         0.23128102 1.
  0.         1.         1.        ]
 [1.         0.         0.95599343 1.         0.23164774 1.
  0.         0.90529525 1.        ]
 [1.         0.         1.         1.         0.23257734 1.
  1.         0.         1.        ]
 [1.         0.         1.         1.         0.23132625 1.
  0.         0.56372283 1.        ]
 [1.         0.         1.         1.         0.23150206 1.
  0.32380332 1.         1.        ]
 [1.         0.         1.         1.         0.23021843 1.
  0.         1.         1.        ]
 [1.         0.         0.26932467 0.39332373 0.22912735 1.
  0.         0.6667964  1.        ]
 [1.         0.         0.79082608 1.         0.23198834 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.2316953  1.
  0.20191906 0.62631296 1.        ]
 [1.         0.         1.         1.         0.23318485 1.
  0.         0.85214789 1.        ]
 [1.         0.         0.7336128  1.         0.23074709 1.
  0.         0.97449956 1.        ]
 [1.         0.         1.         1.         0.23164343 1.
  1.         0.72962157 1.        ]
 [1.         0.         1.         1.         0.23138562 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.23029195 1.
  0.89959721 1.         1.        ]
 [1.         0.         0.9987979  1.         0.23089092 1.
  0.70447697 1.         1.        ]
 [1.         0.         0.59393714 0.87961251 0.23013085 1.
  0.         0.59824115 1.        ]
 [1.         0.         0.02926937 0.42441925 0.22923605 1.
  0.         0.80284206 1.        ]
 [1.         0.         1.         1.         0.23158405 1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
1.0
#####################         POISON         ###############################################

############################################################################################

comm_round: 13 | global_test_acc: 87.500% | global_f1: 0.9333333333333333 | global_precision: 0.875
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.88      1.00      0.93         7

    accuracy                           0.88         8
   macro avg       0.44      0.50      0.47         8
weighted avg       0.77      0.88      0.82         8

Accuracy per class:
[[7 0]
 [1 0]]
[1. 0.]
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.09538427 0.6917984  0.89126893 0.54821801 0.47051302
 1.         1.         1.         0.88039979 0.         1.
 0.         0.         0.72626964 1.         0.         0.
 0.47406262 0.57307928 1.         1.         1.         1.
 1.         1.        ]
wv_ed shape (26,)
[0.         0.00958071 0.87484951 0.68773814 0.89051876 0.82713856
 1.         1.         1.         1.         0.         1.
 0.         0.         0.94009185 0.70781577 0.         0.
 0.52803424 0.71074413 1.         1.         1.         1.
 1.         0.91743785]
wv_lg shape (26, 1)
[[0.2275657 ]
 [0.2330267 ]
 [0.23278405]
 [0.23387364]
 [0.23230169]
 [0.23271222]
 [0.23297398]
 [0.23267757]
 [0.23242528]
 [0.23252836]
 [0.23077153]
 [0.23258051]
 [0.23124642]
 [0.2321302 ]
 [0.23245518]
 [0.2340836 ]
 [0.23342954]
 [0.23257817]
 [0.23327844]
 [0.23269151]
 [0.23420703]
 [0.23365741]
 [0.23311682]
 [0.23171006]
 [0.23331004]
 [0.23243117]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1.         0.51066652 0.         1.         0.         0.
 1.         0.         0.         0.         0.         0.
 0.         0.         0.         1.         0.         0.
 1.         0.         1.         1.         0.04066465 0.
 1.         0.19091342]
wv_std shape (26,)
[0.         0.         0.08924124 0.         1.         1.
 1.         0.         1.         1.         0.         0.72770804
 0.23419995 0.         1.         0.         0.         0.
 0.08778688 0.         0.         0.         0.70624493 1.
 0.         0.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.2275657  1.
  1.         0.         0.        ]
 [1.         0.         0.09538427 0.00958071 0.2330267  1.
  0.51066652 0.         1.        ]
 [1.         0.         0.6917984  0.87484951 0.23278405 1.
  0.         0.08924124 1.        ]
 [1.         0.         0.89126893 0.68773814 0.23387364 1.
  1.         0.         1.        ]
 [1.         0.         0.54821801 0.89051876 0.23230169 1.
  0.         1.         1.        ]
 [1.         0.         0.47051302 0.82713856 0.23271222 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.23297398 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.23267757 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.23242528 1.
  0.         1.         1.        ]
 [1.         0.         0.88039979 1.         0.23252836 1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.23077153 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.23258051 1.
  0.         0.72770804 1.        ]
 [1.         0.         0.         0.         0.23124642 1.
  0.         0.23419995 1.        ]
 [1.         0.         0.         0.         0.2321302  1.
  0.         0.         1.        ]
 [1.         0.         0.72626964 0.94009185 0.23245518 1.
  0.         1.         1.        ]
 [1.         0.         1.         0.70781577 0.2340836  1.
  1.         0.         1.        ]
 [1.         0.         0.         0.         0.23342954 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.23257817 1.
  0.         0.         1.        ]
 [1.         0.         0.47406262 0.52803424 0.23327844 1.
  1.         0.08778688 1.        ]
 [1.         0.         0.57307928 0.71074413 0.23269151 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.23420703 1.
  1.         0.         1.        ]
 [1.         0.         1.         1.         0.23365741 1.
  1.         0.         1.        ]
 [1.         0.         1.         1.         0.23311682 1.
  0.04066465 0.70624493 1.        ]
 [1.         0.         1.         1.         0.23171006 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.23331004 1.
  1.         0.         1.        ]
 [1.         0.         1.         0.91743785 0.23243117 1.
  0.19091342 0.         1.        ]]

Best Training Poisoning Accuracy:
0.9166666865348816
#####################         POISON         ###############################################

############################################################################################

comm_round: 14 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8

Accuracy per class:
[[8 0]
 [0 0]]
[ 1. nan]
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.         0.24309662 0.06531832 1.         0.77663606
 0.95632059 0.60968015 1.         1.         1.         1.
 0.         1.         1.         0.85170035 1.         0.
 0.         1.         0.         1.         0.67963139 0.61399073
 1.         1.        ]
wv_ed shape (26,)
[0.         0.         0.16591753 0.         0.9452922  0.58489903
 0.05284457 0.30073167 0.89014833 1.         1.         1.
 0.         0.5316735  1.         0.87462328 0.61762997 0.01883902
 0.         1.         0.         0.918766   0.31310813 0.76173957
 1.         1.        ]
wv_lg shape (26, 1)
[[0.22905569]
 [0.23539479]
 [0.23514476]
 [0.23505164]
 [0.23389929]
 [0.23511577]
 [0.23600973]
 [0.23447972]
 [0.23480916]
 [0.23308327]
 [0.23445099]
 [0.2344993 ]
 [0.23407202]
 [0.23482474]
 [0.23572744]
 [0.23422067]
 [0.23431901]
 [0.23408965]
 [0.23471686]
 [0.2340941 ]
 [0.23486791]
 [0.23532494]
 [0.236241  ]
 [0.23427373]
 [0.23425589]
 [0.23513338]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1.         0.         0.         0.         1.         0.59766623
 0.90485192 0.76952086 1.         0.59422188 0.         1.
 1.         0.81981927 0.         0.         0.         0.
 1.         0.         0.         1.         0.         0.
 1.         0.        ]
wv_std shape (26,)
[0.         1.         0.07967222 0.         1.         1.
 0.         0.00393082 0.82825891 1.         0.36949642 0.22750175
 1.         0.         0.11130984 0.58609905 0.         0.47731141
 0.54030058 1.         0.         0.98255938 0.82331679 1.
 1.         1.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.22905569 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.23539479 1.
  0.         1.         1.        ]
 [1.         0.         0.24309662 0.16591753 0.23514476 1.
  0.         0.07967222 1.        ]
 [1.         0.         0.06531832 0.         0.23505164 1.
  0.         0.         1.        ]
 [1.         0.         1.         0.9452922  0.23389929 1.
  1.         1.         1.        ]
 [1.         0.         0.77663606 0.58489903 0.23511577 1.
  0.59766623 1.         1.        ]
 [1.         0.         0.95632059 0.05284457 0.23600973 1.
  0.90485192 0.         1.        ]
 [1.         0.         0.60968015 0.30073167 0.23447972 1.
  0.76952086 0.00393082 1.        ]
 [1.         0.         1.         0.89014833 0.23480916 1.
  1.         0.82825891 1.        ]
 [1.         0.         1.         1.         0.23308327 1.
  0.59422188 1.         1.        ]
 [1.         0.         1.         1.         0.23445099 1.
  0.         0.36949642 1.        ]
 [1.         0.         1.         1.         0.2344993  1.
  1.         0.22750175 1.        ]
 [1.         0.         0.         0.         0.23407202 1.
  1.         1.         1.        ]
 [1.         0.         1.         0.5316735  0.23482474 1.
  0.81981927 0.         1.        ]
 [1.         0.         1.         1.         0.23572744 1.
  0.         0.11130984 1.        ]
 [1.         0.         0.85170035 0.87462328 0.23422067 1.
  0.         0.58609905 1.        ]
 [1.         0.         1.         0.61762997 0.23431901 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.01883902 0.23408965 1.
  0.         0.47731141 1.        ]
 [1.         0.         0.         0.         0.23471686 1.
  1.         0.54030058 1.        ]
 [1.         0.         1.         1.         0.2340941  1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.23486791 1.
  0.         0.         1.        ]
 [1.         0.         1.         0.918766   0.23532494 1.
  1.         0.98255938 1.        ]
 [1.         0.         0.67963139 0.31310813 0.236241   1.
  0.         0.82331679 1.        ]
 [1.         0.         0.61399073 0.76173957 0.23427373 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.23425589 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.23513338 1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
1.0
#####################         POISON         ###############################################

############################################################################################

comm_round: 15 | global_test_acc: 87.500% | global_f1: 0.9333333333333333 | global_precision: 0.875
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.88      1.00      0.93         7

    accuracy                           0.88         8
   macro avg       0.44      0.50      0.47         8
weighted avg       0.77      0.88      0.82         8

Accuracy per class:
[[7 0]
 [1 0]]
[1. 0.]
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.9685464  1.         0.         1.         1.
 0.06844945 0.57891982 1.         0.79027582 0.52629264 0.
 0.         0.80804889 0.         0.79818836 1.         1.
 0.46615947 0.66229836 1.         0.         0.11204616 0.67271164
 0.67060681 1.        ]
wv_ed shape (26,)
[0.         1.         1.         0.         1.         1.
 0.65889927 0.91446892 1.         0.62979377 0.59153677 0.
 0.21998993 0.99997015 0.         1.         1.         1.
 0.6386794  1.         1.         0.         0.56096895 1.
 1.         1.        ]
wv_lg shape (26, 1)
[[0.23116053]
 [0.23750458]
 [0.23644715]
 [0.23676758]
 [0.23627081]
 [0.23607214]
 [0.2358539 ]
 [0.23686582]
 [0.23544477]
 [0.23679684]
 [0.2372896 ]
 [0.2367084 ]
 [0.23676621]
 [0.23702197]
 [0.23657613]
 [0.23438181]
 [0.23750558]
 [0.2367279 ]
 [0.23698684]
 [0.23516846]
 [0.23710444]
 [0.23557626]
 [0.23665441]
 [0.23639275]
 [0.2363902 ]
 [0.23789917]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1.         1.         0.         0.         1.         0.
 0.         0.69234386 0.         1.         1.         0.
 1.         0.         1.         1.         0.         0.2264061
 0.         0.         0.52732831 0.         0.29274341 0.
 0.         0.        ]
wv_std shape (26,)
[0.         0.00390624 0.46860298 0.         0.         1.
 1.         0.28842091 1.         0.         0.         0.
 0.         0.         0.         1.         0.30563313 0.
 0.         1.         0.         1.         0.06411332 0.85524549
 0.23660549 1.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.23116053 1.
  1.         0.         0.        ]
 [1.         0.         0.9685464  1.         0.23750458 1.
  1.         0.00390624 1.        ]
 [1.         0.         1.         1.         0.23644715 1.
  0.         0.46860298 1.        ]
 [1.         0.         0.         0.         0.23676758 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.23627081 1.
  1.         0.         1.        ]
 [1.         0.         1.         1.         0.23607214 1.
  0.         1.         1.        ]
 [1.         0.         0.06844945 0.65889927 0.2358539  1.
  0.         1.         1.        ]
 [1.         0.         0.57891982 0.91446892 0.23686582 1.
  0.69234386 0.28842091 1.        ]
 [1.         0.         1.         1.         0.23544477 1.
  0.         1.         1.        ]
 [1.         0.         0.79027582 0.62979377 0.23679684 1.
  1.         0.         1.        ]
 [1.         0.         0.52629264 0.59153677 0.2372896  1.
  1.         0.         1.        ]
 [0.         0.         0.         0.         0.2367084  1.
  0.         0.         1.        ]
 [1.         0.         0.         0.21998993 0.23676621 1.
  1.         0.         1.        ]
 [1.         0.         0.80804889 0.99997015 0.23702197 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.23657613 1.
  1.         0.         1.        ]
 [1.         0.         0.79818836 1.         0.23438181 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.23750558 1.
  0.         0.30563313 1.        ]
 [1.         0.         1.         1.         0.2367279  1.
  0.2264061  0.         1.        ]
 [1.         0.         0.46615947 0.6386794  0.23698684 1.
  0.         0.         1.        ]
 [1.         0.         0.66229836 1.         0.23516846 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.23710444 1.
  0.52732831 0.         1.        ]
 [1.         0.         0.         0.         0.23557626 1.
  0.         1.         1.        ]
 [1.         0.         0.11204616 0.56096895 0.23665441 1.
  0.29274341 0.06411332 1.        ]
 [1.         0.         0.67271164 1.         0.23639275 1.
  0.         0.85524549 1.        ]
 [1.         0.         0.67060681 1.         0.2363902  1.
  0.         0.23660549 1.        ]
 [1.         0.         1.         1.         0.23789917 1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
1.0
#####################         POISON         ###############################################

############################################################################################

comm_round: 16 | global_test_acc: 87.500% | global_f1: 0.9333333333333333 | global_precision: 0.875
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.88      1.00      0.93         7

    accuracy                           0.88         8
   macro avg       0.44      0.50      0.47         8
weighted avg       0.77      0.88      0.82         8

Accuracy per class:
[[7 0]
 [1 0]]
[1. 0.]
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         1.         1.         1.         1.         0.11883376
 0.         1.         0.         0.63033074 0.5338765  1.
 0.57441205 0.         1.         0.         1.         1.
 0.         1.         1.         1.         1.         0.
 0.         0.        ]
wv_ed shape (26,)
[0.         0.95684886 0.73698694 1.         1.         0.26390867
 0.14064611 1.         0.         0.41350342 0.18639845 1.
 0.         0.         0.562092   0.         1.         1.
 0.         1.         1.         1.         1.         0.
 0.         0.        ]
wv_lg shape (26, 1)
[[0.23381329]
 [0.23965533]
 [0.23909858]
 [0.23872901]
 [0.23885591]
 [0.23826464]
 [0.23809985]
 [0.2391618 ]
 [0.23846324]
 [0.23875361]
 [0.24016223]
 [0.23826381]
 [0.23946281]
 [0.23885652]
 [0.23889214]
 [0.23986315]
 [0.23883833]
 [0.23980611]
 [0.23889366]
 [0.2389016 ]
 [0.23995476]
 [0.23950335]
 [0.23856039]
 [0.23828036]
 [0.23793659]
 [0.23859171]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[0.77893775 0.88472857 0.14356058 0.         0.62253557 0.
 0.         1.         0.         0.         0.         1.
 0.01884874 0.         0.36971292 0.         0.19045035 1.
 1.         0.         0.         0.45552921 1.         0.
 0.         0.        ]
wv_std shape (26,)
[0.         0.81798486 0.         1.         0.53562155 0.83547064
 0.64438106 0.56569692 0.67150896 0.14342625 0.09492077 1.
 0.         0.2017347  0.         0.         1.         0.
 0.         1.         1.         0.64793841 1.         0.27606223
 0.53305085 0.16662273]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.23381329 1.
  0.77893775 0.         0.        ]
 [1.         0.         1.         0.95684886 0.23965533 1.
  0.88472857 0.81798486 1.        ]
 [1.         0.         1.         0.73698694 0.23909858 1.
  0.14356058 0.         1.        ]
 [1.         0.         1.         1.         0.23872901 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.23885591 1.
  0.62253557 0.53562155 1.        ]
 [1.         0.         0.11883376 0.26390867 0.23826464 1.
  0.         0.83547064 1.        ]
 [1.         0.         0.         0.14064611 0.23809985 1.
  0.         0.64438106 1.        ]
 [1.         0.         1.         1.         0.2391618  1.
  1.         0.56569692 1.        ]
 [1.         0.         0.         0.         0.23846324 1.
  0.         0.67150896 1.        ]
 [1.         0.         0.63033074 0.41350342 0.23875361 1.
  0.         0.14342625 1.        ]
 [1.         0.         0.5338765  0.18639845 0.24016223 1.
  0.         0.09492077 1.        ]
 [1.         0.         1.         1.         0.23826381 1.
  1.         1.         1.        ]
 [1.         0.         0.57441205 0.         0.23946281 1.
  0.01884874 0.         1.        ]
 [1.         0.         0.         0.         0.23885652 1.
  0.         0.2017347  1.        ]
 [1.         0.         1.         0.562092   0.23889214 1.
  0.36971292 0.         1.        ]
 [0.         0.         0.         0.         0.23986315 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.23883833 1.
  0.19045035 1.         1.        ]
 [1.         0.         1.         1.         0.23980611 1.
  1.         0.         1.        ]
 [1.         0.         0.         0.         0.23889366 1.
  1.         0.         1.        ]
 [1.         0.         1.         1.         0.2389016  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.23995476 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.23950335 1.
  0.45552921 0.64793841 1.        ]
 [1.         0.         1.         1.         0.23856039 1.
  1.         1.         1.        ]
 [1.         0.         0.         0.         0.23828036 1.
  0.         0.27606223 1.        ]
 [1.         0.         0.         0.         0.23793659 1.
  0.         0.53305085 1.        ]
 [1.         0.         0.         0.         0.23859171 1.
  0.         0.16662273 1.        ]]

Best Training Poisoning Accuracy:
1.0
#####################         POISON         ###############################################

############################################################################################

comm_round: 17 | global_test_acc: 87.500% | global_f1: 0.9333333333333333 | global_precision: 0.875
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.88      1.00      0.93         7

    accuracy                           0.88         8
   macro avg       0.44      0.50      0.47         8
weighted avg       0.77      0.88      0.82         8

Accuracy per class:
[[7 0]
 [1 0]]
[1. 0.]
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.45916374 0.62747895 0.78390561 1.         1.
 0.         0.23624664 0.25063734 0.         0.34929065 1.
 0.39518606 0.         1.         0.84758981 0.85716863 0.
 1.         1.         1.         0.10913035 0.         1.
 0.43250683 0.51231426]
wv_ed shape (26,)
[0.         0.28259575 0.         0.51298447 1.         1.
 0.         0.57683194 0.         0.         0.52963476 1.
 0.86114903 0.         0.67485111 1.         0.         0.
 1.         0.29906112 1.         0.28753098 0.         1.
 0.54095326 0.        ]
wv_lg shape (26, 1)
[[0.23741111]
 [0.2424269 ]
 [0.24307884]
 [0.24297854]
 [0.24295482]
 [0.2429503 ]
 [0.24233235]
 [0.24180121]
 [0.24333117]
 [0.24274336]
 [0.24312436]
 [0.24365204]
 [0.24276349]
 [0.24257871]
 [0.24277159]
 [0.24235523]
 [0.24286789]
 [0.24288935]
 [0.24313345]
 [0.24354399]
 [0.24225153]
 [0.24176243]
 [0.24196833]
 [0.24263633]
 [0.24220126]
 [0.24302972]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[0.67358177 0.44532117 1.         1.         0.         1.
 0.22106813 1.         0.         0.10978349 0.         0.
 0.         0.         0.         0.         0.95355487 0.
 0.         1.         0.64552595 0.         0.         0.
 0.82353648 0.        ]
wv_std shape (26,)
[0.         0.36823641 0.         0.50107651 1.         1.
 0.         1.         0.4975209  1.         1.         0.27395965
 1.         0.10264332 0.24601513 1.         0.         1.
 1.         0.         1.         0.80772887 0.74664151 0.88450094
 0.69070093 0.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.23741111 1.
  0.67358177 0.         0.        ]
 [1.         0.         0.45916374 0.28259575 0.2424269  1.
  0.44532117 0.36823641 1.        ]
 [1.         0.         0.62747895 0.         0.24307884 1.
  1.         0.         1.        ]
 [1.         0.         0.78390561 0.51298447 0.24297854 1.
  1.         0.50107651 1.        ]
 [1.         0.         1.         1.         0.24295482 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.2429503  1.
  1.         1.         1.        ]
 [0.         0.         0.         0.         0.24233235 1.
  0.22106813 0.         1.        ]
 [1.         0.         0.23624664 0.57683194 0.24180121 1.
  1.         1.         1.        ]
 [1.         0.         0.25063734 0.         0.24333117 1.
  0.         0.4975209  1.        ]
 [1.         0.         0.         0.         0.24274336 1.
  0.10978349 1.         1.        ]
 [1.         0.         0.34929065 0.52963476 0.24312436 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.24365204 1.
  0.         0.27395965 1.        ]
 [1.         0.         0.39518606 0.86114903 0.24276349 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.24257871 1.
  0.         0.10264332 1.        ]
 [1.         0.         1.         0.67485111 0.24277159 1.
  0.         0.24601513 1.        ]
 [1.         0.         0.84758981 1.         0.24235523 1.
  0.         1.         1.        ]
 [1.         0.         0.85716863 0.         0.24286789 1.
  0.95355487 0.         1.        ]
 [1.         0.         0.         0.         0.24288935 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.24313345 1.
  0.         1.         1.        ]
 [1.         0.         1.         0.29906112 0.24354399 1.
  1.         0.         1.        ]
 [1.         0.         1.         1.         0.24225153 1.
  0.64552595 1.         1.        ]
 [1.         0.         0.10913035 0.28753098 0.24176243 1.
  0.         0.80772887 1.        ]
 [1.         0.         0.         0.         0.24196833 1.
  0.         0.74664151 1.        ]
 [1.         0.         1.         1.         0.24263633 1.
  0.         0.88450094 1.        ]
 [1.         0.         0.43250683 0.54095326 0.24220126 1.
  0.82353648 0.69070093 1.        ]
 [1.         0.         0.51231426 0.         0.24302972 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
1.0
#####################         POISON         ###############################################

############################################################################################

comm_round: 18 | global_test_acc: 87.500% | global_f1: 0.9333333333333333 | global_precision: 0.875
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.88      1.00      0.93         7

    accuracy                           0.88         8
   macro avg       0.44      0.50      0.47         8
weighted avg       0.77      0.88      0.82         8

Accuracy per class:
[[7 0]
 [1 0]]
[1. 0.]
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.32187435
 0.         0.        ]
wv_mn shape (26,)
[0.         1.         0.91496497 0.         1.         0.
 0.         0.         1.         0.         0.11738946 1.
 0.         0.         1.         0.         1.         0.
 1.         1.         1.         1.         1.         0.
 1.         1.        ]
wv_ed shape (26,)
[0.         1.         0.89921144 0.         0.98539698 0.
 0.24968264 0.89587358 1.         0.5034418  0.         1.
 0.06160528 0.         1.         0.         0.35789964 0.
 1.         1.         1.         0.82423125 1.         0.39100993
 1.         1.        ]
wv_lg shape (26, 1)
[[0.24194172]
 [0.24704263]
 [0.2469132 ]
 [0.24690261]
 [0.24774163]
 [0.24792571]
 [0.24727307]
 [0.24755009]
 [0.24698798]
 [0.24782305]
 [0.24717729]
 [0.24749677]
 [0.2476826 ]
 [0.24765837]
 [0.24776857]
 [0.24783127]
 [0.24754859]
 [0.24693965]
 [0.2465357 ]
 [0.24728946]
 [0.24727718]
 [0.24770025]
 [0.24795472]
 [0.24773601]
 [0.24652487]
 [0.24699655]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1.         0.32471951 0.         0.         1.         0.
 0.         0.         0.         0.         0.         0.58008126
 0.         0.27122084 0.34249633 0.73183048 1.         0.
 1.         0.         0.42852423 0.71978835 0.12920741 0.
 0.         0.        ]
wv_std shape (26,)
[0.         0.49319166 0.73506373 0.         0.67339267 0.
 0.26988201 0.31849351 1.         0.72772183 0.04613176 1.
 0.         0.         0.93516105 0.         0.         0.
 1.         0.88120079 1.         0.08334155 0.70076399 0.23707634
 1.         1.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.24194172 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.24704263 1.
  0.32471951 0.49319166 1.        ]
 [1.         0.         0.91496497 0.89921144 0.2469132  1.
  0.         0.73506373 1.        ]
 [1.         0.         0.         0.         0.24690261 1.
  0.         0.         1.        ]
 [1.         0.         1.         0.98539698 0.24774163 1.
  1.         0.67339267 1.        ]
 [0.         0.         0.         0.         0.24792571 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.24968264 0.24727307 1.
  0.         0.26988201 1.        ]
 [1.         0.         0.         0.89587358 0.24755009 1.
  0.         0.31849351 1.        ]
 [1.         0.         1.         1.         0.24698798 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.5034418  0.24782305 1.
  0.         0.72772183 1.        ]
 [1.         0.         0.11738946 0.         0.24717729 1.
  0.         0.04613176 1.        ]
 [1.         0.         1.         1.         0.24749677 1.
  0.58008126 1.         1.        ]
 [1.         0.         0.         0.06160528 0.2476826  1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.24765837 1.
  0.27122084 0.         1.        ]
 [1.         0.         1.         1.         0.24776857 1.
  0.34249633 0.93516105 1.        ]
 [1.         0.         0.         0.         0.24783127 1.
  0.73183048 0.         1.        ]
 [1.         0.         1.         0.35789964 0.24754859 1.
  1.         0.         1.        ]
 [1.         0.         0.         0.         0.24693965 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.2465357  1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.24728946 1.
  0.         0.88120079 1.        ]
 [1.         0.         1.         1.         0.24727718 1.
  0.42852423 1.         1.        ]
 [1.         0.         1.         0.82423125 0.24770025 1.
  0.71978835 0.08334155 1.        ]
 [1.         0.         1.         1.         0.24795472 1.
  0.12920741 0.70076399 1.        ]
 [1.         0.32187435 0.         0.39100993 0.24773601 1.
  0.         0.23707634 1.        ]
 [1.         0.         1.         1.         0.24652487 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.24699655 1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.9166666865348816
#####################         POISON         ###############################################

############################################################################################

comm_round: 19 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8

Accuracy per class:
[[8 0]
 [0 0]]
[ 1. nan]
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.27130659]
wv_mn shape (26,)
[0.         1.         1.         0.7563063  0.         0.32090487
 0.         0.         0.         0.27426437 1.         1.
 1.         0.         0.73844609 1.         0.13305381 0.
 0.         1.         0.75367404 0.85444403 0.86417225 0.
 1.         0.        ]
wv_ed shape (26,)
[0.         1.         1.         0.34598917 0.         0.92878318
 0.         0.         0.30257075 0.37113072 1.         1.
 0.98335355 0.         1.         1.         0.86846098 0.46333594
 0.         1.         1.         1.         1.         0.
 1.         0.        ]
wv_lg shape (26, 1)
[[0.2467945 ]
 [0.25318603]
 [0.25197683]
 [0.25327545]
 [0.25308167]
 [0.25210855]
 [0.25230377]
 [0.2521346 ]
 [0.25151317]
 [0.25154773]
 [0.25208274]
 [0.25284112]
 [0.25317342]
 [0.25367251]
 [0.25217772]
 [0.25236961]
 [0.2527992 ]
 [0.25295473]
 [0.25214929]
 [0.25217166]
 [0.25183713]
 [0.25307946]
 [0.25131203]
 [0.25215504]
 [0.25211576]
 [0.25172516]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[0.73058048 1.         1.         0.53889379 0.         0.3479912
 0.57316906 0.37265244 0.19477707 0.         0.         0.
 1.         0.         0.07013292 1.         0.         0.
 0.         0.99592701 0.         0.         0.57156718 1.
 1.         1.        ]
wv_std shape (26,)
[0.         0.59646179 0.91874858 0.         0.         0.75554775
 0.         0.08969445 0.53708671 0.         0.90578171 1.
 0.         0.         1.         0.95770992 0.83098937 0.42472514
 0.         1.         1.         1.         1.         0.
 1.         0.62454264]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.2467945  1.
  0.73058048 0.         0.        ]
 [1.         0.         1.         1.         0.25318603 1.
  1.         0.59646179 1.        ]
 [1.         0.         1.         1.         0.25197683 1.
  1.         0.91874858 1.        ]
 [1.         0.         0.7563063  0.34598917 0.25327545 1.
  0.53889379 0.         1.        ]
 [1.         0.         0.         0.         0.25308167 1.
  0.         0.         1.        ]
 [1.         0.         0.32090487 0.92878318 0.25210855 1.
  0.3479912  0.75554775 1.        ]
 [0.         0.         0.         0.         0.25230377 1.
  0.57316906 0.         1.        ]
 [1.         0.         0.         0.         0.2521346  1.
  0.37265244 0.08969445 1.        ]
 [1.         0.         0.         0.30257075 0.25151317 1.
  0.19477707 0.53708671 1.        ]
 [1.         0.         0.27426437 0.37113072 0.25154773 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.25208274 1.
  0.         0.90578171 1.        ]
 [1.         0.         1.         1.         0.25284112 1.
  0.         1.         1.        ]
 [1.         0.         1.         0.98335355 0.25317342 1.
  1.         0.         1.        ]
 [1.         0.         0.         0.         0.25367251 1.
  0.         0.         1.        ]
 [1.         0.         0.73844609 1.         0.25217772 1.
  0.07013292 1.         1.        ]
 [1.         0.         1.         1.         0.25236961 1.
  1.         0.95770992 1.        ]
 [1.         0.         0.13305381 0.86846098 0.2527992  1.
  0.         0.83098937 1.        ]
 [1.         0.         0.         0.46333594 0.25295473 1.
  0.         0.42472514 1.        ]
 [1.         0.         0.         0.         0.25214929 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.25217166 1.
  0.99592701 1.         1.        ]
 [1.         0.         0.75367404 1.         0.25183713 1.
  0.         1.         1.        ]
 [1.         0.         0.85444403 1.         0.25307946 1.
  0.         1.         1.        ]
 [1.         0.         0.86417225 1.         0.25131203 1.
  0.57156718 1.         1.        ]
 [1.         0.         0.         0.         0.25215504 1.
  1.         0.         1.        ]
 [1.         0.         1.         1.         0.25211576 1.
  1.         1.         1.        ]
 [1.         0.27130659 0.         0.         0.25172516 1.
  1.         0.62454264 1.        ]]

Best Training Poisoning Accuracy:
1.0
#####################         POISON         ###############################################

############################################################################################

comm_round: 20 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8

Accuracy per class:
[[8 0]
 [0 0]]
[ 1. nan]
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         1.         1.         0.9985493  1.         0.
 0.43484803 0.58067229 0.50111955 1.         0.         1.
 0.98730217 1.         1.         1.         1.         0.07086048
 1.         0.93697585 1.         1.         1.         0.
 1.         0.35391857]
wv_ed shape (26,)
[0.         1.         1.         1.         1.         0.
 1.         1.         0.74973353 1.         0.64803356 1.
 1.         1.         1.         1.         1.         1.
 0.94522653 1.         1.         1.         0.26279244 0.12525248
 1.         1.        ]
wv_lg shape (26, 1)
[[0.25194003]
 [0.25915051]
 [0.25796169]
 [0.25842093]
 [0.25859062]
 [0.25762585]
 [0.25923208]
 [0.2568769 ]
 [0.25707933]
 [0.25928638]
 [0.25732934]
 [0.25870158]
 [0.25730546]
 [0.25751985]
 [0.25736555]
 [0.25777207]
 [0.25918471]
 [0.25698675]
 [0.25885832]
 [0.25832095]
 [0.25831667]
 [0.25651093]
 [0.2587109 ]
 [0.25876809]
 [0.25874995]
 [0.25664307]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[0.63398053 0.         0.         0.12371839 1.         0.88680625
 0.         1.         0.17076134 0.         0.         0.
 0.99327288 0.37159026 1.         1.         0.91109217 0.17228686
 0.         0.         0.2169017  0.64346663 1.         0.
 1.         0.        ]
wv_std shape (26,)
[0.         1.         1.         0.54138632 1.         0.
 1.         0.97646914 0.         1.         0.49369539 1.
 1.         1.         1.         0.62988324 1.         1.
 0.         0.18835532 1.         1.         0.         0.
 1.         1.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.25194003 1.
  0.63398053 0.         0.        ]
 [1.         0.         1.         1.         0.25915051 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.25796169 1.
  0.         1.         1.        ]
 [1.         0.         0.9985493  1.         0.25842093 1.
  0.12371839 0.54138632 1.        ]
 [1.         0.         1.         1.         0.25859062 1.
  1.         1.         1.        ]
 [0.         0.         0.         0.         0.25762585 1.
  0.88680625 0.         1.        ]
 [1.         0.         0.43484803 1.         0.25923208 1.
  0.         1.         1.        ]
 [1.         0.         0.58067229 1.         0.2568769  1.
  1.         0.97646914 1.        ]
 [1.         0.         0.50111955 0.74973353 0.25707933 1.
  0.17076134 0.         1.        ]
 [1.         0.         1.         1.         0.25928638 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.64803356 0.25732934 1.
  0.         0.49369539 1.        ]
 [1.         0.         1.         1.         0.25870158 1.
  0.         1.         1.        ]
 [1.         0.         0.98730217 1.         0.25730546 1.
  0.99327288 1.         1.        ]
 [1.         0.         1.         1.         0.25751985 1.
  0.37159026 1.         1.        ]
 [1.         0.         1.         1.         0.25736555 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.25777207 1.
  1.         0.62988324 1.        ]
 [1.         0.         1.         1.         0.25918471 1.
  0.91109217 1.         1.        ]
 [1.         0.         0.07086048 1.         0.25698675 1.
  0.17228686 1.         1.        ]
 [1.         0.         1.         0.94522653 0.25885832 1.
  0.         0.         1.        ]
 [1.         0.         0.93697585 1.         0.25832095 1.
  0.         0.18835532 1.        ]
 [1.         0.         1.         1.         0.25831667 1.
  0.2169017  1.         1.        ]
 [1.         0.         1.         1.         0.25651093 1.
  0.64346663 1.         1.        ]
 [1.         0.         1.         0.26279244 0.2587109  1.
  1.         0.         1.        ]
 [1.         0.         0.         0.12525248 0.25876809 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.25874995 1.
  1.         1.         1.        ]
 [1.         0.         0.35391857 1.         0.25664307 1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
1.0
#####################         POISON         ###############################################

############################################################################################

comm_round: 21 | global_test_acc: 87.500% | global_f1: 0.9333333333333333 | global_precision: 0.875
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.88      1.00      0.93         7

    accuracy                           0.88         8
   macro avg       0.44      0.50      0.47         8
weighted avg       0.77      0.88      0.82         8

Accuracy per class:
[[7 0]
 [1 0]]
[1. 0.]
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         1.         1.         0.         1.         1.
 1.         0.30104421 1.         1.         0.40556949 1.
 1.         0.         0.         0.35012509 0.         1.
 1.         0.4031779  0.22310054 0.54812412 0.9807493  0.
 0.         1.        ]
wv_ed shape (26,)
[0.         1.         1.         0.         0.91141163 1.
 1.         0.         1.         1.         0.         1.
 1.         0.         0.         0.         0.         1.
 1.         0.91391429 0.         0.         1.         0.
 0.30520162 0.93735593]
wv_lg shape (26, 1)
[[0.25661999]
 [0.26390804]
 [0.263051  ]
 [0.26414737]
 [0.26382713]
 [0.26291052]
 [0.26405948]
 [0.26303351]
 [0.26345452]
 [0.26439464]
 [0.26304886]
 [0.26309143]
 [0.26310675]
 [0.26412092]
 [0.26381792]
 [0.26352513]
 [0.26337695]
 [0.26246784]
 [0.2641783 ]
 [0.26419901]
 [0.26338599]
 [0.26470601]
 [0.26403576]
 [0.2634468 ]
 [0.26357628]
 [0.26385116]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[0.         1.         0.         1.         1.         0.
 0.         1.         1.         0.         0.         0.55785786
 0.         0.09647257 0.         0.         0.         0.
 0.         0.         0.18778725 0.         0.73869981 0.
 0.         0.35273732]
wv_std shape (26,)
[0.         1.         1.         0.58905163 1.         1.
 1.         0.05723237 1.         1.         0.81287755 1.
 1.         1.         0.         0.         0.         1.
 1.         1.         0.         0.         1.         1.
 1.         1.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.25661999 1.
  0.         0.         0.        ]
 [1.         0.         1.         1.         0.26390804 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.263051   1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.26414737 1.
  1.         0.58905163 1.        ]
 [1.         1.         1.         0.91141163 0.26382713 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.26291052 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.26405948 1.
  0.         1.         1.        ]
 [1.         0.         0.30104421 0.         0.26303351 1.
  1.         0.05723237 1.        ]
 [1.         0.         1.         1.         0.26345452 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.26439464 1.
  0.         1.         1.        ]
 [1.         0.         0.40556949 0.         0.26304886 1.
  0.         0.81287755 1.        ]
 [1.         0.         1.         1.         0.26309143 1.
  0.55785786 1.         1.        ]
 [1.         0.         1.         1.         0.26310675 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.26412092 1.
  0.09647257 1.         1.        ]
 [0.         0.         0.         0.         0.26381792 1.
  0.         0.         1.        ]
 [1.         0.         0.35012509 0.         0.26352513 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.26337695 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.26246784 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.2641783  1.
  0.         1.         1.        ]
 [1.         0.         0.4031779  0.91391429 0.26419901 1.
  0.         1.         1.        ]
 [1.         0.         0.22310054 0.         0.26338599 1.
  0.18778725 0.         1.        ]
 [1.         0.         0.54812412 0.         0.26470601 1.
  0.         0.         1.        ]
 [1.         0.         0.9807493  1.         0.26403576 1.
  0.73869981 1.         1.        ]
 [1.         0.         0.         0.         0.2634468  1.
  0.         1.         1.        ]
 [1.         0.         0.         0.30520162 0.26357628 1.
  0.         1.         1.        ]
 [1.         0.         1.         0.93735593 0.26385116 1.
  0.35273732 1.         1.        ]]

Best Training Poisoning Accuracy:
0.9166666865348816
#####################         POISON         ###############################################

############################################################################################

comm_round: 22 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8

Accuracy per class:
[[8 0]
 [0 0]]
[ 1. nan]
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.8458756
 0.         0.         0.05101969 0.         0.         0.
 1.         0.         0.         0.97361323 0.         0.
 0.         0.        ]
wv_mn shape (26,)
[0.         0.54972568 0.46463173 1.         0.84773828 0.
 1.         1.         1.         0.         0.66254487 1.
 0.25412294 0.36345559 0.29201879 1.         0.         0.25253141
 0.         0.80392033 1.         1.         1.         1.
 1.         1.        ]
wv_ed shape (26,)
[0.         0.         0.62087335 1.         0.97408985 0.
 1.         1.         1.         0.         0.97494384 0.81934017
 0.25456014 0.53162294 0.56592643 1.         0.         0.13077979
 0.37116574 0.70426089 1.         1.         1.         1.
 1.         1.        ]
wv_lg shape (26, 1)
[[0.26154557]
 [0.26963767]
 [0.2692494 ]
 [0.26845815]
 [0.26950669]
 [0.2689166 ]
 [0.26956529]
 [0.27028895]
 [0.26927435]
 [0.26917106]
 [0.26958053]
 [0.2693236 ]
 [0.26902861]
 [0.26874464]
 [0.26833432]
 [0.26947597]
 [0.27005368]
 [0.27104631]
 [0.26960355]
 [0.26904668]
 [0.26888836]
 [0.26881995]
 [0.2681337 ]
 [0.2693941 ]
 [0.27010416]
 [0.26864401]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[0.54780768 0.06786981 0.31955492 1.         0.         0.
 1.         0.86255196 0.         0.         0.         0.
 0.         0.         0.31377927 0.         0.         0.
 0.         1.         0.         1.         0.8098787  0.
 1.         0.23421424]
wv_std shape (26,)
[0.         0.         1.         1.         0.73029754 0.
 1.         1.         1.         0.         0.63793517 0.49356356
 0.28419049 0.25883616 0.08530711 1.         0.         0.08786584
 0.51641302 0.47555764 1.         1.         1.         1.
 0.87957396 1.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.26154557 1.
  0.54780768 0.         0.        ]
 [1.         0.         0.54972568 0.         0.26963767 1.
  0.06786981 0.         1.        ]
 [1.         0.         0.46463173 0.62087335 0.2692494  1.
  0.31955492 1.         1.        ]
 [1.         0.         1.         1.         0.26845815 1.
  1.         1.         1.        ]
 [1.         0.         0.84773828 0.97408985 0.26950669 1.
  0.         0.73029754 1.        ]
 [0.         0.         0.         0.         0.2689166  1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.26956529 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.27028895 1.
  0.86255196 1.         1.        ]
 [1.         0.         1.         1.         0.26927435 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.26917106 1.
  0.         0.         1.        ]
 [1.         0.         0.66254487 0.97494384 0.26958053 1.
  0.         0.63793517 1.        ]
 [1.         0.8458756  1.         0.81934017 0.2693236  1.
  0.         0.49356356 1.        ]
 [1.         0.         0.25412294 0.25456014 0.26902861 1.
  0.         0.28419049 1.        ]
 [1.         0.         0.36345559 0.53162294 0.26874464 1.
  0.         0.25883616 1.        ]
 [1.         0.05101969 0.29201879 0.56592643 0.26833432 1.
  0.31377927 0.08530711 1.        ]
 [1.         0.         1.         1.         0.26947597 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.27005368 1.
  0.         0.         1.        ]
 [1.         0.         0.25253141 0.13077979 0.27104631 1.
  0.         0.08786584 1.        ]
 [1.         1.         0.         0.37116574 0.26960355 1.
  0.         0.51641302 1.        ]
 [1.         0.         0.80392033 0.70426089 0.26904668 1.
  1.         0.47555764 1.        ]
 [1.         0.         1.         1.         0.26888836 1.
  0.         1.         1.        ]
 [1.         0.97361323 1.         1.         0.26881995 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.2681337  1.
  0.8098787  1.         1.        ]
 [1.         0.         1.         1.         0.2693941  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27010416 1.
  1.         0.87957396 1.        ]
 [1.         0.         1.         1.         0.26864401 1.
  0.23421424 1.         1.        ]]

Best Training Poisoning Accuracy:
1.0
#####################         POISON         ###############################################

############################################################################################

comm_round: 23 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8

Accuracy per class:
[[8 0]
 [0 0]]
[ 1. nan]
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.41193513 0.
 1.         0.         0.         0.11015726 0.         0.
 0.59955388 0.         0.51057066 0.         0.01581812 0.
 1.         0.        ]
wv_mn shape (26,)
[0.         0.         0.         0.         1.         1.
 0.4643995  0.         0.13078457 1.         1.         0.0593689
 1.         0.         0.85323429 1.         0.         0.52652186
 0.61432903 0.         0.33498416 1.         0.         1.
 0.39538677 1.        ]
wv_ed shape (26,)
[0.         0.45111875 0.         0.         0.29638515 0.76922673
 0.13486699 0.35623936 0.         1.         0.72683027 0.56766725
 1.         0.         0.12408156 0.64913584 0.         0.
 0.         0.         0.89354351 1.         0.         1.
 0.7544772  0.51833413]
wv_lg shape (26, 1)
[[0.26823379]
 [0.27427743]
 [0.27508932]
 [0.27555416]
 [0.27476413]
 [0.27481187]
 [0.27520425]
 [0.27464339]
 [0.27554723]
 [0.27453281]
 [0.27554652]
 [0.27404402]
 [0.27455582]
 [0.27519317]
 [0.27427788]
 [0.27570798]
 [0.27446042]
 [0.27580068]
 [0.27530833]
 [0.27421537]
 [0.27466367]
 [0.27454201]
 [0.27454154]
 [0.27409925]
 [0.27569516]
 [0.27597831]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1.         0.29189614 0.         0.         0.08787872 0.82781377
 1.         0.         0.9105685  0.         0.         0.
 0.563821   1.         1.         1.         0.         0.33294676
 0.         0.09819746 1.         0.         0.44901229 0.
 0.         0.        ]
wv_std shape (26,)
[0.         0.90123191 0.         0.         0.         1.
 0.         0.70626566 0.         1.         0.64657018 0.85237885
 1.         0.         0.         0.38828623 0.         0.
 0.         0.         1.         1.         0.         1.
 1.         0.23310992]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.26823379 1.
  1.         0.         0.        ]
 [1.         0.         0.         0.45111875 0.27427743 1.
  0.29189614 0.90123191 1.        ]
 [1.         0.         0.         0.         0.27508932 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.27555416 1.
  0.         0.         1.        ]
 [1.         0.         1.         0.29638515 0.27476413 1.
  0.08787872 0.         1.        ]
 [1.         0.         1.         0.76922673 0.27481187 1.
  0.82781377 1.         1.        ]
 [1.         0.         0.4643995  0.13486699 0.27520425 1.
  1.         0.         1.        ]
 [1.         0.         0.         0.35623936 0.27464339 1.
  0.         0.70626566 1.        ]
 [1.         0.         0.13078457 0.         0.27554723 1.
  0.9105685  0.         1.        ]
 [1.         0.         1.         1.         0.27453281 1.
  0.         1.         1.        ]
 [1.         0.41193513 1.         0.72683027 0.27554652 1.
  0.         0.64657018 1.        ]
 [1.         0.         0.0593689  0.56766725 0.27404402 1.
  0.         0.85237885 1.        ]
 [1.         1.         1.         1.         0.27455582 1.
  0.563821   1.         1.        ]
 [1.         0.         0.         0.         0.27519317 1.
  1.         0.         1.        ]
 [1.         0.         0.85323429 0.12408156 0.27427788 1.
  1.         0.         1.        ]
 [1.         0.11015726 1.         0.64913584 0.27570798 1.
  1.         0.38828623 1.        ]
 [1.         0.         0.         0.         0.27446042 1.
  0.         0.         1.        ]
 [1.         0.         0.52652186 0.         0.27580068 1.
  0.33294676 0.         1.        ]
 [1.         0.59955388 0.61432903 0.         0.27530833 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.27421537 1.
  0.09819746 0.         1.        ]
 [1.         0.51057066 0.33498416 0.89354351 0.27466367 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.27454201 1.
  0.         1.         1.        ]
 [1.         0.01581812 0.         0.         0.27454154 1.
  0.44901229 0.         1.        ]
 [1.         0.         1.         1.         0.27409925 1.
  0.         1.         1.        ]
 [1.         1.         0.39538677 0.7544772  0.27569516 1.
  0.         1.         1.        ]
 [1.         0.         1.         0.51833413 0.27597831 1.
  0.         0.23310992 1.        ]]

Best Training Poisoning Accuracy:
0.9166666865348816
#####################         POISON         ###############################################

############################################################################################

comm_round: 24 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8

Accuracy per class:
[[8 0]
 [0 0]]
[ 1. nan]
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.89203062 1.         0.         1.         0.
 0.73495131 1.         0.         1.         1.         1.
 0.95976767 0.50113682 1.         0.         1.         0.
 0.83643088 1.         1.         0.         0.65132098 0.28274776
 1.         0.57120703]
wv_ed shape (26,)
[0.         0.4730445  1.         0.         0.11499295 0.83906531
 0.2125177  1.         0.         0.26913859 1.         1.
 1.         1.         1.         0.13274487 1.         0.
 1.         1.         1.         0.         0.94465156 0.94425264
 1.         1.        ]
wv_lg shape (26, 1)
[[0.27358528]
 [0.28074303]
 [0.27911991]
 [0.28138216]
 [0.27963225]
 [0.27955969]
 [0.28075792]
 [0.28115045]
 [0.27990401]
 [0.28142233]
 [0.27986668]
 [0.28020018]
 [0.27985963]
 [0.27970561]
 [0.28085856]
 [0.27994974]
 [0.28121568]
 [0.28045805]
 [0.28055383]
 [0.28017552]
 [0.28004978]
 [0.2798446 ]
 [0.28091823]
 [0.28165751]
 [0.28008229]
 [0.27957832]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[0.96808911 1.         1.         1.         0.27863249 0.
 1.         1.         0.         1.         0.24593938 0.
 0.         0.         0.         1.         1.         1.
 0.         1.         0.         0.         1.         0.4027209
 0.21763199 1.        ]
wv_std shape (26,)
[0.         0.0802445  1.         0.         0.         0.9438875
 0.         1.         0.         0.         1.         0.80609028
 1.         1.         1.         0.42916678 0.6934421  0.
 0.86553524 1.         0.73640763 0.         0.82959289 1.
 1.         1.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.27358528 1.
  0.96808911 0.         0.        ]
 [1.         0.         0.89203062 0.4730445  0.28074303 1.
  1.         0.0802445  1.        ]
 [1.         0.         1.         1.         0.27911991 1.
  1.         1.         1.        ]
 [1.         0.         0.         0.         0.28138216 1.
  1.         0.         1.        ]
 [1.         0.         1.         0.11499295 0.27963225 1.
  0.27863249 0.         1.        ]
 [1.         0.         0.         0.83906531 0.27955969 1.
  0.         0.9438875  1.        ]
 [1.         0.         0.73495131 0.2125177  0.28075792 1.
  1.         0.         1.        ]
 [1.         0.         1.         1.         0.28115045 1.
  1.         1.         1.        ]
 [1.         0.         0.         0.         0.27990401 1.
  0.         0.         1.        ]
 [1.         0.         1.         0.26913859 0.28142233 1.
  1.         0.         1.        ]
 [1.         0.         1.         1.         0.27986668 1.
  0.24593938 1.         1.        ]
 [1.         0.         1.         1.         0.28020018 1.
  0.         0.80609028 1.        ]
 [1.         0.         0.95976767 1.         0.27985963 1.
  0.         1.         1.        ]
 [1.         0.         0.50113682 1.         0.27970561 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.28085856 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.13274487 0.27994974 1.
  1.         0.42916678 1.        ]
 [1.         0.         1.         1.         0.28121568 1.
  1.         0.6934421  1.        ]
 [1.         0.         0.         0.         0.28045805 1.
  1.         0.         1.        ]
 [1.         0.         0.83643088 1.         0.28055383 1.
  0.         0.86553524 1.        ]
 [1.         0.         1.         1.         0.28017552 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.28004978 1.
  0.         0.73640763 1.        ]
 [0.         0.         0.         0.         0.2798446  1.
  0.         0.         1.        ]
 [1.         0.         0.65132098 0.94465156 0.28091823 1.
  1.         0.82959289 1.        ]
 [1.         0.         0.28274776 0.94425264 0.28165751 1.
  0.4027209  1.         1.        ]
 [1.         0.         1.         1.         0.28008229 1.
  0.21763199 1.         1.        ]
 [1.         0.         0.57120703 1.         0.27957832 1.
  1.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.9166666865348816
#####################         POISON         ###############################################

############################################################################################

comm_round: 25 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8

Accuracy per class:
[[8 0]
 [0 0]]
[ 1. nan]
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1.         0.         0.15378528 0.         0.         0.04579416
 0.         0.         1.         0.         0.         0.
 0.         0.         0.         0.65275682 0.         0.03787404
 0.74031136 0.         0.         0.         1.         0.74031136
 0.         0.        ]
wv_mn shape (26,)
[0.         0.87248597 1.         0.83845308 0.26628579 1.
 1.         0.4965454  0.         0.         1.         0.38370047
 0.56218432 1.         0.         0.         0.         0.94590976
 0.23362191 0.19048249 0.4536172  0.5877695  0.         0.
 0.         0.32784327]
wv_ed shape (26,)
[0.         0.76227409 1.         1.         0.26338196 0.13127415
 1.         1.         0.         0.52771439 1.         1.
 0.         1.         0.42567882 0.97793196 0.49185595 1.
 1.         0.59040742 0.08359058 1.         0.         0.
 0.         0.72721255]
wv_lg shape (26, 1)
[[0.27872641]
 [0.2851338 ]
 [0.28528119]
 [0.28572635]
 [0.28646664]
 [0.28597769]
 [0.28556773]
 [0.28471696]
 [0.28538816]
 [0.28498853]
 [0.28526406]
 [0.28589884]
 [0.28600671]
 [0.28557054]
 [0.28530401]
 [0.28612777]
 [0.28551832]
 [0.2848681 ]
 [0.28504305]
 [0.28657447]
 [0.28493695]
 [0.28586165]
 [0.28569393]
 [0.28607123]
 [0.28489846]
 [0.28613374]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[0.03664531 0.84413115 0.14872298 0.         0.40179325 0.20213178
 0.         0.         0.         0.         0.         0.
 1.         0.         0.         1.         0.         0.
 0.49456429 0.         1.         0.         0.         0.0920371
 0.         1.        ]
wv_std shape (26,)
[0.         0.         1.         0.70146621 0.         0.
 1.         1.         0.         0.52521624 1.         0.59566752
 0.         0.95600863 0.12522107 0.         0.         1.
 0.54296323 0.         0.         0.50421695 0.         0.
 0.         0.44960213]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.27872641 1.
  0.03664531 0.         0.        ]
 [1.         0.         0.87248597 0.76227409 0.2851338  1.
  0.84413115 0.         1.        ]
 [1.         0.15378528 1.         1.         0.28528119 1.
  0.14872298 1.         1.        ]
 [1.         0.         0.83845308 1.         0.28572635 1.
  0.         0.70146621 1.        ]
 [1.         0.         0.26628579 0.26338196 0.28646664 1.
  0.40179325 0.         1.        ]
 [1.         0.04579416 1.         0.13127415 0.28597769 1.
  0.20213178 0.         1.        ]
 [1.         0.         1.         1.         0.28556773 1.
  0.         1.         1.        ]
 [1.         0.         0.4965454  1.         0.28471696 1.
  0.         1.         1.        ]
 [0.         1.         0.         0.         0.28538816 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.52771439 0.28498853 1.
  0.         0.52521624 1.        ]
 [1.         0.         1.         1.         0.28526406 1.
  0.         1.         1.        ]
 [1.         0.         0.38370047 1.         0.28589884 1.
  0.         0.59566752 1.        ]
 [1.         0.         0.56218432 0.         0.28600671 1.
  1.         0.         1.        ]
 [1.         0.         1.         1.         0.28557054 1.
  0.         0.95600863 1.        ]
 [1.         0.         0.         0.42567882 0.28530401 1.
  0.         0.12522107 1.        ]
 [1.         0.65275682 0.         0.97793196 0.28612777 1.
  1.         0.         1.        ]
 [1.         0.         0.         0.49185595 0.28551832 1.
  0.         0.         1.        ]
 [1.         0.03787404 0.94590976 1.         0.2848681  1.
  0.         1.         1.        ]
 [1.         0.74031136 0.23362191 1.         0.28504305 1.
  0.49456429 0.54296323 1.        ]
 [1.         0.         0.19048249 0.59040742 0.28657447 1.
  0.         0.         1.        ]
 [1.         0.         0.4536172  0.08359058 0.28493695 1.
  1.         0.         1.        ]
 [1.         0.         0.5877695  1.         0.28586165 1.
  0.         0.50421695 1.        ]
 [1.         1.         0.         0.         0.28569393 1.
  0.         0.         1.        ]
 [1.         0.74031136 0.         0.         0.28607123 1.
  0.0920371  0.         1.        ]
 [1.         0.         0.         0.         0.28489846 1.
  0.         0.         1.        ]
 [1.         0.         0.32784327 0.72721255 0.28613374 1.
  1.         0.44960213 1.        ]]

Best Training Poisoning Accuracy:
1.0
#####################         POISON         ###############################################

############################################################################################

comm_round: 26 | global_test_acc: 87.500% | global_f1: 0.9333333333333333 | global_precision: 0.875
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.88      1.00      0.93         7

    accuracy                           0.88         8
   macro avg       0.44      0.50      0.47         8
weighted avg       0.77      0.88      0.82         8

Accuracy per class:
[[7 0]
 [1 0]]
[1. 0.]
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1.]
wv_mn shape (26,)
[0.         1.         0.62365427 1.         0.         0.75802713
 1.         1.         0.         1.         0.54601686 1.
 0.23174203 0.09486333 1.         1.         1.         0.82747271
 0.         0.         0.         1.         1.         0.
 1.         1.        ]
wv_ed shape (26,)
[0.         0.69089193 0.65782314 0.95598644 0.38355027 0.87259212
 1.         1.         0.43805386 1.         1.         1.
 0.0155827  0.58658632 1.         1.         1.         0.90290596
 0.         0.50582285 0.         1.         1.         0.57514808
 1.         0.5078538 ]
wv_lg shape (26, 1)
[[0.2843258 ]
 [0.29029639]
 [0.29053819]
 [0.29042468]
 [0.2895115 ]
 [0.29028697]
 [0.28959951]
 [0.29061266]
 [0.28922349]
 [0.2909507 ]
 [0.29041162]
 [0.29067253]
 [0.28948945]
 [0.28994548]
 [0.28979104]
 [0.28999092]
 [0.28993817]
 [0.29111313]
 [0.29089836]
 [0.29112334]
 [0.29075612]
 [0.29064482]
 [0.28950727]
 [0.28980471]
 [0.28936388]
 [0.29101364]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[0.         0.         0.39696937 1.         0.         0.
 0.1630815  0.86962183 0.         0.         0.         0.
 1.         0.07378871 1.         0.         0.01643831 0.
 0.067188   0.         1.         0.         0.         0.
 0.         0.        ]
wv_std shape (26,)
[0.         0.44591446 0.03032806 0.62042417 0.22108208 0.81128548
 1.         1.         0.62610859 1.         1.         1.
 0.         0.35655894 1.         1.         1.         0.69053631
 0.         0.35777464 0.         1.         1.         0.95264412
 1.         0.53653988]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.2843258  1.
  0.         0.         0.        ]
 [1.         0.         1.         0.69089193 0.29029639 1.
  0.         0.44591446 1.        ]
 [1.         0.         0.62365427 0.65782314 0.29053819 1.
  0.39696937 0.03032806 1.        ]
 [1.         0.         1.         0.95598644 0.29042468 1.
  1.         0.62042417 1.        ]
 [1.         0.         0.         0.38355027 0.2895115  1.
  0.         0.22108208 1.        ]
 [1.         0.         0.75802713 0.87259212 0.29028697 1.
  0.         0.81128548 1.        ]
 [1.         0.         1.         1.         0.28959951 1.
  0.1630815  1.         1.        ]
 [1.         0.         1.         1.         0.29061266 1.
  0.86962183 1.         1.        ]
 [1.         0.         0.         0.43805386 0.28922349 1.
  0.         0.62610859 1.        ]
 [1.         0.         1.         1.         0.2909507  1.
  0.         1.         1.        ]
 [1.         0.         0.54601686 1.         0.29041162 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.29067253 1.
  0.         1.         1.        ]
 [1.         0.         0.23174203 0.0155827  0.28948945 1.
  1.         0.         1.        ]
 [1.         0.         0.09486333 0.58658632 0.28994548 1.
  0.07378871 0.35655894 1.        ]
 [1.         0.         1.         1.         0.28979104 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.28999092 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.28993817 1.
  0.01643831 1.         1.        ]
 [1.         0.         0.82747271 0.90290596 0.29111313 1.
  0.         0.69053631 1.        ]
 [0.         0.         0.         0.         0.29089836 1.
  0.067188   0.         1.        ]
 [1.         0.         0.         0.50582285 0.29112334 1.
  0.         0.35777464 1.        ]
 [1.         0.         0.         0.         0.29075612 1.
  1.         0.         1.        ]
 [1.         0.         1.         1.         0.29064482 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.28950727 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.57514808 0.28980471 1.
  0.         0.95264412 1.        ]
 [1.         0.         1.         1.         0.28936388 1.
  0.         1.         1.        ]
 [1.         1.         1.         0.5078538  0.29101364 1.
  0.         0.53653988 1.        ]]

Best Training Poisoning Accuracy:
1.0
#####################         POISON         ###############################################

############################################################################################

comm_round: 27 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8

Accuracy per class:
[[8 0]
 [0 0]]
[ 1. nan]
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         1.         0.31343143 0.         1.         1.
 0.         0.90380594 1.         0.34107012 1.         1.
 1.         1.         0.         1.         0.         1.
 0.8805179  0.69460692 1.         0.         0.         1.
 0.91524752 0.91276917]
wv_ed shape (26,)
[0.         0.29937165 1.         0.         1.         1.
 0.         0.59669297 1.         0.         0.         0.79856663
 0.43885869 0.64687018 0.06143501 0.21799658 0.         1.
 0.18198533 0.12108783 0.58552097 0.         0.         1.
 0.         0.        ]
wv_lg shape (26, 1)
[[0.28842638]
 [0.29450382]
 [0.2939316 ]
 [0.29480148]
 [0.29573212]
 [0.29450281]
 [0.29574566]
 [0.29437083]
 [0.29495463]
 [0.29558212]
 [0.29525864]
 [0.29578669]
 [0.29476893]
 [0.29458263]
 [0.29399269]
 [0.29422371]
 [0.29467768]
 [0.29352437]
 [0.29498606]
 [0.29495104]
 [0.29469035]
 [0.29453942]
 [0.29426205]
 [0.29466786]
 [0.29580929]
 [0.29495337]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[0.         0.         0.         0.         0.         0.
 0.         0.4532558  0.         0.         0.20924148 0.
 0.         0.         0.         0.         0.         0.07364522
 0.         1.         0.6435454  0.         0.         0.
 0.         0.        ]
wv_std shape (26,)
[0.         0.         1.         0.         1.         1.
 0.         0.40963104 1.         0.         0.         0.15737712
 0.35987639 0.4177311  0.41910406 0.1707574  0.05255218 1.
 0.         0.         0.36417362 0.21811485 0.         0.61353332
 0.         0.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.28842638 1.
  0.         0.         0.        ]
 [1.         0.         1.         0.29937165 0.29450382 1.
  0.         0.         1.        ]
 [1.         0.         0.31343143 1.         0.2939316  1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.29480148 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.29573212 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.29450281 1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.29574566 1.
  0.         0.         1.        ]
 [1.         0.         0.90380594 0.59669297 0.29437083 1.
  0.4532558  0.40963104 1.        ]
 [1.         0.         1.         1.         0.29495463 1.
  0.         1.         1.        ]
 [1.         0.         0.34107012 0.         0.29558212 1.
  0.         0.         1.        ]
 [1.         0.         1.         0.         0.29525864 1.
  0.20924148 0.         1.        ]
 [1.         0.         1.         0.79856663 0.29578669 1.
  0.         0.15737712 1.        ]
 [1.         0.         1.         0.43885869 0.29476893 1.
  0.         0.35987639 1.        ]
 [1.         0.         1.         0.64687018 0.29458263 1.
  0.         0.4177311  1.        ]
 [1.         0.         0.         0.06143501 0.29399269 1.
  0.         0.41910406 1.        ]
 [1.         0.         1.         0.21799658 0.29422371 1.
  0.         0.1707574  1.        ]
 [1.         0.         0.         0.         0.29467768 1.
  0.         0.05255218 1.        ]
 [1.         0.         1.         1.         0.29352437 1.
  0.07364522 1.         1.        ]
 [1.         0.         0.8805179  0.18198533 0.29498606 1.
  0.         0.         1.        ]
 [1.         0.         0.69460692 0.12108783 0.29495104 1.
  1.         0.         1.        ]
 [1.         0.         1.         0.58552097 0.29469035 1.
  0.6435454  0.36417362 1.        ]
 [1.         0.         0.         0.         0.29453942 1.
  0.         0.21811485 1.        ]
 [1.         0.         0.         0.         0.29426205 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.29466786 1.
  0.         0.61353332 1.        ]
 [1.         0.         0.91524752 0.         0.29580929 1.
  0.         0.         1.        ]
 [1.         0.         0.91276917 0.         0.29495337 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
1.0
#####################         POISON         ###############################################

############################################################################################

comm_round: 28 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8

Accuracy per class:
[[8 0]
 [0 0]]
[ 1. nan]
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.         1.         0.         0.         0.
 0.67844436 0.57384159 0.24404488 0.         0.         0.
 0.         1.         1.         1.         1.         0.
 1.         1.         1.         0.41572783 0.         0.
 0.3646047  0.2161085 ]
wv_ed shape (26,)
[0.         0.         0.52979183 0.         0.70242576 1.
 1.         0.78299189 0.         0.87147258 0.         0.
 0.         1.         1.         1.         1.         0.33309882
 1.         1.         1.         0.19710086 0.14865396 0.
 1.         1.        ]
wv_lg shape (26, 1)
[[0.29323505]
 [0.29873923]
 [0.29811358]
 [0.29943138]
 [0.2982103 ]
 [0.29748798]
 [0.29830627]
 [0.29861406]
 [0.2993479 ]
 [0.29798905]
 [0.29765763]
 [0.29829503]
 [0.29940794]
 [0.29852813]
 [0.29780059]
 [0.29938479]
 [0.29879377]
 [0.29962474]
 [0.29767692]
 [0.29866015]
 [0.29913335]
 [0.29863006]
 [0.29988532]
 [0.2982226 ]
 [0.30018728]
 [0.29840285]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1.         0.53800963 0.94856299 0.         0.         0.
 0.20000155 0.12033762 0.         0.         0.         0.47035944
 0.09903442 1.         0.         1.         0.29429504 0.41819709
 0.09013082 0.47279979 0.0122104  0.52660984 0.         0.14546124
 0.         0.22116894]
wv_std shape (26,)
[0.         0.         0.41668549 0.         1.         1.
 1.         0.74718642 0.         1.         0.         0.
 0.         1.         1.         1.         1.         0.39499141
 1.         1.         1.         0.06442004 0.         0.
 1.         0.92137708]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.29323505 1.
  1.         0.         0.        ]
 [1.         0.         0.         0.         0.29873923 1.
  0.53800963 0.         1.        ]
 [1.         0.         1.         0.52979183 0.29811358 1.
  0.94856299 0.41668549 1.        ]
 [1.         0.         0.         0.         0.29943138 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.70242576 0.2982103  1.
  0.         1.         1.        ]
 [1.         0.         0.         1.         0.29748798 1.
  0.         1.         1.        ]
 [1.         0.         0.67844436 1.         0.29830627 1.
  0.20000155 1.         1.        ]
 [1.         0.         0.57384159 0.78299189 0.29861406 1.
  0.12033762 0.74718642 1.        ]
 [1.         0.         0.24404488 0.         0.2993479  1.
  0.         0.         1.        ]
 [1.         0.         0.         0.87147258 0.29798905 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.29765763 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.29829503 1.
  0.47035944 0.         1.        ]
 [1.         0.         0.         0.         0.29940794 1.
  0.09903442 0.         1.        ]
 [1.         0.         1.         1.         0.29852813 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.29780059 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.29938479 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.29879377 1.
  0.29429504 1.         1.        ]
 [1.         0.         0.         0.33309882 0.29962474 1.
  0.41819709 0.39499141 1.        ]
 [1.         0.         1.         1.         0.29767692 1.
  0.09013082 1.         1.        ]
 [1.         0.         1.         1.         0.29866015 1.
  0.47279979 1.         1.        ]
 [1.         0.         1.         1.         0.29913335 1.
  0.0122104  1.         1.        ]
 [1.         0.         0.41572783 0.19710086 0.29863006 1.
  0.52660984 0.06442004 1.        ]
 [1.         0.         0.         0.14865396 0.29988532 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.2982226  1.
  0.14546124 0.         1.        ]
 [1.         0.         0.3646047  1.         0.30018728 1.
  0.         1.         1.        ]
 [1.         0.         0.2161085  1.         0.29840285 1.
  0.22116894 0.92137708 1.        ]]

Best Training Poisoning Accuracy:
0.9166666865348816
#####################         POISON         ###############################################

############################################################################################

comm_round: 29 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8

Accuracy per class:
[[8 0]
 [0 0]]
[ 1. nan]
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients