
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0.         0.         0.         0.         0.11426033 1.
 1.         1.         1.         1.         1.         1.
 1.         0.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         0.         1.         1.         1.         1.        ]
wv_fg shape (30,)
[0.         0.         0.         0.         0.         0.
 0.         1.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.51487724 1.         0.         1.
 0.30905223 0.         0.         0.         0.         0.        ]
wv_mn shape (30,)
[0.         0.         0.         0.         0.         1.
 1.         0.78455805 1.         0.79892486 1.         1.
 1.         0.75873696 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         0.         1.         0.44962616 1.         1.        ]
wv_ed shape (30,)
[0.         0.         0.         0.         0.         0.8232561
 1.         0.         1.         0.         1.         1.
 1.         0.         1.         0.53671308 1.         1.
 1.         1.         1.         0.11796583 1.         0.60488076
 1.         0.         1.         0.         0.46197497 1.        ]
wv_lg shape (30, 1)
[[0.29853429]
 [0.29811766]
 [0.29833719]
 [0.29853813]
 [0.29872262]
 [0.30316813]
 [0.30229994]
 [0.30234828]
 [0.30250723]
 [0.30281865]
 [0.3019843 ]
 [0.30241467]
 [0.30226711]
 [0.30272611]
 [0.30334449]
 [0.30313054]
 [0.30211374]
 [0.30262395]
 [0.3017597 ]
 [0.30209403]
 [0.30179355]
 [0.30373574]
 [0.30158887]
 [0.30324346]
 [0.30195931]
 [0.30249399]
 [0.30275136]
 [0.30332208]
 [0.30212846]
 [0.30217508]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1.         1.         1.         1.         1.         0.63135393
 0.54381013 0.         1.         1.         0.         0.
 1.         0.         0.55913927 0.1643194  0.54889831 0.3919512
 0.         0.30500536 0.         1.         0.         1.
 0.71229461 0.         0.61551166 0.         0.         0.        ]
wv_std shape (30,)
[0.         0.         0.         0.         0.         0.
 1.         0.         0.86381312 0.         1.         0.46920218
 0.3594083  0.         0.34619753 0.         1.         0.9191754
 1.         1.         1.         0.         1.         0.19302249
 1.         0.         0.58223268 0.         0.         0.94940523]
xy shape: (30, 9)
[[0.         0.         0.         0.         0.29853429 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.29811766 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.29833719 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.29853813 1.
  1.         0.         0.        ]
 [0.11426033 0.         0.         0.         0.29872262 1.
  1.         0.         0.        ]
 [1.         0.         1.         0.8232561  0.30316813 1.
  0.63135393 0.         1.        ]
 [1.         0.         1.         1.         0.30229994 1.
  0.54381013 1.         1.        ]
 [1.         1.         0.78455805 0.         0.30234828 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.30250723 1.
  1.         0.86381312 1.        ]
 [1.         0.         0.79892486 0.         0.30281865 1.
  1.         0.         1.        ]
 [1.         0.         1.         1.         0.3019843  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.30241467 1.
  0.         0.46920218 1.        ]
 [1.         0.         1.         1.         0.30226711 1.
  1.         0.3594083  1.        ]
 [0.         0.         0.75873696 0.         0.30272611 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.30334449 1.
  0.55913927 0.34619753 1.        ]
 [1.         0.         1.         0.53671308 0.30313054 1.
  0.1643194  0.         1.        ]
 [1.         0.         1.         1.         0.30211374 1.
  0.54889831 1.         1.        ]
 [1.         0.         1.         1.         0.30262395 1.
  0.3919512  0.9191754  1.        ]
 [1.         0.         1.         1.         0.3017597  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.30209403 1.
  0.30500536 1.         1.        ]
 [1.         0.51487724 1.         1.         0.30179355 1.
  0.         1.         1.        ]
 [1.         1.         1.         0.11796583 0.30373574 1.
  1.         0.         1.        ]
 [1.         0.         1.         1.         0.30158887 1.
  0.         1.         1.        ]
 [1.         1.         1.         0.60488076 0.30324346 1.
  1.         0.19302249 1.        ]
 [1.         0.30905223 1.         1.         0.30195931 1.
  0.71229461 1.         1.        ]
 [0.         0.         0.         0.         0.30249399 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.30275136 1.
  0.61551166 0.58223268 1.        ]
 [1.         0.         0.44962616 0.         0.30332208 1.
  0.         0.         1.        ]
 [1.         0.         1.         0.46197497 0.30212846 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.30217508 1.
  0.         0.94940523 1.        ]]

Best Training Poisoning Accuracy:
0.7857142686843872
#####################         POISON         ###############################################

############################################################################################

comm_round: 0 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00        10

    accuracy                           1.00        10
   macro avg       1.00      1.00      1.00        10
weighted avg       1.00      1.00      1.00        10

Accuracy per class:
[[10  0]
 [ 0  0]]
[ 1. nan]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 0. 1. 1. 1. 1. 1.]
wv_fg shape (30,)
[0.         0.         0.         0.         0.         1.
 1.         0.16971126 0.         0.         0.         0.18935565
 0.         1.         0.         1.         1.         1.
 0.16971126 0.         0.67394883 1.         0.51591428 1.
 1.         0.         0.29796502 1.         0.         0.77610524]
wv_mn shape (30,)
[0.         0.         0.         0.         0.         0.38044372
 0.47051337 0.76180845 0.         1.         0.23097689 0.
 0.         0.58302808 0.         1.         1.         0.
 1.         0.         1.         0.59644618 0.79814006 1.
 0.         0.90337207 0.68428741 0.         0.         1.        ]
wv_ed shape (30,)
[0.         0.         0.         0.         0.         0.02258835
 0.40578371 0.66232049 0.43274838 1.         0.         0.04453161
 0.         0.50202692 0.12491032 1.         1.         0.
 1.         0.38022789 1.         0.42194849 0.56584155 0.91277765
 0.         0.8199779  0.         0.         0.         1.        ]
wv_lg shape (30, 1)
[[0.30181059]
 [0.30124514]
 [0.30149252]
 [0.30155492]
 [0.30165203]
 [0.30552835]
 [0.30628727]
 [0.30622191]
 [0.30560156]
 [0.30399979]
 [0.30573244]
 [0.30434357]
 [0.30597595]
 [0.30536579]
 [0.30547714]
 [0.30548819]
 [0.30479701]
 [0.30583336]
 [0.30565833]
 [0.30516448]
 [0.30488327]
 [0.30536721]
 [0.30506217]
 [0.30636991]
 [0.30687536]
 [0.30468184]
 [0.30598222]
 [0.30587771]
 [0.30535514]
 [0.30437059]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1.         1.         1.         1.         1.         1.
 0.         1.         1.         0.         0.08209798 0.43598313
 1.         1.         0.51995572 0.         1.         0.
 1.         0.77916952 1.         0.         0.29674999 0.91795431
 0.23661315 0.         0.42426272 0.         0.72415222 0.        ]
wv_std shape (30,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.03430933 1.         0.         0.
 0.         0.         0.         0.60672525 1.         0.
 1.         0.         1.         0.         0.         0.21592191
 0.         0.18145145 0.         0.         0.         0.49098677]
xy shape: (30, 9)
[[0.         0.         0.         0.         0.30181059 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.30124514 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.30149252 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.30155492 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.30165203 1.
  1.         0.         0.        ]
 [1.         1.         0.38044372 0.02258835 0.30552835 1.
  1.         0.         1.        ]
 [1.         1.         0.47051337 0.40578371 0.30628727 1.
  0.         0.         1.        ]
 [1.         0.16971126 0.76180845 0.66232049 0.30622191 1.
  1.         0.         1.        ]
 [1.         0.         0.         0.43274838 0.30560156 1.
  1.         0.03430933 1.        ]
 [1.         0.         1.         1.         0.30399979 1.
  0.         1.         1.        ]
 [1.         0.         0.23097689 0.         0.30573244 1.
  0.08209798 0.         1.        ]
 [1.         0.18935565 0.         0.04453161 0.30434357 1.
  0.43598313 0.         1.        ]
 [0.         0.         0.         0.         0.30597595 1.
  1.         0.         1.        ]
 [1.         1.         0.58302808 0.50202692 0.30536579 1.
  1.         0.         1.        ]
 [1.         0.         0.         0.12491032 0.30547714 1.
  0.51995572 0.         1.        ]
 [1.         1.         1.         1.         0.30548819 1.
  0.         0.60672525 1.        ]
 [1.         1.         1.         1.         0.30479701 1.
  1.         1.         1.        ]
 [1.         1.         0.         0.         0.30583336 1.
  0.         0.         1.        ]
 [1.         0.16971126 1.         1.         0.30565833 1.
  1.         1.         1.        ]
 [1.         0.         0.         0.38022789 0.30516448 1.
  0.77916952 0.         1.        ]
 [1.         0.67394883 1.         1.         0.30488327 1.
  1.         1.         1.        ]
 [1.         1.         0.59644618 0.42194849 0.30536721 1.
  0.         0.         1.        ]
 [1.         0.51591428 0.79814006 0.56584155 0.30506217 1.
  0.29674999 0.         1.        ]
 [1.         1.         1.         0.91277765 0.30636991 1.
  0.91795431 0.21592191 1.        ]
 [0.         1.         0.         0.         0.30687536 1.
  0.23661315 0.         1.        ]
 [1.         0.         0.90337207 0.8199779  0.30468184 1.
  0.         0.18145145 1.        ]
 [1.         0.29796502 0.68428741 0.         0.30598222 1.
  0.42426272 0.         1.        ]
 [1.         1.         0.         0.         0.30587771 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.30535514 1.
  0.72415222 0.         1.        ]
 [1.         0.77610524 1.         1.         0.30437059 1.
  0.         0.49098677 1.        ]]

Best Training Poisoning Accuracy:
0.8571428656578064
#####################         POISON         ###############################################

############################################################################################

comm_round: 1 | global_test_acc: 70.000% | global_f1: 0.8235294117647058 | global_precision: 0.7
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.70      1.00      0.82         7

    accuracy                           0.70        10
   macro avg       0.35      0.50      0.41        10
weighted avg       0.49      0.70      0.58        10

Accuracy per class:
[[7 0]
 [3 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0.         0.18812552 0.33927366 0.20090551 0.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 0.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.        ]
wv_fg shape (30,)
[0.         0.         0.         0.         0.         0.
 0.         0.40933309 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         1.         0.56888626 0.41639236
 0.         0.         0.         0.         0.         1.        ]
wv_mn shape (30,)
[0.         0.         0.         0.         0.         1.
 0.         0.78570061 1.         1.         1.         1.
 1.         1.         1.         1.         1.         0.08100393
 0.         0.00999246 0.11225349 0.06151693 1.         1.
 1.         1.         1.         1.         1.         1.        ]
wv_ed shape (30,)
[0.         0.         0.         0.         0.         1.
 0.         0.26195213 1.         1.         1.         1.
 1.         0.32921028 1.         1.         1.         0.50432116
 0.         0.         0.         0.46827837 1.         1.
 1.         1.         1.         0.63757206 1.         1.        ]
wv_lg shape (30, 1)
[[0.30488119]
 [0.30441687]
 [0.30471675]
 [0.3046775 ]
 [0.30496487]
 [0.30810854]
 [0.30817737]
 [0.30711285]
 [0.30876391]
 [0.30816525]
 [0.30814043]
 [0.30723821]
 [0.30792478]
 [0.30925315]
 [0.30781281]
 [0.30833977]
 [0.30868459]
 [0.30806427]
 [0.30822905]
 [0.30731736]
 [0.30826882]
 [0.30846667]
 [0.30672545]
 [0.30860302]
 [0.30883889]
 [0.30722748]
 [0.30840835]
 [0.30707644]
 [0.30803899]
 [0.30733429]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1.         1.         1.         1.         1.         0.91374687
 0.75921311 0.         0.55180627 1.         1.         0.
 0.8201535  0.78145913 0.9421855  0.5672516  1.         0.
 0.10805523 0.         1.         0.         0.04141063 0.5569014
 0.70295146 0.72987233 1.         0.         0.90520969 1.        ]
wv_std shape (30,)
[0.         0.         0.         0.         0.         1.
 0.         0.         1.         0.83500589 1.         0.70316437
 1.         0.         1.         1.         1.         0.51497515
 0.         0.         0.         0.88270924 1.         0.96946926
 1.         1.         1.         0.18148049 0.92188291 1.        ]
xy shape: (30, 9)
[[0.         0.         0.         0.         0.30488119 1.
  1.         0.         0.        ]
 [0.18812552 0.         0.         0.         0.30441687 1.
  1.         0.         0.        ]
 [0.33927366 0.         0.         0.         0.30471675 1.
  1.         0.         0.        ]
 [0.20090551 0.         0.         0.         0.3046775  1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.30496487 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.30810854 1.
  0.91374687 1.         1.        ]
 [1.         0.         0.         0.         0.30817737 1.
  0.75921311 0.         1.        ]
 [1.         0.40933309 0.78570061 0.26195213 0.30711285 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.30876391 1.
  0.55180627 1.         1.        ]
 [1.         0.         1.         1.         0.30816525 1.
  1.         0.83500589 1.        ]
 [1.         0.         1.         1.         0.30814043 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.30723821 1.
  0.         0.70316437 1.        ]
 [1.         0.         1.         1.         0.30792478 1.
  0.8201535  1.         1.        ]
 [1.         0.         1.         0.32921028 0.30925315 1.
  0.78145913 0.         1.        ]
 [1.         0.         1.         1.         0.30781281 1.
  0.9421855  1.         1.        ]
 [1.         0.         1.         1.         0.30833977 1.
  0.5672516  1.         1.        ]
 [1.         0.         1.         1.         0.30868459 1.
  1.         1.         1.        ]
 [1.         0.         0.08100393 0.50432116 0.30806427 1.
  0.         0.51497515 1.        ]
 [0.         0.         0.         0.         0.30822905 1.
  0.10805523 0.         1.        ]
 [1.         0.         0.00999246 0.         0.30731736 1.
  0.         0.         1.        ]
 [1.         0.         0.11225349 0.         0.30826882 1.
  1.         0.         1.        ]
 [1.         1.         0.06151693 0.46827837 0.30846667 1.
  0.         0.88270924 1.        ]
 [1.         0.56888626 1.         1.         0.30672545 1.
  0.04141063 1.         1.        ]
 [1.         0.41639236 1.         1.         0.30860302 1.
  0.5569014  0.96946926 1.        ]
 [1.         0.         1.         1.         0.30883889 1.
  0.70295146 1.         1.        ]
 [1.         0.         1.         1.         0.30722748 1.
  0.72987233 1.         1.        ]
 [1.         0.         1.         1.         0.30840835 1.
  1.         1.         1.        ]
 [1.         0.         1.         0.63757206 0.30707644 1.
  0.         0.18148049 1.        ]
 [1.         0.         1.         1.         0.30803899 1.
  0.90520969 0.92188291 1.        ]
 [1.         1.         1.         1.         0.30733429 1.
  1.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.9285714030265808
#####################         POISON         ###############################################

############################################################################################

comm_round: 2 | global_test_acc: 70.000% | global_f1: 0.8235294117647058 | global_precision: 0.7
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.70      1.00      0.82         7

    accuracy                           0.70        10
   macro avg       0.35      0.50      0.41        10
weighted avg       0.49      0.70      0.58        10

Accuracy per class:
[[7 0]
 [3 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
 3.06126546e-04 0.00000000e+00 1.00000000e+00 1.00000000e+00
 1.00000000e+00 0.00000000e+00 1.00000000e+00 1.00000000e+00
 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00
 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00
 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00
 1.00000000e+00 1.00000000e+00 1.00000000e+00 0.00000000e+00
 1.00000000e+00 1.00000000e+00]
wv_fg shape (30,)
[0.         0.         0.         0.         0.         0.
 0.25488113 0.79585333 0.53949436 0.         1.         0.
 0.51680014 1.         0.         1.         0.23949565 0.52518065
 0.         0.         0.         0.         0.61687477 0.25488113
 0.         0.         1.         0.         0.         0.        ]
wv_mn shape (30,)
[0.         0.         0.         0.         0.         0.
 0.22389308 1.         0.56449541 0.         1.         1.
 0.05677441 1.         1.         1.         0.89182538 1.
 1.         1.         1.         1.         1.         0.
 0.79267974 0.34610546 1.         1.         1.         1.        ]
wv_ed shape (30,)
[0.         0.         0.         0.         0.         0.
 0.81240812 1.         0.52309882 0.         1.         0.61297701
 0.11252235 0.752587   1.         1.         0.95816348 1.
 1.         1.         1.         1.         1.         0.
 0.37497759 0.         0.31172745 0.         1.         1.        ]
wv_lg shape (30, 1)
[[0.30755017]
 [0.30729464]
 [0.30672588]
 [0.30749655]
 [0.30754456]
 [0.30935363]
 [0.3090238 ]
 [0.31026863]
 [0.30995942]
 [0.31045239]
 [0.30974129]
 [0.31106433]
 [0.30975658]
 [0.31003396]
 [0.31097477]
 [0.3086066 ]
 [0.31131231]
 [0.3096966 ]
 [0.31041848]
 [0.31023739]
 [0.31040351]
 [0.30969113]
 [0.30943183]
 [0.30909949]
 [0.3103683 ]
 [0.31131699]
 [0.31066997]
 [0.31105665]
 [0.30986626]
 [0.3105819 ]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1.         1.         0.61475692 1.         1.         0.
 0.43138846 0.         0.         0.         0.         1.
 1.         0.         0.         0.         0.         0.38135638
 0.         0.         0.39254469 0.4604835  0.82119328 0.
 1.         0.         1.         1.         0.         1.        ]
wv_std shape (30,)
[0.         0.         0.         0.         0.         0.
 1.         1.         0.24574781 0.         1.         0.
 0.         0.10485301 0.82528878 1.         0.42781215 0.41215175
 0.90047553 1.         1.         1.         1.         0.727612
 0.         0.         0.15243936 0.         1.         1.        ]
xy shape: (30, 9)
[[0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
  3.07550172e-01 1.00000000e+00 1.00000000e+00 0.00000000e+00
  0.00000000e+00]
 [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
  3.07294642e-01 1.00000000e+00 1.00000000e+00 0.00000000e+00
  0.00000000e+00]
 [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
  3.06725877e-01 1.00000000e+00 6.14756924e-01 0.00000000e+00
  0.00000000e+00]
 [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
  3.07496546e-01 1.00000000e+00 1.00000000e+00 0.00000000e+00
  0.00000000e+00]
 [3.06126546e-04 0.00000000e+00 0.00000000e+00 0.00000000e+00
  3.07544560e-01 1.00000000e+00 1.00000000e+00 0.00000000e+00
  0.00000000e+00]
 [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
  3.09353625e-01 1.00000000e+00 0.00000000e+00 0.00000000e+00
  1.00000000e+00]
 [1.00000000e+00 2.54881126e-01 2.23893076e-01 8.12408123e-01
  3.09023805e-01 1.00000000e+00 4.31388463e-01 1.00000000e+00
  1.00000000e+00]
 [1.00000000e+00 7.95853325e-01 1.00000000e+00 1.00000000e+00
  3.10268633e-01 1.00000000e+00 0.00000000e+00 1.00000000e+00
  1.00000000e+00]
 [1.00000000e+00 5.39494363e-01 5.64495408e-01 5.23098824e-01
  3.09959417e-01 1.00000000e+00 0.00000000e+00 2.45747814e-01
  1.00000000e+00]
 [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
  3.10452391e-01 1.00000000e+00 0.00000000e+00 0.00000000e+00
  1.00000000e+00]
 [1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00
  3.09741295e-01 1.00000000e+00 0.00000000e+00 1.00000000e+00
  1.00000000e+00]
 [1.00000000e+00 0.00000000e+00 1.00000000e+00 6.12977010e-01
  3.11064331e-01 1.00000000e+00 1.00000000e+00 0.00000000e+00
  1.00000000e+00]
 [1.00000000e+00 5.16800137e-01 5.67744063e-02 1.12522348e-01
  3.09756579e-01 1.00000000e+00 1.00000000e+00 0.00000000e+00
  1.00000000e+00]
 [1.00000000e+00 1.00000000e+00 1.00000000e+00 7.52586998e-01
  3.10033961e-01 1.00000000e+00 0.00000000e+00 1.04853011e-01
  1.00000000e+00]
 [1.00000000e+00 0.00000000e+00 1.00000000e+00 1.00000000e+00
  3.10974774e-01 1.00000000e+00 0.00000000e+00 8.25288784e-01
  1.00000000e+00]
 [1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00
  3.08606600e-01 1.00000000e+00 0.00000000e+00 1.00000000e+00
  1.00000000e+00]
 [1.00000000e+00 2.39495648e-01 8.91825379e-01 9.58163481e-01
  3.11312311e-01 1.00000000e+00 0.00000000e+00 4.27812150e-01
  1.00000000e+00]
 [1.00000000e+00 5.25180647e-01 1.00000000e+00 1.00000000e+00
  3.09696601e-01 1.00000000e+00 3.81356377e-01 4.12151745e-01
  1.00000000e+00]
 [1.00000000e+00 0.00000000e+00 1.00000000e+00 1.00000000e+00
  3.10418475e-01 1.00000000e+00 0.00000000e+00 9.00475526e-01
  1.00000000e+00]
 [1.00000000e+00 0.00000000e+00 1.00000000e+00 1.00000000e+00
  3.10237389e-01 1.00000000e+00 0.00000000e+00 1.00000000e+00
  1.00000000e+00]
 [1.00000000e+00 0.00000000e+00 1.00000000e+00 1.00000000e+00
  3.10403508e-01 1.00000000e+00 3.92544695e-01 1.00000000e+00
  1.00000000e+00]
 [1.00000000e+00 0.00000000e+00 1.00000000e+00 1.00000000e+00
  3.09691133e-01 1.00000000e+00 4.60483505e-01 1.00000000e+00
  1.00000000e+00]
 [1.00000000e+00 6.16874772e-01 1.00000000e+00 1.00000000e+00
  3.09431828e-01 1.00000000e+00 8.21193279e-01 1.00000000e+00
  1.00000000e+00]
 [1.00000000e+00 2.54881126e-01 0.00000000e+00 0.00000000e+00
  3.09099494e-01 1.00000000e+00 0.00000000e+00 7.27611998e-01
  1.00000000e+00]
 [1.00000000e+00 0.00000000e+00 7.92679737e-01 3.74977592e-01
  3.10368304e-01 1.00000000e+00 1.00000000e+00 0.00000000e+00
  1.00000000e+00]
 [1.00000000e+00 0.00000000e+00 3.46105463e-01 0.00000000e+00
  3.11316986e-01 1.00000000e+00 0.00000000e+00 0.00000000e+00
  1.00000000e+00]
 [1.00000000e+00 1.00000000e+00 1.00000000e+00 3.11727454e-01
  3.10669972e-01 1.00000000e+00 1.00000000e+00 1.52439364e-01
  1.00000000e+00]
 [0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00
  3.11056645e-01 1.00000000e+00 1.00000000e+00 0.00000000e+00
  1.00000000e+00]
 [1.00000000e+00 0.00000000e+00 1.00000000e+00 1.00000000e+00
  3.09866262e-01 1.00000000e+00 0.00000000e+00 1.00000000e+00
  1.00000000e+00]
 [1.00000000e+00 0.00000000e+00 1.00000000e+00 1.00000000e+00
  3.10581896e-01 1.00000000e+00 1.00000000e+00 1.00000000e+00
  1.00000000e+00]]

Best Training Poisoning Accuracy:
0.8571428656578064
#####################         POISON         ###############################################

############################################################################################

comm_round: 3 | global_test_acc: 80.000% | global_f1: 0.888888888888889 | global_precision: 0.8
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.80      1.00      0.89         8

    accuracy                           0.80        10
   macro avg       0.40      0.50      0.44        10
weighted avg       0.64      0.80      0.71        10

Accuracy per class:
[[8 0]
 [2 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[1.         1.         1.         0.         1.         1.
 1.         1.         0.40975948 1.         1.         1.
 1.         1.         1.         1.         0.66189631 1.
 1.         1.         0.         1.         1.         1.
 0.         0.65449565 1.         0.13157648 1.         0.        ]
wv_fg shape (30,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.14785303 0.         0.         0.         0.
 0.         0.         0.         0.28190165 0.         0.0943844
 0.         0.         0.         0.         1.         1.        ]
wv_mn shape (30,)
[0.         0.         0.19572793 0.         0.         1.
 1.         1.         0.35769772 1.         0.63833764 1.
 0.84152392 1.         0.69276343 1.         0.44058466 0.
 0.         0.         0.         0.86058057 0.0272615  0.72964146
 0.         0.         1.         0.         1.         0.        ]
wv_ed shape (30,)
[0.         0.         0.078138   0.         0.         0.6438842
 1.         1.         0.         1.         0.55862788 1.
 0.78941011 1.         1.         1.         0.         0.58147055
 0.3271894  0.6373435  0.         1.         0.30488349 1.
 0.         0.         1.         0.         1.         0.        ]
wv_lg shape (30, 1)
[[0.30945512]
 [0.30926175]
 [0.3096719 ]
 [0.30965626]
 [0.30976607]
 [0.31277027]
 [0.31311283]
 [0.31204498]
 [0.31309982]
 [0.31303216]
 [0.3125399 ]
 [0.31229369]
 [0.31350257]
 [0.31154884]
 [0.31210874]
 [0.31130314]
 [0.31293338]
 [0.31255807]
 [0.31190815]
 [0.31225307]
 [0.31238095]
 [0.31159326]
 [0.311587  ]
 [0.31323393]
 [0.31365988]
 [0.31286829]
 [0.31212627]
 [0.31333155]
 [0.31329321]
 [0.31393014]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1.         1.         1.         1.         1.         0.
 0.42215809 0.98828907 0.21958588 0.93848845 1.         0.2547404
 0.34249916 1.         0.8794907  0.         0.40413061 0.49175084
 0.         0.55907055 0.         0.         0.67358402 0.02672312
 0.08761126 0.         0.87803705 0.34471202 1.         0.        ]
wv_std shape (30,)
[0.         0.         0.         0.         0.         0.14039012
 1.         0.71322867 0.         1.         0.1547212  1.
 0.34277746 1.         0.75219048 1.         0.         0.73549391
 0.46370829 0.46610258 0.         1.         0.02684914 1.
 0.         0.         0.38682828 0.         1.         0.        ]
xy shape: (30, 9)
[[1.         0.         0.         0.         0.30945512 1.
  1.         0.         0.        ]
 [1.         0.         0.         0.         0.30926175 1.
  1.         0.         0.        ]
 [1.         0.         0.19572793 0.078138   0.3096719  1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.30965626 1.
  1.         0.         0.        ]
 [1.         0.         0.         0.         0.30976607 1.
  1.         0.         0.        ]
 [1.         0.         1.         0.6438842  0.31277027 1.
  0.         0.14039012 1.        ]
 [1.         0.         1.         1.         0.31311283 1.
  0.42215809 1.         1.        ]
 [1.         0.         1.         1.         0.31204498 1.
  0.98828907 0.71322867 1.        ]
 [0.40975948 0.         0.35769772 0.         0.31309982 1.
  0.21958588 0.         1.        ]
 [1.         0.         1.         1.         0.31303216 1.
  0.93848845 1.         1.        ]
 [1.         0.         0.63833764 0.55862788 0.3125399  1.
  1.         0.1547212  1.        ]
 [1.         0.         1.         1.         0.31229369 1.
  0.2547404  1.         1.        ]
 [1.         0.         0.84152392 0.78941011 0.31350257 1.
  0.34249916 0.34277746 1.        ]
 [1.         0.14785303 1.         1.         0.31154884 1.
  1.         1.         1.        ]
 [1.         0.         0.69276343 1.         0.31210874 1.
  0.8794907  0.75219048 1.        ]
 [1.         0.         1.         1.         0.31130314 1.
  0.         1.         1.        ]
 [0.66189631 0.         0.44058466 0.         0.31293338 1.
  0.40413061 0.         1.        ]
 [1.         0.         0.         0.58147055 0.31255807 1.
  0.49175084 0.73549391 1.        ]
 [1.         0.         0.         0.3271894  0.31190815 1.
  0.         0.46370829 1.        ]
 [1.         0.         0.         0.6373435  0.31225307 1.
  0.55907055 0.46610258 1.        ]
 [0.         0.         0.         0.         0.31238095 1.
  0.         0.         1.        ]
 [1.         0.28190165 0.86058057 1.         0.31159326 1.
  0.         1.         1.        ]
 [1.         0.         0.0272615  0.30488349 0.311587   1.
  0.67358402 0.02684914 1.        ]
 [1.         0.0943844  0.72964146 1.         0.31323393 1.
  0.02672312 1.         1.        ]
 [0.         0.         0.         0.         0.31365988 1.
  0.08761126 0.         1.        ]
 [0.65449565 0.         0.         0.         0.31286829 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.31212627 1.
  0.87803705 0.38682828 1.        ]
 [0.13157648 0.         0.         0.         0.31333155 1.
  0.34471202 0.         1.        ]
 [1.         1.         1.         1.         0.31329321 1.
  1.         1.         1.        ]
 [0.         1.         0.         0.         0.31393014 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.8571428656578064
#####################         POISON         ###############################################

############################################################################################

comm_round: 4 | global_test_acc: 70.000% | global_f1: 0.8235294117647058 | global_precision: 0.7
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.70      1.00      0.82         7

    accuracy                           0.70        10
   macro avg       0.35      0.50      0.41        10
weighted avg       0.49      0.70      0.58        10

Accuracy per class:
[[7 0]
 [3 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 0. 1. 1.]
wv_fg shape (30,)
[0.         0.         0.         0.         0.         0.
 0.59928804 0.         1.         0.5460797  0.         0.
 0.17465382 0.         0.70493162 0.         1.         0.88500169
 1.         0.51156271 0.         0.11620038 1.         0.
 0.54550976 0.         0.         0.39232166 0.         0.70493162]
wv_mn shape (30,)
[0.         0.         0.         0.         0.         0.04145521
 1.         0.         1.         1.         1.         0.6593561
 1.         0.58076079 0.         1.         1.         0.
 1.         1.         1.         0.05154546 1.         0.59572938
 1.         1.         1.         0.         0.86660074 0.08814167]
wv_ed shape (30,)
[0.         0.         0.         0.         0.         0.32246207
 1.         0.34797436 0.8694353  1.         1.         0.57634831
 1.         0.51793043 0.45515772 1.         1.         0.06690963
 1.         1.         1.         0.23777074 1.         0.77135154
 1.         1.         0.77965575 0.         0.74236433 1.        ]
wv_lg shape (30, 1)
[[0.31178844]
 [0.31222944]
 [0.31233786]
 [0.31221218]
 [0.3114679 ]
 [0.31410034]
 [0.31630712]
 [0.31528163]
 [0.3128598 ]
 [0.31311264]
 [0.31496811]
 [0.31482241]
 [0.31392286]
 [0.31498346]
 [0.31453628]
 [0.31412636]
 [0.31558204]
 [0.31365837]
 [0.31477874]
 [0.31470142]
 [0.31530943]
 [0.31475602]
 [0.31439228]
 [0.31562608]
 [0.31415061]
 [0.31398488]
 [0.31536151]
 [0.31463271]
 [0.3150918 ]
 [0.31351025]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1.         1.         1.         1.         1.         0.18796862
 0.89998758 0.         0.56880866 0.         0.47062062 0.
 1.         0.         1.         1.         0.48248896 1.
 1.         0.         1.         0.42392467 0.         0.
 1.         0.43664879 1.         0.         0.74892909 0.        ]
wv_std shape (30,)
[0.         0.         0.         0.         0.         0.
 0.50258187 0.24778962 0.28070811 1.         0.78567836 0.11516171
 1.         0.22572707 0.61106814 1.         1.         0.06594019
 1.         1.         1.         0.         0.98218794 0.49538502
 0.47430608 1.         0.18133353 0.         0.04655861 1.        ]
xy shape: (30, 9)
[[1.         0.         0.         0.         0.31178844 1.
  1.         0.         0.        ]
 [1.         0.         0.         0.         0.31222944 1.
  1.         0.         0.        ]
 [1.         0.         0.         0.         0.31233786 1.
  1.         0.         0.        ]
 [1.         0.         0.         0.         0.31221218 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.3114679  1.
  1.         0.         0.        ]
 [1.         0.         0.04145521 0.32246207 0.31410034 1.
  0.18796862 0.         1.        ]
 [1.         0.59928804 1.         1.         0.31630712 1.
  0.89998758 0.50258187 1.        ]
 [1.         0.         0.         0.34797436 0.31528163 1.
  0.         0.24778962 1.        ]
 [1.         1.         1.         0.8694353  0.3128598  1.
  0.56880866 0.28070811 1.        ]
 [1.         0.5460797  1.         1.         0.31311264 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.31496811 1.
  0.47062062 0.78567836 1.        ]
 [1.         0.         0.6593561  0.57634831 0.31482241 1.
  0.         0.11516171 1.        ]
 [0.         0.17465382 1.         1.         0.31392286 1.
  1.         1.         1.        ]
 [1.         0.         0.58076079 0.51793043 0.31498346 1.
  0.         0.22572707 1.        ]
 [1.         0.70493162 0.         0.45515772 0.31453628 1.
  1.         0.61106814 1.        ]
 [1.         0.         1.         1.         0.31412636 1.
  1.         1.         1.        ]
 [1.         1.         1.         1.         0.31558204 1.
  0.48248896 1.         1.        ]
 [1.         0.88500169 0.         0.06690963 0.31365837 1.
  1.         0.06594019 1.        ]
 [1.         1.         1.         1.         0.31477874 1.
  1.         1.         1.        ]
 [1.         0.51156271 1.         1.         0.31470142 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.31530943 1.
  1.         1.         1.        ]
 [1.         0.11620038 0.05154546 0.23777074 0.31475602 1.
  0.42392467 0.         1.        ]
 [1.         1.         1.         1.         0.31439228 1.
  0.         0.98218794 1.        ]
 [1.         0.         0.59572938 0.77135154 0.31562608 1.
  0.         0.49538502 1.        ]
 [1.         0.54550976 1.         1.         0.31415061 1.
  1.         0.47430608 1.        ]
 [1.         0.         1.         1.         0.31398488 1.
  0.43664879 1.         1.        ]
 [1.         0.         1.         0.77965575 0.31536151 1.
  1.         0.18133353 1.        ]
 [0.         0.39232166 0.         0.         0.31463271 1.
  0.         0.         1.        ]
 [1.         0.         0.86660074 0.74236433 0.3150918  1.
  0.74892909 0.04655861 1.        ]
 [1.         0.70493162 0.08814167 1.         0.31351025 1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.9285714030265808
#####################         POISON         ###############################################

############################################################################################

comm_round: 5 | global_test_acc: 70.000% | global_f1: 0.8235294117647058 | global_precision: 0.7
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.70      1.00      0.82         7

    accuracy                           0.70        10
   macro avg       0.35      0.50      0.41        10
weighted avg       0.49      0.70      0.58        10

Accuracy per class:
[[7 0]
 [3 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0.         0.         0.26001889 0.         0.         1.
 1.         1.         1.         0.24173783 1.         1.
 1.         1.         1.         0.10755521 1.         1.
 1.         1.         1.         1.         1.         1.
 0.         1.         1.         1.         0.1812467  1.        ]
wv_fg shape (30,)
[0.         0.         0.         0.         0.         1.
 0.32478671 0.65453913 0.         0.         0.         0.
 0.         0.         1.         0.         1.         0.
 0.         0.4140938  0.         0.         0.         0.04359994
 0.         0.         0.         0.         0.         0.        ]
wv_mn shape (30,)
[0.         0.         0.         0.         0.         1.
 0.         0.         1.         0.41499828 0.17056742 1.
 0.         0.18566214 0.45018123 0.         0.         1.
 0.         0.         1.         1.         0.03862261 0.27543662
 0.         1.         1.         1.         0.         0.78603471]
wv_ed shape (30,)
[0.         0.         0.         0.         0.         1.
 0.         0.32364729 1.         0.         0.         1.
 0.         0.38914346 0.23835587 0.         0.32890983 0.47353902
 0.05734333 0.         0.65724873 1.         0.45224773 0.91274564
 0.         0.75428093 1.         1.         0.         1.        ]
wv_lg shape (30, 1)
[[0.31421819]
 [0.31384269]
 [0.313926  ]
 [0.31402798]
 [0.31434322]
 [0.31557783]
 [0.31596059]
 [0.3156247 ]
 [0.31628046]
 [0.31695063]
 [0.31704119]
 [0.31564325]
 [0.31793794]
 [0.31684639]
 [0.3172464 ]
 [0.31673799]
 [0.31582253]
 [0.31618813]
 [0.31625728]
 [0.31567536]
 [0.31627602]
 [0.3168722 ]
 [0.31647026]
 [0.31546483]
 [0.31765616]
 [0.31578705]
 [0.31492929]
 [0.31601626]
 [0.31780701]
 [0.31629195]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1.         0.62168588 0.7233755  1.         1.         0.
 0.         0.         0.10849375 0.50913361 0.         0.
 0.         0.         1.         0.22188597 0.         1.
 0.         0.         0.84316977 0.16490671 0.10612377 0.
 0.         0.50174812 0.         0.25278558 0.         0.16981224]
wv_std shape (30,)
[0.         0.         0.         0.         0.         1.
 0.         0.3268797  0.57751959 0.         0.         1.
 0.         0.1181089  0.         0.         0.26748059 0.
 0.12567224 0.         0.02537667 1.         0.         0.66752918
 0.         0.21754489 1.         0.86098721 0.         0.83677902]
xy shape: (30, 9)
[[0.         0.         0.         0.         0.31421819 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.31384269 1.
  0.62168588 0.         0.        ]
 [0.26001889 0.         0.         0.         0.313926   1.
  0.7233755  0.         0.        ]
 [0.         0.         0.         0.         0.31402798 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.31434322 1.
  1.         0.         0.        ]
 [1.         1.         1.         1.         0.31557783 1.
  0.         1.         1.        ]
 [1.         0.32478671 0.         0.         0.31596059 1.
  0.         0.         1.        ]
 [1.         0.65453913 0.         0.32364729 0.3156247  1.
  0.         0.3268797  1.        ]
 [1.         0.         1.         1.         0.31628046 1.
  0.10849375 0.57751959 1.        ]
 [0.24173783 0.         0.41499828 0.         0.31695063 1.
  0.50913361 0.         1.        ]
 [1.         0.         0.17056742 0.         0.31704119 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.31564325 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.31793794 1.
  0.         0.         1.        ]
 [1.         0.         0.18566214 0.38914346 0.31684639 1.
  0.         0.1181089  1.        ]
 [1.         1.         0.45018123 0.23835587 0.3172464  1.
  1.         0.         1.        ]
 [0.10755521 0.         0.         0.         0.31673799 1.
  0.22188597 0.         1.        ]
 [1.         1.         0.         0.32890983 0.31582253 1.
  0.         0.26748059 1.        ]
 [1.         0.         1.         0.47353902 0.31618813 1.
  1.         0.         1.        ]
 [1.         0.         0.         0.05734333 0.31625728 1.
  0.         0.12567224 1.        ]
 [1.         0.4140938  0.         0.         0.31567536 1.
  0.         0.         1.        ]
 [1.         0.         1.         0.65724873 0.31627602 1.
  0.84316977 0.02537667 1.        ]
 [1.         0.         1.         1.         0.3168722  1.
  0.16490671 1.         1.        ]
 [1.         0.         0.03862261 0.45224773 0.31647026 1.
  0.10612377 0.         1.        ]
 [1.         0.04359994 0.27543662 0.91274564 0.31546483 1.
  0.         0.66752918 1.        ]
 [0.         0.         0.         0.         0.31765616 1.
  0.         0.         1.        ]
 [1.         0.         1.         0.75428093 0.31578705 1.
  0.50174812 0.21754489 1.        ]
 [1.         0.         1.         1.         0.31492929 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.31601626 1.
  0.25278558 0.86098721 1.        ]
 [0.1812467  0.         0.         0.         0.31780701 1.
  0.         0.         1.        ]
 [1.         0.         0.78603471 1.         0.31629195 1.
  0.16981224 0.83677902 1.        ]]

Best Training Poisoning Accuracy:
0.9285714030265808
#####################         POISON         ###############################################

############################################################################################

comm_round: 6 | global_test_acc: 80.000% | global_f1: 0.888888888888889 | global_precision: 0.8
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.80      1.00      0.89         8

    accuracy                           0.80        10
   macro avg       0.40      0.50      0.44        10
weighted avg       0.64      0.80      0.71        10

Accuracy per class:
[[8 0]
 [2 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0.         0.         0.         0.09963535 0.45422569 1.
 1.         0.         0.         1.         1.         1.
 0.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 0.         1.         1.         1.         1.         1.        ]
wv_fg shape (30,)
[0.         0.         0.         0.         0.         0.
 0.         0.08528513 1.         0.37141778 1.         0.
 0.         0.         0.55897323 0.         0.37141778 0.
 0.         0.         0.         0.60520753 0.         0.
 0.         0.00269735 0.         1.         1.         1.        ]
wv_mn shape (30,)
[0.         0.         0.         0.         0.         0.44549974
 1.         0.         0.         1.         0.         1.
 0.         1.         0.75044033 1.         1.         0.61729158
 1.         1.         0.68732274 1.         0.58686321 1.
 0.         0.06247122 0.15644574 1.         1.         1.        ]
wv_ed shape (30,)
[0.         0.         0.         0.         0.         0.76439253
 1.         0.         0.         1.         0.         1.
 0.         1.         0.11331818 1.         1.         1.
 1.         1.         1.         1.         1.         1.
 0.         0.         0.36184752 1.         1.         1.        ]
wv_lg shape (30, 1)
[[0.31575033]
 [0.31561526]
 [0.31577534]
 [0.31606032]
 [0.3161073 ]
 [0.31794601]
 [0.31754643]
 [0.31942129]
 [0.31827871]
 [0.31916056]
 [0.31864573]
 [0.31792737]
 [0.31843056]
 [0.31824441]
 [0.31967873]
 [0.31832268]
 [0.31833025]
 [0.31843263]
 [0.3175029 ]
 [0.31811831]
 [0.31919794]
 [0.31845177]
 [0.3180778 ]
 [0.31822682]
 [0.31921285]
 [0.31844342]
 [0.31851483]
 [0.31912035]
 [0.31869958]
 [0.31784215]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[0.6145617  0.92332786 0.46344512 0.77143347 0.91428164 0.
 0.         0.         1.         0.23498887 0.         0.
 0.         0.         0.09436183 1.         0.40464978 0.27042669
 0.         0.         0.         0.06916266 0.         0.
 0.         0.41844845 0.         1.         0.         0.        ]
wv_std shape (30,)
[0.         0.         0.         0.         0.         0.94672862
 1.         0.         0.         1.         0.         0.46076549
 0.         0.4118879  0.         1.         1.         0.72400972
 1.         1.         1.         0.90597109 1.         0.56955164
 0.         0.         0.         1.         1.         1.        ]
xy shape: (30, 9)
[[0.         0.         0.         0.         0.31575033 1.
  0.6145617  0.         0.        ]
 [0.         0.         0.         0.         0.31561526 1.
  0.92332786 0.         0.        ]
 [0.         0.         0.         0.         0.31577534 1.
  0.46344512 0.         0.        ]
 [0.09963535 0.         0.         0.         0.31606032 1.
  0.77143347 0.         0.        ]
 [0.45422569 0.         0.         0.         0.3161073  1.
  0.91428164 0.         0.        ]
 [1.         0.         0.44549974 0.76439253 0.31794601 1.
  0.         0.94672862 1.        ]
 [1.         0.         1.         1.         0.31754643 1.
  0.         1.         1.        ]
 [0.         0.08528513 0.         0.         0.31942129 1.
  0.         0.         1.        ]
 [0.         1.         0.         0.         0.31827871 1.
  1.         0.         1.        ]
 [1.         0.37141778 1.         1.         0.31916056 1.
  0.23498887 1.         1.        ]
 [1.         1.         0.         0.         0.31864573 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.31792737 1.
  0.         0.46076549 1.        ]
 [0.         0.         0.         0.         0.31843056 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.31824441 1.
  0.         0.4118879  1.        ]
 [1.         0.55897323 0.75044033 0.11331818 0.31967873 1.
  0.09436183 0.         1.        ]
 [1.         0.         1.         1.         0.31832268 1.
  1.         1.         1.        ]
 [1.         0.37141778 1.         1.         0.31833025 1.
  0.40464978 1.         1.        ]
 [1.         0.         0.61729158 1.         0.31843263 1.
  0.27042669 0.72400972 1.        ]
 [1.         0.         1.         1.         0.3175029  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.31811831 1.
  0.         1.         1.        ]
 [1.         0.         0.68732274 1.         0.31919794 1.
  0.         1.         1.        ]
 [1.         0.60520753 1.         1.         0.31845177 1.
  0.06916266 0.90597109 1.        ]
 [1.         0.         0.58686321 1.         0.3180778  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.31822682 1.
  0.         0.56955164 1.        ]
 [0.         0.         0.         0.         0.31921285 1.
  0.         0.         1.        ]
 [1.         0.00269735 0.06247122 0.         0.31844342 1.
  0.41844845 0.         1.        ]
 [1.         0.         0.15644574 0.36184752 0.31851483 1.
  0.         0.         1.        ]
 [1.         1.         1.         1.         0.31912035 1.
  1.         1.         1.        ]
 [1.         1.         1.         1.         0.31869958 1.
  0.         1.         1.        ]
 [1.         1.         1.         1.         0.31784215 1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.7857142686843872
#####################         POISON         ###############################################

############################################################################################

comm_round: 7 | global_test_acc: 90.000% | global_f1: 0.9473684210526316 | global_precision: 0.9
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.90      1.00      0.95         9

    accuracy                           0.90        10
   macro avg       0.45      0.50      0.47        10
weighted avg       0.81      0.90      0.85        10

Accuracy per class:
[[9 0]
 [1 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0.         0.2978651  0.         0.30187431 0.0080072  1.
 0.         1.         1.         1.         1.         1.
 0.84678691 1.         1.         1.         0.         0.91651863
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.        ]
wv_fg shape (30,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         1.         0.         0.
 0.         0.12617896 1.         0.05525241 0.         0.
 0.46013373 1.         0.         1.         0.46013373 0.
 0.         0.         0.         0.70039301 0.         0.        ]
wv_mn shape (30,)
[0.         0.         0.         0.         0.         1.
 0.         1.         0.2567233  0.         0.37787663 1.
 1.         0.43094648 1.         0.20769825 0.         1.
 1.         0.         1.         1.         1.         1.
 1.         0.63050092 1.         1.         0.         1.        ]
wv_ed shape (30,)
[0.         0.         0.         0.         0.         1.
 0.         1.         0.         0.         0.702938   1.
 1.         0.32672913 1.         0.37433678 0.         1.
 1.         0.05613657 0.09141213 1.         1.         1.
 1.         0.53309243 1.         1.         0.         1.        ]
wv_lg shape (30, 1)
[[0.31799743]
 [0.3175815 ]
 [0.31805605]
 [0.3181401 ]
 [0.31792532]
 [0.32023347]
 [0.32084018]
 [0.3191731 ]
 [0.32100456]
 [0.32019972]
 [0.31993579]
 [0.31969593]
 [0.31954372]
 [0.32113305]
 [0.32064047]
 [0.31951738]
 [0.31976876]
 [0.31963907]
 [0.32042322]
 [0.31959746]
 [0.32083246]
 [0.31992536]
 [0.31996196]
 [0.31890754]
 [0.32007187]
 [0.31999856]
 [0.31854176]
 [0.3206809 ]
 [0.32047275]
 [0.32041522]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1.         1.         1.         1.         0.59448024 0.
 0.         0.37168768 0.3853549  0.         0.         0.07977835
 0.20558068 1.         1.         0.         0.         0.
 0.52618754 0.         0.67076745 1.         0.         0.39190271
 1.         0.64276247 0.         0.45171889 0.         0.67105976]
wv_std shape (30,)
[0.         0.         0.         0.         0.         0.88375222
 0.         1.         0.         0.         0.29247704 1.
 1.         0.         0.82586737 0.00604857 0.         1.
 1.         0.39991062 0.         0.2925077  1.         1.
 0.83430994 0.         1.         0.12097142 0.         0.45662988]
xy shape: (30, 9)
[[0.         0.         0.         0.         0.31799743 1.
  1.         0.         0.        ]
 [0.2978651  0.         0.         0.         0.3175815  1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.31805605 1.
  1.         0.         0.        ]
 [0.30187431 0.         0.         0.         0.3181401  1.
  1.         0.         0.        ]
 [0.0080072  0.         0.         0.         0.31792532 1.
  0.59448024 0.         0.        ]
 [1.         0.         1.         1.         0.32023347 1.
  0.         0.88375222 1.        ]
 [0.         0.         0.         0.         0.32084018 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.3191731  1.
  0.37168768 1.         1.        ]
 [1.         0.         0.2567233  0.         0.32100456 1.
  0.3853549  0.         1.        ]
 [1.         1.         0.         0.         0.32019972 1.
  0.         0.         1.        ]
 [1.         0.         0.37787663 0.702938   0.31993579 1.
  0.         0.29247704 1.        ]
 [1.         0.         1.         1.         0.31969593 1.
  0.07977835 1.         1.        ]
 [0.84678691 0.         1.         1.         0.31954372 1.
  0.20558068 1.         1.        ]
 [1.         0.12617896 0.43094648 0.32672913 0.32113305 1.
  1.         0.         1.        ]
 [1.         1.         1.         1.         0.32064047 1.
  1.         0.82586737 1.        ]
 [1.         0.05525241 0.20769825 0.37433678 0.31951738 1.
  0.         0.00604857 1.        ]
 [0.         0.         0.         0.         0.31976876 1.
  0.         0.         1.        ]
 [0.91651863 0.         1.         1.         0.31963907 1.
  0.         1.         1.        ]
 [1.         0.46013373 1.         1.         0.32042322 1.
  0.52618754 1.         1.        ]
 [1.         1.         0.         0.05613657 0.31959746 1.
  0.         0.39991062 1.        ]
 [1.         0.         1.         0.09141213 0.32083246 1.
  0.67076745 0.         1.        ]
 [1.         1.         1.         1.         0.31992536 1.
  1.         0.2925077  1.        ]
 [1.         0.46013373 1.         1.         0.31996196 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.31890754 1.
  0.39190271 1.         1.        ]
 [1.         0.         1.         1.         0.32007187 1.
  1.         0.83430994 1.        ]
 [1.         0.         0.63050092 0.53309243 0.31999856 1.
  0.64276247 0.         1.        ]
 [1.         0.         1.         1.         0.31854176 1.
  0.         1.         1.        ]
 [1.         0.70039301 1.         1.         0.3206809  1.
  0.45171889 0.12097142 1.        ]
 [1.         0.         0.         0.         0.32047275 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.32041522 1.
  0.67105976 0.45662988 1.        ]]

Best Training Poisoning Accuracy:
0.8571428656578064
#####################         POISON         ###############################################

############################################################################################

comm_round: 8 | global_test_acc: 80.000% | global_f1: 0.888888888888889 | global_precision: 0.8
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.80      1.00      0.89         8

    accuracy                           0.80        10
   macro avg       0.40      0.50      0.44        10
weighted avg       0.64      0.80      0.71        10

Accuracy per class:
[[8 0]
 [2 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0.         0.         0.         1.         0.18210729 0.
 0.         1.         1.         1.         0.         1.
 1.         0.45527584 1.         0.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.        ]
wv_fg shape (30,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.8946361  1.         1.         0.
 0.         0.         0.         0.         0.         0.65624136
 1.         0.         0.         0.         0.35638907 0.
 0.         1.         0.         0.         0.         0.        ]
wv_mn shape (30,)
[0.         0.         0.         0.         0.         0.
 0.         0.9172994  1.         1.         0.         0.4980133
 1.         0.         0.         1.         1.         0.8392017
 0.37848573 0.76136211 0.         1.         1.         1.
 1.         1.         1.         1.         0.         1.        ]
wv_ed shape (30,)
[0.         0.         0.         0.         0.         0.
 0.         0.74303169 1.         1.         0.         0.19755482
 0.68531315 0.         0.         1.         0.94667343 0.24878406
 1.         0.94276686 0.16043781 1.         1.         0.84550176
 1.         1.         0.85618753 1.         0.57301356 1.        ]
wv_lg shape (30, 1)
[[0.31950695]
 [0.31918082]
 [0.31981185]
 [0.31977722]
 [0.31969886]
 [0.32136644]
 [0.32182267]
 [0.32107654]
 [0.32142372]
 [0.32021329]
 [0.32170599]
 [0.3221451 ]
 [0.32122133]
 [0.32141587]
 [0.32003312]
 [0.32148379]
 [0.32083304]
 [0.32105702]
 [0.32068996]
 [0.32164369]
 [0.32214652]
 [0.32179236]
 [0.32138644]
 [0.32160969]
 [0.32169502]
 [0.32267201]
 [0.32134838]
 [0.32127904]
 [0.32066738]
 [0.32156331]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[0.95752673 0.92459964 1.         1.         0.86404977 0.
 0.         0.33758392 1.         0.         0.         0.56460066
 0.         0.         0.         0.         0.02397649 0.16945359
 0.         0.         0.26620145 1.         0.         0.49177119
 0.18662155 0.         0.         0.         0.         0.1162876 ]
wv_std shape (30,)
[0.         0.         0.         0.         0.         0.
 0.         0.         1.         1.         0.         0.
 0.         0.         0.18797137 1.         0.18565232 0.
 1.         0.28433528 0.         0.32240445 0.47606378 0.04787688
 0.38472465 0.56775311 0.06788717 1.         0.43190505 1.        ]
xy shape: (30, 9)
[[0.         0.         0.         0.         0.31950695 1.
  0.95752673 0.         0.        ]
 [0.         0.         0.         0.         0.31918082 1.
  0.92459964 0.         0.        ]
 [0.         0.         0.         0.         0.31981185 1.
  1.         0.         0.        ]
 [1.         0.         0.         0.         0.31977722 1.
  1.         0.         0.        ]
 [0.18210729 0.         0.         0.         0.31969886 1.
  0.86404977 0.         0.        ]
 [0.         0.         0.         0.         0.32136644 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.32182267 1.
  0.         0.         1.        ]
 [1.         0.         0.9172994  0.74303169 0.32107654 1.
  0.33758392 0.         1.        ]
 [1.         0.8946361  1.         1.         0.32142372 1.
  1.         1.         1.        ]
 [1.         1.         1.         1.         0.32021329 1.
  0.         1.         1.        ]
 [0.         1.         0.         0.         0.32170599 1.
  0.         0.         1.        ]
 [1.         0.         0.4980133  0.19755482 0.3221451  1.
  0.56460066 0.         1.        ]
 [1.         0.         1.         0.68531315 0.32122133 1.
  0.         0.         1.        ]
 [0.45527584 0.         0.         0.         0.32141587 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.32003312 1.
  0.         0.18797137 1.        ]
 [0.         0.         1.         1.         0.32148379 1.
  0.         1.         1.        ]
 [1.         0.         1.         0.94667343 0.32083304 1.
  0.02397649 0.18565232 1.        ]
 [1.         0.65624136 0.8392017  0.24878406 0.32105702 1.
  0.16945359 0.         1.        ]
 [1.         1.         0.37848573 1.         0.32068996 1.
  0.         1.         1.        ]
 [1.         0.         0.76136211 0.94276686 0.32164369 1.
  0.         0.28433528 1.        ]
 [1.         0.         0.         0.16043781 0.32214652 1.
  0.26620145 0.         1.        ]
 [1.         0.         1.         1.         0.32179236 1.
  1.         0.32240445 1.        ]
 [1.         0.35638907 1.         1.         0.32138644 1.
  0.         0.47606378 1.        ]
 [1.         0.         1.         0.84550176 0.32160969 1.
  0.49177119 0.04787688 1.        ]
 [1.         0.         1.         1.         0.32169502 1.
  0.18662155 0.38472465 1.        ]
 [1.         1.         1.         1.         0.32267201 1.
  0.         0.56775311 1.        ]
 [1.         0.         1.         0.85618753 0.32134838 1.
  0.         0.06788717 1.        ]
 [1.         0.         1.         1.         0.32127904 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.57301356 0.32066738 1.
  0.         0.43190505 1.        ]
 [1.         0.         1.         1.         0.32156331 1.
  0.1162876  1.         1.        ]]

Best Training Poisoning Accuracy:
0.7142857313156128
#####################         POISON         ###############################################

############################################################################################

comm_round: 9 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00        10

    accuracy                           1.00        10
   macro avg       1.00      1.00      1.00        10
weighted avg       1.00      1.00      1.00        10

Accuracy per class:
[[10  0]
 [ 0  0]]
[ 1. nan]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0.         0.62913289 0.75200249 0.         0.         1.
 1.         1.         1.         0.10793927 1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 0.         1.         1.         1.         1.         1.        ]
wv_fg shape (30,)
[0.         0.         0.         0.         0.         0.82887211
 0.         0.         0.         0.         1.         0.
 0.         0.         1.         0.         0.         0.
 0.         0.         1.         0.08866861 0.         0.
 0.         1.         1.         0.65589137 1.         0.        ]
wv_mn shape (30,)
[0.         0.         0.         0.         0.         0.
 1.         0.02316972 0.72326095 0.         1.         0.22175542
 0.8772103  0.48831626 0.         0.36254436 0.         1.
 0.         1.         0.86578642 1.         0.         0.
 0.         0.         0.         1.         0.07111379 1.        ]
wv_ed shape (30,)
[0.         0.         0.         0.         0.         0.55008592
 1.         0.71482892 1.         0.         1.         0.49945237
 0.69377226 0.74279779 0.61825217 0.79858111 0.         1.
 0.27541732 1.         1.         1.         0.03137719 0.290771
 0.         0.         1.         1.         0.83737834 1.        ]
wv_lg shape (30, 1)
[[0.3211058 ]
 [0.32066901]
 [0.32122243]
 [0.32130169]
 [0.32060979]
 [0.32242059]
 [0.32347741]
 [0.32176268]
 [0.32243738]
 [0.32290418]
 [0.32232555]
 [0.32179164]
 [0.32344556]
 [0.32321146]
 [0.321968  ]
 [0.32217526]
 [0.323409  ]
 [0.32344096]
 [0.32249784]
 [0.32358674]
 [0.32315769]
 [0.32247225]
 [0.32261392]
 [0.32331611]
 [0.32380299]
 [0.32312095]
 [0.32153839]
 [0.32327118]
 [0.32394784]
 [0.32381951]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1.         1.         0.86216192 0.73918679 1.         0.
 0.         0.13815502 0.         0.         1.         0.
 0.58032596 0.         0.58083047 0.         0.         0.93294381
 0.29114735 0.38458011 0.32451002 0.40389099 0.         0.
 0.0482104  0.         0.         0.         0.10859114 0.44191782]
wv_std shape (30,)
[0.         0.         0.         0.         0.         0.94312188
 0.43955784 0.72598669 1.         0.         1.         0.079935
 0.         0.         0.78509023 0.17555519 0.         0.55020386
 0.36827326 0.20493707 0.68083175 1.         0.         0.
 0.         0.         1.         1.         0.48279036 0.35845703]
xy shape: (30, 9)
[[0.         0.         0.         0.         0.3211058  1.
  1.         0.         0.        ]
 [0.62913289 0.         0.         0.         0.32066901 1.
  1.         0.         0.        ]
 [0.75200249 0.         0.         0.         0.32122243 1.
  0.86216192 0.         0.        ]
 [0.         0.         0.         0.         0.32130169 1.
  0.73918679 0.         0.        ]
 [0.         0.         0.         0.         0.32060979 1.
  1.         0.         0.        ]
 [1.         0.82887211 0.         0.55008592 0.32242059 1.
  0.         0.94312188 1.        ]
 [1.         0.         1.         1.         0.32347741 1.
  0.         0.43955784 1.        ]
 [1.         0.         0.02316972 0.71482892 0.32176268 1.
  0.13815502 0.72598669 1.        ]
 [1.         0.         0.72326095 1.         0.32243738 1.
  0.         1.         1.        ]
 [0.10793927 0.         0.         0.         0.32290418 1.
  0.         0.         1.        ]
 [1.         1.         1.         1.         0.32232555 1.
  1.         1.         1.        ]
 [1.         0.         0.22175542 0.49945237 0.32179164 1.
  0.         0.079935   1.        ]
 [1.         0.         0.8772103  0.69377226 0.32344556 1.
  0.58032596 0.         1.        ]
 [1.         0.         0.48831626 0.74279779 0.32321146 1.
  0.         0.         1.        ]
 [1.         1.         0.         0.61825217 0.321968   1.
  0.58083047 0.78509023 1.        ]
 [1.         0.         0.36254436 0.79858111 0.32217526 1.
  0.         0.17555519 1.        ]
 [1.         0.         0.         0.         0.323409   1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.32344096 1.
  0.93294381 0.55020386 1.        ]
 [1.         0.         0.         0.27541732 0.32249784 1.
  0.29114735 0.36827326 1.        ]
 [1.         0.         1.         1.         0.32358674 1.
  0.38458011 0.20493707 1.        ]
 [1.         1.         0.86578642 1.         0.32315769 1.
  0.32451002 0.68083175 1.        ]
 [1.         0.08866861 1.         1.         0.32247225 1.
  0.40389099 1.         1.        ]
 [1.         0.         0.         0.03137719 0.32261392 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.290771   0.32331611 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.32380299 1.
  0.0482104  0.         1.        ]
 [1.         1.         0.         0.         0.32312095 1.
  0.         0.         1.        ]
 [1.         1.         0.         1.         0.32153839 1.
  0.         1.         1.        ]
 [1.         0.65589137 1.         1.         0.32327118 1.
  0.         1.         1.        ]
 [1.         1.         0.07111379 0.83737834 0.32394784 1.
  0.10859114 0.48279036 1.        ]
 [1.         0.         1.         1.         0.32381951 1.
  0.44191782 0.35845703 1.        ]]

Best Training Poisoning Accuracy:
0.7142857313156128
#####################         POISON         ###############################################

############################################################################################

comm_round: 10 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00        10

    accuracy                           1.00        10
   macro avg       1.00      1.00      1.00        10
weighted avg       1.00      1.00      1.00        10

Accuracy per class:
[[10  0]
 [ 0  0]]
[ 1. nan]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0.95931247 0.84134645 0.         0.76297664 0.52646593 1.
 1.         1.         1.         0.         1.         1.
 1.         0.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         0.         1.         0.67909946 1.         1.        ]
wv_fg shape (30,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 1.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.38996423 1.
 0.         0.         0.         0.05172469 0.         0.24816192]
wv_mn shape (30,)
[0.         0.         0.         0.         0.         0.07815983
 0.98944234 1.         1.         1.         0.75807018 0.22646523
 1.         1.         0.79264082 0.80998073 1.         0.66803877
 1.         1.         1.         1.         1.         0.14804818
 0.         0.         1.         1.         0.53365419 1.        ]
wv_ed shape (30,)
[0.         0.         0.         0.         0.         0.71940253
 0.96174464 1.         0.61823643 1.         1.         0.33348679
 1.         1.         1.         1.         1.         0.46355564
 1.         1.         1.         1.         1.         0.
 0.2002584  0.         0.41024392 1.         1.         1.        ]
wv_lg shape (30, 1)
[[0.32247261]
 [0.32252445]
 [0.32275854]
 [0.3221175 ]
 [0.32250787]
 [0.32393087]
 [0.32386028]
 [0.32489864]
 [0.32511072]
 [0.32409697]
 [0.32480356]
 [0.32491664]
 [0.32555826]
 [0.32444395]
 [0.32298729]
 [0.32431098]
 [0.32367812]
 [0.3245456 ]
 [0.3243299 ]
 [0.32394829]
 [0.32299207]
 [0.3244719 ]
 [0.32483756]
 [0.32651771]
 [0.32344665]
 [0.32410888]
 [0.32526396]
 [0.32490593]
 [0.32345266]
 [0.3255814 ]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[0.18706201 0.41303427 0.13111752 0.         0.26909028 0.
 0.         0.52585018 0.01030924 0.02560982 0.         0.
 0.         0.         0.         0.         0.         0.61394269
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         1.         0.         0.        ]
wv_std shape (30,)
[0.         0.         0.         0.         0.         0.99362404
 0.46300713 0.55219811 0.         1.         1.         0.
 1.         1.         1.         1.         1.         0.
 1.         1.         1.         0.9081427  1.         0.
 0.64012207 0.         0.         1.         1.         1.        ]
xy shape: (30, 9)
[[0.95931247 0.         0.         0.         0.32247261 1.
  0.18706201 0.         0.        ]
 [0.84134645 0.         0.         0.         0.32252445 1.
  0.41303427 0.         0.        ]
 [0.         0.         0.         0.         0.32275854 1.
  0.13111752 0.         0.        ]
 [0.76297664 0.         0.         0.         0.3221175  1.
  0.         0.         0.        ]
 [0.52646593 0.         0.         0.         0.32250787 1.
  0.26909028 0.         0.        ]
 [1.         0.         0.07815983 0.71940253 0.32393087 1.
  0.         0.99362404 1.        ]
 [1.         0.         0.98944234 0.96174464 0.32386028 1.
  0.         0.46300713 1.        ]
 [1.         0.         1.         1.         0.32489864 1.
  0.52585018 0.55219811 1.        ]
 [1.         0.         1.         0.61823643 0.32511072 1.
  0.01030924 0.         1.        ]
 [0.         0.         1.         1.         0.32409697 1.
  0.02560982 1.         1.        ]
 [1.         0.         0.75807018 1.         0.32480356 1.
  0.         1.         1.        ]
 [1.         0.         0.22646523 0.33348679 0.32491664 1.
  0.         0.         1.        ]
 [1.         1.         1.         1.         0.32555826 1.
  0.         1.         1.        ]
 [0.         0.         1.         1.         0.32444395 1.
  0.         1.         1.        ]
 [1.         0.         0.79264082 1.         0.32298729 1.
  0.         1.         1.        ]
 [1.         0.         0.80998073 1.         0.32431098 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.32367812 1.
  0.         1.         1.        ]
 [1.         0.         0.66803877 0.46355564 0.3245456  1.
  0.61394269 0.         1.        ]
 [1.         0.         1.         1.         0.3243299  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.32394829 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.32299207 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.3244719  1.
  0.         0.9081427  1.        ]
 [1.         0.38996423 1.         1.         0.32483756 1.
  0.         1.         1.        ]
 [1.         1.         0.14804818 0.         0.32651771 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.2002584  0.32344665 1.
  0.         0.64012207 1.        ]
 [0.         0.         0.         0.         0.32410888 1.
  0.         0.         1.        ]
 [1.         0.         1.         0.41024392 0.32526396 1.
  0.         0.         1.        ]
 [0.67909946 0.05172469 1.         1.         0.32490593 1.
  1.         1.         1.        ]
 [1.         0.         0.53365419 1.         0.32345266 1.
  0.         1.         1.        ]
 [1.         0.24816192 1.         1.         0.3255814  1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.8571428656578064
#####################         POISON         ###############################################

############################################################################################

comm_round: 11 | global_test_acc: 70.000% | global_f1: 0.8235294117647058 | global_precision: 0.7
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.70      1.00      0.82         7

    accuracy                           0.70        10
   macro avg       0.35      0.50      0.41        10
weighted avg       0.49      0.70      0.58        10

Accuracy per class:
[[7 0]
 [3 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0.16099901 1.         0.         0.89805477 0.         1.
 1.         0.57403567 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 0.         1.         1.         0.         1.         1.
 0.         1.         1.         1.         0.         1.        ]
wv_fg shape (30,)
[0.         0.         0.         0.         0.         0.56859968
 1.         0.         0.         0.         0.         1.
 0.62829049 0.         0.         0.         1.         0.12557722
 0.12557722 0.92522507 0.         0.         0.         0.66033232
 0.16041772 0.         0.74611081 0.         0.0940515  0.        ]
wv_mn shape (30,)
[0.         0.         0.         0.         0.         0.06361881
 0.37704142 0.         1.         0.6297716  1.         1.
 1.         1.         0.         0.19677488 0.74808679 0.
 0.         1.         0.74398371 1.         0.5115074  1.
 1.         0.         1.         1.         0.         1.        ]
wv_ed shape (30,)
[0.         0.         0.         0.         0.         0.30007116
 1.         0.         1.         1.         1.         1.
 1.         1.         0.         0.32641399 1.         0.95491587
 0.         1.         1.         1.         0.98235742 1.
 1.         0.13848419 1.         1.         0.         1.        ]
wv_lg shape (30, 1)
[[0.32374659]
 [0.32408405]
 [0.32401295]
 [0.32425567]
 [0.32389281]
 [0.32688331]
 [0.32544642]
 [0.32493878]
 [0.32518254]
 [0.32572594]
 [0.32579677]
 [0.32615884]
 [0.3241154 ]
 [0.32563808]
 [0.32589079]
 [0.32590689]
 [0.32499792]
 [0.32525762]
 [0.32662176]
 [0.32501529]
 [0.32616874]
 [0.3260085 ]
 [0.32593294]
 [0.3262732 ]
 [0.32533444]
 [0.32460969]
 [0.32589782]
 [0.32615362]
 [0.32733578]
 [0.32587634]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1.         1.         0.94851399 1.         1.         0.4418796
 1.         0.         1.         0.         1.         1.
 0.         0.         0.77807124 0.         0.         0.
 0.         1.         0.         0.         1.         1.
 0.         0.         0.         0.         0.         0.        ]
wv_std shape (30,)
[0.         0.         0.         0.         0.         0.07686144
 1.         0.         0.90611943 1.         1.         1.
 1.         1.         0.         0.         1.         1.
 0.         1.         0.37710618 1.         0.48983023 0.46279805
 1.         0.22405752 0.50953269 1.         0.         1.        ]
xy shape: (30, 9)
[[0.16099901 0.         0.         0.         0.32374659 1.
  1.         0.         0.        ]
 [1.         0.         0.         0.         0.32408405 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.32401295 1.
  0.94851399 0.         0.        ]
 [0.89805477 0.         0.         0.         0.32425567 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.32389281 1.
  1.         0.         0.        ]
 [1.         0.56859968 0.06361881 0.30007116 0.32688331 1.
  0.4418796  0.07686144 1.        ]
 [1.         1.         0.37704142 1.         0.32544642 1.
  1.         1.         1.        ]
 [0.57403567 0.         0.         0.         0.32493878 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.32518254 1.
  1.         0.90611943 1.        ]
 [1.         0.         0.6297716  1.         0.32572594 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.32579677 1.
  1.         1.         1.        ]
 [1.         1.         1.         1.         0.32615884 1.
  1.         1.         1.        ]
 [1.         0.62829049 1.         1.         0.3241154  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.32563808 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.32589079 1.
  0.77807124 0.         1.        ]
 [1.         0.         0.19677488 0.32641399 0.32590689 1.
  0.         0.         1.        ]
 [1.         1.         0.74808679 1.         0.32499792 1.
  0.         1.         1.        ]
 [1.         0.12557722 0.         0.95491587 0.32525762 1.
  0.         1.         1.        ]
 [0.         0.12557722 0.         0.         0.32662176 1.
  0.         0.         1.        ]
 [1.         0.92522507 1.         1.         0.32501529 1.
  1.         1.         1.        ]
 [1.         0.         0.74398371 1.         0.32616874 1.
  0.         0.37710618 1.        ]
 [0.         0.         1.         1.         0.3260085  1.
  0.         1.         1.        ]
 [1.         0.         0.5115074  0.98235742 0.32593294 1.
  1.         0.48983023 1.        ]
 [1.         0.66033232 1.         1.         0.3262732  1.
  1.         0.46279805 1.        ]
 [0.         0.16041772 1.         1.         0.32533444 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.13848419 0.32460969 1.
  0.         0.22405752 1.        ]
 [1.         0.74611081 1.         1.         0.32589782 1.
  0.         0.50953269 1.        ]
 [1.         0.         1.         1.         0.32615362 1.
  0.         1.         1.        ]
 [0.         0.0940515  0.         0.         0.32733578 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.32587634 1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.8571428656578064
#####################         POISON         ###############################################

############################################################################################

comm_round: 12 | global_test_acc: 80.000% | global_f1: 0.888888888888889 | global_precision: 0.8
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.80      1.00      0.89         8

    accuracy                           0.80        10
   macro avg       0.40      0.50      0.44        10
weighted avg       0.64      0.80      0.71        10

Accuracy per class:
[[8 0]
 [2 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0.12454093 0.94328728 0.         0.47375384 0.65532704 1.
 1.         1.         0.38305818 1.         1.         0.55515815
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 0.         0.21494587 1.         1.         1.         0.66519516]
wv_fg shape (30,)
[0.         0.         0.         0.         0.         0.
 0.         0.         1.         0.         0.         0.
 1.         0.         0.         0.         0.33846456 0.
 0.73331898 0.         0.14584121 0.         0.         1.
 0.         0.         0.         0.         0.         0.64130345]
wv_mn shape (30,)
[0.         0.         0.         0.         0.         1.
 1.         1.         1.         1.         0.99633614 1.
 0.         1.         1.         1.         1.         0.88864894
 1.         0.         0.88326066 1.         1.         0.72934512
 0.         1.         1.         1.         1.         1.        ]
wv_ed shape (30,)
[0.         0.         0.         0.         0.         1.
 1.         1.         1.         1.         1.         1.
 0.         1.         1.         1.         1.         1.
 1.         0.18017676 0.98815013 1.         1.         0.88492389
 0.         1.         1.         1.         1.         1.        ]
wv_lg shape (30, 1)
[[0.3255391 ]
 [0.32506433]
 [0.32482043]
 [0.32524482]
 [0.32488885]
 [0.32873551]
 [0.32733568]
 [0.32849785]
 [0.32664691]
 [0.32636143]
 [0.32739898]
 [0.32630639]
 [0.32649849]
 [0.32694269]
 [0.32659783]
 [0.32632455]
 [0.32727846]
 [0.32646128]
 [0.32697293]
 [0.32703957]
 [0.32691388]
 [0.32785761]
 [0.32718458]
 [0.32687394]
 [0.32762825]
 [0.32647215]
 [0.32592807]
 [0.32653461]
 [0.32747899]
 [0.32835265]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1.         1.         1.         1.         1.         0.35708506
 1.         0.         0.38599863 0.         0.27436761 1.
 0.64607978 0.26405255 0.         0.         0.46366225 0.31718694
 1.         0.07909864 0.         0.21674865 0.37637621 0.07280467
 0.         1.         0.4005895  1.         0.53452581 1.        ]
wv_std shape (30,)
[0.         0.         0.         0.         0.         0.34499583
 1.         0.40122657 1.         1.         0.80526846 1.
 0.         1.         1.         1.         0.84543592 0.90429826
 1.         0.         0.04010593 0.4988217  0.40643063 0.57449606
 0.         1.         1.         1.         1.         1.        ]
xy shape: (30, 9)
[[0.12454093 0.         0.         0.         0.3255391  1.
  1.         0.         0.        ]
 [0.94328728 0.         0.         0.         0.32506433 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.32482043 1.
  1.         0.         0.        ]
 [0.47375384 0.         0.         0.         0.32524482 1.
  1.         0.         0.        ]
 [0.65532704 0.         0.         0.         0.32488885 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.32873551 1.
  0.35708506 0.34499583 1.        ]
 [1.         0.         1.         1.         0.32733568 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.32849785 1.
  0.         0.40122657 1.        ]
 [0.38305818 1.         1.         1.         0.32664691 1.
  0.38599863 1.         1.        ]
 [1.         0.         1.         1.         0.32636143 1.
  0.         1.         1.        ]
 [1.         0.         0.99633614 1.         0.32739898 1.
  0.27436761 0.80526846 1.        ]
 [0.55515815 0.         1.         1.         0.32630639 1.
  1.         1.         1.        ]
 [1.         1.         0.         0.         0.32649849 1.
  0.64607978 0.         1.        ]
 [1.         0.         1.         1.         0.32694269 1.
  0.26405255 1.         1.        ]
 [1.         0.         1.         1.         0.32659783 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.32632455 1.
  0.         1.         1.        ]
 [1.         0.33846456 1.         1.         0.32727846 1.
  0.46366225 0.84543592 1.        ]
 [1.         0.         0.88864894 1.         0.32646128 1.
  0.31718694 0.90429826 1.        ]
 [1.         0.73331898 1.         1.         0.32697293 1.
  1.         1.         1.        ]
 [1.         0.         0.         0.18017676 0.32703957 1.
  0.07909864 0.         1.        ]
 [1.         0.14584121 0.88326066 0.98815013 0.32691388 1.
  0.         0.04010593 1.        ]
 [1.         0.         1.         1.         0.32785761 1.
  0.21674865 0.4988217  1.        ]
 [1.         0.         1.         1.         0.32718458 1.
  0.37637621 0.40643063 1.        ]
 [1.         1.         0.72934512 0.88492389 0.32687394 1.
  0.07280467 0.57449606 1.        ]
 [0.         0.         0.         0.         0.32762825 1.
  0.         0.         1.        ]
 [0.21494587 0.         1.         1.         0.32647215 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.32592807 1.
  0.4005895  1.         1.        ]
 [1.         0.         1.         1.         0.32653461 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.32747899 1.
  0.53452581 1.         1.        ]
 [0.66519516 0.64130345 1.         1.         0.32835265 1.
  1.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.9285714030265808
#####################         POISON         ###############################################

############################################################################################

comm_round: 13 | global_test_acc: 80.000% | global_f1: 0.888888888888889 | global_precision: 0.8
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.80      1.00      0.89         8

    accuracy                           0.80        10
   macro avg       0.40      0.50      0.44        10
weighted avg       0.64      0.80      0.71        10

Accuracy per class:
[[8 0]
 [2 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0.         0.18206426 0.14868    0.         0.53821138 0.
 1.         0.         1.         1.         1.         1.
 0.         1.         1.         1.         1.         1.
 0.         1.         1.         1.         0.41586844 1.
 1.         1.         1.         1.         0.45986371 0.        ]
wv_fg shape (30,)
[0.         0.         0.         0.         0.         1.
 0.         1.         0.         0.6808021  0.         0.
 1.         0.         0.         0.         0.26809249 0.
 0.         1.         0.60491165 0.09332196 0.         0.
 0.         1.         0.         0.60491165 0.         0.0070971 ]
wv_mn shape (30,)
[0.         0.         0.         0.         0.         1.
 0.24023488 0.         1.         1.         1.         0.60467708
 0.         0.52963091 0.         1.         0.         1.
 1.         1.         0.         0.74056995 0.         1.
 1.         1.         0.         0.         0.         0.        ]
wv_ed shape (30,)
[0.         0.         0.         0.         0.         1.
 0.28054814 0.         1.         0.67627424 1.         1.
 0.         1.         0.66571323 1.         0.63552388 1.
 1.         1.         0.         0.73792957 0.         1.
 1.         1.         0.         0.         0.         0.        ]
wv_lg shape (30, 1)
[[0.32683319]
 [0.32627764]
 [0.32670742]
 [0.32641197]
 [0.32599602]
 [0.32771866]
 [0.32782194]
 [0.32935009]
 [0.32895083]
 [0.32824011]
 [0.32813666]
 [0.32762962]
 [0.32850339]
 [0.32775142]
 [0.32786087]
 [0.32773334]
 [0.32778537]
 [0.32823693]
 [0.32768667]
 [0.32868397]
 [0.32811031]
 [0.32837296]
 [0.32809282]
 [0.3276552 ]
 [0.32876034]
 [0.32738114]
 [0.32789617]
 [0.32954121]
 [0.32900726]
 [0.32886208]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1.         1.         1.         0.8554123  1.         0.78162546
 0.         0.4591417  1.         0.         1.         0.
 0.17921152 0.         0.         0.         0.17592269 0.
 0.71505857 0.95716364 0.         0.         0.         0.26556452
 0.43522832 0.         0.         0.         0.         0.        ]
wv_std shape (30,)
[0.         0.         0.         0.         0.         1.
 0.05018146 0.         0.1180672  0.         0.6438922  1.
 0.         1.         1.         0.94678124 0.87543974 1.
 1.         0.67899516 0.         0.         0.         1.
 1.         1.         0.51531601 0.         0.         0.        ]
xy shape: (30, 9)
[[0.         0.         0.         0.         0.32683319 1.
  1.         0.         0.        ]
 [0.18206426 0.         0.         0.         0.32627764 1.
  1.         0.         0.        ]
 [0.14868    0.         0.         0.         0.32670742 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.32641197 1.
  0.8554123  0.         0.        ]
 [0.53821138 0.         0.         0.         0.32599602 1.
  1.         0.         0.        ]
 [0.         1.         1.         1.         0.32771866 1.
  0.78162546 1.         1.        ]
 [1.         0.         0.24023488 0.28054814 0.32782194 1.
  0.         0.05018146 1.        ]
 [0.         1.         0.         0.         0.32935009 1.
  0.4591417  0.         1.        ]
 [1.         0.         1.         1.         0.32895083 1.
  1.         0.1180672  1.        ]
 [1.         0.6808021  1.         0.67627424 0.32824011 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.32813666 1.
  1.         0.6438922  1.        ]
 [1.         0.         0.60467708 1.         0.32762962 1.
  0.         1.         1.        ]
 [0.         1.         0.         0.         0.32850339 1.
  0.17921152 0.         1.        ]
 [1.         0.         0.52963091 1.         0.32775142 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.66571323 0.32786087 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.32773334 1.
  0.         0.94678124 1.        ]
 [1.         0.26809249 0.         0.63552388 0.32778537 1.
  0.17592269 0.87543974 1.        ]
 [1.         0.         1.         1.         0.32823693 1.
  0.         1.         1.        ]
 [0.         0.         1.         1.         0.32768667 1.
  0.71505857 1.         1.        ]
 [1.         1.         1.         1.         0.32868397 1.
  0.95716364 0.67899516 1.        ]
 [1.         0.60491165 0.         0.         0.32811031 1.
  0.         0.         1.        ]
 [1.         0.09332196 0.74056995 0.73792957 0.32837296 1.
  0.         0.         1.        ]
 [0.41586844 0.         0.         0.         0.32809282 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.3276552  1.
  0.26556452 1.         1.        ]
 [1.         0.         1.         1.         0.32876034 1.
  0.43522832 1.         1.        ]
 [1.         1.         1.         1.         0.32738114 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.32789617 1.
  0.         0.51531601 1.        ]
 [1.         0.60491165 0.         0.         0.32954121 1.
  0.         0.         1.        ]
 [0.45986371 0.         0.         0.         0.32900726 1.
  0.         0.         1.        ]
 [0.         0.0070971  0.         0.         0.32886208 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.7857142686843872
#####################         POISON         ###############################################

############################################################################################

comm_round: 14 | global_test_acc: 90.000% | global_f1: 0.9473684210526316 | global_precision: 0.9
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.90      1.00      0.95         9

    accuracy                           0.90        10
   macro avg       0.45      0.50      0.47        10
weighted avg       0.81      0.90      0.85        10

Accuracy per class:
[[9 0]
 [1 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[1.         1.         1.         1.         0.         1.
 1.         1.         1.         0.         1.         1.
 0.16862831 1.         0.62290397 0.37412384 0.         1.
 1.         1.         1.         1.         1.         0.33787684
 0.         1.         1.         1.         1.         1.        ]
wv_fg shape (30,)
[0.         0.         0.         0.         0.         0.
 0.         0.74587027 0.03724004 1.         0.         0.12051173
 0.46091524 0.         0.         0.         1.         0.
 0.         0.         0.         0.         0.59925794 1.
 0.         0.         1.         0.         0.         0.        ]
wv_mn shape (30,)
[0.         0.         0.         0.         0.         1.
 1.         0.51531205 1.         0.         0.78851714 1.
 0.         1.         1.         1.         1.         1.
 1.         1.         0.99798934 1.         0.         0.
 1.         1.         1.         1.         1.         1.        ]
wv_ed shape (30,)
[0.         0.         0.         0.         0.         1.
 0.76261087 0.39444063 1.         0.         0.6597231  1.
 0.         1.         1.         1.         1.         1.
 0.9640793  1.         0.91091435 1.         0.02296217 0.
 1.         0.93280908 1.         1.         0.59682267 1.        ]
wv_lg shape (30, 1)
[[0.32788429]
 [0.32729439]
 [0.32789282]
 [0.32818658]
 [0.32713029]
 [0.32967855]
 [0.32968069]
 [0.3290621 ]
 [0.32956259]
 [0.32841543]
 [0.33005288]
 [0.32810787]
 [0.32970201]
 [0.32885111]
 [0.3281257 ]
 [0.32914313]
 [0.32970773]
 [0.32931563]
 [0.32813173]
 [0.32833709]
 [0.32868145]
 [0.32974838]
 [0.32948017]
 [0.32927865]
 [0.32917587]
 [0.32944184]
 [0.33051457]
 [0.32919081]
 [0.3295791 ]
 [0.32841797]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1.         1.         1.         1.         1.         1.
 0.13937628 0.         0.2405182  0.36942456 0.         0.62636008
 1.         0.91642826 0.54501145 1.         0.         1.
 1.         1.         0.32472754 1.         0.05253077 0.
 1.         0.47604278 1.         1.         1.         0.59114082]
wv_std shape (30,)
[0.         0.         0.         0.         0.         1.
 0.         0.32301658 0.44500026 0.         0.         0.08064751
 0.         0.51753811 1.         1.         1.         1.
 0.38500481 1.         0.31339642 0.01093674 0.         0.
 1.         0.06985326 1.         0.64458182 0.         0.24244889]
xy shape: (30, 9)
[[1.         0.         0.         0.         0.32788429 1.
  1.         0.         0.        ]
 [1.         0.         0.         0.         0.32729439 1.
  1.         0.         0.        ]
 [1.         0.         0.         0.         0.32789282 1.
  1.         0.         0.        ]
 [1.         0.         0.         0.         0.32818658 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.32713029 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.32967855 1.
  1.         1.         1.        ]
 [1.         0.         1.         0.76261087 0.32968069 1.
  0.13937628 0.         1.        ]
 [1.         0.74587027 0.51531205 0.39444063 0.3290621  1.
  0.         0.32301658 1.        ]
 [1.         0.03724004 1.         1.         0.32956259 1.
  0.2405182  0.44500026 1.        ]
 [0.         1.         0.         0.         0.32841543 1.
  0.36942456 0.         1.        ]
 [1.         0.         0.78851714 0.6597231  0.33005288 1.
  0.         0.         1.        ]
 [1.         0.12051173 1.         1.         0.32810787 1.
  0.62636008 0.08064751 1.        ]
 [0.16862831 0.46091524 0.         0.         0.32970201 1.
  1.         0.         1.        ]
 [1.         0.         1.         1.         0.32885111 1.
  0.91642826 0.51753811 1.        ]
 [0.62290397 0.         1.         1.         0.3281257  1.
  0.54501145 1.         1.        ]
 [0.37412384 0.         1.         1.         0.32914313 1.
  1.         1.         1.        ]
 [0.         1.         1.         1.         0.32970773 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.32931563 1.
  1.         1.         1.        ]
 [1.         0.         1.         0.9640793  0.32813173 1.
  1.         0.38500481 1.        ]
 [1.         0.         1.         1.         0.32833709 1.
  1.         1.         1.        ]
 [1.         0.         0.99798934 0.91091435 0.32868145 1.
  0.32472754 0.31339642 1.        ]
 [1.         0.         1.         1.         0.32974838 1.
  1.         0.01093674 1.        ]
 [1.         0.59925794 0.         0.02296217 0.32948017 1.
  0.05253077 0.         1.        ]
 [0.33787684 1.         0.         0.         0.32927865 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.32917587 1.
  1.         1.         1.        ]
 [1.         0.         1.         0.93280908 0.32944184 1.
  0.47604278 0.06985326 1.        ]
 [1.         1.         1.         1.         0.33051457 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.32919081 1.
  1.         0.64458182 1.        ]
 [1.         0.         1.         0.59682267 0.3295791  1.
  1.         0.         1.        ]
 [1.         0.         1.         1.         0.32841797 1.
  0.59114082 0.24244889 1.        ]]

Best Training Poisoning Accuracy:
0.8571428656578064
#####################         POISON         ###############################################

############################################################################################

comm_round: 15 | global_test_acc: 70.000% | global_f1: 0.8235294117647058 | global_precision: 0.7
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.70      1.00      0.82         7

    accuracy                           0.70        10
   macro avg       0.35      0.50      0.41        10
weighted avg       0.49      0.70      0.58        10

Accuracy per class:
[[7 0]
 [3 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0.         0.         0.19325009 0.         0.         1.
 1.         0.         1.         0.         1.         1.
 1.         0.62806591 1.         1.         1.         1.
 1.         1.         1.         1.         1.         0.
 1.         1.         1.         1.         1.         1.        ]
wv_fg shape (30,)
[0.         0.         0.         0.         0.         1.
 0.22426555 0.         0.49375526 0.         0.         1.
 0.         1.         0.72079466 0.52176003 0.61363609 0.
 0.49375526 0.         0.         1.         0.15622809 0.
 1.         0.         1.         0.15622809 0.         0.22426555]
wv_mn shape (30,)
[0.         0.         0.         0.         0.         1.
 0.         1.         0.         0.         1.         1.
 0.78147427 1.         0.89343744 1.         0.         1.
 0.58026417 1.         0.         0.         0.         1.
 1.         1.         1.         1.         0.         0.        ]
wv_ed shape (30,)
[0.         0.         0.         0.         0.         1.
 0.         1.         0.33509319 0.         1.         0.8309816
 0.91262576 1.         0.         1.         0.         1.
 0.87113823 1.         0.45734403 0.         0.         1.
 1.         1.         1.         1.         0.20850482 0.        ]
wv_lg shape (30, 1)
[[0.3289315 ]
 [0.32892065]
 [0.32896651]
 [0.3281676 ]
 [0.32816585]
 [0.331465  ]
 [0.33011678]
 [0.32982639]
 [0.32983125]
 [0.33075811]
 [0.33052386]
 [0.32970112]
 [0.33033891]
 [0.32849848]
 [0.33039376]
 [0.32990494]
 [0.33149914]
 [0.33104385]
 [0.32932391]
 [0.33001349]
 [0.3305181 ]
 [0.33032486]
 [0.33096669]
 [0.33034127]
 [0.33024474]
 [0.33107707]
 [0.33031369]
 [0.33060036]
 [0.33096832]
 [0.33051666]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1.         1.         1.         1.         1.         0.87176425
 0.         0.35088482 0.         0.         0.44480587 1.
 1.         1.         1.         0.56107984 0.71191165 1.
 0.         0.         0.         0.         0.         0.82278868
 1.         1.         0.9319628  0.         0.50259542 0.        ]
wv_std shape (30,)
[0.         0.         0.         0.         0.         0.1645006
 0.         1.         0.         0.         0.6797363  0.
 0.17888847 1.         0.         0.93124341 0.         0.77476668
 0.40682068 1.         0.76871118 0.         0.         1.
 0.41198766 0.48843359 0.43628271 0.57734685 0.28225319 0.        ]
xy shape: (30, 9)
[[0.         0.         0.         0.         0.3289315  1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.32892065 1.
  1.         0.         0.        ]
 [0.19325009 0.         0.         0.         0.32896651 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.3281676  1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.32816585 1.
  1.         0.         0.        ]
 [1.         1.         1.         1.         0.331465   1.
  0.87176425 0.1645006  1.        ]
 [1.         0.22426555 0.         0.         0.33011678 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.32982639 1.
  0.35088482 1.         1.        ]
 [1.         0.49375526 0.         0.33509319 0.32983125 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33075811 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.33052386 1.
  0.44480587 0.6797363  1.        ]
 [1.         1.         1.         0.8309816  0.32970112 1.
  1.         0.         1.        ]
 [1.         0.         0.78147427 0.91262576 0.33033891 1.
  1.         0.17888847 1.        ]
 [0.62806591 1.         1.         1.         0.32849848 1.
  1.         1.         1.        ]
 [1.         0.72079466 0.89343744 0.         0.33039376 1.
  1.         0.         1.        ]
 [1.         0.52176003 1.         1.         0.32990494 1.
  0.56107984 0.93124341 1.        ]
 [1.         0.61363609 0.         0.         0.33149914 1.
  0.71191165 0.         1.        ]
 [1.         0.         1.         1.         0.33104385 1.
  1.         0.77476668 1.        ]
 [1.         0.49375526 0.58026417 0.87113823 0.32932391 1.
  0.         0.40682068 1.        ]
 [1.         0.         1.         1.         0.33001349 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.45734403 0.3305181  1.
  0.         0.76871118 1.        ]
 [1.         1.         0.         0.         0.33032486 1.
  0.         0.         1.        ]
 [1.         0.15622809 0.         0.         0.33096669 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.33034127 1.
  0.82278868 1.         1.        ]
 [1.         1.         1.         1.         0.33024474 1.
  1.         0.41198766 1.        ]
 [1.         0.         1.         1.         0.33107707 1.
  1.         0.48843359 1.        ]
 [1.         1.         1.         1.         0.33031369 1.
  0.9319628  0.43628271 1.        ]
 [1.         0.15622809 1.         1.         0.33060036 1.
  0.         0.57734685 1.        ]
 [1.         0.         0.         0.20850482 0.33096832 1.
  0.50259542 0.28225319 1.        ]
 [1.         0.22426555 0.         0.         0.33051666 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.7857142686843872
#####################         POISON         ###############################################

############################################################################################

comm_round: 16 | global_test_acc: 90.000% | global_f1: 0.9473684210526316 | global_precision: 0.9
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.90      1.00      0.95         9

    accuracy                           0.90        10
   macro avg       0.45      0.50      0.47        10
weighted avg       0.81      0.90      0.85        10

Accuracy per class:
[[9 0]
 [1 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0.8965804  0.         0.0085975  0.         0.20247162 0.
 1.         1.         1.         1.         0.8229846  1.
 1.         1.         1.         1.         1.         1.
 1.         0.62970452 0.         1.         0.         0.
 1.         1.         0.         1.         0.         0.5045894 ]
wv_fg shape (30,)
[0.         0.         0.         0.         0.         0.04141931
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         1.         0.38398591 0.
 0.         0.45821464 1.         1.         0.3694271  0.61307392
 0.         0.21607617 0.         0.         0.         0.        ]
wv_mn shape (30,)
[0.         0.         0.         0.         0.         1.
 0.86114426 1.         0.         0.58494422 0.41519991 1.
 1.         1.         1.         0.98526732 1.         0.
 1.         0.         1.         1.         1.         0.
 0.64814793 1.         0.         1.         0.         0.67116218]
wv_ed shape (30,)
[0.         0.         0.         0.         0.         1.
 0.76002017 0.52863912 0.         0.50232139 0.         1.
 0.77685438 1.         1.         0.32476591 0.64787404 0.
 1.         0.         1.         0.13065878 1.         0.
 0.02863357 1.         0.         1.         0.         0.        ]
wv_lg shape (30, 1)
[[0.32993715]
 [0.33025767]
 [0.3298824 ]
 [0.3302201 ]
 [0.32962643]
 [0.33106475]
 [0.3313506 ]
 [0.33136587]
 [0.33092519]
 [0.331892  ]
 [0.33089994]
 [0.33205131]
 [0.33125288]
 [0.33062502]
 [0.33110193]
 [0.33022472]
 [0.33205534]
 [0.33103418]
 [0.33101956]
 [0.33147805]
 [0.33259251]
 [0.33221073]
 [0.33104744]
 [0.33170418]
 [0.33111219]
 [0.3306189 ]
 [0.33156288]
 [0.33151314]
 [0.33173593]
 [0.33153426]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1.         1.         1.         1.         1.         0.72754558
 1.         1.         0.         0.77371603 0.         0.
 1.         0.         0.         1.         0.63016673 0.
 0.21433261 0.66368848 0.69045924 0.         0.         0.3629028
 0.07729172 0.25033214 0.38891099 1.         0.         1.        ]
wv_std shape (30,)
[0.         0.         0.         0.         0.         1.
 0.60888167 0.         0.         0.59246251 0.         0.86872282
 0.31968913 1.         1.         0.36963419 0.25303637 0.
 0.5461851  0.         1.         0.         1.         0.
 0.         1.         0.         0.20055229 0.         0.        ]
xy shape: (30, 9)
[[0.8965804  0.         0.         0.         0.32993715 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.33025767 1.
  1.         0.         0.        ]
 [0.0085975  0.         0.         0.         0.3298824  1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.3302201  1.
  1.         0.         0.        ]
 [0.20247162 0.         0.         0.         0.32962643 1.
  1.         0.         0.        ]
 [0.         0.04141931 1.         1.         0.33106475 1.
  0.72754558 1.         1.        ]
 [1.         0.         0.86114426 0.76002017 0.3313506  1.
  1.         0.60888167 1.        ]
 [1.         0.         1.         0.52863912 0.33136587 1.
  1.         0.         1.        ]
 [1.         0.         0.         0.         0.33092519 1.
  0.         0.         1.        ]
 [1.         0.         0.58494422 0.50232139 0.331892   1.
  0.77371603 0.59246251 1.        ]
 [0.8229846  0.         0.41519991 0.         0.33089994 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.33205131 1.
  0.         0.86872282 1.        ]
 [1.         0.         1.         0.77685438 0.33125288 1.
  1.         0.31968913 1.        ]
 [1.         0.         1.         1.         0.33062502 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.33110193 1.
  0.         1.         1.        ]
 [1.         1.         0.98526732 0.32476591 0.33022472 1.
  1.         0.36963419 1.        ]
 [1.         0.38398591 1.         0.64787404 0.33205534 1.
  0.63016673 0.25303637 1.        ]
 [1.         0.         0.         0.         0.33103418 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.33101956 1.
  0.21433261 0.5461851  1.        ]
 [0.62970452 0.45821464 0.         0.         0.33147805 1.
  0.66368848 0.         1.        ]
 [0.         1.         1.         1.         0.33259251 1.
  0.69045924 1.         1.        ]
 [1.         1.         1.         0.13065878 0.33221073 1.
  0.         0.         1.        ]
 [0.         0.3694271  1.         1.         0.33104744 1.
  0.         1.         1.        ]
 [0.         0.61307392 0.         0.         0.33170418 1.
  0.3629028  0.         1.        ]
 [1.         0.         0.64814793 0.02863357 0.33111219 1.
  0.07729172 0.         1.        ]
 [1.         0.21607617 1.         1.         0.3306189  1.
  0.25033214 1.         1.        ]
 [0.         0.         0.         0.         0.33156288 1.
  0.38891099 0.         1.        ]
 [1.         0.         1.         1.         0.33151314 1.
  1.         0.20055229 1.        ]
 [0.         0.         0.         0.         0.33173593 1.
  0.         0.         1.        ]
 [0.5045894  0.         0.67116218 0.         0.33153426 1.
  1.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.7857142686843872
#####################         POISON         ###############################################

############################################################################################

comm_round: 17 | global_test_acc: 90.000% | global_f1: 0.9473684210526316 | global_precision: 0.9
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.90      1.00      0.95         9

    accuracy                           0.90        10
   macro avg       0.45      0.50      0.47        10
weighted avg       0.81      0.90      0.85        10

Accuracy per class:
[[9 0]
 [1 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0.         0.         0.26724018 0.         0.         1.
 1.         1.         1.         1.         0.         0.0430244
 1.         0.         1.         1.         0.         0.
 1.         1.         1.         1.         0.         1.
 1.         1.         1.         1.         1.         1.        ]
wv_fg shape (30,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         1.         0.         0.         0.         0.
 1.         0.         1.         0.8121514  0.70327384 0.21108263
 0.85702891 0.         0.         0.12141433 0.         0.        ]
wv_mn shape (30,)
[0.         0.         0.         0.         0.         0.67025664
 1.         1.         1.         1.         0.         0.30620016
 1.         1.         0.41641808 1.         0.         0.
 1.         0.39752172 1.         1.         0.         1.
 1.         0.84161922 1.         0.97565598 0.95709331 1.        ]
wv_ed shape (30,)
[0.         0.         0.         0.         0.         1.
 1.         1.         1.         1.         0.         0.
 1.         1.         0.         1.         0.         0.
 1.         0.92301995 0.81078043 1.         0.         0.
 1.         0.23846179 0.95709392 0.40709177 0.39849402 1.        ]
wv_lg shape (30, 1)
[[0.33125252]
 [0.33047286]
 [0.33090238]
 [0.33041558]
 [0.33020944]
 [0.33239721]
 [0.33361484]
 [0.3332486 ]
 [0.33192999]
 [0.33232971]
 [0.33337728]
 [0.33343214]
 [0.33258051]
 [0.33148636]
 [0.33303694]
 [0.33235137]
 [0.33301299]
 [0.33380136]
 [0.33283924]
 [0.33183707]
 [0.33236088]
 [0.33042171]
 [0.33210974]
 [0.3317815 ]
 [0.3333372 ]
 [0.33289713]
 [0.33170446]
 [0.33337956]
 [0.33255971]
 [0.33248141]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1.         1.         1.         1.         1.         0.76062189
 1.         1.         0.         0.         0.         0.20434719
 0.         0.         0.17343418 0.         0.         0.59403962
 1.         0.75186849 1.         0.         1.         0.56120568
 0.92921835 0.         0.         1.         0.18904172 0.        ]
wv_std shape (30,)
[0.         0.         0.         0.         0.         0.50041317
 0.28011954 0.63654398 0.68235997 1.         0.         0.
 0.06807883 1.         0.         1.         0.         0.
 0.98289998 0.24230264 0.         1.         0.         0.
 0.         0.         0.         0.         0.         0.9118195 ]
xy shape: (30, 9)
[[0.         0.         0.         0.         0.33125252 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.33047286 1.
  1.         0.         0.        ]
 [0.26724018 0.         0.         0.         0.33090238 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.33041558 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.33020944 1.
  1.         0.         0.        ]
 [1.         0.         0.67025664 1.         0.33239721 1.
  0.76062189 0.50041317 1.        ]
 [1.         0.         1.         1.         0.33361484 1.
  1.         0.28011954 1.        ]
 [1.         0.         1.         1.         0.3332486  1.
  1.         0.63654398 1.        ]
 [1.         0.         1.         1.         0.33192999 1.
  0.         0.68235997 1.        ]
 [1.         0.         1.         1.         0.33232971 1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.33337728 1.
  0.         0.         1.        ]
 [0.0430244  0.         0.30620016 0.         0.33343214 1.
  0.20434719 0.         1.        ]
 [1.         0.         1.         1.         0.33258051 1.
  0.         0.06807883 1.        ]
 [0.         1.         1.         1.         0.33148636 1.
  0.         1.         1.        ]
 [1.         0.         0.41641808 0.         0.33303694 1.
  0.17343418 0.         1.        ]
 [1.         0.         1.         1.         0.33235137 1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.33301299 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33380136 1.
  0.59403962 0.         1.        ]
 [1.         1.         1.         1.         0.33283924 1.
  1.         0.98289998 1.        ]
 [1.         0.         0.39752172 0.92301995 0.33183707 1.
  0.75186849 0.24230264 1.        ]
 [1.         1.         1.         0.81078043 0.33236088 1.
  1.         0.         1.        ]
 [1.         0.8121514  1.         1.         0.33042171 1.
  0.         1.         1.        ]
 [0.         0.70327384 0.         0.         0.33210974 1.
  1.         0.         1.        ]
 [1.         0.21108263 1.         0.         0.3317815  1.
  0.56120568 0.         1.        ]
 [1.         0.85702891 1.         1.         0.3333372  1.
  0.92921835 0.         1.        ]
 [1.         0.         0.84161922 0.23846179 0.33289713 1.
  0.         0.         1.        ]
 [1.         0.         1.         0.95709392 0.33170446 1.
  0.         0.         1.        ]
 [1.         0.12141433 0.97565598 0.40709177 0.33337956 1.
  1.         0.         1.        ]
 [1.         0.         0.95709331 0.39849402 0.33255971 1.
  0.18904172 0.         1.        ]
 [1.         0.         1.         1.         0.33248141 1.
  0.         0.9118195  1.        ]]

Best Training Poisoning Accuracy:
0.7857142686843872
#####################         POISON         ###############################################

############################################################################################

comm_round: 18 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00        10

    accuracy                           1.00        10
   macro avg       1.00      1.00      1.00        10
weighted avg       1.00      1.00      1.00        10

Accuracy per class:
[[10  0]
 [ 0  0]]
[ 1. nan]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[1.         0.85804761 0.30761783 0.1009985  0.08491455 1.
 1.         1.         1.         1.         1.         1.
 1.         1.         0.8868066  1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         0.         1.         1.        ]
wv_fg shape (30,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.46396193 0.         0.         0.         0.         0.
 0.         0.30921983 0.         0.         1.         0.        ]
wv_mn shape (30,)
[0.3681911  0.         0.         0.         0.         1.
 1.         1.         1.         1.         1.         1.
 0.6842002  1.         1.         1.         1.         0.60067881
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         0.         1.         1.        ]
wv_ed shape (30,)
[0.08868922 0.         0.         0.         0.         1.
 0.90397489 1.         1.         1.         1.         1.
 0.60573105 1.         1.         1.         1.         0.72746894
 0.72163577 1.         1.         1.         1.         0.47392091
 1.         1.         1.         0.         1.         1.        ]
wv_lg shape (30, 1)
[[0.33212213]
 [0.33222313]
 [0.33162709]
 [0.33164948]
 [0.33208526]
 [0.33396404]
 [0.33377404]
 [0.33382679]
 [0.33373824]
 [0.33383011]
 [0.33433344]
 [0.33423399]
 [0.33428493]
 [0.33352701]
 [0.33249473]
 [0.3341133 ]
 [0.33336336]
 [0.33366697]
 [0.33324912]
 [0.33404787]
 [0.33424132]
 [0.3336819 ]
 [0.3336491 ]
 [0.33506606]
 [0.33386727]
 [0.33459974]
 [0.33430243]
 [0.33412108]
 [0.33422886]
 [0.3341474 ]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[0.86511162 1.         1.         0.40063528 1.         0.
 0.24060764 0.         0.3216927  0.         0.08871096 0.
 0.         0.14733026 0.         0.         0.         0.
 0.         0.73895501 1.         0.         0.         0.
 0.67558792 1.         1.         0.31916219 0.75921094 0.14018916]
wv_std shape (30,)
[0.         0.         0.         0.         0.         1.
 0.         0.97511682 0.78813801 0.17088058 0.26610016 0.70152712
 0.         1.         1.         0.40489322 1.         0.
 0.         0.05264219 1.         1.         1.         0.
 1.         0.50786274 0.         0.         0.6612139  0.15227576]
xy shape: (30, 9)
[[1.         0.         0.3681911  0.08868922 0.33212213 1.
  0.86511162 0.         0.        ]
 [0.85804761 0.         0.         0.         0.33222313 1.
  1.         0.         0.        ]
 [0.30761783 0.         0.         0.         0.33162709 1.
  1.         0.         0.        ]
 [0.1009985  0.         0.         0.         0.33164948 1.
  0.40063528 0.         0.        ]
 [0.08491455 0.         0.         0.         0.33208526 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.33396404 1.
  0.         1.         1.        ]
 [1.         0.         1.         0.90397489 0.33377404 1.
  0.24060764 0.         1.        ]
 [1.         0.         1.         1.         0.33382679 1.
  0.         0.97511682 1.        ]
 [1.         0.         1.         1.         0.33373824 1.
  0.3216927  0.78813801 1.        ]
 [1.         0.         1.         1.         0.33383011 1.
  0.         0.17088058 1.        ]
 [1.         0.         1.         1.         0.33433344 1.
  0.08871096 0.26610016 1.        ]
 [1.         0.         1.         1.         0.33423399 1.
  0.         0.70152712 1.        ]
 [1.         0.         0.6842002  0.60573105 0.33428493 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.33352701 1.
  0.14733026 1.         1.        ]
 [0.8868066  0.         1.         1.         0.33249473 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.3341133  1.
  0.         0.40489322 1.        ]
 [1.         0.         1.         1.         0.33336336 1.
  0.         1.         1.        ]
 [1.         0.         0.60067881 0.72746894 0.33366697 1.
  0.         0.         1.        ]
 [1.         0.46396193 1.         0.72163577 0.33324912 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.33404787 1.
  0.73895501 0.05264219 1.        ]
 [1.         0.         1.         1.         0.33424132 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.3336819  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.3336491  1.
  0.         1.         1.        ]
 [1.         0.         1.         0.47392091 0.33506606 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.33386727 1.
  0.67558792 1.         1.        ]
 [1.         0.30921983 1.         1.         0.33459974 1.
  1.         0.50786274 1.        ]
 [1.         0.         1.         1.         0.33430243 1.
  1.         0.         1.        ]
 [0.         0.         0.         0.         0.33412108 1.
  0.31916219 0.         1.        ]
 [1.         1.         1.         1.         0.33422886 1.
  0.75921094 0.6612139  1.        ]
 [1.         0.         1.         1.         0.3341474  1.
  0.14018916 0.15227576 1.        ]]

Best Training Poisoning Accuracy:
0.8571428656578064
#####################         POISON         ###############################################

############################################################################################

comm_round: 19 | global_test_acc: 80.000% | global_f1: 0.888888888888889 | global_precision: 0.8
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.80      1.00      0.89         8

    accuracy                           0.80        10
   macro avg       0.40      0.50      0.44        10
weighted avg       0.64      0.80      0.71        10

Accuracy per class:
[[8 0]
 [2 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[1.        0.4528529 1.        1.        0.        1.        0.
 0.        0.        0.        0.        1.        0.        1.
 1.        1.        0.        0.        1.        0.        0.
 1.        0.        1.        1.        1.        1.        1.
 1.        1.       ]
wv_fg shape (30,)
[0.         0.         0.         0.         0.         0.
 0.         0.34558102 0.         0.         0.         1.
 0.         0.         0.51814793 0.         0.6258001  0.
 0.         0.46658966 0.         0.         0.         0.
 0.         0.         0.         0.37674537 0.         0.        ]
wv_mn shape (30,)
[0.         0.         0.         0.         0.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         0.33066516 1.         0.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.        ]
wv_ed shape (30,)
[0.         0.         0.         0.         0.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         0.29780345 1.         0.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.79884432 1.        ]
wv_lg shape (30, 1)
[[0.33373916]
 [0.33248468]
 [0.33293369]
 [0.33318411]
 [0.33387227]
 [0.3352114 ]
 [0.33558722]
 [0.33543967]
 [0.33546382]
 [0.33495647]
 [0.33453852]
 [0.33439916]
 [0.33426666]
 [0.33561241]
 [0.33395283]
 [0.33534562]
 [0.33496206]
 [0.33478099]
 [0.33512839]
 [0.33466955]
 [0.33559582]
 [0.33526004]
 [0.33489817]
 [0.33561225]
 [0.33466109]
 [0.33526735]
 [0.33503611]
 [0.33422578]
 [0.33582453]
 [0.33481091]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1.         1.         1.         1.         1.         0.28602554
 0.95095908 0.89646169 0.45618418 0.         1.         0.61965105
 0.         0.63994745 0.         0.         0.         0.68258925
 1.         0.         0.20016521 0.06478983 1.         0.48953429
 0.         1.         0.         0.95556786 0.28496461 0.8857117 ]
wv_std shape (30,)
[0.         0.         0.         0.         0.         0.
 1.         1.         1.         1.         1.         0.8690661
 1.         0.24545995 0.         1.         0.         1.
 0.2386424  1.         1.         0.8107162  1.         1.
 1.         0.86530297 1.         1.         0.         0.03481315]
xy shape: (30, 9)
[[1.         0.         0.         0.         0.33373916 1.
  1.         0.         0.        ]
 [0.4528529  0.         0.         0.         0.33248468 1.
  1.         0.         0.        ]
 [1.         0.         0.         0.         0.33293369 1.
  1.         0.         0.        ]
 [1.         0.         0.         0.         0.33318411 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.33387227 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.3352114  1.
  0.28602554 0.         1.        ]
 [0.         0.         1.         1.         0.33558722 1.
  0.95095908 1.         1.        ]
 [0.         0.34558102 1.         1.         0.33543967 1.
  0.89646169 1.         1.        ]
 [0.         0.         1.         1.         0.33546382 1.
  0.45618418 1.         1.        ]
 [0.         0.         1.         1.         0.33495647 1.
  0.         1.         1.        ]
 [0.         0.         1.         1.         0.33453852 1.
  1.         1.         1.        ]
 [1.         1.         1.         1.         0.33439916 1.
  0.61965105 0.8690661  1.        ]
 [0.         0.         1.         1.         0.33426666 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.33561241 1.
  0.63994745 0.24545995 1.        ]
 [1.         0.51814793 0.33066516 0.29780345 0.33395283 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.33534562 1.
  0.         1.         1.        ]
 [0.         0.6258001  0.         0.         0.33496206 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.33478099 1.
  0.68258925 1.         1.        ]
 [1.         0.         1.         1.         0.33512839 1.
  1.         0.2386424  1.        ]
 [0.         0.46658966 1.         1.         0.33466955 1.
  0.         1.         1.        ]
 [0.         0.         1.         1.         0.33559582 1.
  0.20016521 1.         1.        ]
 [1.         0.         1.         1.         0.33526004 1.
  0.06478983 0.8107162  1.        ]
 [0.         0.         1.         1.         0.33489817 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.33561225 1.
  0.48953429 1.         1.        ]
 [1.         0.         1.         1.         0.33466109 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.33526735 1.
  1.         0.86530297 1.        ]
 [1.         0.         1.         1.         0.33503611 1.
  0.         1.         1.        ]
 [1.         0.37674537 1.         1.         0.33422578 1.
  0.95556786 1.         1.        ]
 [1.         0.         1.         0.79884432 0.33582453 1.
  0.28496461 0.         1.        ]
 [1.         0.         1.         1.         0.33481091 1.
  0.8857117  0.03481315 1.        ]]

Best Training Poisoning Accuracy:
0.8571428656578064
#####################         POISON         ###############################################

############################################################################################

comm_round: 20 | global_test_acc: 80.000% | global_f1: 0.888888888888889 | global_precision: 0.8
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.80      1.00      0.89         8

    accuracy                           0.80        10
   macro avg       0.40      0.50      0.44        10
weighted avg       0.64      0.80      0.71        10

Accuracy per class:
[[8 0]
 [2 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0.         1.         0.4763432  0.32859025 0.         1.
 1.         1.         1.         1.         1.         1.
 0.         1.         1.         1.         1.         1.
 1.         1.         0.         1.         1.         1.
 1.         1.         1.         1.         1.         1.        ]
wv_fg shape (30,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         1.
 0.         0.         1.         0.         0.27832673 1.
 0.72188124 0.         0.         1.         0.         0.
 1.         0.         0.5192197  0.         1.         0.        ]
wv_mn shape (30,)
[0.         0.58604604 0.         0.         0.         1.
 1.         1.         1.         1.         0.35422117 0.38594687
 0.         1.         1.         1.         0.9379603  1.
 1.         1.         0.         1.         0.74002844 0.
 1.         0.31206848 1.         0.93586261 1.         1.        ]
wv_ed shape (30,)
[0.         0.54361163 0.         0.         0.         1.
 1.         1.         0.84962623 1.         0.         0.29274957
 0.         1.         1.         1.         0.62587418 1.
 1.         1.         0.         1.         0.81315481 0.4251147
 1.         0.         1.         0.70216126 1.         1.        ]
wv_lg shape (30, 1)
[[0.33449087]
 [0.33466131]
 [0.33444229]
 [0.33485837]
 [0.33425291]
 [0.33617215]
 [0.33653307]
 [0.33669973]
 [0.33628662]
 [0.33526688]
 [0.33673352]
 [0.33461418]
 [0.33670939]
 [0.33586838]
 [0.33664778]
 [0.33526153]
 [0.33580508]
 [0.33535866]
 [0.33537022]
 [0.33525341]
 [0.33626174]
 [0.33505979]
 [0.33625321]
 [0.33514617]
 [0.33732545]
 [0.33592834]
 [0.33620924]
 [0.33631739]
 [0.33481661]
 [0.33606086]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1.         1.         0.44168597 1.         1.         0.8906179
 0.         0.         1.         0.         0.81637292 0.
 0.04430272 0.         1.         0.         0.         0.
 0.01114684 0.35159754 0.         0.78617674 0.         0.69774953
 1.         0.         1.         0.87241042 0.         0.24898067]
wv_std shape (30,)
[0.         0.         0.         0.         0.         1.
 1.         0.44144046 0.         1.         0.         0.4625659
 0.         0.48102245 1.         1.         0.20717279 1.
 1.         1.         0.         0.68737326 0.2286829  0.71192968
 0.37545275 0.         1.         0.         1.         1.        ]
xy shape: (30, 9)
[[0.         0.         0.         0.         0.33449087 1.
  1.         0.         0.        ]
 [1.         0.         0.58604604 0.54361163 0.33466131 1.
  1.         0.         0.        ]
 [0.4763432  0.         0.         0.         0.33444229 1.
  0.44168597 0.         0.        ]
 [0.32859025 0.         0.         0.         0.33485837 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.33425291 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.33617215 1.
  0.8906179  1.         1.        ]
 [1.         0.         1.         1.         0.33653307 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.33669973 1.
  0.         0.44144046 1.        ]
 [1.         0.         1.         0.84962623 0.33628662 1.
  1.         0.         1.        ]
 [1.         0.         1.         1.         0.33526688 1.
  0.         1.         1.        ]
 [1.         0.         0.35422117 0.         0.33673352 1.
  0.81637292 0.         1.        ]
 [1.         1.         0.38594687 0.29274957 0.33461418 1.
  0.         0.4625659  1.        ]
 [0.         0.         0.         0.         0.33670939 1.
  0.04430272 0.         1.        ]
 [1.         0.         1.         1.         0.33586838 1.
  0.         0.48102245 1.        ]
 [1.         1.         1.         1.         0.33664778 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.33526153 1.
  0.         1.         1.        ]
 [1.         0.27832673 0.9379603  0.62587418 0.33580508 1.
  0.         0.20717279 1.        ]
 [1.         1.         1.         1.         0.33535866 1.
  0.         1.         1.        ]
 [1.         0.72188124 1.         1.         0.33537022 1.
  0.01114684 1.         1.        ]
 [1.         0.         1.         1.         0.33525341 1.
  0.35159754 1.         1.        ]
 [0.         0.         0.         0.         0.33626174 1.
  0.         0.         1.        ]
 [1.         1.         1.         1.         0.33505979 1.
  0.78617674 0.68737326 1.        ]
 [1.         0.         0.74002844 0.81315481 0.33625321 1.
  0.         0.2286829  1.        ]
 [1.         0.         0.         0.4251147  0.33514617 1.
  0.69774953 0.71192968 1.        ]
 [1.         1.         1.         1.         0.33732545 1.
  1.         0.37545275 1.        ]
 [1.         0.         0.31206848 0.         0.33592834 1.
  0.         0.         1.        ]
 [1.         0.5192197  1.         1.         0.33620924 1.
  1.         1.         1.        ]
 [1.         0.         0.93586261 0.70216126 0.33631739 1.
  0.87241042 0.         1.        ]
 [1.         1.         1.         1.         0.33481661 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.33606086 1.
  0.24898067 1.         1.        ]]

Best Training Poisoning Accuracy:
0.7857142686843872
#####################         POISON         ###############################################

############################################################################################

comm_round: 21 | global_test_acc: 80.000% | global_f1: 0.888888888888889 | global_precision: 0.8
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.80      1.00      0.89         8

    accuracy                           0.80        10
   macro avg       0.40      0.50      0.44        10
weighted avg       0.64      0.80      0.71        10

Accuracy per class:
[[8 0]
 [2 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0.0131764  0.         0.22331955 0.         0.23325105 1.
 0.         1.         1.         1.         1.         0.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.        ]
wv_fg shape (30,)
[0.         0.         0.         0.         0.         1.
 1.         0.         0.46972188 0.         0.         0.
 0.         0.         0.08327899 0.         0.         1.
 0.64950356 0.         1.         0.         0.         0.
 0.         0.79631258 1.         1.         0.         1.        ]
wv_mn shape (30,)
[0.         0.         0.         0.         0.         1.
 0.         1.         1.         1.         1.         0.
 0.0720919  0.22807089 1.         1.         0.96485897 1.
 1.         0.83190473 1.         0.7386475  1.         1.
 1.         0.49746695 1.         1.         1.         0.        ]
wv_ed shape (30,)
[0.         0.         0.         0.         0.         1.
 0.         1.         1.         1.         1.         0.
 0.         0.22804077 1.         1.         1.         0.92256897
 1.         0.         0.61642892 0.50772955 0.89582311 0.67500765
 1.         1.         0.93904992 1.         1.         0.30960085]
wv_lg shape (30, 1)
[[0.33535837]
 [0.33529655]
 [0.33551983]
 [0.33594792]
 [0.3354628 ]
 [0.33765274]
 [0.33767401]
 [0.33604278]
 [0.33708643]
 [0.33645552]
 [0.33713408]
 [0.33747491]
 [0.33744647]
 [0.33658587]
 [0.33739299]
 [0.33737605]
 [0.33728626]
 [0.33752158]
 [0.33655014]
 [0.33663533]
 [0.33801899]
 [0.33782889]
 [0.3365719 ]
 [0.33749374]
 [0.33632207]
 [0.3370298 ]
 [0.33692535]
 [0.3360178 ]
 [0.33664893]
 [0.33816813]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[0.36303425 1.         1.         1.         1.         0.
 0.         0.         1.         0.         0.24036004 0.
 0.30658539 0.         0.         0.24369237 0.         1.
 0.         0.         0.49031832 0.         0.         1.
 0.         0.25868217 0.         0.         0.         0.34055989]
wv_std shape (30,)
[0.         0.         0.         0.         0.         0.46768259
 0.         1.         1.         1.         1.         0.
 0.         0.20074613 1.         1.         0.79889388 0.23419204
 1.         0.         0.12401931 0.         0.23429973 0.
 1.         1.         1.         1.         1.         0.53794479]
xy shape: (30, 9)
[[0.0131764  0.         0.         0.         0.33535837 1.
  0.36303425 0.         0.        ]
 [0.         0.         0.         0.         0.33529655 1.
  1.         0.         0.        ]
 [0.22331955 0.         0.         0.         0.33551983 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.33594792 1.
  1.         0.         0.        ]
 [0.23325105 0.         0.         0.         0.3354628  1.
  1.         0.         0.        ]
 [1.         1.         1.         1.         0.33765274 1.
  0.         0.46768259 1.        ]
 [0.         1.         0.         0.         0.33767401 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.33604278 1.
  0.         1.         1.        ]
 [1.         0.46972188 1.         1.         0.33708643 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.33645552 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.33713408 1.
  0.24036004 1.         1.        ]
 [0.         0.         0.         0.         0.33747491 1.
  0.         0.         1.        ]
 [1.         0.         0.0720919  0.         0.33744647 1.
  0.30658539 0.         1.        ]
 [1.         0.         0.22807089 0.22804077 0.33658587 1.
  0.         0.20074613 1.        ]
 [1.         0.08327899 1.         1.         0.33739299 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.33737605 1.
  0.24369237 1.         1.        ]
 [1.         0.         0.96485897 1.         0.33728626 1.
  0.         0.79889388 1.        ]
 [1.         1.         1.         0.92256897 0.33752158 1.
  1.         0.23419204 1.        ]
 [1.         0.64950356 1.         1.         0.33655014 1.
  0.         1.         1.        ]
 [1.         0.         0.83190473 0.         0.33663533 1.
  0.         0.         1.        ]
 [1.         1.         1.         0.61642892 0.33801899 1.
  0.49031832 0.12401931 1.        ]
 [1.         0.         0.7386475  0.50772955 0.33782889 1.
  0.         0.         1.        ]
 [1.         0.         1.         0.89582311 0.3365719  1.
  0.         0.23429973 1.        ]
 [1.         0.         1.         0.67500765 0.33749374 1.
  1.         0.         1.        ]
 [1.         0.         1.         1.         0.33632207 1.
  0.         1.         1.        ]
 [1.         0.79631258 0.49746695 1.         0.3370298  1.
  0.25868217 1.         1.        ]
 [1.         1.         1.         0.93904992 0.33692535 1.
  0.         1.         1.        ]
 [1.         1.         1.         1.         0.3360178  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.33664893 1.
  0.         1.         1.        ]
 [1.         1.         0.         0.30960085 0.33816813 1.
  0.34055989 0.53794479 1.        ]]

Best Training Poisoning Accuracy:
0.9285714030265808
#####################         POISON         ###############################################

############################################################################################

comm_round: 22 | global_test_acc: 80.000% | global_f1: 0.888888888888889 | global_precision: 0.8
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.80      1.00      0.89         8

    accuracy                           0.80        10
   macro avg       0.40      0.50      0.44        10
weighted avg       0.64      0.80      0.71        10

Accuracy per class:
[[8 0]
 [2 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0.82400596 0.         0.08534019 0.1077929  0.24459106 1.
 1.         0.92030363 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.21835278 1.
 1.         0.13233518 1.         0.         1.         0.        ]
wv_fg shape (30,)
[0.         0.         0.         0.         0.         0.57130522
 0.         0.74048497 0.         0.         0.         1.
 0.         0.         0.07939787 0.         0.         0.
 0.2117506  0.         0.         0.25045261 1.         0.8639706
 0.         0.         0.         1.         0.         0.66350058]
wv_mn shape (30,)
[0.         0.         0.         0.         0.         1.
 1.         1.         1.         0.70605105 0.         0.46578884
 0.         0.92249526 1.         1.         0.77967181 0.
 0.93654116 1.         0.29060671 0.         1.         1.
 0.59686235 1.         1.         0.         0.         1.        ]
wv_ed shape (30,)
[0.         0.         0.         0.         0.         1.
 1.         1.         1.         1.         0.         0.1180145
 0.08046123 0.7144062  1.         1.         1.         0.
 0.52393549 1.         0.68803662 0.34758769 1.         1.
 1.         1.         1.         0.         0.16499214 1.        ]
wv_lg shape (30, 1)
[[0.33660119]
 [0.33640188]
 [0.33635029]
 [0.33651924]
 [0.33645991]
 [0.33847963]
 [0.33742297]
 [0.33736389]
 [0.33797373]
 [0.33766476]
 [0.33805993]
 [0.33970368]
 [0.33827471]
 [0.33834257]
 [0.33742117]
 [0.33699591]
 [0.33795795]
 [0.33784618]
 [0.33777936]
 [0.3370599 ]
 [0.33819273]
 [0.33921817]
 [0.33773639]
 [0.33702156]
 [0.33828741]
 [0.33855243]
 [0.33913376]
 [0.34002945]
 [0.33799181]
 [0.3370451 ]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[0.19960243 0.40064034 0.         0.35260132 0.64014753 0.61608837
 0.         0.45999245 0.         0.         0.         1.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.49895391 0.
 0.         0.         0.         0.         0.         0.        ]
wv_std shape (30,)
[0.         0.         0.         0.         0.         0.50243355
 0.4154292  1.         0.73705372 0.85026957 0.         0.
 0.         0.         1.         1.         1.         0.
 0.         1.         0.         0.04610176 1.         1.
 0.3679363  1.         0.69181687 0.         0.         1.        ]
xy shape: (30, 9)
[[0.82400596 0.         0.         0.         0.33660119 1.
  0.19960243 0.         0.        ]
 [0.         0.         0.         0.         0.33640188 1.
  0.40064034 0.         0.        ]
 [0.08534019 0.         0.         0.         0.33635029 1.
  0.         0.         0.        ]
 [0.1077929  0.         0.         0.         0.33651924 1.
  0.35260132 0.         0.        ]
 [0.24459106 0.         0.         0.         0.33645991 1.
  0.64014753 0.         0.        ]
 [1.         0.57130522 1.         1.         0.33847963 1.
  0.61608837 0.50243355 1.        ]
 [1.         0.         1.         1.         0.33742297 1.
  0.         0.4154292  1.        ]
 [0.92030363 0.74048497 1.         1.         0.33736389 1.
  0.45999245 1.         1.        ]
 [1.         0.         1.         1.         0.33797373 1.
  0.         0.73705372 1.        ]
 [1.         0.         0.70605105 1.         0.33766476 1.
  0.         0.85026957 1.        ]
 [1.         0.         0.         0.         0.33805993 1.
  0.         0.         1.        ]
 [1.         1.         0.46578884 0.1180145  0.33970368 1.
  1.         0.         1.        ]
 [1.         0.         0.         0.08046123 0.33827471 1.
  0.         0.         1.        ]
 [1.         0.         0.92249526 0.7144062  0.33834257 1.
  0.         0.         1.        ]
 [1.         0.07939787 1.         1.         0.33742117 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.33699591 1.
  0.         1.         1.        ]
 [1.         0.         0.77967181 1.         0.33795795 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.33784618 1.
  0.         0.         1.        ]
 [1.         0.2117506  0.93654116 0.52393549 0.33777936 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.3370599  1.
  0.         1.         1.        ]
 [1.         0.         0.29060671 0.68803662 0.33819273 1.
  0.         0.         1.        ]
 [1.         0.25045261 0.         0.34758769 0.33921817 1.
  0.         0.04610176 1.        ]
 [0.21835278 1.         1.         1.         0.33773639 1.
  0.49895391 1.         1.        ]
 [1.         0.8639706  1.         1.         0.33702156 1.
  0.         1.         1.        ]
 [1.         0.         0.59686235 1.         0.33828741 1.
  0.         0.3679363  1.        ]
 [0.13233518 0.         1.         1.         0.33855243 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.33913376 1.
  0.         0.69181687 1.        ]
 [0.         1.         0.         0.         0.34002945 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.16499214 0.33799181 1.
  0.         0.         1.        ]
 [0.         0.66350058 1.         1.         0.3370451  1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.8571428656578064
#####################         POISON         ###############################################

############################################################################################

comm_round: 23 | global_test_acc: 80.000% | global_f1: 0.888888888888889 | global_precision: 0.8
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.80      1.00      0.89         8

    accuracy                           0.80        10
   macro avg       0.40      0.50      0.44        10
weighted avg       0.64      0.80      0.71        10

Accuracy per class:
[[8 0]
 [2 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0.         0.95442929 0.16005623 1.         0.89965937 1.
 1.         1.         1.         1.         1.         1.
 0.         1.         1.         0.         1.         1.
 1.         1.         0.         1.         1.         0.
 1.         0.         0.50516494 1.         0.50338877 1.        ]
wv_fg shape (30,)
[0.         0.         0.         0.         0.         0.75333028
 0.         0.         0.         0.         0.         1.
 0.         0.         0.         0.         0.         0.
 0.20537243 0.         0.         0.48162027 0.         0.07950109
 0.         0.20537243 0.         1.         0.         1.        ]
wv_mn shape (30,)
[0.         0.         0.         0.         0.         0.8192934
 0.         1.         1.         1.         0.16774938 0.19144651
 0.         1.         0.35812178 0.         0.21344169 1.
 0.55258698 1.         0.         1.         1.         0.
 1.         0.         0.         0.31160957 0.         0.79233352]
wv_ed shape (30,)
[0.         0.         0.         0.07653867 0.         0.78711682
 0.         1.         1.         1.         0.37241385 0.
 0.         1.         0.         0.         0.         1.
 0.         0.98979132 0.         1.         1.         0.
 1.         0.         0.         0.22074304 0.         0.47698569]
wv_lg shape (30, 1)
[[0.33742602]
 [0.33756322]
 [0.33711121]
 [0.33786957]
 [0.33735049]
 [0.33906443]
 [0.33895002]
 [0.33857391]
 [0.33862136]
 [0.33927711]
 [0.33861532]
 [0.33881439]
 [0.33891674]
 [0.33911938]
 [0.33935978]
 [0.33954177]
 [0.33873082]
 [0.33768029]
 [0.34013411]
 [0.33846684]
 [0.33961672]
 [0.3385231 ]
 [0.33866766]
 [0.33943467]
 [0.33806104]
 [0.33974703]
 [0.33913443]
 [0.34049682]
 [0.3391666 ]
 [0.33843748]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[0.6736232  0.83398735 1.         0.8889763  1.         1.
 0.         0.         0.81012979 1.         0.         0.69907924
 0.         0.         0.         0.         0.         0.24493243
 0.02690732 0.         0.06700965 0.         0.50962078 0.01406126
 0.         0.09403511 0.         0.9894461  0.         1.        ]
wv_std shape (30,)
[0.         0.         0.         0.         0.         0.58109568
 0.13785849 1.         1.         1.         0.39139935 0.
 0.         1.         0.         0.         0.         1.
 0.         0.39955512 0.         1.         1.         0.
 1.         0.         0.         0.         0.         0.        ]
xy shape: (30, 9)
[[0.         0.         0.         0.         0.33742602 1.
  0.6736232  0.         0.        ]
 [0.95442929 0.         0.         0.         0.33756322 1.
  0.83398735 0.         0.        ]
 [0.16005623 0.         0.         0.         0.33711121 1.
  1.         0.         0.        ]
 [1.         0.         0.         0.07653867 0.33786957 1.
  0.8889763  0.         0.        ]
 [0.89965937 0.         0.         0.         0.33735049 1.
  1.         0.         0.        ]
 [1.         0.75333028 0.8192934  0.78711682 0.33906443 1.
  1.         0.58109568 1.        ]
 [1.         0.         0.         0.         0.33895002 1.
  0.         0.13785849 1.        ]
 [1.         0.         1.         1.         0.33857391 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.33862136 1.
  0.81012979 1.         1.        ]
 [1.         0.         1.         1.         0.33927711 1.
  1.         1.         1.        ]
 [1.         0.         0.16774938 0.37241385 0.33861532 1.
  0.         0.39139935 1.        ]
 [1.         1.         0.19144651 0.         0.33881439 1.
  0.69907924 0.         1.        ]
 [0.         0.         0.         0.         0.33891674 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.33911938 1.
  0.         1.         1.        ]
 [1.         0.         0.35812178 0.         0.33935978 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33954177 1.
  0.         0.         1.        ]
 [1.         0.         0.21344169 0.         0.33873082 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.33768029 1.
  0.24493243 1.         1.        ]
 [1.         0.20537243 0.55258698 0.         0.34013411 1.
  0.02690732 0.         1.        ]
 [1.         0.         1.         0.98979132 0.33846684 1.
  0.         0.39955512 1.        ]
 [0.         0.         0.         0.         0.33961672 1.
  0.06700965 0.         1.        ]
 [1.         0.48162027 1.         1.         0.3385231  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.33866766 1.
  0.50962078 1.         1.        ]
 [0.         0.07950109 0.         0.         0.33943467 1.
  0.01406126 0.         1.        ]
 [1.         0.         1.         1.         0.33806104 1.
  0.         1.         1.        ]
 [0.         0.20537243 0.         0.         0.33974703 1.
  0.09403511 0.         1.        ]
 [0.50516494 0.         0.         0.         0.33913443 1.
  0.         0.         1.        ]
 [1.         1.         0.31160957 0.22074304 0.34049682 1.
  0.9894461  0.         1.        ]
 [0.50338877 0.         0.         0.         0.3391666  1.
  0.         0.         1.        ]
 [1.         1.         0.79233352 0.47698569 0.33843748 1.
  1.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.7857142686843872
#####################         POISON         ###############################################

############################################################################################

comm_round: 24 | global_test_acc: 90.000% | global_f1: 0.9473684210526316 | global_precision: 0.9
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.90      1.00      0.95         9

    accuracy                           0.90        10
   macro avg       0.45      0.50      0.47        10
weighted avg       0.81      0.90      0.85        10

Accuracy per class:
[[9 0]
 [1 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0.         0.13916381 0.         0.         0.         1.
 1.         1.         0.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.         1.
 1.         1.         1.         1.         1.         1.        ]
wv_fg shape (30,)
[0.         0.         0.         0.         0.         0.96923997
 0.         0.10460711 1.         1.         0.         1.
 0.74044343 0.         0.         0.2677974  0.         0.21218036
 0.         1.         0.21218036 0.         1.         0.96772138
 0.         0.         1.         0.         0.         1.        ]
wv_mn shape (30,)
[0.         0.         0.         0.         0.         1.
 1.         1.         0.2436584  1.         0.49296794 1.
 1.         0.73054384 0.993559   1.         1.         0.70852567
 1.         1.         1.         1.         0.         1.
 1.         0.31910349 0.95076196 0.8749281  1.         1.        ]
wv_ed shape (30,)
[0.         0.         0.         0.         0.         0.8021569
 0.40119416 0.21890682 0.         1.         0.05842166 1.
 1.         0.0578585  0.78207733 0.36183271 0.73779781 0.28139373
 1.         1.         1.         1.         0.         1.
 1.         0.15683375 0.47877336 0.16629585 1.         0.65262212]
wv_lg shape (30, 1)
[[0.33892115]
 [0.33841901]
 [0.33777206]
 [0.33776896]
 [0.33787018]
 [0.33929381]
 [0.34020605]
 [0.34012103]
 [0.34014587]
 [0.33918917]
 [0.33998471]
 [0.33911179]
 [0.34022425]
 [0.34029394]
 [0.33990166]
 [0.34009202]
 [0.33961467]
 [0.34055564]
 [0.33952149]
 [0.33994685]
 [0.34041329]
 [0.3396973 ]
 [0.33983072]
 [0.34006295]
 [0.3394455 ]
 [0.3398089 ]
 [0.34068026]
 [0.34029744]
 [0.33986258]
 [0.3401787 ]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1.         1.         1.         1.         1.         0.
 1.         1.         0.         0.5495226  0.31062485 1.
 1.         0.80067558 1.         0.68414117 0.         0.
 0.96897778 0.         0.2660207  0.         0.         1.
 0.         0.24914358 0.41646985 0.         1.         0.4491053 ]
wv_std shape (30,)
[0.         0.         0.         0.         0.         0.00490059
 0.         0.         0.         1.         0.         0.62271165
 0.33552887 0.         0.         0.         0.         0.
 1.         1.         0.         1.         0.         0.
 1.         0.         0.         0.         0.83438006 0.        ]
xy shape: (30, 9)
[[0.         0.         0.         0.         0.33892115 1.
  1.         0.         0.        ]
 [0.13916381 0.         0.         0.         0.33841901 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.33777206 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.33776896 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.33787018 1.
  1.         0.         0.        ]
 [1.         0.96923997 1.         0.8021569  0.33929381 1.
  0.         0.00490059 1.        ]
 [1.         0.         1.         0.40119416 0.34020605 1.
  1.         0.         1.        ]
 [1.         0.10460711 1.         0.21890682 0.34012103 1.
  1.         0.         1.        ]
 [0.         1.         0.2436584  0.         0.34014587 1.
  0.         0.         1.        ]
 [1.         1.         1.         1.         0.33918917 1.
  0.5495226  1.         1.        ]
 [1.         0.         0.49296794 0.05842166 0.33998471 1.
  0.31062485 0.         1.        ]
 [1.         1.         1.         1.         0.33911179 1.
  1.         0.62271165 1.        ]
 [1.         0.74044343 1.         1.         0.34022425 1.
  1.         0.33552887 1.        ]
 [1.         0.         0.73054384 0.0578585  0.34029394 1.
  0.80067558 0.         1.        ]
 [1.         0.         0.993559   0.78207733 0.33990166 1.
  1.         0.         1.        ]
 [1.         0.2677974  1.         0.36183271 0.34009202 1.
  0.68414117 0.         1.        ]
 [1.         0.         1.         0.73779781 0.33961467 1.
  0.         0.         1.        ]
 [1.         0.21218036 0.70852567 0.28139373 0.34055564 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.33952149 1.
  0.96897778 1.         1.        ]
 [1.         1.         1.         1.         0.33994685 1.
  0.         1.         1.        ]
 [1.         0.21218036 1.         1.         0.34041329 1.
  0.2660207  0.         1.        ]
 [1.         0.         1.         1.         0.3396973  1.
  0.         1.         1.        ]
 [0.         1.         0.         0.         0.33983072 1.
  0.         0.         1.        ]
 [1.         0.96772138 1.         1.         0.34006295 1.
  1.         0.         1.        ]
 [1.         0.         1.         1.         0.3394455  1.
  0.         1.         1.        ]
 [1.         0.         0.31910349 0.15683375 0.3398089  1.
  0.24914358 0.         1.        ]
 [1.         1.         0.95076196 0.47877336 0.34068026 1.
  0.41646985 0.         1.        ]
 [1.         0.         0.8749281  0.16629585 0.34029744 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.33986258 1.
  1.         0.83438006 1.        ]
 [1.         1.         1.         0.65262212 0.3401787  1.
  0.4491053  0.         1.        ]]

Best Training Poisoning Accuracy:
0.9285714030265808
#####################         POISON         ###############################################

############################################################################################

comm_round: 25 | global_test_acc: 70.000% | global_f1: 0.8235294117647058 | global_precision: 0.7
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.70      1.00      0.82         7

    accuracy                           0.70        10
   macro avg       0.35      0.50      0.41        10
weighted avg       0.49      0.70      0.58        10

Accuracy per class:
[[7 0]
 [3 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[1.         0.         0.84973481 1.         1.         1.
 1.         1.         1.         1.         0.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 0.         1.         1.         1.         1.         1.        ]
wv_fg shape (30,)
[0.         0.         0.         0.         0.         0.
 0.55583505 0.1906804  0.43617149 0.         0.         0.
 0.         0.35097393 1.         0.         0.         0.48617905
 0.         0.         0.03153694 0.         0.         0.27086894
 1.         0.         1.         0.         0.         0.        ]
wv_mn shape (30,)
[0.18795671 0.         0.         0.         0.29726515 1.
 1.         1.         1.         0.1288753  0.         1.
 1.         0.73225222 0.8807585  1.         1.         1.
 1.         1.         1.         1.         1.         1.
 0.24658648 0.76192223 0.98055226 1.         1.         1.        ]
wv_ed shape (30,)
[0.         0.         0.         0.         0.67250077 1.
 1.         1.         0.49099183 0.41830632 0.         0.93710241
 1.         0.8502035  0.36137879 1.         1.         1.
 1.         1.         1.         0.45881179 1.         1.
 0.         0.2897945  1.         1.         1.         1.        ]
wv_lg shape (30, 1)
[[0.33942408]
 [0.33915569]
 [0.33882172]
 [0.33910556]
 [0.33966476]
 [0.34075608]
 [0.3407402 ]
 [0.34084811]
 [0.34067463]
 [0.34047697]
 [0.34069341]
 [0.34047811]
 [0.34080624]
 [0.34114326]
 [0.34144682]
 [0.34081741]
 [0.34128006]
 [0.34058524]
 [0.34050038]
 [0.34081789]
 [0.34037115]
 [0.34142814]
 [0.34119165]
 [0.34139257]
 [0.34177391]
 [0.34104725]
 [0.34012113]
 [0.34102033]
 [0.34073233]
 [0.34114448]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1.         1.         1.         1.         1.         1.
 1.         0.07347206 0.83505306 0.45895878 0.         0.41325195
 1.         0.         0.         0.24438573 1.         1.
 1.         0.00459034 0.53836761 1.         1.         0.61008464
 0.67680347 0.3796958  0.         0.         0.01840097 1.        ]
wv_std shape (30,)
[0.         0.         0.         0.         0.         1.
 1.         1.         0.         0.41891539 0.         0.19862684
 0.37192693 0.56323157 0.10976014 1.         1.         1.
 1.         1.         1.         0.         1.         0.77777779
 0.         0.         1.         1.         1.         0.50267863]
xy shape: (30, 9)
[[1.         0.         0.18795671 0.         0.33942408 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.33915569 1.
  1.         0.         0.        ]
 [0.84973481 0.         0.         0.         0.33882172 1.
  1.         0.         0.        ]
 [1.         0.         0.         0.         0.33910556 1.
  1.         0.         0.        ]
 [1.         0.         0.29726515 0.67250077 0.33966476 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.34075608 1.
  1.         1.         1.        ]
 [1.         0.55583505 1.         1.         0.3407402  1.
  1.         1.         1.        ]
 [1.         0.1906804  1.         1.         0.34084811 1.
  0.07347206 1.         1.        ]
 [1.         0.43617149 1.         0.49099183 0.34067463 1.
  0.83505306 0.         1.        ]
 [1.         0.         0.1288753  0.41830632 0.34047697 1.
  0.45895878 0.41891539 1.        ]
 [0.         0.         0.         0.         0.34069341 1.
  0.         0.         1.        ]
 [1.         0.         1.         0.93710241 0.34047811 1.
  0.41325195 0.19862684 1.        ]
 [1.         0.         1.         1.         0.34080624 1.
  1.         0.37192693 1.        ]
 [1.         0.35097393 0.73225222 0.8502035  0.34114326 1.
  0.         0.56323157 1.        ]
 [1.         1.         0.8807585  0.36137879 0.34144682 1.
  0.         0.10976014 1.        ]
 [1.         0.         1.         1.         0.34081741 1.
  0.24438573 1.         1.        ]
 [1.         0.         1.         1.         0.34128006 1.
  1.         1.         1.        ]
 [1.         0.48617905 1.         1.         0.34058524 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.34050038 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.34081789 1.
  0.00459034 1.         1.        ]
 [1.         0.03153694 1.         1.         0.34037115 1.
  0.53836761 1.         1.        ]
 [1.         0.         1.         0.45881179 0.34142814 1.
  1.         0.         1.        ]
 [1.         0.         1.         1.         0.34119165 1.
  1.         1.         1.        ]
 [1.         0.27086894 1.         1.         0.34139257 1.
  0.61008464 0.77777779 1.        ]
 [0.         1.         0.24658648 0.         0.34177391 1.
  0.67680347 0.         1.        ]
 [1.         0.         0.76192223 0.2897945  0.34104725 1.
  0.3796958  0.         1.        ]
 [1.         1.         0.98055226 1.         0.34012113 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.34102033 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.34073233 1.
  0.01840097 1.         1.        ]
 [1.         0.         1.         1.         0.34114448 1.
  1.         0.50267863 1.        ]]

Best Training Poisoning Accuracy:
0.7857142686843872
#####################         POISON         ###############################################

############################################################################################

comm_round: 26 | global_test_acc: 90.000% | global_f1: 0.9473684210526316 | global_precision: 0.9
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.90      1.00      0.95         9

    accuracy                           0.90        10
   macro avg       0.45      0.50      0.47        10
weighted avg       0.81      0.90      0.85        10

Accuracy per class:
[[9 0]
 [1 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0.         0.         0.39042932 0.         0.29706032 0.41730422
 1.         1.         1.         1.         1.         1.
 0.27141151 1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 0.         0.17690516 1.         1.         1.         1.        ]
wv_fg shape (30,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.83443662 0.
 0.         0.24650529 1.         0.0673368  0.         0.89402102
 0.0673368  0.         0.         0.         0.         0.
 0.         0.         0.         1.         0.         0.        ]
wv_mn shape (30,)
[0.         0.         0.         0.         0.         0.
 0.51081231 0.86473227 1.         1.         1.         0.
 0.15178198 0.         1.         0.03107482 1.         0.89814792
 1.         1.         1.         0.59244874 1.         1.
 0.         0.         0.         0.         1.         0.85907342]
wv_ed shape (30,)
[0.         0.         0.         0.         0.         0.
 0.62285369 0.78924209 1.         1.         1.         0.66807283
 0.         0.         0.38760832 0.42333703 1.         1.
 1.         1.         1.         1.         1.         1.
 0.         0.         0.         0.         1.         1.        ]
wv_lg shape (30, 1)
[[0.34000006]
 [0.34035486]
 [0.3402313 ]
 [0.340517  ]
 [0.34022858]
 [0.34239018]
 [0.34233263]
 [0.3426069 ]
 [0.3422961 ]
 [0.34151294]
 [0.34124225]
 [0.34099223]
 [0.34121513]
 [0.3415662 ]
 [0.34180749]
 [0.34117372]
 [0.34082618]
 [0.34097554]
 [0.34167744]
 [0.34171789]
 [0.34142974]
 [0.34178424]
 [0.34251693]
 [0.34124148]
 [0.34164808]
 [0.34247609]
 [0.34135308]
 [0.34174158]
 [0.34247761]
 [0.34172846]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1.         1.         1.         1.         1.         0.
 0.13694397 0.09484334 0.         0.         0.33791425 0.
 0.19394114 0.         0.74751671 0.         1.         0.
 0.54358286 0.         1.         0.         1.         0.16580655
 0.         0.17552931 0.22226397 0.68301535 0.         0.79237012]
wv_std shape (30,)
[0.         0.         0.         0.         0.         0.
 0.         0.30137093 0.55616492 1.         1.         1.
 0.         0.         0.         0.07819543 1.         0.94013239
 1.         1.         1.         1.         0.36659829 1.
 0.         0.         0.         0.         0.74053058 0.324191  ]
xy shape: (30, 9)
[[0.         0.         0.         0.         0.34000006 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.34035486 1.
  1.         0.         0.        ]
 [0.39042932 0.         0.         0.         0.3402313  1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.340517   1.
  1.         0.         0.        ]
 [0.29706032 0.         0.         0.         0.34022858 1.
  1.         0.         0.        ]
 [0.41730422 0.         0.         0.         0.34239018 1.
  0.         0.         1.        ]
 [1.         0.         0.51081231 0.62285369 0.34233263 1.
  0.13694397 0.         1.        ]
 [1.         0.         0.86473227 0.78924209 0.3426069  1.
  0.09484334 0.30137093 1.        ]
 [1.         0.         1.         1.         0.3422961  1.
  0.         0.55616492 1.        ]
 [1.         0.         1.         1.         0.34151294 1.
  0.         1.         1.        ]
 [1.         0.83443662 1.         1.         0.34124225 1.
  0.33791425 1.         1.        ]
 [1.         0.         0.         0.66807283 0.34099223 1.
  0.         1.         1.        ]
 [0.27141151 0.         0.15178198 0.         0.34121513 1.
  0.19394114 0.         1.        ]
 [1.         0.24650529 0.         0.         0.3415662  1.
  0.         0.         1.        ]
 [1.         1.         1.         0.38760832 0.34180749 1.
  0.74751671 0.         1.        ]
 [1.         0.0673368  0.03107482 0.42333703 0.34117372 1.
  0.         0.07819543 1.        ]
 [1.         0.         1.         1.         0.34082618 1.
  1.         1.         1.        ]
 [1.         0.89402102 0.89814792 1.         0.34097554 1.
  0.         0.94013239 1.        ]
 [1.         0.0673368  1.         1.         0.34167744 1.
  0.54358286 1.         1.        ]
 [1.         0.         1.         1.         0.34171789 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.34142974 1.
  1.         1.         1.        ]
 [1.         0.         0.59244874 1.         0.34178424 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.34251693 1.
  1.         0.36659829 1.        ]
 [1.         0.         1.         1.         0.34124148 1.
  0.16580655 1.         1.        ]
 [0.         0.         0.         0.         0.34164808 1.
  0.         0.         1.        ]
 [0.17690516 0.         0.         0.         0.34247609 1.
  0.17552931 0.         1.        ]
 [1.         0.         0.         0.         0.34135308 1.
  0.22226397 0.         1.        ]
 [1.         1.         0.         0.         0.34174158 1.
  0.68301535 0.         1.        ]
 [1.         0.         1.         1.         0.34247761 1.
  0.         0.74053058 1.        ]
 [1.         0.         0.85907342 1.         0.34172846 1.
  0.79237012 0.324191   1.        ]]

Best Training Poisoning Accuracy:
0.8571428656578064
#####################         POISON         ###############################################

############################################################################################

comm_round: 27 | global_test_acc: 90.000% | global_f1: 0.9473684210526316 | global_precision: 0.9
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.90      1.00      0.95         9

    accuracy                           0.90        10
   macro avg       0.45      0.50      0.47        10
weighted avg       0.81      0.90      0.85        10

Accuracy per class:
[[9 0]
 [1 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[1.         0.08429928 0.11646459 1.         0.46179352 1.
 1.         1.         1.         1.         1.         1.
 1.         0.94262391 1.         1.         1.         1.
 1.         1.         1.         1.         1.         0.
 1.         1.         1.         1.         1.         1.        ]
wv_fg shape (30,)
[0.         0.         0.         0.         0.         0.07493436
 0.         0.72788884 0.         0.42742334 0.         0.
 0.41375433 0.1390102  1.         1.         0.32795177 1.
 0.41375433 0.09663699 0.         0.         0.         0.
 1.         1.         0.69183165 0.86012255 0.45312326 0.        ]
wv_mn shape (30,)
[0.32290285 0.         0.         0.         0.         0.63258733
 1.         1.         1.         1.         0.34574647 1.
 1.         1.         0.         1.         1.         1.
 1.         1.         1.         1.         0.32727772 0.
 0.4058893  0.40951611 1.         1.         1.         1.        ]
wv_ed shape (30,)
[0.37380877 0.         0.         0.         0.         0.54507926
 1.         1.         1.         1.         0.5831552  0.9749286
 1.         1.         0.         1.         1.         1.
 1.         1.         1.         1.         0.53894398 0.
 0.73364855 1.         0.78231594 1.         0.63588562 1.        ]
wv_lg shape (30, 1)
[[0.34135195]
 [0.3411623 ]
 [0.34083192]
 [0.34155943]
 [0.34139851]
 [0.34241435]
 [0.34242432]
 [0.34339896]
 [0.3433712 ]
 [0.34251948]
 [0.34313193]
 [0.34404693]
 [0.34385795]
 [0.34268582]
 [0.34306141]
 [0.34171189]
 [0.34230013]
 [0.34176064]
 [0.3431006 ]
 [0.34235907]
 [0.34246569]
 [0.34276071]
 [0.34283122]
 [0.34256607]
 [0.34280306]
 [0.34074468]
 [0.34343491]
 [0.34364727]
 [0.34286605]
 [0.34154707]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1.         1.         1.         1.         1.         0.39654222
 1.         0.         1.         1.         1.         1.
 1.         1.         1.         0.         1.         0.
 0.70791963 0.97917901 0.805591   0.24567738 0.         0.
 0.         0.         1.         1.         0.76365425 0.        ]
wv_std shape (30,)
[0.         0.         0.         0.         0.         0.
 1.         1.         1.         0.79860222 0.         0.
 0.55728192 1.         0.24668177 1.         0.79771879 1.
 1.         1.         1.         0.98717671 0.08305228 0.
 1.         1.         0.4798855  1.         0.         1.        ]
xy shape: (30, 9)
[[1.         0.         0.32290285 0.37380877 0.34135195 1.
  1.         0.         0.        ]
 [0.08429928 0.         0.         0.         0.3411623  1.
  1.         0.         0.        ]
 [0.11646459 0.         0.         0.         0.34083192 1.
  1.         0.         0.        ]
 [1.         0.         0.         0.         0.34155943 1.
  1.         0.         0.        ]
 [0.46179352 0.         0.         0.         0.34139851 1.
  1.         0.         0.        ]
 [1.         0.07493436 0.63258733 0.54507926 0.34241435 1.
  0.39654222 0.         1.        ]
 [1.         0.         1.         1.         0.34242432 1.
  1.         1.         1.        ]
 [1.         0.72788884 1.         1.         0.34339896 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.3433712  1.
  1.         1.         1.        ]
 [1.         0.42742334 1.         1.         0.34251948 1.
  1.         0.79860222 1.        ]
 [1.         0.         0.34574647 0.5831552  0.34313193 1.
  1.         0.         1.        ]
 [1.         0.         1.         0.9749286  0.34404693 1.
  1.         0.         1.        ]
 [1.         0.41375433 1.         1.         0.34385795 1.
  1.         0.55728192 1.        ]
 [0.94262391 0.1390102  1.         1.         0.34268582 1.
  1.         1.         1.        ]
 [1.         1.         0.         0.         0.34306141 1.
  1.         0.24668177 1.        ]
 [1.         1.         1.         1.         0.34171189 1.
  0.         1.         1.        ]
 [1.         0.32795177 1.         1.         0.34230013 1.
  1.         0.79771879 1.        ]
 [1.         1.         1.         1.         0.34176064 1.
  0.         1.         1.        ]
 [1.         0.41375433 1.         1.         0.3431006  1.
  0.70791963 1.         1.        ]
 [1.         0.09663699 1.         1.         0.34235907 1.
  0.97917901 1.         1.        ]
 [1.         0.         1.         1.         0.34246569 1.
  0.805591   1.         1.        ]
 [1.         0.         1.         1.         0.34276071 1.
  0.24567738 0.98717671 1.        ]
 [1.         0.         0.32727772 0.53894398 0.34283122 1.
  0.         0.08305228 1.        ]
 [0.         0.         0.         0.         0.34256607 1.
  0.         0.         1.        ]
 [1.         1.         0.4058893  0.73364855 0.34280306 1.
  0.         1.         1.        ]
 [1.         1.         0.40951611 1.         0.34074468 1.
  0.         1.         1.        ]
 [1.         0.69183165 1.         0.78231594 0.34343491 1.
  1.         0.4798855  1.        ]
 [1.         0.86012255 1.         1.         0.34364727 1.
  1.         1.         1.        ]
 [1.         0.45312326 1.         0.63588562 0.34286605 1.
  0.76365425 0.         1.        ]
 [1.         0.         1.         1.         0.34154707 1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.7857142686843872
#####################         POISON         ###############################################

############################################################################################

comm_round: 28 | global_test_acc: 90.000% | global_f1: 0.9473684210526316 | global_precision: 0.9
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.90      1.00      0.95         9

    accuracy                           0.90        10
   macro avg       0.45      0.50      0.47        10
weighted avg       0.81      0.90      0.85        10

Accuracy per class:
[[9 0]
 [1 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0.         1.         0.         1.         0.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         0.
 1.         0.5545677  1.         0.         1.         0.92996669
 1.         1.         1.         0.         0.81580559 0.82799098]
wv_fg shape (30,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         1.         0.         0.
 0.         0.         0.         0.         0.56243491 0.
 0.         0.10035664 0.36159385 0.         0.         0.
 0.68891729 0.23438913 0.48586474 0.         0.05113256 0.        ]
wv_mn shape (30,)
[0.         0.10422927 0.         0.         0.         0.916943
 0.45969643 0.         0.         1.         1.         1.
 1.         0.00451806 1.         0.         0.3719036  0.
 0.98938963 0.3435674  1.         0.         1.         0.
 1.         1.         1.         0.         0.         0.        ]
wv_ed shape (30,)
[0.         0.02866435 0.         0.17690846 0.         0.60698479
 0.93683486 0.33526034 0.50415811 1.         1.         1.
 1.         0.8786724  1.         0.71573906 1.         0.
 0.83815834 0.         1.         0.         1.         0.
 1.         1.         1.         0.         0.         0.        ]
wv_lg shape (30, 1)
[[0.34204947]
 [0.34215286]
 [0.34205229]
 [0.34255017]
 [0.34185961]
 [0.34308236]
 [0.34345226]
 [0.34337474]
 [0.34303076]
 [0.34305436]
 [0.34419305]
 [0.34435032]
 [0.34236618]
 [0.34320766]
 [0.34410768]
 [0.34324337]
 [0.34350314]
 [0.34381548]
 [0.34417844]
 [0.34362545]
 [0.34298671]
 [0.34422167]
 [0.34248196]
 [0.34296681]
 [0.34317394]
 [0.34445279]
 [0.34376358]
 [0.34432322]
 [0.34319633]
 [0.3438347 ]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[0.79251182 1.         0.91854266 1.         1.         0.
 0.         0.         0.         0.49102142 0.30453858 0.77684522
 0.         0.         0.07961901 0.         0.         0.47611358
 0.         0.31540923 0.22212368 0.72574793 0.34401895 0.
 1.         0.03160286 1.         0.5545216  0.16656501 0.44952605]
wv_std shape (30,)
[0.         0.         0.         0.         0.         0.
 0.63997105 0.47858749 0.25527223 1.         0.30129841 1.
 1.         1.         0.93246641 0.8068956  1.         0.
 0.02260955 0.         1.         0.         1.         0.
 1.         1.         0.84161072 0.         0.         0.        ]
xy shape: (30, 9)
[[0.         0.         0.         0.         0.34204947 1.
  0.79251182 0.         0.        ]
 [1.         0.         0.10422927 0.02866435 0.34215286 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.34205229 1.
  0.91854266 0.         0.        ]
 [1.         0.         0.         0.17690846 0.34255017 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.34185961 1.
  1.         0.         0.        ]
 [1.         0.         0.916943   0.60698479 0.34308236 1.
  0.         0.         1.        ]
 [1.         0.         0.45969643 0.93683486 0.34345226 1.
  0.         0.63997105 1.        ]
 [1.         0.         0.         0.33526034 0.34337474 1.
  0.         0.47858749 1.        ]
 [1.         0.         0.         0.50415811 0.34303076 1.
  0.         0.25527223 1.        ]
 [1.         1.         1.         1.         0.34305436 1.
  0.49102142 1.         1.        ]
 [1.         0.         1.         1.         0.34419305 1.
  0.30453858 0.30129841 1.        ]
 [1.         0.         1.         1.         0.34435032 1.
  0.77684522 1.         1.        ]
 [1.         0.         1.         1.         0.34236618 1.
  0.         1.         1.        ]
 [1.         0.         0.00451806 0.8786724  0.34320766 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.34410768 1.
  0.07961901 0.93246641 1.        ]
 [1.         0.         0.         0.71573906 0.34324337 1.
  0.         0.8068956  1.        ]
 [1.         0.56243491 0.3719036  1.         0.34350314 1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.34381548 1.
  0.47611358 0.         1.        ]
 [1.         0.         0.98938963 0.83815834 0.34417844 1.
  0.         0.02260955 1.        ]
 [0.5545677  0.10035664 0.3435674  0.         0.34362545 1.
  0.31540923 0.         1.        ]
 [1.         0.36159385 1.         1.         0.34298671 1.
  0.22212368 1.         1.        ]
 [0.         0.         0.         0.         0.34422167 1.
  0.72574793 0.         1.        ]
 [1.         0.         1.         1.         0.34248196 1.
  0.34401895 1.         1.        ]
 [0.92996669 0.         0.         0.         0.34296681 1.
  0.         0.         1.        ]
 [1.         0.68891729 1.         1.         0.34317394 1.
  1.         1.         1.        ]
 [1.         0.23438913 1.         1.         0.34445279 1.
  0.03160286 1.         1.        ]
 [1.         0.48586474 1.         1.         0.34376358 1.
  1.         0.84161072 1.        ]
 [0.         0.         0.         0.         0.34432322 1.
  0.5545216  0.         1.        ]
 [0.81580559 0.05113256 0.         0.         0.34319633 1.
  0.16656501 0.         1.        ]
 [0.82799098 0.         0.         0.         0.3438347  1.
  0.44952605 0.         1.        ]]

Best Training Poisoning Accuracy:
0.8571428656578064
#####################         POISON         ###############################################

############################################################################################

comm_round: 29 | global_test_acc: 80.000% | global_f1: 0.888888888888889 | global_precision: 0.8
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.80      1.00      0.89         8

    accuracy                           0.80        10
   macro avg       0.40      0.50      0.44        10
weighted avg       0.64      0.80      0.71        10

Accuracy per class:
[[8 0]
 [2 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients