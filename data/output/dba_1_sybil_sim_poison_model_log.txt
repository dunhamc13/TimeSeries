
y shape (29,)
[0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (29,)
[1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_fg shape (29,)
[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0.]
wv_mn shape (29,)
[0.99904671 1.         0.         0.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.        ]
wv_ed shape (29,)
[0.20889111 1.         0.         0.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.        ]
wv_lg shape (29, 1)
[[0.34371684]
 [0.3476461 ]
 [0.33136962]
 [0.37284394]
 [0.36259501]
 [0.36317036]
 [0.36356805]
 [0.36294969]
 [0.36332542]
 [0.36310649]
 [0.36323774]
 [0.36314404]
 [0.36378273]
 [0.36361788]
 [0.3631842 ]
 [0.36359168]
 [0.36407716]
 [0.36322457]
 [0.36385612]
 [0.36291546]
 [0.36337538]
 [0.36401815]
 [0.3640765 ]
 [0.36417496]
 [0.36407937]
 [0.36436043]
 [0.36306453]
 [0.36333901]
 [0.36370914]]
wv_jc shape (29,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ndT shape (29,)
[0.         1.         0.         0.71302659 1.         1.
 1.         0.94518964 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.        ]
wv_std shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
xy shape: (29, 9)
[[1.         0.         0.99904671 0.20889111 0.34371684 1.
  0.         0.         0.        ]
 [1.         0.         1.         1.         0.3476461  1.
  1.         1.         0.        ]
 [0.         1.         0.         0.         0.33136962 1.
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.37284394 1.
  0.71302659 0.         0.        ]
 [1.         0.         1.         1.         0.36259501 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36317036 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36356805 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36294969 1.
  0.94518964 1.         1.        ]
 [1.         0.         1.         1.         0.36332542 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36310649 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36323774 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36314404 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36378273 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36361788 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.3631842  1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36359168 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36407716 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36322457 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36385612 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36291546 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36337538 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36401815 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.3640765  1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36417496 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36407937 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36436043 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36306453 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36333901 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36370914 1.
  1.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.7857142686843872
#####################         POISON         ###############################################

############################################################################################

comm_round: 0 | global_test_acc: 88.889% | global_f1: 0.9411764705882353 | global_precision: 0.8888888888888888
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.89      1.00      0.94         8

    accuracy                           0.89         9
   macro avg       0.44      0.50      0.47         9
weighted avg       0.79      0.89      0.84         9

Accuracy per class:
[[8 0]
 [1 0]]
[1. 0.]
poison scaling shape: (29, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 29 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clients
y shape (29,)
[0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (29,)
[1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_fg shape (29,)
[1.         0.03467772 1.         1.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_mn shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ed shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_lg shape (29, 1)
[[0.34543806]
 [0.35494582]
 [0.34289083]
 [0.37148219]
 [0.36308393]
 [0.36279159]
 [0.36266581]
 [0.36323812]
 [0.36290594]
 [0.36261339]
 [0.36329268]
 [0.36296762]
 [0.36245155]
 [0.36271771]
 [0.36299062]
 [0.36340162]
 [0.36203423]
 [0.36162433]
 [0.3628702 ]
 [0.36294629]
 [0.3624149 ]
 [0.36241055]
 [0.36366665]
 [0.36319006]
 [0.36293486]
 [0.36379567]
 [0.36329538]
 [0.36233378]
 [0.36247679]]
wv_jc shape (29,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ndT shape (29,)
[0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_std shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
xy shape: (29, 9)
[[1.         1.         0.         0.         0.34543806 1.
  0.         0.         0.        ]
 [1.         0.03467772 1.         1.         0.35494582 1.
  1.         1.         0.        ]
 [0.         1.         0.         0.         0.34289083 1.
  0.         0.         0.        ]
 [0.         1.         0.         0.         0.37148219 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.36308393 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36279159 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36266581 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36323812 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36290594 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36261339 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36329268 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36296762 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36245155 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36271771 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36299062 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36340162 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36203423 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36162433 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.3628702  1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36294629 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.3624149  1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36241055 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36366665 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36319006 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36293486 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36379567 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36329538 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36233378 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36247679 1.
  1.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.8571428656578064
#####################         POISON         ###############################################

############################################################################################

comm_round: 1 | global_test_acc: 77.778% | global_f1: 0.8750000000000001 | global_precision: 0.7777777777777778
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.78      1.00      0.88         7

    accuracy                           0.78         9
   macro avg       0.39      0.50      0.44         9
weighted avg       0.60      0.78      0.68         9

Accuracy per class:
[[7 0]
 [2 0]]
[1. 0.]
poison scaling shape: (29, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 29 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clients
y shape (29,)
[0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (29,)
[1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_fg shape (29,)
[1.         0.58101472 1.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_mn shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ed shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_lg shape (29, 1)
[[0.34927721]
 [0.35383911]
 [0.34320425]
 [0.36918527]
 [0.36297478]
 [0.36333318]
 [0.36186589]
 [0.36238182]
 [0.36331958]
 [0.36280582]
 [0.36313787]
 [0.36228444]
 [0.36332114]
 [0.3634993 ]
 [0.36330338]
 [0.36303289]
 [0.36255584]
 [0.36280296]
 [0.36248373]
 [0.36239711]
 [0.36306341]
 [0.36196927]
 [0.36315546]
 [0.36238279]
 [0.36240081]
 [0.3629441 ]
 [0.36223827]
 [0.36284967]
 [0.36228468]]
wv_jc shape (29,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ndT shape (29,)
[0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_std shape (29,)
[0.         0.85642468 0.         0.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.        ]
xy shape: (29, 9)
[[1.         1.         0.         0.         0.34927721 1.
  0.         0.         0.        ]
 [1.         0.58101472 1.         1.         0.35383911 1.
  1.         0.85642468 0.        ]
 [0.         1.         0.         0.         0.34320425 1.
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.36918527 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.36297478 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36333318 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36186589 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36238182 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36331958 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36280582 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36313787 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36228444 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36332114 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.3634993  1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36330338 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36303289 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36255584 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36280296 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36248373 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36239711 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36306341 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36196927 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36315546 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36238279 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36240081 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.3629441  1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36223827 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36284967 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36228468 1.
  1.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.8571428656578064
#####################         POISON         ###############################################

############################################################################################

comm_round: 2 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         9

    accuracy                           1.00         9
   macro avg       1.00      1.00      1.00         9
weighted avg       1.00      1.00      1.00         9

Accuracy per class:
[[9 0]
 [0 0]]
[ 1. nan]
poison scaling shape: (29, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 29 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clients
y shape (29,)
[0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (29,)
[1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_fg shape (29,)
[1.         0.50119704 1.         1.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_mn shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ed shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_lg shape (29, 1)
[[0.35062341]
 [0.35411624]
 [0.35289709]
 [0.36797882]
 [0.36288741]
 [0.36334542]
 [0.36241324]
 [0.36322189]
 [0.36258468]
 [0.36238571]
 [0.36279326]
 [0.36370222]
 [0.36250474]
 [0.3622672 ]
 [0.36347388]
 [0.364054  ]
 [0.36329306]
 [0.36315267]
 [0.36377964]
 [0.36331208]
 [0.36285496]
 [0.36214   ]
 [0.36225089]
 [0.36263657]
 [0.36308759]
 [0.36295519]
 [0.36294741]
 [0.36273583]
 [0.36268179]]
wv_jc shape (29,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ndT shape (29,)
[0.         1.         0.         0.         1.         1.
 1.         1.         1.         0.88195598 1.         1.
 1.         1.         1.         1.         0.56842124 1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.        ]
wv_std shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
xy shape: (29, 9)
[[1.         1.         0.         0.         0.35062341 1.
  0.         0.         0.        ]
 [1.         0.50119704 1.         1.         0.35411624 1.
  1.         0.         0.        ]
 [0.         1.         0.         0.         0.35289709 1.
  0.         0.         0.        ]
 [0.         1.         0.         0.         0.36797882 1.
  0.         0.         0.        ]
 [1.         0.         1.         1.         0.36288741 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36334542 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36241324 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36322189 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36258468 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36238571 1.
  0.88195598 1.         1.        ]
 [1.         0.         1.         1.         0.36279326 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36370222 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36250474 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.3622672  1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36347388 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.364054   1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36329306 1.
  0.56842124 1.         1.        ]
 [1.         0.         1.         1.         0.36315267 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36377964 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36331208 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36285496 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36214    1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36225089 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36263657 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36308759 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36295519 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36294741 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36273583 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36268179 1.
  1.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.8571428656578064
#####################         POISON         ###############################################

############################################################################################

comm_round: 3 | global_test_acc: 88.889% | global_f1: 0.9411764705882353 | global_precision: 0.8888888888888888
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.89      1.00      0.94         8

    accuracy                           0.89         9
   macro avg       0.44      0.50      0.47         9
weighted avg       0.79      0.89      0.84         9

Accuracy per class:
[[8 0]
 [1 0]]
[1. 0.]
poison scaling shape: (29, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 29 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clients
y shape (29,)
[0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (29,)
[1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_fg shape (29,)
[1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0.]
wv_mn shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ed shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_lg shape (29, 1)
[[0.35165379]
 [0.35366235]
 [0.35103045]
 [0.37186009]
 [0.36354582]
 [0.36320905]
 [0.36324647]
 [0.36374566]
 [0.36327137]
 [0.36330673]
 [0.36300862]
 [0.36339992]
 [0.36344795]
 [0.36359895]
 [0.36323098]
 [0.36348749]
 [0.36288979]
 [0.36366456]
 [0.36297968]
 [0.36310503]
 [0.36336462]
 [0.3628191 ]
 [0.36312499]
 [0.36218092]
 [0.36305804]
 [0.36415142]
 [0.36331987]
 [0.36352206]
 [0.36403852]]
wv_jc shape (29,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ndT shape (29,)
[0.20612956 1.         0.         0.         0.53932135 0.13643638
 0.         0.55698339 0.23622866 0.01042712 0.31807475 0.13239662
 0.         0.67077248 0.20142889 0.         0.38865199 0.
 0.         0.         0.16125198 0.02845212 0.         0.
 0.         0.57523811 0.31081166 0.38357148 0.88729576]
wv_std shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
xy shape: (29, 9)
[[1.         1.         0.         0.         0.35165379 1.
  0.20612956 0.         0.        ]
 [1.         1.         1.         1.         0.35366235 1.
  1.         0.         0.        ]
 [0.         1.         0.         0.         0.35103045 1.
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.37186009 1.
  0.         0.         0.        ]
 [1.         0.         1.         1.         0.36354582 1.
  0.53932135 1.         1.        ]
 [1.         0.         1.         1.         0.36320905 1.
  0.13643638 1.         1.        ]
 [1.         0.         1.         1.         0.36324647 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.36374566 1.
  0.55698339 1.         1.        ]
 [1.         0.         1.         1.         0.36327137 1.
  0.23622866 1.         1.        ]
 [1.         0.         1.         1.         0.36330673 1.
  0.01042712 1.         1.        ]
 [1.         0.         1.         1.         0.36300862 1.
  0.31807475 1.         1.        ]
 [1.         0.         1.         1.         0.36339992 1.
  0.13239662 1.         1.        ]
 [1.         0.         1.         1.         0.36344795 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.36359895 1.
  0.67077248 1.         1.        ]
 [1.         0.         1.         1.         0.36323098 1.
  0.20142889 1.         1.        ]
 [1.         0.         1.         1.         0.36348749 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.36288979 1.
  0.38865199 1.         1.        ]
 [1.         0.         1.         1.         0.36366456 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.36297968 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.36310503 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.36336462 1.
  0.16125198 1.         1.        ]
 [1.         0.         1.         1.         0.3628191  1.
  0.02845212 1.         1.        ]
 [1.         0.         1.         1.         0.36312499 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.36218092 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.36305804 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.36415142 1.
  0.57523811 1.         1.        ]
 [1.         0.         1.         1.         0.36331987 1.
  0.31081166 1.         1.        ]
 [1.         0.         1.         1.         0.36352206 1.
  0.38357148 1.         1.        ]
 [1.         0.         1.         1.         0.36403852 1.
  0.88729576 1.         1.        ]]

Best Training Poisoning Accuracy:
0.8571428656578064
#####################         POISON         ###############################################

############################################################################################

comm_round: 4 | global_test_acc: 88.889% | global_f1: 0.9411764705882353 | global_precision: 0.8888888888888888
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.89      1.00      0.94         8

    accuracy                           0.89         9
   macro avg       0.44      0.50      0.47         9
weighted avg       0.79      0.89      0.84         9

Accuracy per class:
[[8 0]
 [1 0]]
[1. 0.]
poison scaling shape: (29, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 29 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clients
y shape (29,)
[0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (29,)
[1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_fg shape (29,)
[0.         0.93437611 0.         1.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_mn shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ed shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_lg shape (29, 1)
[[0.35373406]
 [0.35805794]
 [0.35349522]
 [0.37154724]
 [0.36313822]
 [0.36419236]
 [0.36295631]
 [0.36314591]
 [0.36370481]
 [0.363394  ]
 [0.36358282]
 [0.36327276]
 [0.36342906]
 [0.36373695]
 [0.36407604]
 [0.36419345]
 [0.3630714 ]
 [0.36391002]
 [0.36379603]
 [0.36343016]
 [0.36355152]
 [0.36399492]
 [0.36401411]
 [0.36433327]
 [0.36326674]
 [0.36396158]
 [0.36459056]
 [0.36357968]
 [0.36465564]]
wv_jc shape (29,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ndT shape (29,)
[0.91581691 1.         0.         0.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         0.93813531 1.         1.         1.
 1.         1.         1.         1.         1.        ]
wv_std shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
xy shape: (29, 9)
[[1.         0.         0.         0.         0.35373406 1.
  0.91581691 0.         0.        ]
 [1.         0.93437611 1.         1.         0.35805794 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.35349522 1.
  0.         0.         0.        ]
 [0.         1.         0.         0.         0.37154724 1.
  0.         0.         0.        ]
 [1.         0.         1.         1.         0.36313822 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36419236 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36295631 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36314591 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36370481 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.363394   1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36358282 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36327276 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36342906 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36373695 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36407604 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36419345 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.3630714  1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36391002 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36379603 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36343016 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36355152 1.
  0.93813531 1.         1.        ]
 [1.         0.         1.         1.         0.36399492 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36401411 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36433327 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36326674 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36396158 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36459056 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36357968 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36465564 1.
  1.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.9285714030265808
#####################         POISON         ###############################################

############################################################################################

comm_round: 5 | global_test_acc: 77.778% | global_f1: 0.8750000000000001 | global_precision: 0.7777777777777778
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.78      1.00      0.88         7

    accuracy                           0.78         9
   macro avg       0.39      0.50      0.44         9
weighted avg       0.60      0.78      0.68         9

Accuracy per class:
[[7 0]
 [2 0]]
[1. 0.]
poison scaling shape: (29, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 29 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clients
y shape (29,)
[0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (29,)
[1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_fg shape (29,)
[0.00463426 0.00463426 1.         1.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_mn shape (29,)
[0.08571039 1.         0.         0.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.        ]
wv_ed shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_lg shape (29, 1)
[[0.35653358]
 [0.35634304]
 [0.3503    ]
 [0.37419898]
 [0.36472098]
 [0.36482163]
 [0.36423482]
 [0.36400337]
 [0.36455978]
 [0.3646898 ]
 [0.3639331 ]
 [0.36415098]
 [0.36447476]
 [0.36437532]
 [0.36435701]
 [0.36373176]
 [0.36393407]
 [0.36434741]
 [0.36481728]
 [0.36415455]
 [0.36451352]
 [0.36419386]
 [0.36520854]
 [0.36402284]
 [0.36500531]
 [0.36454155]
 [0.36435816]
 [0.36467787]
 [0.36395341]]
wv_jc shape (29,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ndT shape (29,)
[0.         0.94939126 0.19025014 0.         1.         0.19023676
 1.         1.         0.4915555  1.         1.         1.
 0.93065398 1.         0.27229533 1.         0.57181403 0.56909095
 0.67588232 1.         0.30779588 1.         0.33431385 0.21109394
 1.         0.80532011 1.         0.76129582 0.77708498]
wv_std shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
xy shape: (29, 9)
[[1.         0.00463426 0.08571039 0.         0.35653358 1.
  0.         0.         0.        ]
 [1.         0.00463426 1.         1.         0.35634304 1.
  0.94939126 0.         0.        ]
 [0.         1.         0.         0.         0.3503     1.
  0.19025014 0.         0.        ]
 [0.         1.         0.         0.         0.37419898 1.
  0.         0.         0.        ]
 [1.         0.         1.         1.         0.36472098 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36482163 1.
  0.19023676 1.         1.        ]
 [1.         0.         1.         1.         0.36423482 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36400337 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36455978 1.
  0.4915555  1.         1.        ]
 [1.         0.         1.         1.         0.3646898  1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.3639331  1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36415098 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36447476 1.
  0.93065398 1.         1.        ]
 [1.         0.         1.         1.         0.36437532 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36435701 1.
  0.27229533 1.         1.        ]
 [1.         0.         1.         1.         0.36373176 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36393407 1.
  0.57181403 1.         1.        ]
 [1.         0.         1.         1.         0.36434741 1.
  0.56909095 1.         1.        ]
 [1.         0.         1.         1.         0.36481728 1.
  0.67588232 1.         1.        ]
 [1.         0.         1.         1.         0.36415455 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36451352 1.
  0.30779588 1.         1.        ]
 [1.         0.         1.         1.         0.36419386 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36520854 1.
  0.33431385 1.         1.        ]
 [1.         0.         1.         1.         0.36402284 1.
  0.21109394 1.         1.        ]
 [1.         0.         1.         1.         0.36500531 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36454155 1.
  0.80532011 1.         1.        ]
 [1.         0.         1.         1.         0.36435816 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36467787 1.
  0.76129582 1.         1.        ]
 [1.         0.         1.         1.         0.36395341 1.
  0.77708498 1.         1.        ]]

Best Training Poisoning Accuracy:
0.8571428656578064
#####################         POISON         ###############################################

############################################################################################

comm_round: 6 | global_test_acc: 77.778% | global_f1: 0.8750000000000001 | global_precision: 0.7777777777777778
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.78      1.00      0.88         7

    accuracy                           0.78         9
   macro avg       0.39      0.50      0.44         9
weighted avg       0.60      0.78      0.68         9

Accuracy per class:
[[7 0]
 [2 0]]
[1. 0.]
poison scaling shape: (29, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 29 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clients
y shape (29,)
[0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (29,)
[1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_fg shape (29,)
[0.47007744 0.47007744 1.         1.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_mn shape (29,)
[0.         0.39853625 0.         0.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.        ]
wv_ed shape (29,)
[0.         0.12215798 0.         0.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.        ]
wv_lg shape (29, 1)
[[0.36014639]
 [0.35588042]
 [0.35984826]
 [0.37820444]
 [0.36516443]
 [0.36498789]
 [0.36497959]
 [0.36486537]
 [0.36470572]
 [0.36529244]
 [0.36502538]
 [0.36513518]
 [0.36466533]
 [0.36597558]
 [0.36493992]
 [0.36537815]
 [0.36476027]
 [0.36564669]
 [0.36477291]
 [0.36537428]
 [0.36520848]
 [0.36536875]
 [0.36539266]
 [0.36471547]
 [0.36525782]
 [0.36516828]
 [0.36496226]
 [0.36483777]
 [0.36452056]]
wv_jc shape (29,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ndT shape (29,)
[0.21559298 0.         0.36674012 0.         0.67874061 0.
 0.60787449 0.06311746 0.         0.59988271 0.24326156 0.72948995
 0.         0.         0.         1.         0.18613618 1.
 0.75284918 0.5250666  0.         1.         0.         0.
 0.10562338 0.90387768 1.         0.         1.        ]
wv_std shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
xy shape: (29, 9)
[[1.         0.47007744 0.         0.         0.36014639 1.
  0.21559298 0.         0.        ]
 [1.         0.47007744 0.39853625 0.12215798 0.35588042 1.
  0.         0.         0.        ]
 [0.         1.         0.         0.         0.35984826 1.
  0.36674012 0.         0.        ]
 [0.         1.         0.         0.         0.37820444 1.
  0.         0.         0.        ]
 [1.         0.         1.         1.         0.36516443 1.
  0.67874061 1.         1.        ]
 [1.         0.         1.         1.         0.36498789 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.36497959 1.
  0.60787449 1.         1.        ]
 [1.         0.         1.         1.         0.36486537 1.
  0.06311746 1.         1.        ]
 [1.         0.         1.         1.         0.36470572 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.36529244 1.
  0.59988271 1.         1.        ]
 [1.         0.         1.         1.         0.36502538 1.
  0.24326156 1.         1.        ]
 [1.         0.         1.         1.         0.36513518 1.
  0.72948995 1.         1.        ]
 [1.         0.         1.         1.         0.36466533 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.36597558 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.36493992 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.36537815 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36476027 1.
  0.18613618 1.         1.        ]
 [1.         0.         1.         1.         0.36564669 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36477291 1.
  0.75284918 1.         1.        ]
 [1.         0.         1.         1.         0.36537428 1.
  0.5250666  1.         1.        ]
 [1.         0.         1.         1.         0.36520848 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.36536875 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36539266 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.36471547 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.36525782 1.
  0.10562338 1.         1.        ]
 [1.         0.         1.         1.         0.36516828 1.
  0.90387768 1.         1.        ]
 [1.         0.         1.         1.         0.36496226 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36483777 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.36452056 1.
  1.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.8571428656578064
#####################         POISON         ###############################################

############################################################################################

comm_round: 7 | global_test_acc: 88.889% | global_f1: 0.9411764705882353 | global_precision: 0.8888888888888888
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.89      1.00      0.94         8

    accuracy                           0.89         9
   macro avg       0.44      0.50      0.47         9
weighted avg       0.79      0.89      0.84         9

Accuracy per class:
[[8 0]
 [1 0]]
[1. 0.]
poison scaling shape: (29, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 29 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clients
y shape (29,)
[0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (29,)
[0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_fg shape (29,)
[0.         0.40728018 0.         1.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_mn shape (29,)
[0.         0.12071114 0.         0.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.        ]
wv_ed shape (29,)
[0.         0.09591264 0.         0.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.        ]
wv_lg shape (29, 1)
[[0.35931326]
 [0.3589684 ]
 [0.36020044]
 [0.37787306]
 [0.36663313]
 [0.36594825]
 [0.3660069 ]
 [0.36627583]
 [0.36574702]
 [0.36644277]
 [0.36635273]
 [0.36568893]
 [0.36601756]
 [0.36566965]
 [0.36772457]
 [0.36571036]
 [0.36624036]
 [0.36605084]
 [0.36646961]
 [0.36598447]
 [0.3661257 ]
 [0.36568256]
 [0.36527798]
 [0.36576306]
 [0.36641554]
 [0.36606471]
 [0.36644713]
 [0.36563279]
 [0.36655085]]
wv_jc shape (29,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ndT shape (29,)
[0.         0.         0.         0.         1.         0.78386339
 0.89900407 1.         0.81263012 1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         0.94020206 1.         1.         1.
 1.         1.         1.         1.         1.        ]
wv_std shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
xy shape: (29, 9)
[[0.         0.         0.         0.         0.35931326 1.
  0.         0.         0.        ]
 [1.         0.40728018 0.12071114 0.09591264 0.3589684  1.
  0.         0.         0.        ]
 [1.         0.         0.         0.         0.36020044 1.
  0.         0.         0.        ]
 [0.         1.         0.         0.         0.37787306 1.
  0.         0.         0.        ]
 [1.         0.         1.         1.         0.36663313 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36594825 1.
  0.78386339 1.         1.        ]
 [1.         0.         1.         1.         0.3660069  1.
  0.89900407 1.         1.        ]
 [1.         0.         1.         1.         0.36627583 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36574702 1.
  0.81263012 1.         1.        ]
 [1.         0.         1.         1.         0.36644277 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36635273 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36568893 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36601756 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36566965 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36772457 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36571036 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36624036 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36605084 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36646961 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36598447 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.3661257  1.
  0.94020206 1.         1.        ]
 [1.         0.         1.         1.         0.36568256 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36527798 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36576306 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36641554 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36606471 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36644713 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36563279 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36655085 1.
  1.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.9285714030265808
#####################         POISON         ###############################################

############################################################################################

comm_round: 8 | global_test_acc: 77.778% | global_f1: 0.8750000000000001 | global_precision: 0.7777777777777778
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.78      1.00      0.88         7

    accuracy                           0.78         9
   macro avg       0.39      0.50      0.44         9
weighted avg       0.60      0.78      0.68         9

Accuracy per class:
[[7 0]
 [2 0]]
[1. 0.]
poison scaling shape: (29, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 29 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clients
y shape (29,)
[0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (29,)
[1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_fg shape (29,)
[0.1980043 0.        1.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.       ]
wv_mn shape (29,)
[0.11769379 1.         0.         0.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.        ]
wv_ed shape (29,)
[0.         0.81534666 0.         0.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.        ]
wv_lg shape (29, 1)
[[0.36139206]
 [0.36210326]
 [0.35974014]
 [0.37609927]
 [0.36766325]
 [0.36666116]
 [0.36697667]
 [0.36627599]
 [0.36717178]
 [0.36732705]
 [0.36696245]
 [0.36726845]
 [0.36742427]
 [0.36719816]
 [0.36692579]
 [0.36668755]
 [0.36673505]
 [0.36714921]
 [0.36682558]
 [0.36753626]
 [0.36640643]
 [0.36731601]
 [0.3670705 ]
 [0.36684081]
 [0.3670473 ]
 [0.36735059]
 [0.36805645]
 [0.36696789]
 [0.36761477]]
wv_jc shape (29,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ndT shape (29,)
[0.         0.         0.         1.         0.1619672  0.
 0.         0.         0.         0.02177753 0.         0.08830128
 0.01995934 0.         0.08148631 0.         0.37577189 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.03672308 0.25847147]
wv_std shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
xy shape: (29, 9)
[[1.         0.1980043  0.11769379 0.         0.36139206 1.
  0.         0.         0.        ]
 [1.         0.         1.         0.81534666 0.36210326 1.
  0.         0.         0.        ]
 [0.         1.         0.         0.         0.35974014 1.
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.37609927 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.36766325 1.
  0.1619672  1.         1.        ]
 [1.         0.         1.         1.         0.36666116 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.36697667 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.36627599 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.36717178 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.36732705 1.
  0.02177753 1.         1.        ]
 [1.         0.         1.         1.         0.36696245 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.36726845 1.
  0.08830128 1.         1.        ]
 [1.         0.         1.         1.         0.36742427 1.
  0.01995934 1.         1.        ]
 [1.         0.         1.         1.         0.36719816 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.36692579 1.
  0.08148631 1.         1.        ]
 [1.         0.         1.         1.         0.36668755 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.36673505 1.
  0.37577189 1.         1.        ]
 [1.         0.         1.         1.         0.36714921 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.36682558 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.36753626 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.36640643 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.36731601 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.3670705  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.36684081 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.3670473  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.36735059 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.36805645 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.36696789 1.
  0.03672308 1.         1.        ]
 [1.         0.         1.         1.         0.36761477 1.
  0.25847147 1.         1.        ]]

Best Training Poisoning Accuracy:
0.9285714030265808
#####################         POISON         ###############################################

############################################################################################

comm_round: 9 | global_test_acc: 88.889% | global_f1: 0.9411764705882353 | global_precision: 0.8888888888888888
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.89      1.00      0.94         8

    accuracy                           0.89         9
   macro avg       0.44      0.50      0.47         9
weighted avg       0.79      0.89      0.84         9

Accuracy per class:
[[8 0]
 [1 0]]
[1. 0.]
poison scaling shape: (29, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 29 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clients
y shape (29,)
[0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (29,)
[0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_fg shape (29,)
[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0.]
wv_mn shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ed shape (29,)
[0.         0.05514977 0.         0.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.        ]
wv_lg shape (29, 1)
[[0.36254018]
 [0.36051747]
 [0.36432042]
 [0.37735639]
 [0.36817189]
 [0.36743841]
 [0.36817187]
 [0.36801292]
 [0.36806376]
 [0.36783791]
 [0.36825527]
 [0.36843984]
 [0.36874279]
 [0.36779492]
 [0.36773044]
 [0.36809253]
 [0.36789343]
 [0.36826976]
 [0.36775203]
 [0.36759854]
 [0.36798931]
 [0.36785552]
 [0.36775463]
 [0.36798698]
 [0.36789703]
 [0.36707456]
 [0.36760994]
 [0.36791527]
 [0.36874235]]
wv_jc shape (29,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ndT shape (29,)
[1.         0.         0.         1.         0.66120704 1.
 0.51375424 1.         0.03819341 0.44438691 0.75911171 0.67093475
 1.         1.         0.         1.         1.         0.
 1.         0.14354782 0.86687184 0.83929367 0.         0.56082893
 1.         0.79385733 0.08458765 1.         0.72286669]
wv_std shape (29,)
[0.         0.03830162 0.         0.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.        ]
xy shape: (29, 9)
[[0.         0.         0.         0.         0.36254018 1.
  1.         0.         0.        ]
 [1.         0.         0.         0.05514977 0.36051747 1.
  0.         0.03830162 0.        ]
 [1.         0.         0.         0.         0.36432042 1.
  0.         0.         0.        ]
 [0.         1.         0.         0.         0.37735639 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.36817189 1.
  0.66120704 1.         1.        ]
 [1.         0.         1.         1.         0.36743841 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36817187 1.
  0.51375424 1.         1.        ]
 [1.         0.         1.         1.         0.36801292 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36806376 1.
  0.03819341 1.         1.        ]
 [1.         0.         1.         1.         0.36783791 1.
  0.44438691 1.         1.        ]
 [1.         0.         1.         1.         0.36825527 1.
  0.75911171 1.         1.        ]
 [1.         0.         1.         1.         0.36843984 1.
  0.67093475 1.         1.        ]
 [1.         0.         1.         1.         0.36874279 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36779492 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36773044 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.36809253 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36789343 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36826976 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.36775203 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36759854 1.
  0.14354782 1.         1.        ]
 [1.         0.         1.         1.         0.36798931 1.
  0.86687184 1.         1.        ]
 [1.         0.         1.         1.         0.36785552 1.
  0.83929367 1.         1.        ]
 [1.         0.         1.         1.         0.36775463 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.36798698 1.
  0.56082893 1.         1.        ]
 [1.         0.         1.         1.         0.36789703 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36707456 1.
  0.79385733 1.         1.        ]
 [1.         0.         1.         1.         0.36760994 1.
  0.08458765 1.         1.        ]
 [1.         0.         1.         1.         0.36791527 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36874235 1.
  0.72286669 1.         1.        ]]

Best Training Poisoning Accuracy:
0.7857142686843872
#####################         POISON         ###############################################

############################################################################################

comm_round: 10 | global_test_acc: 88.889% | global_f1: 0.9411764705882353 | global_precision: 0.8888888888888888
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.89      1.00      0.94         8

    accuracy                           0.89         9
   macro avg       0.44      0.50      0.47         9
weighted avg       0.79      0.89      0.84         9

Accuracy per class:
[[8 0]
 [1 0]]
[1. 0.]
poison scaling shape: (29, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 29 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clients
y shape (29,)
[0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (29,)
[0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_fg shape (29,)
[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0.]
wv_mn shape (29,)
[0.         0.40372316 0.         0.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.        ]
wv_ed shape (29,)
[0.         0.16251701 0.         0.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.        ]
wv_lg shape (29, 1)
[[0.36381311]
 [0.36006748]
 [0.36312973]
 [0.37519466]
 [0.36942384]
 [0.36889198]
 [0.36878335]
 [0.36874364]
 [0.3682778 ]
 [0.36929111]
 [0.36844877]
 [0.36910118]
 [0.36874966]
 [0.36869368]
 [0.36854512]
 [0.36921685]
 [0.36860894]
 [0.3689845 ]
 [0.36781935]
 [0.36838744]
 [0.36893486]
 [0.36844295]
 [0.3685574 ]
 [0.3687995 ]
 [0.36887844]
 [0.36881554]
 [0.36826315]
 [0.36902182]
 [0.36770775]]
wv_jc shape (29,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ndT shape (29,)
[0.         0.76190529 0.         1.         1.         0.36456425
 0.70567563 0.19094508 0.         1.         0.         1.
 1.         0.89259633 0.6765628  1.         0.41007276 1.
 0.21131383 0.79062744 1.         0.33143762 1.         1.
 0.30098129 1.         0.58668331 0.99417172 0.71781023]
wv_std shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
xy shape: (29, 9)
[[0.         0.         0.         0.         0.36381311 1.
  0.         0.         0.        ]
 [1.         0.         0.40372316 0.16251701 0.36006748 1.
  0.76190529 0.         0.        ]
 [1.         0.         0.         0.         0.36312973 1.
  0.         0.         0.        ]
 [0.         1.         0.         0.         0.37519466 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.36942384 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36889198 1.
  0.36456425 1.         1.        ]
 [1.         0.         1.         1.         0.36878335 1.
  0.70567563 1.         1.        ]
 [1.         0.         1.         1.         0.36874364 1.
  0.19094508 1.         1.        ]
 [1.         0.         1.         1.         0.3682778  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.36929111 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36844877 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.36910118 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36874966 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36869368 1.
  0.89259633 1.         1.        ]
 [1.         0.         1.         1.         0.36854512 1.
  0.6765628  1.         1.        ]
 [1.         0.         1.         1.         0.36921685 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36860894 1.
  0.41007276 1.         1.        ]
 [1.         0.         1.         1.         0.3689845  1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36781935 1.
  0.21131383 1.         1.        ]
 [1.         0.         1.         1.         0.36838744 1.
  0.79062744 1.         1.        ]
 [1.         0.         1.         1.         0.36893486 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36844295 1.
  0.33143762 1.         1.        ]
 [1.         0.         1.         1.         0.3685574  1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.3687995  1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36887844 1.
  0.30098129 1.         1.        ]
 [1.         0.         1.         1.         0.36881554 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36826315 1.
  0.58668331 1.         1.        ]
 [1.         0.         1.         1.         0.36902182 1.
  0.99417172 1.         1.        ]
 [1.         0.         1.         1.         0.36770775 1.
  0.71781023 1.         1.        ]]

Best Training Poisoning Accuracy:
0.9285714030265808
#####################         POISON         ###############################################

############################################################################################

comm_round: 11 | global_test_acc: 77.778% | global_f1: 0.8750000000000001 | global_precision: 0.7777777777777778
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.78      1.00      0.88         7

    accuracy                           0.78         9
   macro avg       0.39      0.50      0.44         9
weighted avg       0.60      0.78      0.68         9

Accuracy per class:
[[7 0]
 [2 0]]
[1. 0.]
poison scaling shape: (29, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 29 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clients
y shape (29,)
[0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (29,)
[1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_fg shape (29,)
[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0.]
wv_mn shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ed shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_lg shape (29, 1)
[[0.36563051]
 [0.35920057]
 [0.36214209]
 [0.3768185 ]
 [0.36927247]
 [0.36887191]
 [0.36951944]
 [0.36976761]
 [0.36920723]
 [0.36981918]
 [0.36967505]
 [0.36968978]
 [0.36936979]
 [0.36889486]
 [0.36908791]
 [0.3695796 ]
 [0.36893366]
 [0.3692297 ]
 [0.36953127]
 [0.36970459]
 [0.36912064]
 [0.36936314]
 [0.36991709]
 [0.36962494]
 [0.36926386]
 [0.36931544]
 [0.36870465]
 [0.36931682]
 [0.36979711]]
wv_jc shape (29,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ndT shape (29,)
[0.         1.         0.         0.         1.         1.
 1.         1.         1.         1.         0.65832307 1.
 1.         1.         1.         1.         1.         1.
 0.76622232 1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.        ]
wv_std shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
xy shape: (29, 9)
[[1.         0.         0.         0.         0.36563051 1.
  0.         0.         0.        ]
 [1.         0.         0.         0.         0.35920057 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.36214209 1.
  0.         0.         0.        ]
 [0.         1.         0.         0.         0.3768185  1.
  0.         0.         0.        ]
 [1.         0.         1.         1.         0.36927247 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36887191 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36951944 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36976761 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36920723 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36981918 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36967505 1.
  0.65832307 1.         1.        ]
 [1.         0.         1.         1.         0.36968978 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36936979 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36889486 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36908791 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.3695796  1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36893366 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.3692297  1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36953127 1.
  0.76622232 1.         1.        ]
 [1.         0.         1.         1.         0.36970459 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36912064 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36936314 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36991709 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36962494 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36926386 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36931544 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36870465 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36931682 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36979711 1.
  1.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.8571428656578064
#####################         POISON         ###############################################

############################################################################################

comm_round: 12 | global_test_acc: 88.889% | global_f1: 0.9411764705882353 | global_precision: 0.8888888888888888
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.89      1.00      0.94         8

    accuracy                           0.89         9
   macro avg       0.44      0.50      0.47         9
weighted avg       0.79      0.89      0.84         9

Accuracy per class:
[[8 0]
 [1 0]]
[1. 0.]
poison scaling shape: (29, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 29 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clients
y shape (29,)
[0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (29,)
[1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_fg shape (29,)
[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0.]
wv_mn shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ed shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_lg shape (29, 1)
[[0.36495901]
 [0.36030783]
 [0.36611654]
 [0.37836271]
 [0.37053414]
 [0.37013448]
 [0.36966345]
 [0.36984894]
 [0.36986494]
 [0.36985999]
 [0.37129936]
 [0.37024396]
 [0.37048143]
 [0.37063329]
 [0.37033883]
 [0.36966136]
 [0.36980691]
 [0.37035638]
 [0.3707992 ]
 [0.36961499]
 [0.37036223]
 [0.37030733]
 [0.36988146]
 [0.36949469]
 [0.36954353]
 [0.37069093]
 [0.37016327]
 [0.37025834]
 [0.36974906]]
wv_jc shape (29,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ndT shape (29,)
[1.         0.         1.         0.         1.         0.
 0.8629465  0.21561114 0.         0.49538315 0.89365239 0.9554318
 0.         0.48804762 0.56098213 1.         0.         0.22109736
 0.4571743  0.02189204 0.07853827 0.17817758 0.49893405 0.
 0.         0.68198128 0.         0.41609083 0.        ]
wv_std shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
xy shape: (29, 9)
[[1.         0.         0.         0.         0.36495901 1.
  1.         0.         0.        ]
 [1.         0.         0.         0.         0.36030783 1.
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.36611654 1.
  1.         0.         0.        ]
 [0.         1.         0.         0.         0.37836271 1.
  0.         0.         0.        ]
 [1.         0.         1.         1.         0.37053414 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.37013448 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.36966345 1.
  0.8629465  1.         1.        ]
 [1.         0.         1.         1.         0.36984894 1.
  0.21561114 1.         1.        ]
 [1.         0.         1.         1.         0.36986494 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.36985999 1.
  0.49538315 1.         1.        ]
 [1.         0.         1.         1.         0.37129936 1.
  0.89365239 1.         1.        ]
 [1.         0.         1.         1.         0.37024396 1.
  0.9554318  1.         1.        ]
 [1.         0.         1.         1.         0.37048143 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37063329 1.
  0.48804762 1.         1.        ]
 [1.         0.         1.         1.         0.37033883 1.
  0.56098213 1.         1.        ]
 [1.         0.         1.         1.         0.36966136 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36980691 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37035638 1.
  0.22109736 1.         1.        ]
 [1.         0.         1.         1.         0.3707992  1.
  0.4571743  1.         1.        ]
 [1.         0.         1.         1.         0.36961499 1.
  0.02189204 1.         1.        ]
 [1.         0.         1.         1.         0.37036223 1.
  0.07853827 1.         1.        ]
 [1.         0.         1.         1.         0.37030733 1.
  0.17817758 1.         1.        ]
 [1.         0.         1.         1.         0.36988146 1.
  0.49893405 1.         1.        ]
 [1.         0.         1.         1.         0.36949469 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.36954353 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37069093 1.
  0.68198128 1.         1.        ]
 [1.         0.         1.         1.         0.37016327 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37025834 1.
  0.41609083 1.         1.        ]
 [1.         0.         1.         1.         0.36974906 1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.8571428656578064
#####################         POISON         ###############################################

############################################################################################

comm_round: 13 | global_test_acc: 88.889% | global_f1: 0.9411764705882353 | global_precision: 0.8888888888888888
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.89      1.00      0.94         8

    accuracy                           0.89         9
   macro avg       0.44      0.50      0.47         9
weighted avg       0.79      0.89      0.84         9

Accuracy per class:
[[8 0]
 [1 0]]
[1. 0.]
poison scaling shape: (29, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 29 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clients
y shape (29,)
[0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (29,)
[1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_fg shape (29,)
[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0.]
wv_mn shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ed shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_lg shape (29, 1)
[[0.36568333]
 [0.3656776 ]
 [0.3651658 ]
 [0.37592113]
 [0.37093579]
 [0.37136881]
 [0.37027667]
 [0.37057552]
 [0.37012949]
 [0.37075579]
 [0.37080734]
 [0.3706914 ]
 [0.37053303]
 [0.37142697]
 [0.37043052]
 [0.37069925]
 [0.37065393]
 [0.37152997]
 [0.37074941]
 [0.37070938]
 [0.37078295]
 [0.37030992]
 [0.37083108]
 [0.36992519]
 [0.37176927]
 [0.37093002]
 [0.37009837]
 [0.37062411]
 [0.3706336 ]]
wv_jc shape (29,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ndT shape (29,)
[0.         0.21858799 0.         0.         1.         1.
 0.38900023 0.69687103 0.71334748 0.         1.         0.20806055
 0.6498233  1.         0.35091291 0.19518689 0.33554157 1.
 0.05165639 1.         0.91830162 0.98618802 0.74385483 0.19670884
 1.         0.33903649 1.         0.19756579 0.63984127]
wv_std shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
xy shape: (29, 9)
[[1.         0.         0.         0.         0.36568333 1.
  0.         0.         0.        ]
 [1.         0.         0.         0.         0.3656776  1.
  0.21858799 0.         0.        ]
 [0.         0.         0.         0.         0.3651658  1.
  0.         0.         0.        ]
 [0.         1.         0.         0.         0.37592113 1.
  0.         0.         0.        ]
 [1.         0.         1.         1.         0.37093579 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.37136881 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.37027667 1.
  0.38900023 1.         1.        ]
 [1.         0.         1.         1.         0.37057552 1.
  0.69687103 1.         1.        ]
 [1.         0.         1.         1.         0.37012949 1.
  0.71334748 1.         1.        ]
 [1.         0.         1.         1.         0.37075579 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37080734 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.3706914  1.
  0.20806055 1.         1.        ]
 [1.         0.         1.         1.         0.37053303 1.
  0.6498233  1.         1.        ]
 [1.         0.         1.         1.         0.37142697 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.37043052 1.
  0.35091291 1.         1.        ]
 [1.         0.         1.         1.         0.37069925 1.
  0.19518689 1.         1.        ]
 [1.         0.         1.         1.         0.37065393 1.
  0.33554157 1.         1.        ]
 [1.         0.         1.         1.         0.37152997 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.37074941 1.
  0.05165639 1.         1.        ]
 [1.         0.         1.         1.         0.37070938 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.37078295 1.
  0.91830162 1.         1.        ]
 [1.         0.         1.         1.         0.37030992 1.
  0.98618802 1.         1.        ]
 [1.         0.         1.         1.         0.37083108 1.
  0.74385483 1.         1.        ]
 [1.         0.         1.         1.         0.36992519 1.
  0.19670884 1.         1.        ]
 [1.         0.         1.         1.         0.37176927 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.37093002 1.
  0.33903649 1.         1.        ]
 [1.         0.         1.         1.         0.37009837 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.37062411 1.
  0.19756579 1.         1.        ]
 [1.         0.         1.         1.         0.3706336  1.
  0.63984127 1.         1.        ]]

Best Training Poisoning Accuracy:
0.7857142686843872
#####################         POISON         ###############################################

############################################################################################

comm_round: 14 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         9

    accuracy                           1.00         9
   macro avg       1.00      1.00      1.00         9
weighted avg       1.00      1.00      1.00         9

Accuracy per class:
[[9 0]
 [0 0]]
[ 1. nan]
poison scaling shape: (29, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 29 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clients
y shape (29,)
[0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (29,)
[0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_fg shape (29,)
[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0.]
wv_mn shape (29,)
[0.         0.22247885 0.         0.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.        ]
wv_ed shape (29,)
[0.         0.23010063 0.         0.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.        ]
wv_lg shape (29, 1)
[[0.36694043]
 [0.36767654]
 [0.36701892]
 [0.37602302]
 [0.37077327]
 [0.3709243 ]
 [0.37164743]
 [0.37134453]
 [0.37117062]
 [0.37160585]
 [0.37063389]
 [0.37189909]
 [0.37117051]
 [0.37133836]
 [0.37061785]
 [0.37116889]
 [0.37104243]
 [0.37138529]
 [0.37080468]
 [0.37134645]
 [0.37095178]
 [0.37205838]
 [0.37125384]
 [0.37097491]
 [0.37184548]
 [0.37182113]
 [0.37117301]
 [0.3708535 ]
 [0.37159735]]
wv_jc shape (29,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ndT shape (29,)
[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0.]
wv_std shape (29,)
[0.         0.         0.         0.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         0.         1.         1.         0.32557241
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.        ]
xy shape: (29, 9)
[[0.         0.         0.         0.         0.36694043 1.
  0.         0.         0.        ]
 [1.         0.         0.22247885 0.23010063 0.36767654 1.
  0.         0.         0.        ]
 [1.         0.         0.         0.         0.36701892 1.
  1.         0.         0.        ]
 [0.         1.         0.         0.         0.37602302 1.
  0.         0.         0.        ]
 [1.         0.         1.         1.         0.37077327 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.3709243  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37164743 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37134453 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37117062 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37160585 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37063389 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37189909 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37117051 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37133836 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37061785 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.37116889 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37104243 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37138529 1.
  0.         0.32557241 1.        ]
 [1.         0.         1.         1.         0.37080468 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37134645 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37095178 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37205838 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37125384 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37097491 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37184548 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37182113 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37117301 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.3708535  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37159735 1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.7857142686843872
#####################         POISON         ###############################################

############################################################################################

comm_round: 15 | global_test_acc: 88.889% | global_f1: 0.9411764705882353 | global_precision: 0.8888888888888888
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.89      1.00      0.94         8

    accuracy                           0.89         9
   macro avg       0.44      0.50      0.47         9
weighted avg       0.79      0.89      0.84         9

Accuracy per class:
[[8 0]
 [1 0]]
[1. 0.]
poison scaling shape: (29, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 29 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clients
y shape (29,)
[0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (29,)
[0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_fg shape (29,)
[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0.]
wv_mn shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ed shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_lg shape (29, 1)
[[0.36678946]
 [0.36817862]
 [0.36789779]
 [0.37929059]
 [0.37203367]
 [0.37187848]
 [0.37232914]
 [0.37129139]
 [0.37132392]
 [0.37157437]
 [0.37226842]
 [0.37128325]
 [0.37189149]
 [0.37232797]
 [0.37110886]
 [0.37136198]
 [0.37228816]
 [0.37226256]
 [0.37175998]
 [0.3715397 ]
 [0.37141716]
 [0.37232757]
 [0.37266781]
 [0.3713048 ]
 [0.37175192]
 [0.37135982]
 [0.37155028]
 [0.37211651]
 [0.37226723]]
wv_jc shape (29,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ndT shape (29,)
[0.26551736 0.11102316 1.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_std shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
xy shape: (29, 9)
[[0.         0.         0.         0.         0.36678946 1.
  0.26551736 0.         0.        ]
 [1.         0.         0.         0.         0.36817862 1.
  0.11102316 0.         0.        ]
 [1.         0.         0.         0.         0.36789779 1.
  1.         0.         0.        ]
 [0.         1.         0.         0.         0.37929059 1.
  0.         0.         0.        ]
 [1.         0.         1.         1.         0.37203367 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37187848 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37232914 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37129139 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37132392 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37157437 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37226842 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37128325 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37189149 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37232797 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37110886 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37136198 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37228816 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37226256 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37175998 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.3715397  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37141716 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37232757 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37266781 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.3713048  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37175192 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37135982 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37155028 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37211651 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37226723 1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.8571428656578064
#####################         POISON         ###############################################

############################################################################################

comm_round: 16 | global_test_acc: 88.889% | global_f1: 0.9411764705882353 | global_precision: 0.8888888888888888
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.89      1.00      0.94         8

    accuracy                           0.89         9
   macro avg       0.44      0.50      0.47         9
weighted avg       0.79      0.89      0.84         9

Accuracy per class:
[[8 0]
 [1 0]]
[1. 0.]
poison scaling shape: (29, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 29 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clients
y shape (29,)
[0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (29,)
[1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_fg shape (29,)
[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0.]
wv_mn shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ed shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_lg shape (29, 1)
[[0.36828982]
 [0.36698086]
 [0.36870546]
 [0.38384399]
 [0.37326338]
 [0.37190636]
 [0.37214307]
 [0.37296369]
 [0.37171572]
 [0.37289801]
 [0.37259468]
 [0.3723359 ]
 [0.37275601]
 [0.37271513]
 [0.37242747]
 [0.3723812 ]
 [0.37232406]
 [0.37223175]
 [0.37218527]
 [0.37236862]
 [0.37283893]
 [0.37189836]
 [0.37204137]
 [0.37225393]
 [0.37264132]
 [0.37234376]
 [0.3720949 ]
 [0.3735805 ]
 [0.37180448]]
wv_jc shape (29,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ndT shape (29,)
[0.         0.         1.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.13757101 0.         0.         0.         0.
 0.         0.         0.         0.         0.05561637 0.
 0.         0.         0.         0.         0.        ]
wv_std shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
xy shape: (29, 9)
[[1.         0.         0.         0.         0.36828982 1.
  0.         0.         0.        ]
 [1.         0.         0.         0.         0.36698086 1.
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.36870546 1.
  1.         0.         0.        ]
 [0.         1.         0.         0.         0.38384399 1.
  0.         0.         0.        ]
 [1.         0.         1.         1.         0.37326338 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37190636 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37214307 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37296369 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37171572 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37289801 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37259468 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.3723359  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37275601 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37271513 1.
  0.13757101 1.         1.        ]
 [1.         0.         1.         1.         0.37242747 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.3723812  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37232406 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37223175 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37218527 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37236862 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37283893 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37189836 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37204137 1.
  0.05561637 1.         1.        ]
 [1.         0.         1.         1.         0.37225393 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37264132 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37234376 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.3720949  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.3735805  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37180448 1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.9285714030265808
#####################         POISON         ###############################################

############################################################################################

comm_round: 17 | global_test_acc: 77.778% | global_f1: 0.8750000000000001 | global_precision: 0.7777777777777778
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.78      1.00      0.88         7

    accuracy                           0.78         9
   macro avg       0.39      0.50      0.44         9
weighted avg       0.60      0.78      0.68         9

Accuracy per class:
[[7 0]
 [2 0]]
[1. 0.]
poison scaling shape: (29, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 29 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clients
y shape (29,)
[0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (29,)
[0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_fg shape (29,)
[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0.]
wv_mn shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ed shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_lg shape (29, 1)
[[0.36815817]
 [0.36863571]
 [0.36987544]
 [0.38226954]
 [0.37335384]
 [0.37301354]
 [0.37310259]
 [0.37369452]
 [0.37302682]
 [0.37271367]
 [0.373669  ]
 [0.37261193]
 [0.37356134]
 [0.37372487]
 [0.373351  ]
 [0.37277023]
 [0.37353072]
 [0.37382268]
 [0.37371227]
 [0.37278944]
 [0.37352886]
 [0.37370154]
 [0.373596  ]
 [0.37273159]
 [0.37261893]
 [0.37292228]
 [0.37328995]
 [0.3739244 ]
 [0.37316075]]
wv_jc shape (29,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ndT shape (29,)
[0.         1.         1.         0.         1.         0.
 0.57935333 0.         0.         0.63084134 0.         0.
 0.81342418 0.52306625 0.         0.         0.28787754 0.0741441
 1.         0.33686929 0.         0.         0.         0.68775833
 0.         0.         0.65206687 1.         0.        ]
wv_std shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
xy shape: (29, 9)
[[0.         0.         0.         0.         0.36815817 1.
  0.         0.         0.        ]
 [1.         0.         0.         0.         0.36863571 1.
  1.         0.         0.        ]
 [1.         0.         0.         0.         0.36987544 1.
  1.         0.         0.        ]
 [0.         1.         0.         0.         0.38226954 1.
  0.         0.         0.        ]
 [1.         0.         1.         1.         0.37335384 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.37301354 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37310259 1.
  0.57935333 1.         1.        ]
 [1.         0.         1.         1.         0.37369452 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37302682 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37271367 1.
  0.63084134 1.         1.        ]
 [1.         0.         1.         1.         0.373669   1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37261193 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37356134 1.
  0.81342418 1.         1.        ]
 [1.         0.         1.         1.         0.37372487 1.
  0.52306625 1.         1.        ]
 [1.         0.         1.         1.         0.373351   1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37277023 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37353072 1.
  0.28787754 1.         1.        ]
 [1.         0.         1.         1.         0.37382268 1.
  0.0741441  1.         1.        ]
 [1.         0.         1.         1.         0.37371227 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.37278944 1.
  0.33686929 1.         1.        ]
 [1.         0.         1.         1.         0.37352886 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37370154 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.373596   1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37273159 1.
  0.68775833 1.         1.        ]
 [1.         0.         1.         1.         0.37261893 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37292228 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37328995 1.
  0.65206687 1.         1.        ]
 [1.         0.         1.         1.         0.3739244  1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.37316075 1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.9285714030265808
#####################         POISON         ###############################################

############################################################################################

comm_round: 18 | global_test_acc: 88.889% | global_f1: 0.9411764705882353 | global_precision: 0.8888888888888888
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.89      1.00      0.94         8

    accuracy                           0.89         9
   macro avg       0.44      0.50      0.47         9
weighted avg       0.79      0.89      0.84         9

Accuracy per class:
[[8 0]
 [1 0]]
[1. 0.]
poison scaling shape: (29, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 29 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clients
y shape (29,)
[0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (29,)
[0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_fg shape (29,)
[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0.]
wv_mn shape (29,)
[0.         0.23186471 0.         0.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.        ]
wv_ed shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_lg shape (29, 1)
[[0.36862983]
 [0.36977922]
 [0.37046745]
 [0.38168125]
 [0.37375758]
 [0.37474896]
 [0.37356925]
 [0.37451695]
 [0.37409156]
 [0.37329557]
 [0.37414897]
 [0.37325302]
 [0.37402818]
 [0.37345694]
 [0.37384395]
 [0.37392901]
 [0.37358177]
 [0.37355503]
 [0.37375745]
 [0.37320969]
 [0.37396381]
 [0.37410279]
 [0.37420052]
 [0.37433121]
 [0.37348649]
 [0.37387868]
 [0.37342395]
 [0.37362642]
 [0.37445472]]
wv_jc shape (29,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ndT shape (29,)
[1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0.]
wv_std shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
xy shape: (29, 9)
[[0.         0.         0.         0.         0.36862983 1.
  1.         0.         0.        ]
 [1.         0.         0.23186471 0.         0.36977922 1.
  0.         0.         0.        ]
 [1.         0.         0.         0.         0.37046745 1.
  1.         0.         0.        ]
 [0.         1.         0.         0.         0.38168125 1.
  0.         0.         0.        ]
 [1.         0.         1.         1.         0.37375758 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37474896 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37356925 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37451695 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37409156 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37329557 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37414897 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37325302 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37402818 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37345694 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37384395 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37392901 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37358177 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37355503 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37375745 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37320969 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37396381 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37410279 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37420052 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37433121 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37348649 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37387868 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37342395 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37362642 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37445472 1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.8571428656578064
#####################         POISON         ###############################################

############################################################################################

comm_round: 19 | global_test_acc: 88.889% | global_f1: 0.9411764705882353 | global_precision: 0.8888888888888888
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.89      1.00      0.94         8

    accuracy                           0.89         9
   macro avg       0.44      0.50      0.47         9
weighted avg       0.79      0.89      0.84         9

Accuracy per class:
[[8 0]
 [1 0]]
[1. 0.]
poison scaling shape: (29, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 29 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clients
y shape (29,)
[0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (29,)
[0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_fg shape (29,)
[0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0.]
wv_mn shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ed shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_lg shape (29, 1)
[[0.36890481]
 [0.37127811]
 [0.37084833]
 [0.38353823]
 [0.37423341]
 [0.37482827]
 [0.37477733]
 [0.37477829]
 [0.3739956 ]
 [0.37403118]
 [0.37479656]
 [0.37415005]
 [0.37459963]
 [0.37417744]
 [0.37435458]
 [0.37495663]
 [0.37430289]
 [0.37475654]
 [0.37410932]
 [0.37454248]
 [0.37402539]
 [0.3743464 ]
 [0.37437086]
 [0.37413968]
 [0.37497323]
 [0.37453281]
 [0.3749794 ]
 [0.37437935]
 [0.37403858]]
wv_jc shape (29,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ndT shape (29,)
[1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0.]
wv_std shape (29,)
[0.         0.05470126 0.         0.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.        ]
xy shape: (29, 9)
[[0.         0.         0.         0.         0.36890481 1.
  1.         0.         0.        ]
 [1.         0.         0.         0.         0.37127811 1.
  0.         0.05470126 0.        ]
 [1.         1.         0.         0.         0.37084833 1.
  0.         0.         0.        ]
 [0.         1.         0.         0.         0.38353823 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.37423341 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37482827 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37477733 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37477829 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.3739956  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37403118 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37479656 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37415005 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37459963 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37417744 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37435458 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37495663 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37430289 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37475654 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37410932 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37454248 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37402539 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.3743464  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37437086 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37413968 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37497323 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37453281 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.3749794  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37437935 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37403858 1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.8571428656578064
#####################         POISON         ###############################################

############################################################################################

comm_round: 20 | global_test_acc: 88.889% | global_f1: 0.9411764705882353 | global_precision: 0.8888888888888888
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.89      1.00      0.94         8

    accuracy                           0.89         9
   macro avg       0.44      0.50      0.47         9
weighted avg       0.79      0.89      0.84         9

Accuracy per class:
[[8 0]
 [1 0]]
[1. 0.]
poison scaling shape: (29, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 29 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clients
y shape (29,)
[0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (29,)
[0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_fg shape (29,)
[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0.]
wv_mn shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ed shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_lg shape (29, 1)
[[0.37223507]
 [0.36660558]
 [0.37230219]
 [0.38362919]
 [0.37473642]
 [0.37485351]
 [0.3754824 ]
 [0.37522777]
 [0.37534603]
 [0.37505324]
 [0.37430149]
 [0.37474725]
 [0.3751731 ]
 [0.37541217]
 [0.37534975]
 [0.37510366]
 [0.37497374]
 [0.37571021]
 [0.37445652]
 [0.37526087]
 [0.37446327]
 [0.374941  ]
 [0.37436588]
 [0.37499289]
 [0.37494467]
 [0.37500043]
 [0.37521783]
 [0.37497354]
 [0.37485538]]
wv_jc shape (29,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ndT shape (29,)
[0.         0.         0.31003452 1.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_std shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
xy shape: (29, 9)
[[0.         0.         0.         0.         0.37223507 1.
  0.         0.         0.        ]
 [1.         0.         0.         0.         0.36660558 1.
  0.         0.         0.        ]
 [1.         0.         0.         0.         0.37230219 1.
  0.31003452 0.         0.        ]
 [0.         1.         0.         0.         0.38362919 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.37473642 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37485351 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.3754824  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37522777 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37534603 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37505324 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37430149 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37474725 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.3751731  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37541217 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37534975 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37510366 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37497374 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37571021 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37445652 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37526087 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37446327 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.374941   1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37436588 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37499289 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37494467 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37500043 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37521783 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37497354 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37485538 1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.8571428656578064
#####################         POISON         ###############################################

############################################################################################

comm_round: 21 | global_test_acc: 77.778% | global_f1: 0.8750000000000001 | global_precision: 0.7777777777777778
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.78      1.00      0.88         7

    accuracy                           0.78         9
   macro avg       0.39      0.50      0.44         9
weighted avg       0.60      0.78      0.68         9

Accuracy per class:
[[7 0]
 [2 0]]
[1. 0.]
poison scaling shape: (29, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 29 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clients
y shape (29,)
[0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (29,)
[0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_fg shape (29,)
[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0.]
wv_mn shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ed shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_lg shape (29, 1)
[[0.37038833]
 [0.37096732]
 [0.37333106]
 [0.37841891]
 [0.37591786]
 [0.37615619]
 [0.37559861]
 [0.37563356]
 [0.3756864 ]
 [0.37569341]
 [0.37538286]
 [0.37560114]
 [0.37601224]
 [0.37544036]
 [0.37528782]
 [0.37594501]
 [0.37555257]
 [0.37594868]
 [0.37669015]
 [0.37532543]
 [0.37555234]
 [0.37608877]
 [0.37594173]
 [0.37558502]
 [0.37584126]
 [0.37528989]
 [0.3749016 ]
 [0.37505377]
 [0.37564756]]
wv_jc shape (29,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ndT shape (29,)
[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0.]
wv_std shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
xy shape: (29, 9)
[[0.         0.         0.         0.         0.37038833 1.
  0.         0.         0.        ]
 [1.         0.         0.         0.         0.37096732 1.
  0.         0.         0.        ]
 [1.         0.         0.         0.         0.37333106 1.
  1.         0.         0.        ]
 [0.         1.         0.         0.         0.37841891 1.
  0.         0.         0.        ]
 [1.         0.         1.         1.         0.37591786 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37615619 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37559861 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37563356 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.3756864  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37569341 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37538286 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37560114 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37601224 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37544036 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37528782 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37594501 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37555257 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37594868 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37669015 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37532543 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37555234 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37608877 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37594173 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37558502 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37584126 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37528989 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.3749016  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37505377 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37564756 1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.7857142686843872
#####################         POISON         ###############################################

############################################################################################

comm_round: 22 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         9

    accuracy                           1.00         9
   macro avg       1.00      1.00      1.00         9
weighted avg       1.00      1.00      1.00         9

Accuracy per class:
[[9 0]
 [0 0]]
[ 1. nan]
poison scaling shape: (29, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 29 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clients
y shape (29,)
[0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (29,)
[1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_fg shape (29,)
[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0.]
wv_mn shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ed shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_lg shape (29, 1)
[[0.37375611]
 [0.37147815]
 [0.37004503]
 [0.38221676]
 [0.37607951]
 [0.37629918]
 [0.37657089]
 [0.37535103]
 [0.37587622]
 [0.37591997]
 [0.37608259]
 [0.37608127]
 [0.37647333]
 [0.37591059]
 [0.37571725]
 [0.37556765]
 [0.37636287]
 [0.37643219]
 [0.37619326]
 [0.37612213]
 [0.37595445]
 [0.37595835]
 [0.3764224 ]
 [0.37569022]
 [0.37582285]
 [0.37625459]
 [0.37611331]
 [0.37564903]
 [0.37572249]]
wv_jc shape (29,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ndT shape (29,)
[0.         1.         0.         1.         0.2981598  0.94069772
 0.84645504 0.03771799 0.         1.         0.58752555 0.
 0.         0.30942913 0.10817708 0.44297297 0.27256078 0.41364433
 0.31099559 0.83528144 0.43808895 0.         0.         0.34071049
 0.70689192 0.4580424  0.         0.93797382 0.49687932]
wv_std shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
xy shape: (29, 9)
[[1.         0.         0.         0.         0.37375611 1.
  0.         0.         0.        ]
 [1.         0.         0.         0.         0.37147815 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.37004503 1.
  0.         0.         0.        ]
 [0.         1.         0.         0.         0.38221676 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.37607951 1.
  0.2981598  1.         1.        ]
 [1.         0.         1.         1.         0.37629918 1.
  0.94069772 1.         1.        ]
 [1.         0.         1.         1.         0.37657089 1.
  0.84645504 1.         1.        ]
 [1.         0.         1.         1.         0.37535103 1.
  0.03771799 1.         1.        ]
 [1.         0.         1.         1.         0.37587622 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37591997 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.37608259 1.
  0.58752555 1.         1.        ]
 [1.         0.         1.         1.         0.37608127 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37647333 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37591059 1.
  0.30942913 1.         1.        ]
 [1.         0.         1.         1.         0.37571725 1.
  0.10817708 1.         1.        ]
 [1.         0.         1.         1.         0.37556765 1.
  0.44297297 1.         1.        ]
 [1.         0.         1.         1.         0.37636287 1.
  0.27256078 1.         1.        ]
 [1.         0.         1.         1.         0.37643219 1.
  0.41364433 1.         1.        ]
 [1.         0.         1.         1.         0.37619326 1.
  0.31099559 1.         1.        ]
 [1.         0.         1.         1.         0.37612213 1.
  0.83528144 1.         1.        ]
 [1.         0.         1.         1.         0.37595445 1.
  0.43808895 1.         1.        ]
 [1.         0.         1.         1.         0.37595835 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.3764224  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37569022 1.
  0.34071049 1.         1.        ]
 [1.         0.         1.         1.         0.37582285 1.
  0.70689192 1.         1.        ]
 [1.         0.         1.         1.         0.37625459 1.
  0.4580424  1.         1.        ]
 [1.         0.         1.         1.         0.37611331 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37564903 1.
  0.93797382 1.         1.        ]
 [1.         0.         1.         1.         0.37572249 1.
  0.49687932 1.         1.        ]]

Best Training Poisoning Accuracy:
0.7857142686843872
#####################         POISON         ###############################################

############################################################################################

comm_round: 23 | global_test_acc: 88.889% | global_f1: 0.9411764705882353 | global_precision: 0.8888888888888888
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.89      1.00      0.94         8

    accuracy                           0.89         9
   macro avg       0.44      0.50      0.47         9
weighted avg       0.79      0.89      0.84         9

Accuracy per class:
[[8 0]
 [1 0]]
[1. 0.]
poison scaling shape: (29, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 29 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clients
y shape (29,)
[0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (29,)
[0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_fg shape (29,)
[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0.]
wv_mn shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ed shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_lg shape (29, 1)
[[0.3744832 ]
 [0.36975349]
 [0.37058053]
 [0.38291513]
 [0.37652161]
 [0.37726485]
 [0.37646141]
 [0.37712147]
 [0.3771577 ]
 [0.37638938]
 [0.37710714]
 [0.37651034]
 [0.37701242]
 [0.37601054]
 [0.37647597]
 [0.37568168]
 [0.37724066]
 [0.37624628]
 [0.37633029]
 [0.37624876]
 [0.37665495]
 [0.37643388]
 [0.37648002]
 [0.37727083]
 [0.37636511]
 [0.3767908 ]
 [0.37673018]
 [0.37653678]
 [0.37679316]]
wv_jc shape (29,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ndT shape (29,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0.]
wv_std shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
xy shape: (29, 9)
[[0.         0.         0.         0.         0.3744832  1.
  1.         0.         0.        ]
 [1.         0.         0.         0.         0.36975349 1.
  0.         0.         0.        ]
 [1.         0.         0.         0.         0.37058053 1.
  0.         0.         0.        ]
 [0.         1.         0.         0.         0.38291513 1.
  0.         0.         0.        ]
 [1.         0.         1.         1.         0.37652161 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37726485 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37646141 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37712147 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.3771577  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37638938 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37710714 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37651034 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37701242 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37601054 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37647597 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37568168 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37724066 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37624628 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37633029 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37624876 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37665495 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37643388 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37648002 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37727083 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37636511 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.3767908  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37673018 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37653678 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37679316 1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.7857142686843872
#####################         POISON         ###############################################

############################################################################################

comm_round: 24 | global_test_acc: 88.889% | global_f1: 0.9411764705882353 | global_precision: 0.8888888888888888
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.89      1.00      0.94         8

    accuracy                           0.89         9
   macro avg       0.44      0.50      0.47         9
weighted avg       0.79      0.89      0.84         9

Accuracy per class:
[[8 0]
 [1 0]]
[1. 0.]
poison scaling shape: (29, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 29 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clients
y shape (29,)
[0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (29,)
[1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_fg shape (29,)
[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0.]
wv_mn shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ed shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_lg shape (29, 1)
[[0.37296591]
 [0.37213815]
 [0.37375548]
 [0.3804867 ]
 [0.37693365]
 [0.37697983]
 [0.37719288]
 [0.37713291]
 [0.37655732]
 [0.37708178]
 [0.37646649]
 [0.37632555]
 [0.37699699]
 [0.37731667]
 [0.37692241]
 [0.37702525]
 [0.3767595 ]
 [0.37764014]
 [0.37680922]
 [0.37642758]
 [0.37747727]
 [0.37718261]
 [0.37675136]
 [0.37688828]
 [0.37714123]
 [0.37683527]
 [0.37775488]
 [0.37762186]
 [0.37767509]]
wv_jc shape (29,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ndT shape (29,)
[0.         0.         0.45797698 0.         1.         1.
 0.         0.         0.         0.         0.         0.32258
 0.30469539 1.         1.         1.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.34512066 1.        ]
wv_std shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
xy shape: (29, 9)
[[1.         0.         0.         0.         0.37296591 1.
  0.         0.         0.        ]
 [1.         0.         0.         0.         0.37213815 1.
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.37375548 1.
  0.45797698 0.         0.        ]
 [0.         1.         0.         0.         0.3804867  1.
  0.         0.         0.        ]
 [1.         0.         1.         1.         0.37693365 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.37697983 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.37719288 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37713291 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37655732 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37708178 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37646649 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37632555 1.
  0.32258    1.         1.        ]
 [1.         0.         1.         1.         0.37699699 1.
  0.30469539 1.         1.        ]
 [1.         0.         1.         1.         0.37731667 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.37692241 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.37702525 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.3767595  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37764014 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37680922 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37642758 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37747727 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37718261 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37675136 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37688828 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37714123 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37683527 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37775488 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37762186 1.
  0.34512066 1.         1.        ]
 [1.         0.         1.         1.         0.37767509 1.
  1.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.9285714030265808
#####################         POISON         ###############################################

############################################################################################

comm_round: 25 | global_test_acc: 77.778% | global_f1: 0.8750000000000001 | global_precision: 0.7777777777777778
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.78      1.00      0.88         7

    accuracy                           0.78         9
   macro avg       0.39      0.50      0.44         9
weighted avg       0.60      0.78      0.68         9

Accuracy per class:
[[7 0]
 [2 0]]
[1. 0.]
poison scaling shape: (29, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 29 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clients
y shape (29,)
[0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (29,)
[1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_fg shape (29,)
[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0.]
wv_mn shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ed shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_lg shape (29, 1)
[[0.37545043]
 [0.37628569]
 [0.37255534]
 [0.38130316]
 [0.37776522]
 [0.37755355]
 [0.37725437]
 [0.37737736]
 [0.37675933]
 [0.37706054]
 [0.37684017]
 [0.37734797]
 [0.37679046]
 [0.37683258]
 [0.37735506]
 [0.37772495]
 [0.37748113]
 [0.37686335]
 [0.37738279]
 [0.37701884]
 [0.37762574]
 [0.37705105]
 [0.37734385]
 [0.37706069]
 [0.37725502]
 [0.37766183]
 [0.37743363]
 [0.37697101]
 [0.37775893]]
wv_jc shape (29,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ndT shape (29,)
[1.         0.         0.67721054 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_std shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
xy shape: (29, 9)
[[1.         0.         0.         0.         0.37545043 1.
  1.         0.         0.        ]
 [1.         0.         0.         0.         0.37628569 1.
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.37255534 1.
  0.67721054 0.         0.        ]
 [0.         1.         0.         0.         0.38130316 1.
  0.         0.         0.        ]
 [1.         0.         1.         1.         0.37776522 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37755355 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37725437 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37737736 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37675933 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37706054 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37684017 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37734797 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37679046 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37683258 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37735506 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37772495 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37748113 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37686335 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37738279 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37701884 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37762574 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37705105 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37734385 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37706069 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37725502 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37766183 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37743363 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37697101 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37775893 1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.9285714030265808
#####################         POISON         ###############################################

############################################################################################

comm_round: 26 | global_test_acc: 66.667% | global_f1: 0.8 | global_precision: 0.6666666666666666
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.67      1.00      0.80         6

    accuracy                           0.67         9
   macro avg       0.33      0.50      0.40         9
weighted avg       0.44      0.67      0.53         9

Accuracy per class:
[[6 0]
 [3 0]]
[1. 0.]
poison scaling shape: (29, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 29 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clients
y shape (29,)
[0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (29,)
[1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_fg shape (29,)
[0.        0.4992716 0.        1.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.       ]
wv_mn shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ed shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_lg shape (29, 1)
[[0.37422563]
 [0.37433776]
 [0.37507557]
 [0.38598517]
 [0.37786473]
 [0.37751792]
 [0.37765189]
 [0.37815408]
 [0.37726215]
 [0.37754449]
 [0.37764678]
 [0.37747573]
 [0.37802517]
 [0.37761385]
 [0.37765995]
 [0.37803819]
 [0.37750487]
 [0.3780486 ]
 [0.37751779]
 [0.37666294]
 [0.37691287]
 [0.37805516]
 [0.37760451]
 [0.37825148]
 [0.3778565 ]
 [0.37819639]
 [0.3785891 ]
 [0.37837859]
 [0.37762891]]
wv_jc shape (29,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ndT shape (29,)
[0.51750667 0.         1.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_std shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
xy shape: (29, 9)
[[1.         0.         0.         0.         0.37422563 1.
  0.51750667 0.         0.        ]
 [1.         0.4992716  0.         0.         0.37433776 1.
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.37507557 1.
  1.         0.         0.        ]
 [0.         1.         0.         0.         0.38598517 1.
  0.         0.         0.        ]
 [1.         0.         1.         1.         0.37786473 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37751792 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37765189 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37815408 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37726215 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37754449 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37764678 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37747573 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37802517 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37761385 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37765995 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37803819 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37750487 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.3780486  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37751779 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37666294 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37691287 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37805516 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37760451 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37825148 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.3778565  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37819639 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.3785891  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37837859 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37762891 1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
1.0
#####################         POISON         ###############################################

############################################################################################

comm_round: 27 | global_test_acc: 77.778% | global_f1: 0.8750000000000001 | global_precision: 0.7777777777777778
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.78      1.00      0.88         7

    accuracy                           0.78         9
   macro avg       0.39      0.50      0.44         9
weighted avg       0.60      0.78      0.68         9

Accuracy per class:
[[7 0]
 [2 0]]
[1. 0.]
poison scaling shape: (29, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 29 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clients
y shape (29,)
[0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (29,)
[0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_fg shape (29,)
[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0.]
wv_mn shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ed shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_lg shape (29, 1)
[[0.37753445]
 [0.3731369 ]
 [0.37153886]
 [0.3817112 ]
 [0.37821238]
 [0.37811788]
 [0.37835627]
 [0.37793029]
 [0.37788098]
 [0.37817934]
 [0.37822652]
 [0.37759885]
 [0.37817873]
 [0.37822639]
 [0.37792628]
 [0.37826588]
 [0.37859928]
 [0.37852139]
 [0.37810494]
 [0.37862809]
 [0.37901672]
 [0.37851725]
 [0.37811024]
 [0.37789029]
 [0.37854433]
 [0.37837837]
 [0.37793335]
 [0.37824284]
 [0.37823146]]
wv_jc shape (29,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ndT shape (29,)
[0.58498364 0.         1.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_std shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
xy shape: (29, 9)
[[0.         0.         0.         0.         0.37753445 1.
  0.58498364 0.         0.        ]
 [1.         0.         0.         0.         0.3731369  1.
  0.         0.         0.        ]
 [1.         0.         0.         0.         0.37153886 1.
  1.         0.         0.        ]
 [0.         1.         0.         0.         0.3817112  1.
  0.         0.         0.        ]
 [1.         0.         1.         1.         0.37821238 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37811788 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37835627 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37793029 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37788098 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37817934 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37822652 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37759885 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37817873 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37822639 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37792628 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37826588 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37859928 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37852139 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37810494 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37862809 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37901672 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37851725 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37811024 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37789029 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37854433 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37837837 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37793335 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37824284 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37823146 1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.9285714030265808
#####################         POISON         ###############################################

############################################################################################

comm_round: 28 | global_test_acc: 88.889% | global_f1: 0.9411764705882353 | global_precision: 0.8888888888888888
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.89      1.00      0.94         8

    accuracy                           0.89         9
   macro avg       0.44      0.50      0.47         9
weighted avg       0.79      0.89      0.84         9

Accuracy per class:
[[8 0]
 [1 0]]
[1. 0.]
poison scaling shape: (29, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 29 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clients
y shape (29,)
[0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (29,)
[1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_fg shape (29,)
[0.         0.         0.19004251 1.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_mn shape (29,)
[0.         0.20393967 0.         0.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.        ]
wv_ed shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_lg shape (29, 1)
[[0.37555961]
 [0.37562585]
 [0.37651946]
 [0.38204786]
 [0.3784944 ]
 [0.37860746]
 [0.37804352]
 [0.37868378]
 [0.37853975]
 [0.37893437]
 [0.37890991]
 [0.37912556]
 [0.3783738 ]
 [0.37903565]
 [0.37875637]
 [0.37848209]
 [0.37845568]
 [0.37946283]
 [0.37884083]
 [0.37882876]
 [0.37843447]
 [0.37906304]
 [0.37891502]
 [0.37802699]
 [0.37859008]
 [0.3793089 ]
 [0.37876337]
 [0.37895822]
 [0.37843553]]
wv_jc shape (29,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ndT shape (29,)
[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0.]
wv_std shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
xy shape: (29, 9)
[[1.         0.         0.         0.         0.37555961 1.
  0.         0.         0.        ]
 [1.         0.         0.20393967 0.         0.37562585 1.
  0.         0.         0.        ]
 [0.         0.19004251 0.         0.         0.37651946 1.
  1.         0.         0.        ]
 [0.         1.         0.         0.         0.38204786 1.
  0.         0.         0.        ]
 [1.         0.         1.         1.         0.3784944  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37860746 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37804352 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37868378 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37853975 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37893437 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37890991 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37912556 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.3783738  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37903565 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37875637 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37848209 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37845568 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37946283 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37884083 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37882876 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37843447 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37906304 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37891502 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37802699 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37859008 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.3793089  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37876337 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37895822 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37843553 1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.9285714030265808
#####################         POISON         ###############################################

############################################################################################

comm_round: 29 | global_test_acc: 66.667% | global_f1: 0.8 | global_precision: 0.6666666666666666
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.67      1.00      0.80         6

    accuracy                           0.67         9
   macro avg       0.33      0.50      0.40         9
weighted avg       0.44      0.67      0.53         9

Accuracy per class:
[[6 0]
 [3 0]]
[1. 0.]
poison scaling shape: (29, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 29 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clients
y shape (29,)
[0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (29,)
[0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_fg shape (29,)
[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0.]
wv_mn shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ed shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_lg shape (29, 1)
[[0.26198672]
 [0.26727948]
 [0.26295462]
 [0.28848113]
 [0.26927024]
 [0.2692883 ]
 [0.26925319]
 [0.26926604]
 [0.26930129]
 [0.26930856]
 [0.26931715]
 [0.26921483]
 [0.26919183]
 [0.26928756]
 [0.26926354]
 [0.26925382]
 [0.26930488]
 [0.26927628]
 [0.26919316]
 [0.26929854]
 [0.26930148]
 [0.26923369]
 [0.26925412]
 [0.26923184]
 [0.2692566 ]
 [0.26916991]
 [0.26925892]
 [0.26923057]
 [0.26925376]]
wv_jc shape (29,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ndT shape (29,)
[1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0.]
wv_std shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
xy shape: (29, 9)
[[0.         0.         0.         0.         0.26198672 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.26727948 1.
  0.         1.         0.        ]
 [1.         0.         0.         0.         0.26295462 1.
  1.         0.         0.        ]
 [0.         1.         0.         0.         0.28848113 1.
  0.         0.         0.        ]
 [1.         0.         1.         1.         0.26927024 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.2692883  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.26925319 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.26926604 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.26930129 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.26930856 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.26931715 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.26921483 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.26919183 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.26928756 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.26926354 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.26925382 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.26930488 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.26927628 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.26919316 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.26929854 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.26930148 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.26923369 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.26925412 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.26923184 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.2692566  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.26916991 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.26925892 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.26923057 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.26925376 1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.2222222238779068
#####################         POISON         ###############################################

############################################################################################

comm_round: 0 | global_test_acc: 11.111% | global_f1: 0.0 | global_precision: 0.0
              precision    recall  f1-score   support

           0       0.11      1.00      0.20         1
           1       0.00      0.00      0.00         8

    accuracy                           0.11         9
   macro avg       0.06      0.50      0.10         9
weighted avg       0.01      0.11      0.02         9
poison scaling shape: (29, 1)
[[0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]]scaled_weight_list: Rows 29 cols 21
y shape (29,)
[0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (29,)
[0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_fg shape (29,)
[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0.]
wv_mn shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ed shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_lg shape (29, 1)
[[0.26126241]
 [0.26720715]
 [0.26293547]
 [0.28814176]
 [0.26914763]
 [0.26924573]
 [0.26922144]
 [0.26933102]
 [0.26925147]
 [0.2692485 ]
 [0.26921985]
 [0.26928525]
 [0.26933718]
 [0.2692803 ]
 [0.26927998]
 [0.26925634]
 [0.26932187]
 [0.26931109]
 [0.26919771]
 [0.26926301]
 [0.26922783]
 [0.26928929]
 [0.26923889]
 [0.26930812]
 [0.2693059 ]
 [0.26922351]
 [0.26927162]
 [0.26918315]
 [0.26931657]]
wv_jc shape (29,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ndT shape (29,)
[0.7118669 0.        1.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.       ]
wv_std shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
xy shape: (29, 9)
[[0.         0.         0.         0.         0.26126241 1.
  0.7118669  0.         0.        ]
 [1.         0.         1.         1.         0.26720715 1.
  0.         1.         0.        ]
 [1.         0.         0.         0.         0.26293547 1.
  1.         0.         0.        ]
 [0.         1.         0.         0.         0.28814176 1.
  0.         0.         0.        ]
 [1.         0.         1.         1.         0.26914763 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.26924573 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.26922144 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.26933102 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.26925147 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.2692485  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.26921985 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.26928525 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.26933718 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.2692803  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.26927998 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.26925634 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.26932187 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.26931109 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.26919771 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.26926301 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.26922783 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.26928929 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.26923889 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.26930812 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.2693059  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.26922351 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.26927162 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.26918315 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.26931657 1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.6111111044883728
#####################         POISON         ###############################################

############################################################################################

comm_round: 1 | global_test_acc: 88.889% | global_f1: 0.9411764705882353 | global_precision: 0.8888888888888888
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.89      1.00      0.94         8

    accuracy                           0.89         9
   macro avg       0.44      0.50      0.47         9
weighted avg       0.79      0.89      0.84         9
poison scaling shape: (29, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 29 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clients
y shape (29,)
[0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (29,)
[0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_fg shape (29,)
[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0.]
wv_mn shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ed shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_lg shape (29, 1)
[[0.26276577]
 [0.2680853 ]
 [0.26387068]
 [0.28758721]
 [0.27007944]
 [0.2700478 ]
 [0.2699555 ]
 [0.27000861]
 [0.27006746]
 [0.27000076]
 [0.27003661]
 [0.26994298]
 [0.2699701 ]
 [0.27002573]
 [0.2700137 ]
 [0.27005318]
 [0.26991832]
 [0.27004703]
 [0.27001313]
 [0.26993632]
 [0.26983338]
 [0.26995792]
 [0.26999033]
 [0.27004264]
 [0.26998796]
 [0.26985357]
 [0.26995176]
 [0.2700201 ]
 [0.26988966]]
wv_jc shape (29,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ndT shape (29,)
[1.         0.99571203 1.         0.         0.08566741 0.20253443
 0.30832009 0.36925526 0.39191984 0.0481379  0.24547658 0.30581404
 0.56052172 0.27863981 0.24742317 0.47631713 0.19642276 0.27939257
 0.21247529 0.07613817 0.28890299 0.45255849 0.47253828 0.25690669
 0.32342781 0.38156525 0.41500992 0.58592096 0.39912617]
wv_std shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
xy shape: (29, 9)
[[0.         0.         0.         0.         0.26276577 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.2680853  1.
  0.99571203 1.         0.        ]
 [1.         0.         0.         0.         0.26387068 1.
  1.         0.         0.        ]
 [0.         1.         0.         0.         0.28758721 1.
  0.         0.         0.        ]
 [1.         0.         1.         1.         0.27007944 1.
  0.08566741 1.         1.        ]
 [1.         0.         1.         1.         0.2700478  1.
  0.20253443 1.         1.        ]
 [1.         0.         1.         1.         0.2699555  1.
  0.30832009 1.         1.        ]
 [1.         0.         1.         1.         0.27000861 1.
  0.36925526 1.         1.        ]
 [1.         0.         1.         1.         0.27006746 1.
  0.39191984 1.         1.        ]
 [1.         0.         1.         1.         0.27000076 1.
  0.0481379  1.         1.        ]
 [1.         0.         1.         1.         0.27003661 1.
  0.24547658 1.         1.        ]
 [1.         0.         1.         1.         0.26994298 1.
  0.30581404 1.         1.        ]
 [1.         0.         1.         1.         0.2699701  1.
  0.56052172 1.         1.        ]
 [1.         0.         1.         1.         0.27002573 1.
  0.27863981 1.         1.        ]
 [1.         0.         1.         1.         0.2700137  1.
  0.24742317 1.         1.        ]
 [1.         0.         1.         1.         0.27005318 1.
  0.47631713 1.         1.        ]
 [1.         0.         1.         1.         0.26991832 1.
  0.19642276 1.         1.        ]
 [1.         0.         1.         1.         0.27004703 1.
  0.27939257 1.         1.        ]
 [1.         0.         1.         1.         0.27001313 1.
  0.21247529 1.         1.        ]
 [1.         0.         1.         1.         0.26993632 1.
  0.07613817 1.         1.        ]
 [1.         0.         1.         1.         0.26983338 1.
  0.28890299 1.         1.        ]
 [1.         0.         1.         1.         0.26995792 1.
  0.45255849 1.         1.        ]
 [1.         0.         1.         1.         0.26999033 1.
  0.47253828 1.         1.        ]
 [1.         0.         1.         1.         0.27004264 1.
  0.25690669 1.         1.        ]
 [1.         0.         1.         1.         0.26998796 1.
  0.32342781 1.         1.        ]
 [1.         0.         1.         1.         0.26985357 1.
  0.38156525 1.         1.        ]
 [1.         0.         1.         1.         0.26995176 1.
  0.41500992 1.         1.        ]
 [1.         0.         1.         1.         0.2700201  1.
  0.58592096 1.         1.        ]
 [1.         0.         1.         1.         0.26988966 1.
  0.39912617 1.         1.        ]]

Best Training Poisoning Accuracy:
0.8333333134651184
#####################         POISON         ###############################################

############################################################################################

comm_round: 2 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         9

    accuracy                           1.00         9
   macro avg       1.00      1.00      1.00         9
weighted avg       1.00      1.00      1.00         9
poison scaling shape: (29, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 29 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clients
y shape (29,)
[0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (29,)
[0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_fg shape (29,)
[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0.]
wv_mn shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ed shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_lg shape (29, 1)
[[0.26383845]
 [0.26850337]
 [0.26412632]
 [0.28809508]
 [0.27071917]
 [0.27062496]
 [0.27071181]
 [0.27077895]
 [0.270744  ]
 [0.27061684]
 [0.2707426 ]
 [0.27064143]
 [0.2707213 ]
 [0.27074451]
 [0.27056399]
 [0.27079432]
 [0.27065494]
 [0.27070169]
 [0.2707238 ]
 [0.27077306]
 [0.27070592]
 [0.27066208]
 [0.27061863]
 [0.27074096]
 [0.27067581]
 [0.27063895]
 [0.27069804]
 [0.27074866]
 [0.27067526]]
wv_jc shape (29,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ndT shape (29,)
[1.         0.30468725 1.         0.         0.26919228 0.38441588
 0.18631802 0.21555671 0.38094698 0.28567559 0.38612682 0.24913217
 0.36609602 0.28884939 0.21590871 0.25415565 0.41540865 0.2636931
 0.31650655 0.25255894 0.14660336 0.32867585 0.37288931 0.30259613
 0.26711955 0.17587288 0.24192067 0.4693798  0.25010466]
wv_std shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
xy shape: (29, 9)
[[0.         0.         0.         0.         0.26383845 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.26850337 1.
  0.30468725 1.         0.        ]
 [1.         0.         0.         0.         0.26412632 1.
  1.         0.         0.        ]
 [0.         1.         0.         0.         0.28809508 1.
  0.         0.         0.        ]
 [1.         0.         1.         1.         0.27071917 1.
  0.26919228 1.         1.        ]
 [1.         0.         1.         1.         0.27062496 1.
  0.38441588 1.         1.        ]
 [1.         0.         1.         1.         0.27071181 1.
  0.18631802 1.         1.        ]
 [1.         0.         1.         1.         0.27077895 1.
  0.21555671 1.         1.        ]
 [1.         0.         1.         1.         0.270744   1.
  0.38094698 1.         1.        ]
 [1.         0.         1.         1.         0.27061684 1.
  0.28567559 1.         1.        ]
 [1.         0.         1.         1.         0.2707426  1.
  0.38612682 1.         1.        ]
 [1.         0.         1.         1.         0.27064143 1.
  0.24913217 1.         1.        ]
 [1.         0.         1.         1.         0.2707213  1.
  0.36609602 1.         1.        ]
 [1.         0.         1.         1.         0.27074451 1.
  0.28884939 1.         1.        ]
 [1.         0.         1.         1.         0.27056399 1.
  0.21590871 1.         1.        ]
 [1.         0.         1.         1.         0.27079432 1.
  0.25415565 1.         1.        ]
 [1.         0.         1.         1.         0.27065494 1.
  0.41540865 1.         1.        ]
 [1.         0.         1.         1.         0.27070169 1.
  0.2636931  1.         1.        ]
 [1.         0.         1.         1.         0.2707238  1.
  0.31650655 1.         1.        ]
 [1.         0.         1.         1.         0.27077306 1.
  0.25255894 1.         1.        ]
 [1.         0.         1.         1.         0.27070592 1.
  0.14660336 1.         1.        ]
 [1.         0.         1.         1.         0.27066208 1.
  0.32867585 1.         1.        ]
 [1.         0.         1.         1.         0.27061863 1.
  0.37288931 1.         1.        ]
 [1.         0.         1.         1.         0.27074096 1.
  0.30259613 1.         1.        ]
 [1.         0.         1.         1.         0.27067581 1.
  0.26711955 1.         1.        ]
 [1.         0.         1.         1.         0.27063895 1.
  0.17587288 1.         1.        ]
 [1.         0.         1.         1.         0.27069804 1.
  0.24192067 1.         1.        ]
 [1.         0.         1.         1.         0.27074866 1.
  0.4693798  1.         1.        ]
 [1.         0.         1.         1.         0.27067526 1.
  0.25010466 1.         1.        ]]

Best Training Poisoning Accuracy:
0.9444444179534912
#####################         POISON         ###############################################

############################################################################################

comm_round: 3 | global_test_acc: 66.667% | global_f1: 0.8 | global_precision: 0.6666666666666666
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.67      1.00      0.80         6

    accuracy                           0.67         9
   macro avg       0.33      0.50      0.40         9
weighted avg       0.44      0.67      0.53         9
poison scaling shape: (29, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 29 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clients
y shape (29,)
[0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (29,)
[0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_fg shape (29,)
[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0.]
wv_mn shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ed shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_lg shape (29, 1)
[[0.26412439]
 [0.26949749]
 [0.26543611]
 [0.28830413]
 [0.27133011]
 [0.27142235]
 [0.2714487 ]
 [0.27131757]
 [0.27148204]
 [0.27136471]
 [0.2714076 ]
 [0.27131138]
 [0.27133404]
 [0.27140016]
 [0.27130121]
 [0.27141151]
 [0.27146147]
 [0.27131091]
 [0.2713503 ]
 [0.27133674]
 [0.27144825]
 [0.27140026]
 [0.27147092]
 [0.27142068]
 [0.27130413]
 [0.27138934]
 [0.2713747 ]
 [0.27146   ]
 [0.27146061]]
wv_jc shape (29,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ndT shape (29,)
[1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0.]
wv_std shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
xy shape: (29, 9)
[[0.         0.         0.         0.         0.26412439 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.26949749 1.
  0.         1.         0.        ]
 [1.         0.         0.         0.         0.26543611 1.
  1.         0.         0.        ]
 [0.         1.         0.         0.         0.28830413 1.
  0.         0.         0.        ]
 [1.         0.         1.         1.         0.27133011 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27142235 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.2714487  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27131757 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27148204 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27136471 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.2714076  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27131138 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27133404 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27140016 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27130121 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27141151 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27146147 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27131091 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.2713503  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27133674 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27144825 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27140026 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27147092 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27142068 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27130413 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27138934 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.2713747  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27146    1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27146061 1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.8333333134651184
#####################         POISON         ###############################################

############################################################################################

comm_round: 4 | global_test_acc: 88.889% | global_f1: 0.9411764705882353 | global_precision: 0.8888888888888888
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.89      1.00      0.94         8

    accuracy                           0.89         9
   macro avg       0.44      0.50      0.47         9
weighted avg       0.79      0.89      0.84         9
poison scaling shape: (29, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 29 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clients
y shape (29,)
[0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (29,)
[0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_fg shape (29,)
[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0.]
wv_mn shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ed shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_lg shape (29, 1)
[[0.2654087 ]
 [0.27008343]
 [0.26593422]
 [0.28950719]
 [0.27196955]
 [0.27207938]
 [0.27213045]
 [0.27199575]
 [0.27209792]
 [0.27204368]
 [0.27208076]
 [0.27209885]
 [0.2720916 ]
 [0.27212245]
 [0.27212412]
 [0.27210407]
 [0.2720175 ]
 [0.27211779]
 [0.27213462]
 [0.27210588]
 [0.2721489 ]
 [0.27202853]
 [0.27209057]
 [0.27209854]
 [0.27204193]
 [0.27203652]
 [0.27208996]
 [0.27207179]
 [0.27203813]]
wv_jc shape (29,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ndT shape (29,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0.]
wv_std shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
xy shape: (29, 9)
[[0.         0.         0.         0.         0.2654087  1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.27008343 1.
  0.         1.         0.        ]
 [1.         0.         0.         0.         0.26593422 1.
  0.         0.         0.        ]
 [0.         1.         0.         0.         0.28950719 1.
  0.         0.         0.        ]
 [1.         0.         1.         1.         0.27196955 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27207938 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27213045 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27199575 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27209792 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27204368 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27208076 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27209885 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.2720916  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27212245 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27212412 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27210407 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.2720175  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27211779 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27213462 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27210588 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.2721489  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27202853 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27209057 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27209854 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27204193 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27203652 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27208996 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27207179 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27203813 1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.8333333134651184
#####################         POISON         ###############################################

############################################################################################

comm_round: 5 | global_test_acc: 88.889% | global_f1: 0.9411764705882353 | global_precision: 0.8888888888888888
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.89      1.00      0.94         8

    accuracy                           0.89         9
   macro avg       0.44      0.50      0.47         9
weighted avg       0.79      0.89      0.84         9
poison scaling shape: (29, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 29 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clients
y shape (29,)
[0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (29,)
[0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_fg shape (29,)
[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0.]
wv_mn shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ed shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_lg shape (29, 1)
[[0.26526368]
 [0.27058609]
 [0.26675033]
 [0.28859171]
 [0.27278331]
 [0.27274576]
 [0.27280073]
 [0.27274474]
 [0.27291232]
 [0.27275624]
 [0.27269867]
 [0.2728016 ]
 [0.27287937]
 [0.27284856]
 [0.27283683]
 [0.27278183]
 [0.27286428]
 [0.27280431]
 [0.27277275]
 [0.27274158]
 [0.27281237]
 [0.27278567]
 [0.27280155]
 [0.27279413]
 [0.27287096]
 [0.27274084]
 [0.27274435]
 [0.27289459]
 [0.27278276]]
wv_jc shape (29,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ndT shape (29,)
[1.         1.         1.         0.         0.65586339 0.9722422
 0.73133947 0.88344439 0.99464077 0.85736116 0.65255151 0.90935053
 0.9020424  1.         0.82754564 0.84869269 1.         0.86730056
 0.85901267 0.83938206 0.89454246 0.93622048 1.         0.733889
 0.9485647  0.97779388 0.82296044 0.6766264  0.62139422]
wv_std shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
xy shape: (29, 9)
[[0.         0.         0.         0.         0.26526368 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.27058609 1.
  1.         1.         0.        ]
 [1.         0.         0.         0.         0.26675033 1.
  1.         0.         0.        ]
 [0.         1.         0.         0.         0.28859171 1.
  0.         0.         0.        ]
 [1.         0.         1.         1.         0.27278331 1.
  0.65586339 1.         1.        ]
 [1.         0.         1.         1.         0.27274576 1.
  0.9722422  1.         1.        ]
 [1.         0.         1.         1.         0.27280073 1.
  0.73133947 1.         1.        ]
 [1.         0.         1.         1.         0.27274474 1.
  0.88344439 1.         1.        ]
 [1.         0.         1.         1.         0.27291232 1.
  0.99464077 1.         1.        ]
 [1.         0.         1.         1.         0.27275624 1.
  0.85736116 1.         1.        ]
 [1.         0.         1.         1.         0.27269867 1.
  0.65255151 1.         1.        ]
 [1.         0.         1.         1.         0.2728016  1.
  0.90935053 1.         1.        ]
 [1.         0.         1.         1.         0.27287937 1.
  0.9020424  1.         1.        ]
 [1.         0.         1.         1.         0.27284856 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.27283683 1.
  0.82754564 1.         1.        ]
 [1.         0.         1.         1.         0.27278183 1.
  0.84869269 1.         1.        ]
 [1.         0.         1.         1.         0.27286428 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.27280431 1.
  0.86730056 1.         1.        ]
 [1.         0.         1.         1.         0.27277275 1.
  0.85901267 1.         1.        ]
 [1.         0.         1.         1.         0.27274158 1.
  0.83938206 1.         1.        ]
 [1.         0.         1.         1.         0.27281237 1.
  0.89454246 1.         1.        ]
 [1.         0.         1.         1.         0.27278567 1.
  0.93622048 1.         1.        ]
 [1.         0.         1.         1.         0.27280155 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.27279413 1.
  0.733889   1.         1.        ]
 [1.         0.         1.         1.         0.27287096 1.
  0.9485647  1.         1.        ]
 [1.         0.         1.         1.         0.27274084 1.
  0.97779388 1.         1.        ]
 [1.         0.         1.         1.         0.27274435 1.
  0.82296044 1.         1.        ]
 [1.         0.         1.         1.         0.27289459 1.
  0.6766264  1.         1.        ]
 [1.         0.         1.         1.         0.27278276 1.
  0.62139422 1.         1.        ]]

Best Training Poisoning Accuracy:
0.7777777910232544
#####################         POISON         ###############################################

############################################################################################

comm_round: 6 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         9

    accuracy                           1.00         9
   macro avg       1.00      1.00      1.00         9
weighted avg       1.00      1.00      1.00         9
poison scaling shape: (29, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 29 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clients
y shape (29,)
[0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (29,)
[0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_fg shape (29,)
[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0.]
wv_mn shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ed shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_lg shape (29, 1)
[[0.26629221]
 [0.27141512]
 [0.26711487]
 [0.28898401]
 [0.273315  ]
 [0.27336438]
 [0.27343306]
 [0.27343081]
 [0.27343948]
 [0.27337646]
 [0.2734166 ]
 [0.2734341 ]
 [0.27333646]
 [0.27348428]
 [0.27343296]
 [0.27347869]
 [0.2734051 ]
 [0.2734581 ]
 [0.27336218]
 [0.2733804 ]
 [0.27347117]
 [0.27337859]
 [0.27342115]
 [0.27337078]
 [0.27351224]
 [0.27338645]
 [0.27338441]
 [0.2734755 ]
 [0.27337408]]
wv_jc shape (29,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ndT shape (29,)
[1.         0.71932618 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_std shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
xy shape: (29, 9)
[[0.         0.         0.         0.         0.26629221 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.27141512 1.
  0.71932618 1.         0.        ]
 [1.         0.         0.         0.         0.26711487 1.
  0.         0.         0.        ]
 [0.         1.         0.         0.         0.28898401 1.
  0.         0.         0.        ]
 [1.         0.         1.         1.         0.273315   1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27336438 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27343306 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27343081 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27343948 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27337646 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.2734166  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.2734341  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27333646 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27348428 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27343296 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27347869 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.2734051  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.2734581  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27336218 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.2733804  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27347117 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27337859 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27342115 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27337078 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27351224 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27338645 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27338441 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.2734755  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27337408 1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.8333333134651184
#####################         POISON         ###############################################

############################################################################################

comm_round: 7 | global_test_acc: 88.889% | global_f1: 0.9411764705882353 | global_precision: 0.8888888888888888
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.89      1.00      0.94         8

    accuracy                           0.89         9
   macro avg       0.44      0.50      0.47         9
weighted avg       0.79      0.89      0.84         9
poison scaling shape: (29, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 29 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clients
y shape (29,)
[0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (29,)
[0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_fg shape (29,)
[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0.]
wv_mn shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ed shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_lg shape (29, 1)
[[0.26690981]
 [0.2717672 ]
 [0.26800942]
 [0.28948955]
 [0.27401142]
 [0.27400333]
 [0.27409248]
 [0.27408843]
 [0.27405466]
 [0.27409505]
 [0.27396135]
 [0.27400342]
 [0.27403829]
 [0.27397902]
 [0.27400144]
 [0.27400341]
 [0.27403885]
 [0.27405066]
 [0.27405701]
 [0.27396478]
 [0.27412108]
 [0.27403431]
 [0.27405735]
 [0.27400411]
 [0.27401499]
 [0.27414227]
 [0.27396481]
 [0.27403249]
 [0.27395542]]
wv_jc shape (29,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ndT shape (29,)
[1.         1.         1.         0.         0.58088961 0.83683641
 1.         0.55849621 0.57506451 0.36266971 0.74047039 0.68761989
 0.92614228 0.57014443 0.52938327 0.40954823 0.46293679 0.3780201
 0.52831594 0.87695625 0.82854265 0.80666404 0.87205598 0.68671814
 0.85837255 0.98026322 0.48811945 0.97804802 1.        ]
wv_std shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
xy shape: (29, 9)
[[0.         0.         0.         0.         0.26690981 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.2717672  1.
  1.         1.         0.        ]
 [1.         0.         0.         0.         0.26800942 1.
  1.         0.         0.        ]
 [0.         1.         0.         0.         0.28948955 1.
  0.         0.         0.        ]
 [1.         0.         1.         1.         0.27401142 1.
  0.58088961 1.         1.        ]
 [1.         0.         1.         1.         0.27400333 1.
  0.83683641 1.         1.        ]
 [1.         0.         1.         1.         0.27409248 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.27408843 1.
  0.55849621 1.         1.        ]
 [1.         0.         1.         1.         0.27405466 1.
  0.57506451 1.         1.        ]
 [1.         0.         1.         1.         0.27409505 1.
  0.36266971 1.         1.        ]
 [1.         0.         1.         1.         0.27396135 1.
  0.74047039 1.         1.        ]
 [1.         0.         1.         1.         0.27400342 1.
  0.68761989 1.         1.        ]
 [1.         0.         1.         1.         0.27403829 1.
  0.92614228 1.         1.        ]
 [1.         0.         1.         1.         0.27397902 1.
  0.57014443 1.         1.        ]
 [1.         0.         1.         1.         0.27400144 1.
  0.52938327 1.         1.        ]
 [1.         0.         1.         1.         0.27400341 1.
  0.40954823 1.         1.        ]
 [1.         0.         1.         1.         0.27403885 1.
  0.46293679 1.         1.        ]
 [1.         0.         1.         1.         0.27405066 1.
  0.3780201  1.         1.        ]
 [1.         0.         1.         1.         0.27405701 1.
  0.52831594 1.         1.        ]
 [1.         0.         1.         1.         0.27396478 1.
  0.87695625 1.         1.        ]
 [1.         0.         1.         1.         0.27412108 1.
  0.82854265 1.         1.        ]
 [1.         0.         1.         1.         0.27403431 1.
  0.80666404 1.         1.        ]
 [1.         0.         1.         1.         0.27405735 1.
  0.87205598 1.         1.        ]
 [1.         0.         1.         1.         0.27400411 1.
  0.68671814 1.         1.        ]
 [1.         0.         1.         1.         0.27401499 1.
  0.85837255 1.         1.        ]
 [1.         0.         1.         1.         0.27414227 1.
  0.98026322 1.         1.        ]
 [1.         0.         1.         1.         0.27396481 1.
  0.48811945 1.         1.        ]
 [1.         0.         1.         1.         0.27403249 1.
  0.97804802 1.         1.        ]
 [1.         0.         1.         1.         0.27395542 1.
  1.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.8888888955116272
#####################         POISON         ###############################################

############################################################################################

comm_round: 8 | global_test_acc: 77.778% | global_f1: 0.8750000000000001 | global_precision: 0.7777777777777778
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.78      1.00      0.88         7

    accuracy                           0.78         9
   macro avg       0.39      0.50      0.44         9
weighted avg       0.60      0.78      0.68         9
poison scaling shape: (29, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 29 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clients
y shape (29,)
[0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (29,)
[0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_fg shape (29,)
[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0.]
wv_mn shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ed shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_lg shape (29, 1)
[[0.26772736]
 [0.27272044]
 [0.26809614]
 [0.28979707]
 [0.27468671]
 [0.27467116]
 [0.27473719]
 [0.27463605]
 [0.27454876]
 [0.27472159]
 [0.27453686]
 [0.27463698]
 [0.27456762]
 [0.27473825]
 [0.274632  ]
 [0.27454364]
 [0.2746344 ]
 [0.27465817]
 [0.27470617]
 [0.27460064]
 [0.27469923]
 [0.2746343 ]
 [0.27463169]
 [0.27458024]
 [0.27464327]
 [0.27462992]
 [0.27463046]
 [0.27467685]
 [0.27458573]]
wv_jc shape (29,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ndT shape (29,)
[1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_std shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
xy shape: (29, 9)
[[0.         0.         0.         0.         0.26772736 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.27272044 1.
  1.         1.         0.        ]
 [1.         0.         0.         0.         0.26809614 1.
  1.         0.         0.        ]
 [0.         1.         0.         0.         0.28979707 1.
  0.         0.         0.        ]
 [1.         0.         1.         1.         0.27468671 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.27467116 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.27473719 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.27463605 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.27454876 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.27472159 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.27453686 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.27463698 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.27456762 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.27473825 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.274632   1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.27454364 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.2746344  1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.27465817 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.27470617 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.27460064 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.27469923 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.2746343  1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.27463169 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.27458024 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.27464327 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.27462992 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.27463046 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.27467685 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.27458573 1.
  1.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.8333333134651184
#####################         POISON         ###############################################

############################################################################################

comm_round: 9 | global_test_acc: 88.889% | global_f1: 0.9411764705882353 | global_precision: 0.8888888888888888
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.89      1.00      0.94         8

    accuracy                           0.89         9
   macro avg       0.44      0.50      0.47         9
weighted avg       0.79      0.89      0.84         9
poison scaling shape: (29, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 29 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clients
y shape (29,)
[0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (29,)
[1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_fg shape (29,)
[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0.]
wv_mn shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ed shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_lg shape (29, 1)
[[0.26848262]
 [0.27317698]
 [0.26917125]
 [0.29084263]
 [0.2751577 ]
 [0.27526004]
 [0.27527948]
 [0.2751005 ]
 [0.2751593 ]
 [0.27526931]
 [0.27516337]
 [0.27520376]
 [0.27526344]
 [0.27529383]
 [0.27532632]
 [0.27532089]
 [0.27524151]
 [0.27518196]
 [0.27525155]
 [0.27523969]
 [0.27512837]
 [0.27520647]
 [0.2752101 ]
 [0.27525587]
 [0.27527287]
 [0.27521612]
 [0.27512708]
 [0.27534456]
 [0.27518475]]
wv_jc shape (29,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ndT shape (29,)
[1.         0.98688423 1.         0.         0.52114923 0.34553874
 0.54246477 0.41055262 0.45942711 0.44466439 0.38006186 0.51709035
 0.33457472 0.47987142 0.47996813 0.50296616 0.52955401 0.38290654
 0.60364259 0.46219465 0.31936268 0.32292741 0.56198938 0.50197205
 0.45719647 0.41915599 0.25791635 0.4512543  0.4111685 ]
wv_std shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
xy shape: (29, 9)
[[1.         0.         0.         0.         0.26848262 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.27317698 1.
  0.98688423 1.         0.        ]
 [0.         0.         0.         0.         0.26917125 1.
  1.         0.         0.        ]
 [0.         1.         0.         0.         0.29084263 1.
  0.         0.         0.        ]
 [1.         0.         1.         1.         0.2751577  1.
  0.52114923 1.         1.        ]
 [1.         0.         1.         1.         0.27526004 1.
  0.34553874 1.         1.        ]
 [1.         0.         1.         1.         0.27527948 1.
  0.54246477 1.         1.        ]
 [1.         0.         1.         1.         0.2751005  1.
  0.41055262 1.         1.        ]
 [1.         0.         1.         1.         0.2751593  1.
  0.45942711 1.         1.        ]
 [1.         0.         1.         1.         0.27526931 1.
  0.44466439 1.         1.        ]
 [1.         0.         1.         1.         0.27516337 1.
  0.38006186 1.         1.        ]
 [1.         0.         1.         1.         0.27520376 1.
  0.51709035 1.         1.        ]
 [1.         0.         1.         1.         0.27526344 1.
  0.33457472 1.         1.        ]
 [1.         0.         1.         1.         0.27529383 1.
  0.47987142 1.         1.        ]
 [1.         0.         1.         1.         0.27532632 1.
  0.47996813 1.         1.        ]
 [1.         0.         1.         1.         0.27532089 1.
  0.50296616 1.         1.        ]
 [1.         0.         1.         1.         0.27524151 1.
  0.52955401 1.         1.        ]
 [1.         0.         1.         1.         0.27518196 1.
  0.38290654 1.         1.        ]
 [1.         0.         1.         1.         0.27525155 1.
  0.60364259 1.         1.        ]
 [1.         0.         1.         1.         0.27523969 1.
  0.46219465 1.         1.        ]
 [1.         0.         1.         1.         0.27512837 1.
  0.31936268 1.         1.        ]
 [1.         0.         1.         1.         0.27520647 1.
  0.32292741 1.         1.        ]
 [1.         0.         1.         1.         0.2752101  1.
  0.56198938 1.         1.        ]
 [1.         0.         1.         1.         0.27525587 1.
  0.50197205 1.         1.        ]
 [1.         0.         1.         1.         0.27527287 1.
  0.45719647 1.         1.        ]
 [1.         0.         1.         1.         0.27521612 1.
  0.41915599 1.         1.        ]
 [1.         0.         1.         1.         0.27512708 1.
  0.25791635 1.         1.        ]
 [1.         0.         1.         1.         0.27534456 1.
  0.4512543  1.         1.        ]
 [1.         0.         1.         1.         0.27518475 1.
  0.4111685  1.         1.        ]]

Best Training Poisoning Accuracy:
0.8888888955116272
#####################         POISON         ###############################################

############################################################################################

comm_round: 10 | global_test_acc: 77.778% | global_f1: 0.8750000000000001 | global_precision: 0.7777777777777778
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.78      1.00      0.88         7

    accuracy                           0.78         9
   macro avg       0.39      0.50      0.44         9
weighted avg       0.60      0.78      0.68         9
poison scaling shape: (29, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 29 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clients
y shape (29,)
[0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (29,)
[0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_fg shape (29,)
[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0.]
wv_mn shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ed shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_lg shape (29, 1)
[[0.26913919]
 [0.27368195]
 [0.26963041]
 [0.28976687]
 [0.27579773]
 [0.275862  ]
 [0.27585289]
 [0.27591431]
 [0.27586088]
 [0.27589065]
 [0.27582205]
 [0.27578845]
 [0.27580071]
 [0.27576695]
 [0.27588144]
 [0.27589742]
 [0.27586447]
 [0.27580615]
 [0.2758101 ]
 [0.27585065]
 [0.27585852]
 [0.27595306]
 [0.27588718]
 [0.27583533]
 [0.27597776]
 [0.27583958]
 [0.27589672]
 [0.27585808]
 [0.27579517]]
wv_jc shape (29,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ndT shape (29,)
[1.         1.         1.         0.         0.97636061 0.90165998
 0.97216135 0.96891776 1.         1.         1.         0.9637504
 0.98617237 0.97860177 1.         0.97873906 0.98300788 0.96426042
 1.         0.94021385 0.9762771  1.         1.         0.88523305
 1.         1.         0.924265   0.99027599 0.97365066]
wv_std shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
xy shape: (29, 9)
[[0.         0.         0.         0.         0.26913919 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.27368195 1.
  1.         1.         0.        ]
 [1.         0.         0.         0.         0.26963041 1.
  1.         0.         0.        ]
 [0.         1.         0.         0.         0.28976687 1.
  0.         0.         0.        ]
 [1.         0.         1.         1.         0.27579773 1.
  0.97636061 1.         1.        ]
 [1.         0.         1.         1.         0.275862   1.
  0.90165998 1.         1.        ]
 [1.         0.         1.         1.         0.27585289 1.
  0.97216135 1.         1.        ]
 [1.         0.         1.         1.         0.27591431 1.
  0.96891776 1.         1.        ]
 [1.         0.         1.         1.         0.27586088 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.27589065 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.27582205 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.27578845 1.
  0.9637504  1.         1.        ]
 [1.         0.         1.         1.         0.27580071 1.
  0.98617237 1.         1.        ]
 [1.         0.         1.         1.         0.27576695 1.
  0.97860177 1.         1.        ]
 [1.         0.         1.         1.         0.27588144 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.27589742 1.
  0.97873906 1.         1.        ]
 [1.         0.         1.         1.         0.27586447 1.
  0.98300788 1.         1.        ]
 [1.         0.         1.         1.         0.27580615 1.
  0.96426042 1.         1.        ]
 [1.         0.         1.         1.         0.2758101  1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.27585065 1.
  0.94021385 1.         1.        ]
 [1.         0.         1.         1.         0.27585852 1.
  0.9762771  1.         1.        ]
 [1.         0.         1.         1.         0.27595306 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.27588718 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.27583533 1.
  0.88523305 1.         1.        ]
 [1.         0.         1.         1.         0.27597776 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.27583958 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.27589672 1.
  0.924265   1.         1.        ]
 [1.         0.         1.         1.         0.27585808 1.
  0.99027599 1.         1.        ]
 [1.         0.         1.         1.         0.27579517 1.
  0.97365066 1.         1.        ]]

Best Training Poisoning Accuracy:
0.7777777910232544
#####################         POISON         ###############################################

############################################################################################

comm_round: 11 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         9

    accuracy                           1.00         9
   macro avg       1.00      1.00      1.00         9
weighted avg       1.00      1.00      1.00         9
poison scaling shape: (29, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 29 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clients
y shape (29,)
[0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (29,)
[0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_fg shape (29,)
[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0.]
wv_mn shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ed shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_lg shape (29, 1)
[[0.2702431 ]
 [0.27431763]
 [0.27042764]
 [0.29048026]
 [0.27650734]
 [0.27642677]
 [0.27639888]
 [0.27634016]
 [0.27634573]
 [0.27644332]
 [0.27638556]
 [0.2763191 ]
 [0.27636247]
 [0.27646789]
 [0.27637224]
 [0.27638021]
 [0.27634496]
 [0.27643981]
 [0.27646484]
 [0.27649897]
 [0.2763966 ]
 [0.27643802]
 [0.27642314]
 [0.27632809]
 [0.27639987]
 [0.27642012]
 [0.27636807]
 [0.27634158]
 [0.27638637]]
wv_jc shape (29,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ndT shape (29,)
[1.         0.47237099 1.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_std shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
xy shape: (29, 9)
[[0.         0.         0.         0.         0.2702431  1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.27431763 1.
  0.47237099 1.         0.        ]
 [1.         0.         0.         0.         0.27042764 1.
  1.         0.         0.        ]
 [0.         1.         0.         0.         0.29048026 1.
  0.         0.         0.        ]
 [1.         0.         1.         1.         0.27650734 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27642677 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27639888 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27634016 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27634573 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27644332 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27638556 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.2763191  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27636247 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27646789 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27637224 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27638021 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27634496 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27643981 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27646484 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27649897 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.2763966  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27643802 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27642314 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27632809 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27639987 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27642012 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27636807 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27634158 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27638637 1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.8333333134651184
#####################         POISON         ###############################################

############################################################################################

comm_round: 12 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         9

    accuracy                           1.00         9
   macro avg       1.00      1.00      1.00         9
weighted avg       1.00      1.00      1.00         9
poison scaling shape: (29, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 29 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clients
y shape (29,)
[0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (29,)
[0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_fg shape (29,)
[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0.]
wv_mn shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ed shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_lg shape (29, 1)
[[0.26971959]
 [0.27491399]
 [0.27111798]
 [0.29038199]
 [0.27689948]
 [0.2770095 ]
 [0.27688242]
 [0.27690499]
 [0.27690752]
 [0.27698334]
 [0.27703979]
 [0.27698399]
 [0.27689585]
 [0.27706045]
 [0.27695744]
 [0.27690029]
 [0.27695024]
 [0.27698578]
 [0.27698911]
 [0.27708779]
 [0.27696813]
 [0.27700481]
 [0.2769539 ]
 [0.27692835]
 [0.27691598]
 [0.27696599]
 [0.27699599]
 [0.27704417]
 [0.27697582]]
wv_jc shape (29,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ndT shape (29,)
[1.        0.        0.2178175 0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.0035617
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.       ]
wv_std shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
xy shape: (29, 9)
[[0.         0.         0.         0.         0.26971959 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.27491399 1.
  0.         1.         0.        ]
 [1.         0.         0.         0.         0.27111798 1.
  0.2178175  0.         0.        ]
 [0.         1.         0.         0.         0.29038199 1.
  0.         0.         0.        ]
 [1.         0.         1.         1.         0.27689948 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.2770095  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27688242 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27690499 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27690752 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27698334 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27703979 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27698399 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27689585 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27706045 1.
  0.0035617  1.         1.        ]
 [1.         0.         1.         1.         0.27695744 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27690029 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27695024 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27698578 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27698911 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27708779 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27696813 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27700481 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.2769539  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27692835 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27691598 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27696599 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27699599 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27704417 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27697582 1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.8333333134651184
#####################         POISON         ###############################################

############################################################################################

comm_round: 13 | global_test_acc: 88.889% | global_f1: 0.9411764705882353 | global_precision: 0.8888888888888888
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.89      1.00      0.94         8

    accuracy                           0.89         9
   macro avg       0.44      0.50      0.47         9
weighted avg       0.79      0.89      0.84         9
poison scaling shape: (29, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 29 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clients
y shape (29,)
[0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (29,)
[0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_fg shape (29,)
[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0.]
wv_mn shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ed shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_lg shape (29, 1)
[[0.2709962 ]
 [0.27540091]
 [0.2714404 ]
 [0.29131493]
 [0.27746803]
 [0.27749934]
 [0.27755728]
 [0.27749721]
 [0.27748672]
 [0.27740762]
 [0.277428  ]
 [0.27742768]
 [0.27741261]
 [0.27750667]
 [0.27744086]
 [0.27751467]
 [0.27747585]
 [0.27751674]
 [0.27742156]
 [0.27742163]
 [0.27742228]
 [0.27745977]
 [0.27746727]
 [0.27753296]
 [0.27746567]
 [0.27749927]
 [0.2775797 ]
 [0.27741219]
 [0.2775382 ]]
wv_jc shape (29,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ndT shape (29,)
[1.         1.         1.         0.         1.         1.
 1.         0.98630709 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 0.91293948 1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.        ]
wv_std shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
xy shape: (29, 9)
[[0.         0.         0.         0.         0.2709962  1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.27540091 1.
  1.         1.         0.        ]
 [1.         0.         0.         0.         0.2714404  1.
  1.         0.         0.        ]
 [0.         1.         0.         0.         0.29131493 1.
  0.         0.         0.        ]
 [1.         0.         1.         1.         0.27746803 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.27749934 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.27755728 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.27749721 1.
  0.98630709 1.         1.        ]
 [1.         0.         1.         1.         0.27748672 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.27740762 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.277428   1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.27742768 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.27741261 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.27750667 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.27744086 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.27751467 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.27747585 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.27751674 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.27742156 1.
  0.91293948 1.         1.        ]
 [1.         0.         1.         1.         0.27742163 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.27742228 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.27745977 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.27746727 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.27753296 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.27746567 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.27749927 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.2775797  1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.27741219 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.2775382  1.
  1.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.8888888955116272
#####################         POISON         ###############################################

############################################################################################

comm_round: 14 | global_test_acc: 77.778% | global_f1: 0.8750000000000001 | global_precision: 0.7777777777777778
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.78      1.00      0.88         7

    accuracy                           0.78         9
   macro avg       0.39      0.50      0.44         9
weighted avg       0.60      0.78      0.68         9
poison scaling shape: (29, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 29 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clients
y shape (29,)
[0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (29,)
[0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_fg shape (29,)
[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0.]
wv_mn shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ed shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_lg shape (29, 1)
[[0.27146096]
 [0.27598852]
 [0.27147864]
 [0.29081738]
 [0.27812634]
 [0.278075  ]
 [0.27797326]
 [0.27807063]
 [0.27798828]
 [0.27796261]
 [0.27806036]
 [0.27799168]
 [0.27797188]
 [0.27802951]
 [0.2780274 ]
 [0.27799802]
 [0.27810219]
 [0.27804169]
 [0.27797998]
 [0.27802495]
 [0.27794377]
 [0.2779818 ]
 [0.27797008]
 [0.27803064]
 [0.27801922]
 [0.27795707]
 [0.2780064 ]
 [0.27795292]
 [0.27805002]]
wv_jc shape (29,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ndT shape (29,)
[1.         1.         0.14966355 0.         0.31770185 0.49331519
 0.30771414 0.46585999 0.76439784 0.29316921 0.46521637 0.54926319
 0.56271806 0.59863387 0.37993671 0.53409674 0.76940948 0.41469045
 0.61765464 0.57859739 0.20393049 0.44786619 0.25582856 0.6238074
 0.29048394 0.68811592 0.57864326 0.26729033 0.42848824]
wv_std shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
xy shape: (29, 9)
[[0.         0.         0.         0.         0.27146096 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.27598852 1.
  1.         1.         0.        ]
 [1.         0.         0.         0.         0.27147864 1.
  0.14966355 0.         0.        ]
 [0.         1.         0.         0.         0.29081738 1.
  0.         0.         0.        ]
 [1.         0.         1.         1.         0.27812634 1.
  0.31770185 1.         1.        ]
 [1.         0.         1.         1.         0.278075   1.
  0.49331519 1.         1.        ]
 [1.         0.         1.         1.         0.27797326 1.
  0.30771414 1.         1.        ]
 [1.         0.         1.         1.         0.27807063 1.
  0.46585999 1.         1.        ]
 [1.         0.         1.         1.         0.27798828 1.
  0.76439784 1.         1.        ]
 [1.         0.         1.         1.         0.27796261 1.
  0.29316921 1.         1.        ]
 [1.         0.         1.         1.         0.27806036 1.
  0.46521637 1.         1.        ]
 [1.         0.         1.         1.         0.27799168 1.
  0.54926319 1.         1.        ]
 [1.         0.         1.         1.         0.27797188 1.
  0.56271806 1.         1.        ]
 [1.         0.         1.         1.         0.27802951 1.
  0.59863387 1.         1.        ]
 [1.         0.         1.         1.         0.2780274  1.
  0.37993671 1.         1.        ]
 [1.         0.         1.         1.         0.27799802 1.
  0.53409674 1.         1.        ]
 [1.         0.         1.         1.         0.27810219 1.
  0.76940948 1.         1.        ]
 [1.         0.         1.         1.         0.27804169 1.
  0.41469045 1.         1.        ]
 [1.         0.         1.         1.         0.27797998 1.
  0.61765464 1.         1.        ]
 [1.         0.         1.         1.         0.27802495 1.
  0.57859739 1.         1.        ]
 [1.         0.         1.         1.         0.27794377 1.
  0.20393049 1.         1.        ]
 [1.         0.         1.         1.         0.2779818  1.
  0.44786619 1.         1.        ]
 [1.         0.         1.         1.         0.27797008 1.
  0.25582856 1.         1.        ]
 [1.         0.         1.         1.         0.27803064 1.
  0.6238074  1.         1.        ]
 [1.         0.         1.         1.         0.27801922 1.
  0.29048394 1.         1.        ]
 [1.         0.         1.         1.         0.27795707 1.
  0.68811592 1.         1.        ]
 [1.         0.         1.         1.         0.2780064  1.
  0.57864326 1.         1.        ]
 [1.         0.         1.         1.         0.27795292 1.
  0.26729033 1.         1.        ]
 [1.         0.         1.         1.         0.27805002 1.
  0.42848824 1.         1.        ]]

Best Training Poisoning Accuracy:
0.8333333134651184
#####################         POISON         ###############################################

############################################################################################

comm_round: 15 | global_test_acc: 88.889% | global_f1: 0.9411764705882353 | global_precision: 0.8888888888888888
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.89      1.00      0.94         8

    accuracy                           0.89         9
   macro avg       0.44      0.50      0.47         9
weighted avg       0.79      0.89      0.84         9
poison scaling shape: (29, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 29 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clients
y shape (29,)
[0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (29,)
[0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_fg shape (29,)
[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0.]
wv_mn shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ed shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_lg shape (29, 1)
[[0.27179887]
 [0.27632104]
 [0.27301289]
 [0.29153234]
 [0.27844046]
 [0.27851668]
 [0.27854665]
 [0.27848707]
 [0.27847888]
 [0.27855288]
 [0.27856202]
 [0.27854995]
 [0.27848189]
 [0.27848728]
 [0.27854486]
 [0.27851724]
 [0.2784799 ]
 [0.27851388]
 [0.27848776]
 [0.278551  ]
 [0.27855004]
 [0.27853024]
 [0.27843881]
 [0.2784909 ]
 [0.27852827]
 [0.27846854]
 [0.27856977]
 [0.27843379]
 [0.27850068]]
wv_jc shape (29,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ndT shape (29,)
[1.         0.         1.         0.         0.         0.
 0.         0.         0.04239278 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_std shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
xy shape: (29, 9)
[[0.         0.         0.         0.         0.27179887 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.27632104 1.
  0.         1.         0.        ]
 [1.         0.         0.         0.         0.27301289 1.
  1.         0.         0.        ]
 [0.         1.         0.         0.         0.29153234 1.
  0.         0.         0.        ]
 [1.         0.         1.         1.         0.27844046 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27851668 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27854665 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27848707 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27847888 1.
  0.04239278 1.         1.        ]
 [1.         0.         1.         1.         0.27855288 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27856202 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27854995 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27848189 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27848728 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27854486 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27851724 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.2784799  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27851388 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27848776 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.278551   1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27855004 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27853024 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27843881 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.2784909  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27852827 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27846854 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27856977 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27843379 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27850068 1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.8888888955116272
#####################         POISON         ###############################################

############################################################################################

comm_round: 16 | global_test_acc: 88.889% | global_f1: 0.9411764705882353 | global_precision: 0.8888888888888888
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.89      1.00      0.94         8

    accuracy                           0.89         9
   macro avg       0.44      0.50      0.47         9
weighted avg       0.79      0.89      0.84         9
poison scaling shape: (29, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 29 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clients
y shape (29,)
[0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (29,)
[0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_fg shape (29,)
[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0.]
wv_mn shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ed shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_lg shape (29, 1)
[[0.27307767]
 [0.27688102]
 [0.2724317 ]
 [0.29140944]
 [0.27895683]
 [0.27904032]
 [0.27905324]
 [0.2789723 ]
 [0.27898804]
 [0.27895981]
 [0.27890533]
 [0.27901809]
 [0.27892254]
 [0.27899886]
 [0.2791032 ]
 [0.27897411]
 [0.27897572]
 [0.27896465]
 [0.27900541]
 [0.27906975]
 [0.27902641]
 [0.27896308]
 [0.27893351]
 [0.27897126]
 [0.27904242]
 [0.27904432]
 [0.27905419]
 [0.27897763]
 [0.27896418]]
wv_jc shape (29,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ndT shape (29,)
[1.         1.         1.         0.         0.95316217 0.88330638
 0.80141431 0.95610121 0.94173717 0.74248188 0.83082911 0.90260297
 0.74730845 0.89926606 0.89594584 0.68402469 0.93516599 1.
 0.77762495 1.         0.821707   0.52520039 0.85019823 0.84922526
 1.         0.88638895 0.84360439 0.78245352 0.86852487]
wv_std shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
xy shape: (29, 9)
[[0.         0.         0.         0.         0.27307767 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.27688102 1.
  1.         1.         0.        ]
 [1.         0.         0.         0.         0.2724317  1.
  1.         0.         0.        ]
 [0.         1.         0.         0.         0.29140944 1.
  0.         0.         0.        ]
 [1.         0.         1.         1.         0.27895683 1.
  0.95316217 1.         1.        ]
 [1.         0.         1.         1.         0.27904032 1.
  0.88330638 1.         1.        ]
 [1.         0.         1.         1.         0.27905324 1.
  0.80141431 1.         1.        ]
 [1.         0.         1.         1.         0.2789723  1.
  0.95610121 1.         1.        ]
 [1.         0.         1.         1.         0.27898804 1.
  0.94173717 1.         1.        ]
 [1.         0.         1.         1.         0.27895981 1.
  0.74248188 1.         1.        ]
 [1.         0.         1.         1.         0.27890533 1.
  0.83082911 1.         1.        ]
 [1.         0.         1.         1.         0.27901809 1.
  0.90260297 1.         1.        ]
 [1.         0.         1.         1.         0.27892254 1.
  0.74730845 1.         1.        ]
 [1.         0.         1.         1.         0.27899886 1.
  0.89926606 1.         1.        ]
 [1.         0.         1.         1.         0.2791032  1.
  0.89594584 1.         1.        ]
 [1.         0.         1.         1.         0.27897411 1.
  0.68402469 1.         1.        ]
 [1.         0.         1.         1.         0.27897572 1.
  0.93516599 1.         1.        ]
 [1.         0.         1.         1.         0.27896465 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.27900541 1.
  0.77762495 1.         1.        ]
 [1.         0.         1.         1.         0.27906975 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.27902641 1.
  0.821707   1.         1.        ]
 [1.         0.         1.         1.         0.27896308 1.
  0.52520039 1.         1.        ]
 [1.         0.         1.         1.         0.27893351 1.
  0.85019823 1.         1.        ]
 [1.         0.         1.         1.         0.27897126 1.
  0.84922526 1.         1.        ]
 [1.         0.         1.         1.         0.27904242 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.27904432 1.
  0.88638895 1.         1.        ]
 [1.         0.         1.         1.         0.27905419 1.
  0.84360439 1.         1.        ]
 [1.         0.         1.         1.         0.27897763 1.
  0.78245352 1.         1.        ]
 [1.         0.         1.         1.         0.27896418 1.
  0.86852487 1.         1.        ]]

Best Training Poisoning Accuracy:
0.8888888955116272
#####################         POISON         ###############################################

############################################################################################

comm_round: 17 | global_test_acc: 77.778% | global_f1: 0.8750000000000001 | global_precision: 0.7777777777777778
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.78      1.00      0.88         7

    accuracy                           0.78         9
   macro avg       0.39      0.50      0.44         9
weighted avg       0.60      0.78      0.68         9
poison scaling shape: (29, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 29 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clients
y shape (29,)
[0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (29,)
[0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_fg shape (29,)
[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0.]
wv_mn shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ed shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_lg shape (29, 1)
[[0.27285477]
 [0.2774241 ]
 [0.27360984]
 [0.29195138]
 [0.27944145]
 [0.27952212]
 [0.27941915]
 [0.27954626]
 [0.27948016]
 [0.2794946 ]
 [0.27945564]
 [0.2794376 ]
 [0.27943918]
 [0.27951556]
 [0.27945337]
 [0.27952753]
 [0.27955997]
 [0.27949143]
 [0.27942463]
 [0.27947841]
 [0.27940741]
 [0.27947644]
 [0.27946713]
 [0.2794596 ]
 [0.2794436 ]
 [0.27949259]
 [0.27951104]
 [0.27948623]
 [0.2794808 ]]
wv_jc shape (29,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ndT shape (29,)
[1.         1.         1.         0.         0.96447301 0.8311252
 0.79166728 0.91839004 0.86911869 0.79252308 1.         0.90965611
 0.89196741 0.88464267 0.88714496 0.96924567 0.8214348  0.77073081
 0.73391448 0.84744329 0.99288733 0.99225933 0.79214133 0.88773051
 0.85660089 0.99625134 0.76064908 0.8109495  0.81854014]
wv_std shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
xy shape: (29, 9)
[[0.         0.         0.         0.         0.27285477 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.2774241  1.
  1.         1.         0.        ]
 [1.         0.         0.         0.         0.27360984 1.
  1.         0.         0.        ]
 [0.         1.         0.         0.         0.29195138 1.
  0.         0.         0.        ]
 [1.         0.         1.         1.         0.27944145 1.
  0.96447301 1.         1.        ]
 [1.         0.         1.         1.         0.27952212 1.
  0.8311252  1.         1.        ]
 [1.         0.         1.         1.         0.27941915 1.
  0.79166728 1.         1.        ]
 [1.         0.         1.         1.         0.27954626 1.
  0.91839004 1.         1.        ]
 [1.         0.         1.         1.         0.27948016 1.
  0.86911869 1.         1.        ]
 [1.         0.         1.         1.         0.2794946  1.
  0.79252308 1.         1.        ]
 [1.         0.         1.         1.         0.27945564 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.2794376  1.
  0.90965611 1.         1.        ]
 [1.         0.         1.         1.         0.27943918 1.
  0.89196741 1.         1.        ]
 [1.         0.         1.         1.         0.27951556 1.
  0.88464267 1.         1.        ]
 [1.         0.         1.         1.         0.27945337 1.
  0.88714496 1.         1.        ]
 [1.         0.         1.         1.         0.27952753 1.
  0.96924567 1.         1.        ]
 [1.         0.         1.         1.         0.27955997 1.
  0.8214348  1.         1.        ]
 [1.         0.         1.         1.         0.27949143 1.
  0.77073081 1.         1.        ]
 [1.         0.         1.         1.         0.27942463 1.
  0.73391448 1.         1.        ]
 [1.         0.         1.         1.         0.27947841 1.
  0.84744329 1.         1.        ]
 [1.         0.         1.         1.         0.27940741 1.
  0.99288733 1.         1.        ]
 [1.         0.         1.         1.         0.27947644 1.
  0.99225933 1.         1.        ]
 [1.         0.         1.         1.         0.27946713 1.
  0.79214133 1.         1.        ]
 [1.         0.         1.         1.         0.2794596  1.
  0.88773051 1.         1.        ]
 [1.         0.         1.         1.         0.2794436  1.
  0.85660089 1.         1.        ]
 [1.         0.         1.         1.         0.27949259 1.
  0.99625134 1.         1.        ]
 [1.         0.         1.         1.         0.27951104 1.
  0.76064908 1.         1.        ]
 [1.         0.         1.         1.         0.27948623 1.
  0.8109495  1.         1.        ]
 [1.         0.         1.         1.         0.2794808  1.
  0.81854014 1.         1.        ]]

Best Training Poisoning Accuracy:
0.9444444179534912
#####################         POISON         ###############################################

############################################################################################

comm_round: 18 | global_test_acc: 66.667% | global_f1: 0.8 | global_precision: 0.6666666666666666
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.67      1.00      0.80         6

    accuracy                           0.67         9
   macro avg       0.33      0.50      0.40         9
weighted avg       0.44      0.67      0.53         9
poison scaling shape: (29, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 29 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clients
y shape (29,)
[0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (29,)
[0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_fg shape (29,)
[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0.]
wv_mn shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ed shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_lg shape (29, 1)
[[0.27310673]
 [0.27763896]
 [0.27381872]
 [0.29274375]
 [0.27993441]
 [0.27994063]
 [0.27987828]
 [0.27990978]
 [0.27993843]
 [0.2798744 ]
 [0.27997167]
 [0.27991677]
 [0.27995531]
 [0.27991794]
 [0.27986301]
 [0.27991737]
 [0.27976642]
 [0.279943  ]
 [0.27991066]
 [0.27997462]
 [0.27986412]
 [0.27995738]
 [0.27989784]
 [0.27997699]
 [0.2799659 ]
 [0.28000201]
 [0.27998032]
 [0.27999778]
 [0.27986373]]
wv_jc shape (29,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ndT shape (29,)
[1.         1.         0.49834183 0.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.        ]
wv_std shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
xy shape: (29, 9)
[[0.         0.         0.         0.         0.27310673 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.27763896 1.
  1.         1.         0.        ]
 [1.         0.         0.         0.         0.27381872 1.
  0.49834183 0.         0.        ]
 [0.         1.         0.         0.         0.29274375 1.
  0.         0.         0.        ]
 [1.         0.         1.         1.         0.27993441 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.27994063 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.27987828 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.27990978 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.27993843 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.2798744  1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.27997167 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.27991677 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.27995531 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.27991794 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.27986301 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.27991737 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.27976642 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.279943   1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.27991066 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.27997462 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.27986412 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.27995738 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.27989784 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.27997699 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.2799659  1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.28000201 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.27998032 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.27999778 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.27986373 1.
  1.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.8333333134651184
#####################         POISON         ###############################################

############################################################################################

comm_round: 19 | global_test_acc: 88.889% | global_f1: 0.9411764705882353 | global_precision: 0.8888888888888888
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.89      1.00      0.94         8

    accuracy                           0.89         9
   macro avg       0.44      0.50      0.47         9
weighted avg       0.79      0.89      0.84         9
poison scaling shape: (29, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 29 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clients
y shape (29,)
[0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (29,)
[0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_fg shape (29,)
[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0.]
wv_mn shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ed shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_lg shape (29, 1)
[[0.27468605]
 [0.27834519]
 [0.27393329]
 [0.29256588]
 [0.28032734]
 [0.2804368 ]
 [0.28044023]
 [0.28039267]
 [0.2804962 ]
 [0.28045308]
 [0.28035366]
 [0.28040378]
 [0.28039792]
 [0.28038248]
 [0.28043441]
 [0.28038423]
 [0.28034975]
 [0.28037103]
 [0.28032382]
 [0.28031773]
 [0.28041712]
 [0.28038001]
 [0.28042249]
 [0.28039408]
 [0.28041209]
 [0.28036803]
 [0.28032488]
 [0.28035673]
 [0.28041085]]
wv_jc shape (29,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ndT shape (29,)
[1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_std shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
xy shape: (29, 9)
[[0.         0.         0.         0.         0.27468605 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.27834519 1.
  1.         1.         0.        ]
 [1.         0.         0.         0.         0.27393329 1.
  1.         0.         0.        ]
 [0.         1.         0.         0.         0.29256588 1.
  0.         0.         0.        ]
 [1.         0.         1.         1.         0.28032734 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.2804368  1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.28044023 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.28039267 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.2804962  1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.28045308 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.28035366 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.28040378 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.28039792 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.28038248 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.28043441 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.28038423 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.28034975 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.28037103 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.28032382 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.28031773 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.28041712 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.28038001 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.28042249 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.28039408 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.28041209 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.28036803 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.28032488 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.28035673 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.28041085 1.
  1.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.8888888955116272
#####################         POISON         ###############################################

############################################################################################

comm_round: 20 | global_test_acc: 77.778% | global_f1: 0.8750000000000001 | global_precision: 0.7777777777777778
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.78      1.00      0.88         7

    accuracy                           0.78         9
   macro avg       0.39      0.50      0.44         9
weighted avg       0.60      0.78      0.68         9
poison scaling shape: (29, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 29 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clients
y shape (29,)
[0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (29,)
[0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_fg shape (29,)
[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0.]
wv_mn shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ed shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_lg shape (29, 1)
[[0.27464934]
 [0.27867512]
 [0.27524164]
 [0.29317458]
 [0.28078401]
 [0.28083042]
 [0.28090075]
 [0.28082569]
 [0.28083432]
 [0.28084288]
 [0.28083254]
 [0.28092336]
 [0.28084112]
 [0.280872  ]
 [0.2808317 ]
 [0.28091221]
 [0.28076321]
 [0.28094717]
 [0.28088561]
 [0.2807677 ]
 [0.28089328]
 [0.28076645]
 [0.28083002]
 [0.28081403]
 [0.28076772]
 [0.28081959]
 [0.28088641]
 [0.28086408]
 [0.28080196]]
wv_jc shape (29,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ndT shape (29,)
[1.         0.38492208 1.         0.         0.06005201 0.
 0.03439911 0.02950077 0.04278148 0.03534145 0.11977317 0.
 0.13345458 0.14465977 0.         0.07118619 0.07854472 0.08211318
 0.         0.         0.02517602 0.         0.05752149 0.04317949
 0.03226427 0.         0.13847558 0.         0.07416199]
wv_std shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
xy shape: (29, 9)
[[0.         0.         0.         0.         0.27464934 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.27867512 1.
  0.38492208 1.         0.        ]
 [1.         0.         0.         0.         0.27524164 1.
  1.         0.         0.        ]
 [0.         1.         0.         0.         0.29317458 1.
  0.         0.         0.        ]
 [1.         0.         1.         1.         0.28078401 1.
  0.06005201 1.         1.        ]
 [1.         0.         1.         1.         0.28083042 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.28090075 1.
  0.03439911 1.         1.        ]
 [1.         0.         1.         1.         0.28082569 1.
  0.02950077 1.         1.        ]
 [1.         0.         1.         1.         0.28083432 1.
  0.04278148 1.         1.        ]
 [1.         0.         1.         1.         0.28084288 1.
  0.03534145 1.         1.        ]
 [1.         0.         1.         1.         0.28083254 1.
  0.11977317 1.         1.        ]
 [1.         0.         1.         1.         0.28092336 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.28084112 1.
  0.13345458 1.         1.        ]
 [1.         0.         1.         1.         0.280872   1.
  0.14465977 1.         1.        ]
 [1.         0.         1.         1.         0.2808317  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.28091221 1.
  0.07118619 1.         1.        ]
 [1.         0.         1.         1.         0.28076321 1.
  0.07854472 1.         1.        ]
 [1.         0.         1.         1.         0.28094717 1.
  0.08211318 1.         1.        ]
 [1.         0.         1.         1.         0.28088561 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.2807677  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.28089328 1.
  0.02517602 1.         1.        ]
 [1.         0.         1.         1.         0.28076645 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.28083002 1.
  0.05752149 1.         1.        ]
 [1.         0.         1.         1.         0.28081403 1.
  0.04317949 1.         1.        ]
 [1.         0.         1.         1.         0.28076772 1.
  0.03226427 1.         1.        ]
 [1.         0.         1.         1.         0.28081959 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.28088641 1.
  0.13847558 1.         1.        ]
 [1.         0.         1.         1.         0.28086408 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.28080196 1.
  0.07416199 1.         1.        ]]

Best Training Poisoning Accuracy:
0.9444444179534912
#####################         POISON         ###############################################

############################################################################################

comm_round: 21 | global_test_acc: 66.667% | global_f1: 0.8 | global_precision: 0.6666666666666666
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.67      1.00      0.80         6

    accuracy                           0.67         9
   macro avg       0.33      0.50      0.40         9
weighted avg       0.44      0.67      0.53         9
poison scaling shape: (29, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 29 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clients
y shape (29,)
[0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (29,)
[0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_fg shape (29,)
[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0.]
wv_mn shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ed shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_lg shape (29, 1)
[[0.27526387]
 [0.27918264]
 [0.27583211]
 [0.29285226]
 [0.28124189]
 [0.28130607]
 [0.28133779]
 [0.28127377]
 [0.28133781]
 [0.28136516]
 [0.28133843]
 [0.28130078]
 [0.28126181]
 [0.28121839]
 [0.28132179]
 [0.28136294]
 [0.28128365]
 [0.28133453]
 [0.28133502]
 [0.28122459]
 [0.28136225]
 [0.28119583]
 [0.28128855]
 [0.28124199]
 [0.28137881]
 [0.2812165 ]
 [0.28139039]
 [0.28134634]
 [0.28123657]]
wv_jc shape (29,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ndT shape (29,)
[1.         1.         1.         0.         0.95171177 0.88784015
 0.94043583 0.78261115 0.80442161 0.8845667  0.82476884 0.92349531
 0.83188267 0.74342849 0.84729061 0.80822567 0.83605894 0.85446967
 0.8206527  0.77687824 0.70707196 0.7337178  0.88200384 0.56124198
 0.75277081 0.78186499 0.92069331 1.         0.76711111]
wv_std shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
xy shape: (29, 9)
[[0.         0.         0.         0.         0.27526387 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.27918264 1.
  1.         1.         0.        ]
 [1.         0.         0.         0.         0.27583211 1.
  1.         0.         0.        ]
 [0.         1.         0.         0.         0.29285226 1.
  0.         0.         0.        ]
 [1.         0.         1.         1.         0.28124189 1.
  0.95171177 1.         1.        ]
 [1.         0.         1.         1.         0.28130607 1.
  0.88784015 1.         1.        ]
 [1.         0.         1.         1.         0.28133779 1.
  0.94043583 1.         1.        ]
 [1.         0.         1.         1.         0.28127377 1.
  0.78261115 1.         1.        ]
 [1.         0.         1.         1.         0.28133781 1.
  0.80442161 1.         1.        ]
 [1.         0.         1.         1.         0.28136516 1.
  0.8845667  1.         1.        ]
 [1.         0.         1.         1.         0.28133843 1.
  0.82476884 1.         1.        ]
 [1.         0.         1.         1.         0.28130078 1.
  0.92349531 1.         1.        ]
 [1.         0.         1.         1.         0.28126181 1.
  0.83188267 1.         1.        ]
 [1.         0.         1.         1.         0.28121839 1.
  0.74342849 1.         1.        ]
 [1.         0.         1.         1.         0.28132179 1.
  0.84729061 1.         1.        ]
 [1.         0.         1.         1.         0.28136294 1.
  0.80822567 1.         1.        ]
 [1.         0.         1.         1.         0.28128365 1.
  0.83605894 1.         1.        ]
 [1.         0.         1.         1.         0.28133453 1.
  0.85446967 1.         1.        ]
 [1.         0.         1.         1.         0.28133502 1.
  0.8206527  1.         1.        ]
 [1.         0.         1.         1.         0.28122459 1.
  0.77687824 1.         1.        ]
 [1.         0.         1.         1.         0.28136225 1.
  0.70707196 1.         1.        ]
 [1.         0.         1.         1.         0.28119583 1.
  0.7337178  1.         1.        ]
 [1.         0.         1.         1.         0.28128855 1.
  0.88200384 1.         1.        ]
 [1.         0.         1.         1.         0.28124199 1.
  0.56124198 1.         1.        ]
 [1.         0.         1.         1.         0.28137881 1.
  0.75277081 1.         1.        ]
 [1.         0.         1.         1.         0.2812165  1.
  0.78186499 1.         1.        ]
 [1.         0.         1.         1.         0.28139039 1.
  0.92069331 1.         1.        ]
 [1.         0.         1.         1.         0.28134634 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.28123657 1.
  0.76711111 1.         1.        ]]

Best Training Poisoning Accuracy:
0.9444444179534912
#####################         POISON         ###############################################

############################################################################################

comm_round: 22 | global_test_acc: 66.667% | global_f1: 0.8 | global_precision: 0.6666666666666666
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.67      1.00      0.80         6

    accuracy                           0.67         9
   macro avg       0.33      0.50      0.40         9
weighted avg       0.44      0.67      0.53         9
poison scaling shape: (29, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 29 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clients
y shape (29,)
[0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (29,)
[0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_fg shape (29,)
[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0.]
wv_mn shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ed shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_lg shape (29, 1)
[[0.27573179]
 [0.27950319]
 [0.27626825]
 [0.29365098]
 [0.28169471]
 [0.28167474]
 [0.28168743]
 [0.2817968 ]
 [0.2817431 ]
 [0.28169365]
 [0.28181011]
 [0.28176128]
 [0.28175161]
 [0.28166717]
 [0.28179434]
 [0.28174066]
 [0.28171145]
 [0.28177899]
 [0.28177849]
 [0.28174033]
 [0.28179928]
 [0.28173406]
 [0.28176086]
 [0.28175369]
 [0.28178679]
 [0.28179186]
 [0.28173631]
 [0.28178076]
 [0.28179828]]
wv_jc shape (29,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ndT shape (29,)
[1.         0.77842182 1.         0.         0.46324938 0.48235089
 0.48480799 0.56943759 0.58494486 0.51324508 0.42603796 0.52120104
 0.3987471  0.42405024 0.37416526 0.49287598 0.49102514 0.53051337
 0.44019084 0.46686621 0.48611871 0.51204506 0.45670366 0.45426252
 0.48553023 0.50492023 0.42091335 0.43755419 0.44418365]
wv_std shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
xy shape: (29, 9)
[[0.         0.         0.         0.         0.27573179 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.27950319 1.
  0.77842182 1.         0.        ]
 [1.         0.         0.         0.         0.27626825 1.
  1.         0.         0.        ]
 [0.         1.         0.         0.         0.29365098 1.
  0.         0.         0.        ]
 [1.         0.         1.         1.         0.28169471 1.
  0.46324938 1.         1.        ]
 [1.         0.         1.         1.         0.28167474 1.
  0.48235089 1.         1.        ]
 [1.         0.         1.         1.         0.28168743 1.
  0.48480799 1.         1.        ]
 [1.         0.         1.         1.         0.2817968  1.
  0.56943759 1.         1.        ]
 [1.         0.         1.         1.         0.2817431  1.
  0.58494486 1.         1.        ]
 [1.         0.         1.         1.         0.28169365 1.
  0.51324508 1.         1.        ]
 [1.         0.         1.         1.         0.28181011 1.
  0.42603796 1.         1.        ]
 [1.         0.         1.         1.         0.28176128 1.
  0.52120104 1.         1.        ]
 [1.         0.         1.         1.         0.28175161 1.
  0.3987471  1.         1.        ]
 [1.         0.         1.         1.         0.28166717 1.
  0.42405024 1.         1.        ]
 [1.         0.         1.         1.         0.28179434 1.
  0.37416526 1.         1.        ]
 [1.         0.         1.         1.         0.28174066 1.
  0.49287598 1.         1.        ]
 [1.         0.         1.         1.         0.28171145 1.
  0.49102514 1.         1.        ]
 [1.         0.         1.         1.         0.28177899 1.
  0.53051337 1.         1.        ]
 [1.         0.         1.         1.         0.28177849 1.
  0.44019084 1.         1.        ]
 [1.         0.         1.         1.         0.28174033 1.
  0.46686621 1.         1.        ]
 [1.         0.         1.         1.         0.28179928 1.
  0.48611871 1.         1.        ]
 [1.         0.         1.         1.         0.28173406 1.
  0.51204506 1.         1.        ]
 [1.         0.         1.         1.         0.28176086 1.
  0.45670366 1.         1.        ]
 [1.         0.         1.         1.         0.28175369 1.
  0.45426252 1.         1.        ]
 [1.         0.         1.         1.         0.28178679 1.
  0.48553023 1.         1.        ]
 [1.         0.         1.         1.         0.28179186 1.
  0.50492023 1.         1.        ]
 [1.         0.         1.         1.         0.28173631 1.
  0.42091335 1.         1.        ]
 [1.         0.         1.         1.         0.28178076 1.
  0.43755419 1.         1.        ]
 [1.         0.         1.         1.         0.28179828 1.
  0.44418365 1.         1.        ]]

Best Training Poisoning Accuracy:
0.8333333134651184
#####################         POISON         ###############################################

############################################################################################

comm_round: 23 | global_test_acc: 88.889% | global_f1: 0.9411764705882353 | global_precision: 0.8888888888888888
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.89      1.00      0.94         8

    accuracy                           0.89         9
   macro avg       0.44      0.50      0.47         9
weighted avg       0.79      0.89      0.84         9
poison scaling shape: (29, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 29 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clients
y shape (29,)
[0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (29,)
[0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_fg shape (29,)
[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0.]
wv_mn shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ed shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_lg shape (29, 1)
[[0.27549294]
 [0.28007468]
 [0.27662109]
 [0.29353872]
 [0.28227719]
 [0.28218144]
 [0.28220043]
 [0.28225567]
 [0.2821398 ]
 [0.28222732]
 [0.28222261]
 [0.28212154]
 [0.28219264]
 [0.28222465]
 [0.28229304]
 [0.28217726]
 [0.2821198 ]
 [0.28219698]
 [0.28222345]
 [0.28222495]
 [0.28224224]
 [0.28217236]
 [0.28221716]
 [0.28216276]
 [0.28213016]
 [0.28220179]
 [0.28213373]
 [0.28221894]
 [0.28223354]]
wv_jc shape (29,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ndT shape (29,)
[1.         1.         0.         0.         1.         0.98740578
 0.98753472 0.99259906 0.81099782 0.98073506 0.94070944 0.90554073
 0.84476167 1.         1.         0.96894543 0.88434731 1.
 1.         1.         1.         0.92646704 1.         0.79284464
 1.         1.         1.         1.         1.        ]
wv_std shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
xy shape: (29, 9)
[[0.         0.         0.         0.         0.27549294 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.28007468 1.
  1.         1.         0.        ]
 [1.         0.         0.         0.         0.27662109 1.
  0.         0.         0.        ]
 [0.         1.         0.         0.         0.29353872 1.
  0.         0.         0.        ]
 [1.         0.         1.         1.         0.28227719 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.28218144 1.
  0.98740578 1.         1.        ]
 [1.         0.         1.         1.         0.28220043 1.
  0.98753472 1.         1.        ]
 [1.         0.         1.         1.         0.28225567 1.
  0.99259906 1.         1.        ]
 [1.         0.         1.         1.         0.2821398  1.
  0.81099782 1.         1.        ]
 [1.         0.         1.         1.         0.28222732 1.
  0.98073506 1.         1.        ]
 [1.         0.         1.         1.         0.28222261 1.
  0.94070944 1.         1.        ]
 [1.         0.         1.         1.         0.28212154 1.
  0.90554073 1.         1.        ]
 [1.         0.         1.         1.         0.28219264 1.
  0.84476167 1.         1.        ]
 [1.         0.         1.         1.         0.28222465 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.28229304 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.28217726 1.
  0.96894543 1.         1.        ]
 [1.         0.         1.         1.         0.2821198  1.
  0.88434731 1.         1.        ]
 [1.         0.         1.         1.         0.28219698 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.28222345 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.28222495 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.28224224 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.28217236 1.
  0.92646704 1.         1.        ]
 [1.         0.         1.         1.         0.28221716 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.28216276 1.
  0.79284464 1.         1.        ]
 [1.         0.         1.         1.         0.28213016 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.28220179 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.28213373 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.28221894 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.28223354 1.
  1.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.8333333134651184
#####################         POISON         ###############################################

############################################################################################

comm_round: 24 | global_test_acc: 88.889% | global_f1: 0.9411764705882353 | global_precision: 0.8888888888888888
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.89      1.00      0.94         8

    accuracy                           0.89         9
   macro avg       0.44      0.50      0.47         9
weighted avg       0.79      0.89      0.84         9
poison scaling shape: (29, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 29 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clients
y shape (29,)
[0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (29,)
[0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_fg shape (29,)
[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0.]
wv_mn shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ed shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_lg shape (29, 1)
[[0.2771271 ]
 [0.28084829]
 [0.27724772]
 [0.29299623]
 [0.28256696]
 [0.28261636]
 [0.28253881]
 [0.2825717 ]
 [0.28258971]
 [0.28256391]
 [0.28254033]
 [0.282643  ]
 [0.28265546]
 [0.28265452]
 [0.28259366]
 [0.28271396]
 [0.28251933]
 [0.28255797]
 [0.2825398 ]
 [0.28258887]
 [0.28258605]
 [0.28251469]
 [0.28258487]
 [0.28264583]
 [0.28246443]
 [0.28254548]
 [0.28260139]
 [0.28265027]
 [0.28259242]]
wv_jc shape (29,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ndT shape (29,)
[1.         0.95202343 1.         0.         0.58842083 0.45689687
 0.51121914 0.49171685 0.57545594 0.42383765 0.68817043 0.66902847
 0.59798386 0.52062804 0.55559149 0.68953149 0.56351875 0.67152828
 0.52886418 0.63835434 0.70526385 0.53429021 0.6289483  0.57974331
 0.5626542  0.61624009 0.59963806 0.63212783 0.58747917]
wv_std shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
xy shape: (29, 9)
[[0.         0.         0.         0.         0.2771271  1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.28084829 1.
  0.95202343 1.         0.        ]
 [1.         0.         0.         0.         0.27724772 1.
  1.         0.         0.        ]
 [0.         1.         0.         0.         0.29299623 1.
  0.         0.         0.        ]
 [1.         0.         1.         1.         0.28256696 1.
  0.58842083 1.         1.        ]
 [1.         0.         1.         1.         0.28261636 1.
  0.45689687 1.         1.        ]
 [1.         0.         1.         1.         0.28253881 1.
  0.51121914 1.         1.        ]
 [1.         0.         1.         1.         0.2825717  1.
  0.49171685 1.         1.        ]
 [1.         0.         1.         1.         0.28258971 1.
  0.57545594 1.         1.        ]
 [1.         0.         1.         1.         0.28256391 1.
  0.42383765 1.         1.        ]
 [1.         0.         1.         1.         0.28254033 1.
  0.68817043 1.         1.        ]
 [1.         0.         1.         1.         0.282643   1.
  0.66902847 1.         1.        ]
 [1.         0.         1.         1.         0.28265546 1.
  0.59798386 1.         1.        ]
 [1.         0.         1.         1.         0.28265452 1.
  0.52062804 1.         1.        ]
 [1.         0.         1.         1.         0.28259366 1.
  0.55559149 1.         1.        ]
 [1.         0.         1.         1.         0.28271396 1.
  0.68953149 1.         1.        ]
 [1.         0.         1.         1.         0.28251933 1.
  0.56351875 1.         1.        ]
 [1.         0.         1.         1.         0.28255797 1.
  0.67152828 1.         1.        ]
 [1.         0.         1.         1.         0.2825398  1.
  0.52886418 1.         1.        ]
 [1.         0.         1.         1.         0.28258887 1.
  0.63835434 1.         1.        ]
 [1.         0.         1.         1.         0.28258605 1.
  0.70526385 1.         1.        ]
 [1.         0.         1.         1.         0.28251469 1.
  0.53429021 1.         1.        ]
 [1.         0.         1.         1.         0.28258487 1.
  0.6289483  1.         1.        ]
 [1.         0.         1.         1.         0.28264583 1.
  0.57974331 1.         1.        ]
 [1.         0.         1.         1.         0.28246443 1.
  0.5626542  1.         1.        ]
 [1.         0.         1.         1.         0.28254548 1.
  0.61624009 1.         1.        ]
 [1.         0.         1.         1.         0.28260139 1.
  0.59963806 1.         1.        ]
 [1.         0.         1.         1.         0.28265027 1.
  0.63212783 1.         1.        ]
 [1.         0.         1.         1.         0.28259242 1.
  0.58747917 1.         1.        ]]

Best Training Poisoning Accuracy:
0.8333333134651184
#####################         POISON         ###############################################

############################################################################################

comm_round: 25 | global_test_acc: 88.889% | global_f1: 0.9411764705882353 | global_precision: 0.8888888888888888
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.89      1.00      0.94         8

    accuracy                           0.89         9
   macro avg       0.44      0.50      0.47         9
weighted avg       0.79      0.89      0.84         9
poison scaling shape: (29, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 29 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clients
y shape (29,)
[0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (29,)
[0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_fg shape (29,)
[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0.]
wv_mn shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ed shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_lg shape (29, 1)
[[0.27738334]
 [0.28103205]
 [0.2781219 ]
 [0.29502595]
 [0.28298057]
 [0.2830067 ]
 [0.28286285]
 [0.28304343]
 [0.28293345]
 [0.28296164]
 [0.28310172]
 [0.28299432]
 [0.28303616]
 [0.28301651]
 [0.28296659]
 [0.28299988]
 [0.28294154]
 [0.28294412]
 [0.28299653]
 [0.28300845]
 [0.28296879]
 [0.28301734]
 [0.2829181 ]
 [0.28303877]
 [0.28299438]
 [0.2830243 ]
 [0.28292958]
 [0.28302399]
 [0.28295263]]
wv_jc shape (29,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ndT shape (29,)
[1.         0.89049851 1.         0.         0.39944696 0.34751538
 0.36942931 0.39340839 0.41843266 0.42644113 0.35744463 0.26785477
 0.39821049 0.43054384 0.25317534 0.42451661 0.42213802 0.39015464
 0.34128942 0.50241166 0.32928632 0.40456888 0.39681962 0.4765034
 0.29286819 0.40891121 0.39304267 0.48742412 0.34296706]
wv_std shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
xy shape: (29, 9)
[[0.         0.         0.         0.         0.27738334 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.28103205 1.
  0.89049851 1.         0.        ]
 [1.         0.         0.         0.         0.2781219  1.
  1.         0.         0.        ]
 [0.         1.         0.         0.         0.29502595 1.
  0.         0.         0.        ]
 [1.         0.         1.         1.         0.28298057 1.
  0.39944696 1.         1.        ]
 [1.         0.         1.         1.         0.2830067  1.
  0.34751538 1.         1.        ]
 [1.         0.         1.         1.         0.28286285 1.
  0.36942931 1.         1.        ]
 [1.         0.         1.         1.         0.28304343 1.
  0.39340839 1.         1.        ]
 [1.         0.         1.         1.         0.28293345 1.
  0.41843266 1.         1.        ]
 [1.         0.         1.         1.         0.28296164 1.
  0.42644113 1.         1.        ]
 [1.         0.         1.         1.         0.28310172 1.
  0.35744463 1.         1.        ]
 [1.         0.         1.         1.         0.28299432 1.
  0.26785477 1.         1.        ]
 [1.         0.         1.         1.         0.28303616 1.
  0.39821049 1.         1.        ]
 [1.         0.         1.         1.         0.28301651 1.
  0.43054384 1.         1.        ]
 [1.         0.         1.         1.         0.28296659 1.
  0.25317534 1.         1.        ]
 [1.         0.         1.         1.         0.28299988 1.
  0.42451661 1.         1.        ]
 [1.         0.         1.         1.         0.28294154 1.
  0.42213802 1.         1.        ]
 [1.         0.         1.         1.         0.28294412 1.
  0.39015464 1.         1.        ]
 [1.         0.         1.         1.         0.28299653 1.
  0.34128942 1.         1.        ]
 [1.         0.         1.         1.         0.28300845 1.
  0.50241166 1.         1.        ]
 [1.         0.         1.         1.         0.28296879 1.
  0.32928632 1.         1.        ]
 [1.         0.         1.         1.         0.28301734 1.
  0.40456888 1.         1.        ]
 [1.         0.         1.         1.         0.2829181  1.
  0.39681962 1.         1.        ]
 [1.         0.         1.         1.         0.28303877 1.
  0.4765034  1.         1.        ]
 [1.         0.         1.         1.         0.28299438 1.
  0.29286819 1.         1.        ]
 [1.         0.         1.         1.         0.2830243  1.
  0.40891121 1.         1.        ]
 [1.         0.         1.         1.         0.28292958 1.
  0.39304267 1.         1.        ]
 [1.         0.         1.         1.         0.28302399 1.
  0.48742412 1.         1.        ]
 [1.         0.         1.         1.         0.28295263 1.
  0.34296706 1.         1.        ]]

Best Training Poisoning Accuracy:
0.8333333134651184
#####################         POISON         ###############################################

############################################################################################

comm_round: 26 | global_test_acc: 88.889% | global_f1: 0.9411764705882353 | global_precision: 0.8888888888888888
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.89      1.00      0.94         8

    accuracy                           0.89         9
   macro avg       0.44      0.50      0.47         9
weighted avg       0.79      0.89      0.84         9
poison scaling shape: (29, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 29 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clients
y shape (29,)
[0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (29,)
[0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_fg shape (29,)
[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0.]
wv_mn shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ed shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_lg shape (29, 1)
[[0.27785585]
 [0.28150442]
 [0.27823308]
 [0.29445184]
 [0.28347592]
 [0.28343989]
 [0.2834377 ]
 [0.28347636]
 [0.28355731]
 [0.2834746 ]
 [0.28343664]
 [0.28352204]
 [0.28338558]
 [0.28351784]
 [0.28349657]
 [0.28340107]
 [0.28355855]
 [0.28352407]
 [0.28346523]
 [0.28350517]
 [0.28357019]
 [0.28357294]
 [0.28348459]
 [0.28341925]
 [0.28342994]
 [0.28354084]
 [0.28347419]
 [0.28341704]
 [0.28344067]]
wv_jc shape (29,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ndT shape (29,)
[1.         1.         1.         0.         1.         1.
 0.86357733 0.98130526 1.         0.95633905 1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.        ]
wv_std shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
xy shape: (29, 9)
[[0.         0.         0.         0.         0.27785585 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.28150442 1.
  1.         1.         0.        ]
 [1.         0.         0.         0.         0.27823308 1.
  1.         0.         0.        ]
 [0.         1.         0.         0.         0.29445184 1.
  0.         0.         0.        ]
 [1.         0.         1.         1.         0.28347592 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.28343989 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.2834377  1.
  0.86357733 1.         1.        ]
 [1.         0.         1.         1.         0.28347636 1.
  0.98130526 1.         1.        ]
 [1.         0.         1.         1.         0.28355731 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.2834746  1.
  0.95633905 1.         1.        ]
 [1.         0.         1.         1.         0.28343664 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.28352204 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.28338558 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.28351784 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.28349657 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.28340107 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.28355855 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.28352407 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.28346523 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.28350517 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.28357019 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.28357294 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.28348459 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.28341925 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.28342994 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.28354084 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.28347419 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.28341704 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.28344067 1.
  1.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.8888888955116272
#####################         POISON         ###############################################

############################################################################################

comm_round: 27 | global_test_acc: 77.778% | global_f1: 0.8750000000000001 | global_precision: 0.7777777777777778
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.78      1.00      0.88         7

    accuracy                           0.78         9
   macro avg       0.39      0.50      0.44         9
weighted avg       0.60      0.78      0.68         9
poison scaling shape: (29, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 29 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clients
y shape (29,)
[0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (29,)
[0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_fg shape (29,)
[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0.]
wv_mn shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ed shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_lg shape (29, 1)
[[0.27827833]
 [0.28175381]
 [0.27873841]
 [0.29465859]
 [0.28390648]
 [0.283892  ]
 [0.28384434]
 [0.28400455]
 [0.28404436]
 [0.28398346]
 [0.28385198]
 [0.28390988]
 [0.28391234]
 [0.2838572 ]
 [0.28392272]
 [0.28383445]
 [0.2839086 ]
 [0.2839053 ]
 [0.28389425]
 [0.28391392]
 [0.28387536]
 [0.28384726]
 [0.28393343]
 [0.28392306]
 [0.28386706]
 [0.28389267]
 [0.28380852]
 [0.28387136]
 [0.28384845]]
wv_jc shape (29,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ndT shape (29,)
[1.         1.         1.         0.         0.6469975  0.67150583
 0.7067732  0.61815736 0.69079438 0.76921361 0.68653593 0.6620358
 0.73013429 0.6462644  0.6959547  0.66780141 0.68426934 0.60289899
 0.70637423 0.60599253 0.59529971 0.63533935 0.72417586 0.6682697
 0.75818209 0.69788326 0.57157862 0.67995812 0.61325774]
wv_std shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
xy shape: (29, 9)
[[0.         0.         0.         0.         0.27827833 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.28175381 1.
  1.         1.         0.        ]
 [1.         0.         0.         0.         0.27873841 1.
  1.         0.         0.        ]
 [0.         1.         0.         0.         0.29465859 1.
  0.         0.         0.        ]
 [1.         0.         1.         1.         0.28390648 1.
  0.6469975  1.         1.        ]
 [1.         0.         1.         1.         0.283892   1.
  0.67150583 1.         1.        ]
 [1.         0.         1.         1.         0.28384434 1.
  0.7067732  1.         1.        ]
 [1.         0.         1.         1.         0.28400455 1.
  0.61815736 1.         1.        ]
 [1.         0.         1.         1.         0.28404436 1.
  0.69079438 1.         1.        ]
 [1.         0.         1.         1.         0.28398346 1.
  0.76921361 1.         1.        ]
 [1.         0.         1.         1.         0.28385198 1.
  0.68653593 1.         1.        ]
 [1.         0.         1.         1.         0.28390988 1.
  0.6620358  1.         1.        ]
 [1.         0.         1.         1.         0.28391234 1.
  0.73013429 1.         1.        ]
 [1.         0.         1.         1.         0.2838572  1.
  0.6462644  1.         1.        ]
 [1.         0.         1.         1.         0.28392272 1.
  0.6959547  1.         1.        ]
 [1.         0.         1.         1.         0.28383445 1.
  0.66780141 1.         1.        ]
 [1.         0.         1.         1.         0.2839086  1.
  0.68426934 1.         1.        ]
 [1.         0.         1.         1.         0.2839053  1.
  0.60289899 1.         1.        ]
 [1.         0.         1.         1.         0.28389425 1.
  0.70637423 1.         1.        ]
 [1.         0.         1.         1.         0.28391392 1.
  0.60599253 1.         1.        ]
 [1.         0.         1.         1.         0.28387536 1.
  0.59529971 1.         1.        ]
 [1.         0.         1.         1.         0.28384726 1.
  0.63533935 1.         1.        ]
 [1.         0.         1.         1.         0.28393343 1.
  0.72417586 1.         1.        ]
 [1.         0.         1.         1.         0.28392306 1.
  0.6682697  1.         1.        ]
 [1.         0.         1.         1.         0.28386706 1.
  0.75818209 1.         1.        ]
 [1.         0.         1.         1.         0.28389267 1.
  0.69788326 1.         1.        ]
 [1.         0.         1.         1.         0.28380852 1.
  0.57157862 1.         1.        ]
 [1.         0.         1.         1.         0.28387136 1.
  0.67995812 1.         1.        ]
 [1.         0.         1.         1.         0.28384845 1.
  0.61325774 1.         1.        ]]

Best Training Poisoning Accuracy:
0.8333333134651184
#####################         POISON         ###############################################

############################################################################################

comm_round: 28 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         9

    accuracy                           1.00         9
   macro avg       1.00      1.00      1.00         9
weighted avg       1.00      1.00      1.00         9
poison scaling shape: (29, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 29 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clients
y shape (29,)
[0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (29,)
[0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_fg shape (29,)
[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0.]
wv_mn shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ed shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_lg shape (29, 1)
[[0.27891206]
 [0.28218962]
 [0.27962015]
 [0.29457669]
 [0.28427767]
 [0.28438792]
 [0.28436803]
 [0.28435326]
 [0.28431407]
 [0.28433115]
 [0.28434146]
 [0.28431207]
 [0.28437805]
 [0.28430027]
 [0.28423575]
 [0.2842717 ]
 [0.28431565]
 [0.28430193]
 [0.28435247]
 [0.28421837]
 [0.28436123]
 [0.28435145]
 [0.28427155]
 [0.28427975]
 [0.28434487]
 [0.28430098]
 [0.28418822]
 [0.28422521]
 [0.28431693]]
wv_jc shape (29,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ndT shape (29,)
[1.         1.         1.         0.         0.81337279 0.96098544
 0.96365677 0.9308109  0.96177674 0.86436269 0.80669038 0.81638335
 0.95707137 0.90593087 0.77650701 0.8810552  0.83769035 0.73442106
 0.80572267 0.78951758 0.85206318 0.77468295 0.90116051 0.85659727
 0.82532259 0.85310813 0.81660577 0.85381916 0.93380516]
wv_std shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
xy shape: (29, 9)
[[0.         0.         0.         0.         0.27891206 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.28218962 1.
  1.         1.         0.        ]
 [1.         0.         0.         0.         0.27962015 1.
  1.         0.         0.        ]
 [0.         1.         0.         0.         0.29457669 1.
  0.         0.         0.        ]
 [1.         0.         1.         1.         0.28427767 1.
  0.81337279 1.         1.        ]
 [1.         0.         1.         1.         0.28438792 1.
  0.96098544 1.         1.        ]
 [1.         0.         1.         1.         0.28436803 1.
  0.96365677 1.         1.        ]
 [1.         0.         1.         1.         0.28435326 1.
  0.9308109  1.         1.        ]
 [1.         0.         1.         1.         0.28431407 1.
  0.96177674 1.         1.        ]
 [1.         0.         1.         1.         0.28433115 1.
  0.86436269 1.         1.        ]
 [1.         0.         1.         1.         0.28434146 1.
  0.80669038 1.         1.        ]
 [1.         0.         1.         1.         0.28431207 1.
  0.81638335 1.         1.        ]
 [1.         0.         1.         1.         0.28437805 1.
  0.95707137 1.         1.        ]
 [1.         0.         1.         1.         0.28430027 1.
  0.90593087 1.         1.        ]
 [1.         0.         1.         1.         0.28423575 1.
  0.77650701 1.         1.        ]
 [1.         0.         1.         1.         0.2842717  1.
  0.8810552  1.         1.        ]
 [1.         0.         1.         1.         0.28431565 1.
  0.83769035 1.         1.        ]
 [1.         0.         1.         1.         0.28430193 1.
  0.73442106 1.         1.        ]
 [1.         0.         1.         1.         0.28435247 1.
  0.80572267 1.         1.        ]
 [1.         0.         1.         1.         0.28421837 1.
  0.78951758 1.         1.        ]
 [1.         0.         1.         1.         0.28436123 1.
  0.85206318 1.         1.        ]
 [1.         0.         1.         1.         0.28435145 1.
  0.77468295 1.         1.        ]
 [1.         0.         1.         1.         0.28427155 1.
  0.90116051 1.         1.        ]
 [1.         0.         1.         1.         0.28427975 1.
  0.85659727 1.         1.        ]
 [1.         0.         1.         1.         0.28434487 1.
  0.82532259 1.         1.        ]
 [1.         0.         1.         1.         0.28430098 1.
  0.85310813 1.         1.        ]
 [1.         0.         1.         1.         0.28418822 1.
  0.81660577 1.         1.        ]
 [1.         0.         1.         1.         0.28422521 1.
  0.85381916 1.         1.        ]
 [1.         0.         1.         1.         0.28431693 1.
  0.93380516 1.         1.        ]]

Best Training Poisoning Accuracy:
0.8333333134651184
#####################         POISON         ###############################################

############################################################################################

comm_round: 29 | global_test_acc: 88.889% | global_f1: 0.9411764705882353 | global_precision: 0.8888888888888888
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.89      1.00      0.94         8

    accuracy                           0.89         9
   macro avg       0.44      0.50      0.47         9
weighted avg       0.79      0.89      0.84         9
poison scaling shape: (29, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 29 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clients