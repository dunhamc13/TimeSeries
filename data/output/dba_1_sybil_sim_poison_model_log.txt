
y shape (29,)
[0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (29,)
[1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_fg shape (29,)
[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0.]
wv_mn shape (29,)
[0.99904671 1.         0.         0.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.        ]
wv_ed shape (29,)
[0.20889111 1.         0.         0.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.        ]
wv_lg shape (29, 1)
[[0.34371684]
 [0.3476461 ]
 [0.33136962]
 [0.37284394]
 [0.36259501]
 [0.36317036]
 [0.36356805]
 [0.36294969]
 [0.36332542]
 [0.36310649]
 [0.36323774]
 [0.36314404]
 [0.36378273]
 [0.36361788]
 [0.3631842 ]
 [0.36359168]
 [0.36407716]
 [0.36322457]
 [0.36385612]
 [0.36291546]
 [0.36337538]
 [0.36401815]
 [0.3640765 ]
 [0.36417496]
 [0.36407937]
 [0.36436043]
 [0.36306453]
 [0.36333901]
 [0.36370914]]
wv_jc shape (29,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ndT shape (29,)
[0.         1.         0.         0.71302659 1.         1.
 1.         0.94518964 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.        ]
wv_std shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
xy shape: (29, 9)
[[1.         0.         0.99904671 0.20889111 0.34371684 1.
  0.         0.         0.        ]
 [1.         0.         1.         1.         0.3476461  1.
  1.         1.         0.        ]
 [0.         1.         0.         0.         0.33136962 1.
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.37284394 1.
  0.71302659 0.         0.        ]
 [1.         0.         1.         1.         0.36259501 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36317036 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36356805 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36294969 1.
  0.94518964 1.         1.        ]
 [1.         0.         1.         1.         0.36332542 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36310649 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36323774 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36314404 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36378273 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36361788 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.3631842  1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36359168 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36407716 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36322457 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36385612 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36291546 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36337538 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36401815 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.3640765  1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36417496 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36407937 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36436043 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36306453 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36333901 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36370914 1.
  1.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.7857142686843872
#####################         POISON         ###############################################

############################################################################################

comm_round: 0 | global_test_acc: 88.889% | global_f1: 0.9411764705882353 | global_precision: 0.8888888888888888
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.89      1.00      0.94         8

    accuracy                           0.89         9
   macro avg       0.44      0.50      0.47         9
weighted avg       0.79      0.89      0.84         9

Accuracy per class:
[[8 0]
 [1 0]]
[1. 0.]
poison scaling shape: (29, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 29 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clients
y shape (29,)
[0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (29,)
[1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_fg shape (29,)
[1.         0.03467772 1.         1.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_mn shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ed shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_lg shape (29, 1)
[[0.34543806]
 [0.35494582]
 [0.34289083]
 [0.37148219]
 [0.36308393]
 [0.36279159]
 [0.36266581]
 [0.36323812]
 [0.36290594]
 [0.36261339]
 [0.36329268]
 [0.36296762]
 [0.36245155]
 [0.36271771]
 [0.36299062]
 [0.36340162]
 [0.36203423]
 [0.36162433]
 [0.3628702 ]
 [0.36294629]
 [0.3624149 ]
 [0.36241055]
 [0.36366665]
 [0.36319006]
 [0.36293486]
 [0.36379567]
 [0.36329538]
 [0.36233378]
 [0.36247679]]
wv_jc shape (29,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ndT shape (29,)
[0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_std shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
xy shape: (29, 9)
[[1.         1.         0.         0.         0.34543806 1.
  0.         0.         0.        ]
 [1.         0.03467772 1.         1.         0.35494582 1.
  1.         1.         0.        ]
 [0.         1.         0.         0.         0.34289083 1.
  0.         0.         0.        ]
 [0.         1.         0.         0.         0.37148219 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.36308393 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36279159 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36266581 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36323812 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36290594 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36261339 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36329268 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36296762 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36245155 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36271771 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36299062 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36340162 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36203423 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36162433 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.3628702  1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36294629 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.3624149  1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36241055 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36366665 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36319006 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36293486 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36379567 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36329538 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36233378 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36247679 1.
  1.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.8571428656578064
#####################         POISON         ###############################################

############################################################################################

comm_round: 1 | global_test_acc: 77.778% | global_f1: 0.8750000000000001 | global_precision: 0.7777777777777778
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.78      1.00      0.88         7

    accuracy                           0.78         9
   macro avg       0.39      0.50      0.44         9
weighted avg       0.60      0.78      0.68         9

Accuracy per class:
[[7 0]
 [2 0]]
[1. 0.]
poison scaling shape: (29, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 29 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clients
y shape (29,)
[0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (29,)
[1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_fg shape (29,)
[1.         0.58101472 1.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_mn shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ed shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_lg shape (29, 1)
[[0.34927721]
 [0.35383911]
 [0.34320425]
 [0.36918527]
 [0.36297478]
 [0.36333318]
 [0.36186589]
 [0.36238182]
 [0.36331958]
 [0.36280582]
 [0.36313787]
 [0.36228444]
 [0.36332114]
 [0.3634993 ]
 [0.36330338]
 [0.36303289]
 [0.36255584]
 [0.36280296]
 [0.36248373]
 [0.36239711]
 [0.36306341]
 [0.36196927]
 [0.36315546]
 [0.36238279]
 [0.36240081]
 [0.3629441 ]
 [0.36223827]
 [0.36284967]
 [0.36228468]]
wv_jc shape (29,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ndT shape (29,)
[0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_std shape (29,)
[0.         0.85642468 0.         0.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.        ]
xy shape: (29, 9)
[[1.         1.         0.         0.         0.34927721 1.
  0.         0.         0.        ]
 [1.         0.58101472 1.         1.         0.35383911 1.
  1.         0.85642468 0.        ]
 [0.         1.         0.         0.         0.34320425 1.
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.36918527 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.36297478 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36333318 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36186589 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36238182 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36331958 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36280582 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36313787 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36228444 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36332114 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.3634993  1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36330338 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36303289 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36255584 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36280296 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36248373 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36239711 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36306341 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36196927 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36315546 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36238279 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36240081 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.3629441  1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36223827 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36284967 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36228468 1.
  1.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.8571428656578064
#####################         POISON         ###############################################

############################################################################################

comm_round: 2 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         9

    accuracy                           1.00         9
   macro avg       1.00      1.00      1.00         9
weighted avg       1.00      1.00      1.00         9

Accuracy per class:
[[9 0]
 [0 0]]
[ 1. nan]
poison scaling shape: (29, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 29 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clients
y shape (29,)
[0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (29,)
[1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_fg shape (29,)
[1.         0.50119704 1.         1.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_mn shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ed shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_lg shape (29, 1)
[[0.35062341]
 [0.35411624]
 [0.35289709]
 [0.36797882]
 [0.36288741]
 [0.36334542]
 [0.36241324]
 [0.36322189]
 [0.36258468]
 [0.36238571]
 [0.36279326]
 [0.36370222]
 [0.36250474]
 [0.3622672 ]
 [0.36347388]
 [0.364054  ]
 [0.36329306]
 [0.36315267]
 [0.36377964]
 [0.36331208]
 [0.36285496]
 [0.36214   ]
 [0.36225089]
 [0.36263657]
 [0.36308759]
 [0.36295519]
 [0.36294741]
 [0.36273583]
 [0.36268179]]
wv_jc shape (29,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ndT shape (29,)
[0.         1.         0.         0.         1.         1.
 1.         1.         1.         0.88195598 1.         1.
 1.         1.         1.         1.         0.56842124 1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.        ]
wv_std shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
xy shape: (29, 9)
[[1.         1.         0.         0.         0.35062341 1.
  0.         0.         0.        ]
 [1.         0.50119704 1.         1.         0.35411624 1.
  1.         0.         0.        ]
 [0.         1.         0.         0.         0.35289709 1.
  0.         0.         0.        ]
 [0.         1.         0.         0.         0.36797882 1.
  0.         0.         0.        ]
 [1.         0.         1.         1.         0.36288741 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36334542 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36241324 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36322189 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36258468 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36238571 1.
  0.88195598 1.         1.        ]
 [1.         0.         1.         1.         0.36279326 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36370222 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36250474 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.3622672  1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36347388 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.364054   1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36329306 1.
  0.56842124 1.         1.        ]
 [1.         0.         1.         1.         0.36315267 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36377964 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36331208 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36285496 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36214    1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36225089 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36263657 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36308759 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36295519 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36294741 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36273583 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36268179 1.
  1.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.8571428656578064
#####################         POISON         ###############################################

############################################################################################

comm_round: 3 | global_test_acc: 88.889% | global_f1: 0.9411764705882353 | global_precision: 0.8888888888888888
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.89      1.00      0.94         8

    accuracy                           0.89         9
   macro avg       0.44      0.50      0.47         9
weighted avg       0.79      0.89      0.84         9

Accuracy per class:
[[8 0]
 [1 0]]
[1. 0.]
poison scaling shape: (29, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 29 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clients
y shape (29,)
[0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (29,)
[1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_fg shape (29,)
[1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0.]
wv_mn shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ed shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_lg shape (29, 1)
[[0.35165379]
 [0.35366235]
 [0.35103045]
 [0.37186009]
 [0.36354582]
 [0.36320905]
 [0.36324647]
 [0.36374566]
 [0.36327137]
 [0.36330673]
 [0.36300862]
 [0.36339992]
 [0.36344795]
 [0.36359895]
 [0.36323098]
 [0.36348749]
 [0.36288979]
 [0.36366456]
 [0.36297968]
 [0.36310503]
 [0.36336462]
 [0.3628191 ]
 [0.36312499]
 [0.36218092]
 [0.36305804]
 [0.36415142]
 [0.36331987]
 [0.36352206]
 [0.36403852]]
wv_jc shape (29,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ndT shape (29,)
[0.20612956 1.         0.         0.         0.53932135 0.13643638
 0.         0.55698339 0.23622866 0.01042712 0.31807475 0.13239662
 0.         0.67077248 0.20142889 0.         0.38865199 0.
 0.         0.         0.16125198 0.02845212 0.         0.
 0.         0.57523811 0.31081166 0.38357148 0.88729576]
wv_std shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
xy shape: (29, 9)
[[1.         1.         0.         0.         0.35165379 1.
  0.20612956 0.         0.        ]
 [1.         1.         1.         1.         0.35366235 1.
  1.         0.         0.        ]
 [0.         1.         0.         0.         0.35103045 1.
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.37186009 1.
  0.         0.         0.        ]
 [1.         0.         1.         1.         0.36354582 1.
  0.53932135 1.         1.        ]
 [1.         0.         1.         1.         0.36320905 1.
  0.13643638 1.         1.        ]
 [1.         0.         1.         1.         0.36324647 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.36374566 1.
  0.55698339 1.         1.        ]
 [1.         0.         1.         1.         0.36327137 1.
  0.23622866 1.         1.        ]
 [1.         0.         1.         1.         0.36330673 1.
  0.01042712 1.         1.        ]
 [1.         0.         1.         1.         0.36300862 1.
  0.31807475 1.         1.        ]
 [1.         0.         1.         1.         0.36339992 1.
  0.13239662 1.         1.        ]
 [1.         0.         1.         1.         0.36344795 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.36359895 1.
  0.67077248 1.         1.        ]
 [1.         0.         1.         1.         0.36323098 1.
  0.20142889 1.         1.        ]
 [1.         0.         1.         1.         0.36348749 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.36288979 1.
  0.38865199 1.         1.        ]
 [1.         0.         1.         1.         0.36366456 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.36297968 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.36310503 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.36336462 1.
  0.16125198 1.         1.        ]
 [1.         0.         1.         1.         0.3628191  1.
  0.02845212 1.         1.        ]
 [1.         0.         1.         1.         0.36312499 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.36218092 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.36305804 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.36415142 1.
  0.57523811 1.         1.        ]
 [1.         0.         1.         1.         0.36331987 1.
  0.31081166 1.         1.        ]
 [1.         0.         1.         1.         0.36352206 1.
  0.38357148 1.         1.        ]
 [1.         0.         1.         1.         0.36403852 1.
  0.88729576 1.         1.        ]]

Best Training Poisoning Accuracy:
0.8571428656578064
#####################         POISON         ###############################################

############################################################################################

comm_round: 4 | global_test_acc: 88.889% | global_f1: 0.9411764705882353 | global_precision: 0.8888888888888888
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.89      1.00      0.94         8

    accuracy                           0.89         9
   macro avg       0.44      0.50      0.47         9
weighted avg       0.79      0.89      0.84         9

Accuracy per class:
[[8 0]
 [1 0]]
[1. 0.]
poison scaling shape: (29, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 29 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clients
y shape (29,)
[0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (29,)
[1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_fg shape (29,)
[0.         0.93437611 0.         1.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_mn shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ed shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_lg shape (29, 1)
[[0.35373406]
 [0.35805794]
 [0.35349522]
 [0.37154724]
 [0.36313822]
 [0.36419236]
 [0.36295631]
 [0.36314591]
 [0.36370481]
 [0.363394  ]
 [0.36358282]
 [0.36327276]
 [0.36342906]
 [0.36373695]
 [0.36407604]
 [0.36419345]
 [0.3630714 ]
 [0.36391002]
 [0.36379603]
 [0.36343016]
 [0.36355152]
 [0.36399492]
 [0.36401411]
 [0.36433327]
 [0.36326674]
 [0.36396158]
 [0.36459056]
 [0.36357968]
 [0.36465564]]
wv_jc shape (29,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ndT shape (29,)
[0.91581691 1.         0.         0.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         0.93813531 1.         1.         1.
 1.         1.         1.         1.         1.        ]
wv_std shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
xy shape: (29, 9)
[[1.         0.         0.         0.         0.35373406 1.
  0.91581691 0.         0.        ]
 [1.         0.93437611 1.         1.         0.35805794 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.35349522 1.
  0.         0.         0.        ]
 [0.         1.         0.         0.         0.37154724 1.
  0.         0.         0.        ]
 [1.         0.         1.         1.         0.36313822 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36419236 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36295631 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36314591 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36370481 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.363394   1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36358282 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36327276 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36342906 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36373695 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36407604 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36419345 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.3630714  1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36391002 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36379603 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36343016 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36355152 1.
  0.93813531 1.         1.        ]
 [1.         0.         1.         1.         0.36399492 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36401411 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36433327 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36326674 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36396158 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36459056 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36357968 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36465564 1.
  1.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.9285714030265808
#####################         POISON         ###############################################

############################################################################################

comm_round: 5 | global_test_acc: 77.778% | global_f1: 0.8750000000000001 | global_precision: 0.7777777777777778
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.78      1.00      0.88         7

    accuracy                           0.78         9
   macro avg       0.39      0.50      0.44         9
weighted avg       0.60      0.78      0.68         9

Accuracy per class:
[[7 0]
 [2 0]]
[1. 0.]
poison scaling shape: (29, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 29 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clients
y shape (29,)
[0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (29,)
[1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_fg shape (29,)
[0.00463426 0.00463426 1.         1.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_mn shape (29,)
[0.08571039 1.         0.         0.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.        ]
wv_ed shape (29,)
[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_lg shape (29, 1)
[[0.35653358]
 [0.35634304]
 [0.3503    ]
 [0.37419898]
 [0.36472098]
 [0.36482163]
 [0.36423482]
 [0.36400337]
 [0.36455978]
 [0.3646898 ]
 [0.3639331 ]
 [0.36415098]
 [0.36447476]
 [0.36437532]
 [0.36435701]
 [0.36373176]
 [0.36393407]
 [0.36434741]
 [0.36481728]
 [0.36415455]
 [0.36451352]
 [0.36419386]
 [0.36520854]
 [0.36402284]
 [0.36500531]
 [0.36454155]
 [0.36435816]
 [0.36467787]
 [0.36395341]]
wv_jc shape (29,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ndT shape (29,)
[0.         0.94939126 0.19025014 0.         1.         0.19023676
 1.         1.         0.4915555  1.         1.         1.
 0.93065398 1.         0.27229533 1.         0.57181403 0.56909095
 0.67588232 1.         0.30779588 1.         0.33431385 0.21109394
 1.         0.80532011 1.         0.76129582 0.77708498]
wv_std shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
xy shape: (29, 9)
[[1.         0.00463426 0.08571039 0.         0.35653358 1.
  0.         0.         0.        ]
 [1.         0.00463426 1.         1.         0.35634304 1.
  0.94939126 0.         0.        ]
 [0.         1.         0.         0.         0.3503     1.
  0.19025014 0.         0.        ]
 [0.         1.         0.         0.         0.37419898 1.
  0.         0.         0.        ]
 [1.         0.         1.         1.         0.36472098 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36482163 1.
  0.19023676 1.         1.        ]
 [1.         0.         1.         1.         0.36423482 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36400337 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36455978 1.
  0.4915555  1.         1.        ]
 [1.         0.         1.         1.         0.3646898  1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.3639331  1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36415098 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36447476 1.
  0.93065398 1.         1.        ]
 [1.         0.         1.         1.         0.36437532 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36435701 1.
  0.27229533 1.         1.        ]
 [1.         0.         1.         1.         0.36373176 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36393407 1.
  0.57181403 1.         1.        ]
 [1.         0.         1.         1.         0.36434741 1.
  0.56909095 1.         1.        ]
 [1.         0.         1.         1.         0.36481728 1.
  0.67588232 1.         1.        ]
 [1.         0.         1.         1.         0.36415455 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36451352 1.
  0.30779588 1.         1.        ]
 [1.         0.         1.         1.         0.36419386 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36520854 1.
  0.33431385 1.         1.        ]
 [1.         0.         1.         1.         0.36402284 1.
  0.21109394 1.         1.        ]
 [1.         0.         1.         1.         0.36500531 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36454155 1.
  0.80532011 1.         1.        ]
 [1.         0.         1.         1.         0.36435816 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36467787 1.
  0.76129582 1.         1.        ]
 [1.         0.         1.         1.         0.36395341 1.
  0.77708498 1.         1.        ]]

Best Training Poisoning Accuracy:
0.8571428656578064
#####################         POISON         ###############################################

############################################################################################

comm_round: 6 | global_test_acc: 77.778% | global_f1: 0.8750000000000001 | global_precision: 0.7777777777777778
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.78      1.00      0.88         7

    accuracy                           0.78         9
   macro avg       0.39      0.50      0.44         9
weighted avg       0.60      0.78      0.68         9

Accuracy per class:
[[7 0]
 [2 0]]
[1. 0.]
poison scaling shape: (29, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 29 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clients
y shape (29,)
[0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (29,)
[1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_fg shape (29,)
[0.47007744 0.47007744 1.         1.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_mn shape (29,)
[0.         0.39853625 0.         0.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.        ]
wv_ed shape (29,)
[0.         0.12215798 0.         0.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.        ]
wv_lg shape (29, 1)
[[0.36014639]
 [0.35588042]
 [0.35984826]
 [0.37820444]
 [0.36516443]
 [0.36498789]
 [0.36497959]
 [0.36486537]
 [0.36470572]
 [0.36529244]
 [0.36502538]
 [0.36513518]
 [0.36466533]
 [0.36597558]
 [0.36493992]
 [0.36537815]
 [0.36476027]
 [0.36564669]
 [0.36477291]
 [0.36537428]
 [0.36520848]
 [0.36536875]
 [0.36539266]
 [0.36471547]
 [0.36525782]
 [0.36516828]
 [0.36496226]
 [0.36483777]
 [0.36452056]]
wv_jc shape (29,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ndT shape (29,)
[0.21559298 0.         0.36674012 0.         0.67874061 0.
 0.60787449 0.06311746 0.         0.59988271 0.24326156 0.72948995
 0.         0.         0.         1.         0.18613618 1.
 0.75284918 0.5250666  0.         1.         0.         0.
 0.10562338 0.90387768 1.         0.         1.        ]
wv_std shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
xy shape: (29, 9)
[[1.         0.47007744 0.         0.         0.36014639 1.
  0.21559298 0.         0.        ]
 [1.         0.47007744 0.39853625 0.12215798 0.35588042 1.
  0.         0.         0.        ]
 [0.         1.         0.         0.         0.35984826 1.
  0.36674012 0.         0.        ]
 [0.         1.         0.         0.         0.37820444 1.
  0.         0.         0.        ]
 [1.         0.         1.         1.         0.36516443 1.
  0.67874061 1.         1.        ]
 [1.         0.         1.         1.         0.36498789 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.36497959 1.
  0.60787449 1.         1.        ]
 [1.         0.         1.         1.         0.36486537 1.
  0.06311746 1.         1.        ]
 [1.         0.         1.         1.         0.36470572 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.36529244 1.
  0.59988271 1.         1.        ]
 [1.         0.         1.         1.         0.36502538 1.
  0.24326156 1.         1.        ]
 [1.         0.         1.         1.         0.36513518 1.
  0.72948995 1.         1.        ]
 [1.         0.         1.         1.         0.36466533 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.36597558 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.36493992 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.36537815 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36476027 1.
  0.18613618 1.         1.        ]
 [1.         0.         1.         1.         0.36564669 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36477291 1.
  0.75284918 1.         1.        ]
 [1.         0.         1.         1.         0.36537428 1.
  0.5250666  1.         1.        ]
 [1.         0.         1.         1.         0.36520848 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.36536875 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36539266 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.36471547 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.36525782 1.
  0.10562338 1.         1.        ]
 [1.         0.         1.         1.         0.36516828 1.
  0.90387768 1.         1.        ]
 [1.         0.         1.         1.         0.36496226 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36483777 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.36452056 1.
  1.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.8571428656578064
#####################         POISON         ###############################################

############################################################################################

comm_round: 7 | global_test_acc: 88.889% | global_f1: 0.9411764705882353 | global_precision: 0.8888888888888888
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.89      1.00      0.94         8

    accuracy                           0.89         9
   macro avg       0.44      0.50      0.47         9
weighted avg       0.79      0.89      0.84         9

Accuracy per class:
[[8 0]
 [1 0]]
[1. 0.]
poison scaling shape: (29, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 29 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clients
y shape (29,)
[0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (29,)
[0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_fg shape (29,)
[0.         0.40728018 0.         1.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_mn shape (29,)
[0.         0.12071114 0.         0.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.        ]
wv_ed shape (29,)
[0.         0.09591264 0.         0.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.        ]
wv_lg shape (29, 1)
[[0.35931326]
 [0.3589684 ]
 [0.36020044]
 [0.37787306]
 [0.36663313]
 [0.36594825]
 [0.3660069 ]
 [0.36627583]
 [0.36574702]
 [0.36644277]
 [0.36635273]
 [0.36568893]
 [0.36601756]
 [0.36566965]
 [0.36772457]
 [0.36571036]
 [0.36624036]
 [0.36605084]
 [0.36646961]
 [0.36598447]
 [0.3661257 ]
 [0.36568256]
 [0.36527798]
 [0.36576306]
 [0.36641554]
 [0.36606471]
 [0.36644713]
 [0.36563279]
 [0.36655085]]
wv_jc shape (29,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ndT shape (29,)
[0.         0.         0.         0.         1.         0.78386339
 0.89900407 1.         0.81263012 1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         0.94020206 1.         1.         1.
 1.         1.         1.         1.         1.        ]
wv_std shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
xy shape: (29, 9)
[[0.         0.         0.         0.         0.35931326 1.
  0.         0.         0.        ]
 [1.         0.40728018 0.12071114 0.09591264 0.3589684  1.
  0.         0.         0.        ]
 [1.         0.         0.         0.         0.36020044 1.
  0.         0.         0.        ]
 [0.         1.         0.         0.         0.37787306 1.
  0.         0.         0.        ]
 [1.         0.         1.         1.         0.36663313 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36594825 1.
  0.78386339 1.         1.        ]
 [1.         0.         1.         1.         0.3660069  1.
  0.89900407 1.         1.        ]
 [1.         0.         1.         1.         0.36627583 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36574702 1.
  0.81263012 1.         1.        ]
 [1.         0.         1.         1.         0.36644277 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36635273 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36568893 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36601756 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36566965 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36772457 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36571036 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36624036 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36605084 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36646961 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36598447 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.3661257  1.
  0.94020206 1.         1.        ]
 [1.         0.         1.         1.         0.36568256 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36527798 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36576306 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36641554 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36606471 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36644713 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36563279 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36655085 1.
  1.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.9285714030265808
#####################         POISON         ###############################################

############################################################################################

comm_round: 8 | global_test_acc: 77.778% | global_f1: 0.8750000000000001 | global_precision: 0.7777777777777778
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.78      1.00      0.88         7

    accuracy                           0.78         9
   macro avg       0.39      0.50      0.44         9
weighted avg       0.60      0.78      0.68         9

Accuracy per class:
[[7 0]
 [2 0]]
[1. 0.]
poison scaling shape: (29, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 29 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clients
y shape (29,)
[0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (29,)
[1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_fg shape (29,)
[0.1980043 0.        1.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.       ]
wv_mn shape (29,)
[0.11769379 1.         0.         0.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.        ]
wv_ed shape (29,)
[0.         0.81534666 0.         0.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.        ]
wv_lg shape (29, 1)
[[0.36139206]
 [0.36210326]
 [0.35974014]
 [0.37609927]
 [0.36766325]
 [0.36666116]
 [0.36697667]
 [0.36627599]
 [0.36717178]
 [0.36732705]
 [0.36696245]
 [0.36726845]
 [0.36742427]
 [0.36719816]
 [0.36692579]
 [0.36668755]
 [0.36673505]
 [0.36714921]
 [0.36682558]
 [0.36753626]
 [0.36640643]
 [0.36731601]
 [0.3670705 ]
 [0.36684081]
 [0.3670473 ]
 [0.36735059]
 [0.36805645]
 [0.36696789]
 [0.36761477]]
wv_jc shape (29,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ndT shape (29,)
[0.         0.         0.         1.         0.1619672  0.
 0.         0.         0.         0.02177753 0.         0.08830128
 0.01995934 0.         0.08148631 0.         0.37577189 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.03672308 0.25847147]
wv_std shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
xy shape: (29, 9)
[[1.         0.1980043  0.11769379 0.         0.36139206 1.
  0.         0.         0.        ]
 [1.         0.         1.         0.81534666 0.36210326 1.
  0.         0.         0.        ]
 [0.         1.         0.         0.         0.35974014 1.
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.37609927 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.36766325 1.
  0.1619672  1.         1.        ]
 [1.         0.         1.         1.         0.36666116 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.36697667 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.36627599 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.36717178 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.36732705 1.
  0.02177753 1.         1.        ]
 [1.         0.         1.         1.         0.36696245 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.36726845 1.
  0.08830128 1.         1.        ]
 [1.         0.         1.         1.         0.36742427 1.
  0.01995934 1.         1.        ]
 [1.         0.         1.         1.         0.36719816 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.36692579 1.
  0.08148631 1.         1.        ]
 [1.         0.         1.         1.         0.36668755 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.36673505 1.
  0.37577189 1.         1.        ]
 [1.         0.         1.         1.         0.36714921 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.36682558 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.36753626 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.36640643 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.36731601 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.3670705  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.36684081 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.3670473  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.36735059 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.36805645 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.36696789 1.
  0.03672308 1.         1.        ]
 [1.         0.         1.         1.         0.36761477 1.
  0.25847147 1.         1.        ]]

Best Training Poisoning Accuracy:
0.9285714030265808
#####################         POISON         ###############################################

############################################################################################

comm_round: 9 | global_test_acc: 88.889% | global_f1: 0.9411764705882353 | global_precision: 0.8888888888888888
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.89      1.00      0.94         8

    accuracy                           0.89         9
   macro avg       0.44      0.50      0.47         9
weighted avg       0.79      0.89      0.84         9

Accuracy per class:
[[8 0]
 [1 0]]
[1. 0.]
poison scaling shape: (29, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 29 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clients
y shape (29,)
[0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (29,)
[0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_fg shape (29,)
[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0.]
wv_mn shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ed shape (29,)
[0.         0.05514977 0.         0.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.        ]
wv_lg shape (29, 1)
[[0.36254018]
 [0.36051747]
 [0.36432042]
 [0.37735639]
 [0.36817189]
 [0.36743841]
 [0.36817187]
 [0.36801292]
 [0.36806376]
 [0.36783791]
 [0.36825527]
 [0.36843984]
 [0.36874279]
 [0.36779492]
 [0.36773044]
 [0.36809253]
 [0.36789343]
 [0.36826976]
 [0.36775203]
 [0.36759854]
 [0.36798931]
 [0.36785552]
 [0.36775463]
 [0.36798698]
 [0.36789703]
 [0.36707456]
 [0.36760994]
 [0.36791527]
 [0.36874235]]
wv_jc shape (29,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ndT shape (29,)
[1.         0.         0.         1.         0.66120704 1.
 0.51375424 1.         0.03819341 0.44438691 0.75911171 0.67093475
 1.         1.         0.         1.         1.         0.
 1.         0.14354782 0.86687184 0.83929367 0.         0.56082893
 1.         0.79385733 0.08458765 1.         0.72286669]
wv_std shape (29,)
[0.         0.03830162 0.         0.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.        ]
xy shape: (29, 9)
[[0.         0.         0.         0.         0.36254018 1.
  1.         0.         0.        ]
 [1.         0.         0.         0.05514977 0.36051747 1.
  0.         0.03830162 0.        ]
 [1.         0.         0.         0.         0.36432042 1.
  0.         0.         0.        ]
 [0.         1.         0.         0.         0.37735639 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.36817189 1.
  0.66120704 1.         1.        ]
 [1.         0.         1.         1.         0.36743841 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36817187 1.
  0.51375424 1.         1.        ]
 [1.         0.         1.         1.         0.36801292 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36806376 1.
  0.03819341 1.         1.        ]
 [1.         0.         1.         1.         0.36783791 1.
  0.44438691 1.         1.        ]
 [1.         0.         1.         1.         0.36825527 1.
  0.75911171 1.         1.        ]
 [1.         0.         1.         1.         0.36843984 1.
  0.67093475 1.         1.        ]
 [1.         0.         1.         1.         0.36874279 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36779492 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36773044 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.36809253 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36789343 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36826976 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.36775203 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36759854 1.
  0.14354782 1.         1.        ]
 [1.         0.         1.         1.         0.36798931 1.
  0.86687184 1.         1.        ]
 [1.         0.         1.         1.         0.36785552 1.
  0.83929367 1.         1.        ]
 [1.         0.         1.         1.         0.36775463 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.36798698 1.
  0.56082893 1.         1.        ]
 [1.         0.         1.         1.         0.36789703 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36707456 1.
  0.79385733 1.         1.        ]
 [1.         0.         1.         1.         0.36760994 1.
  0.08458765 1.         1.        ]
 [1.         0.         1.         1.         0.36791527 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36874235 1.
  0.72286669 1.         1.        ]]

Best Training Poisoning Accuracy:
0.7857142686843872
#####################         POISON         ###############################################

############################################################################################

comm_round: 10 | global_test_acc: 88.889% | global_f1: 0.9411764705882353 | global_precision: 0.8888888888888888
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.89      1.00      0.94         8

    accuracy                           0.89         9
   macro avg       0.44      0.50      0.47         9
weighted avg       0.79      0.89      0.84         9

Accuracy per class:
[[8 0]
 [1 0]]
[1. 0.]
poison scaling shape: (29, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 29 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clients
y shape (29,)
[0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (29,)
[0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_fg shape (29,)
[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0.]
wv_mn shape (29,)
[0.         0.40372316 0.         0.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.        ]
wv_ed shape (29,)
[0.         0.16251701 0.         0.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.        ]
wv_lg shape (29, 1)
[[0.36381311]
 [0.36006748]
 [0.36312973]
 [0.37519466]
 [0.36942384]
 [0.36889198]
 [0.36878335]
 [0.36874364]
 [0.3682778 ]
 [0.36929111]
 [0.36844877]
 [0.36910118]
 [0.36874966]
 [0.36869368]
 [0.36854512]
 [0.36921685]
 [0.36860894]
 [0.3689845 ]
 [0.36781935]
 [0.36838744]
 [0.36893486]
 [0.36844295]
 [0.3685574 ]
 [0.3687995 ]
 [0.36887844]
 [0.36881554]
 [0.36826315]
 [0.36902182]
 [0.36770775]]
wv_jc shape (29,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ndT shape (29,)
[0.         0.76190529 0.         1.         1.         0.36456425
 0.70567563 0.19094508 0.         1.         0.         1.
 1.         0.89259633 0.6765628  1.         0.41007276 1.
 0.21131383 0.79062744 1.         0.33143762 1.         1.
 0.30098129 1.         0.58668331 0.99417172 0.71781023]
wv_std shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
xy shape: (29, 9)
[[0.         0.         0.         0.         0.36381311 1.
  0.         0.         0.        ]
 [1.         0.         0.40372316 0.16251701 0.36006748 1.
  0.76190529 0.         0.        ]
 [1.         0.         0.         0.         0.36312973 1.
  0.         0.         0.        ]
 [0.         1.         0.         0.         0.37519466 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.36942384 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36889198 1.
  0.36456425 1.         1.        ]
 [1.         0.         1.         1.         0.36878335 1.
  0.70567563 1.         1.        ]
 [1.         0.         1.         1.         0.36874364 1.
  0.19094508 1.         1.        ]
 [1.         0.         1.         1.         0.3682778  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.36929111 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36844877 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.36910118 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36874966 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36869368 1.
  0.89259633 1.         1.        ]
 [1.         0.         1.         1.         0.36854512 1.
  0.6765628  1.         1.        ]
 [1.         0.         1.         1.         0.36921685 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36860894 1.
  0.41007276 1.         1.        ]
 [1.         0.         1.         1.         0.3689845  1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36781935 1.
  0.21131383 1.         1.        ]
 [1.         0.         1.         1.         0.36838744 1.
  0.79062744 1.         1.        ]
 [1.         0.         1.         1.         0.36893486 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36844295 1.
  0.33143762 1.         1.        ]
 [1.         0.         1.         1.         0.3685574  1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.3687995  1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36887844 1.
  0.30098129 1.         1.        ]
 [1.         0.         1.         1.         0.36881554 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36826315 1.
  0.58668331 1.         1.        ]
 [1.         0.         1.         1.         0.36902182 1.
  0.99417172 1.         1.        ]
 [1.         0.         1.         1.         0.36770775 1.
  0.71781023 1.         1.        ]]

Best Training Poisoning Accuracy:
0.9285714030265808
#####################         POISON         ###############################################

############################################################################################

comm_round: 11 | global_test_acc: 77.778% | global_f1: 0.8750000000000001 | global_precision: 0.7777777777777778
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.78      1.00      0.88         7

    accuracy                           0.78         9
   macro avg       0.39      0.50      0.44         9
weighted avg       0.60      0.78      0.68         9

Accuracy per class:
[[7 0]
 [2 0]]
[1. 0.]
poison scaling shape: (29, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 29 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clients
y shape (29,)
[0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (29,)
[1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_fg shape (29,)
[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0.]
wv_mn shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ed shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_lg shape (29, 1)
[[0.36563051]
 [0.35920057]
 [0.36214209]
 [0.3768185 ]
 [0.36927247]
 [0.36887191]
 [0.36951944]
 [0.36976761]
 [0.36920723]
 [0.36981918]
 [0.36967505]
 [0.36968978]
 [0.36936979]
 [0.36889486]
 [0.36908791]
 [0.3695796 ]
 [0.36893366]
 [0.3692297 ]
 [0.36953127]
 [0.36970459]
 [0.36912064]
 [0.36936314]
 [0.36991709]
 [0.36962494]
 [0.36926386]
 [0.36931544]
 [0.36870465]
 [0.36931682]
 [0.36979711]]
wv_jc shape (29,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ndT shape (29,)
[0.         1.         0.         0.         1.         1.
 1.         1.         1.         1.         0.65832307 1.
 1.         1.         1.         1.         1.         1.
 0.76622232 1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.        ]
wv_std shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
xy shape: (29, 9)
[[1.         0.         0.         0.         0.36563051 1.
  0.         0.         0.        ]
 [1.         0.         0.         0.         0.35920057 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.36214209 1.
  0.         0.         0.        ]
 [0.         1.         0.         0.         0.3768185  1.
  0.         0.         0.        ]
 [1.         0.         1.         1.         0.36927247 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36887191 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36951944 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36976761 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36920723 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36981918 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36967505 1.
  0.65832307 1.         1.        ]
 [1.         0.         1.         1.         0.36968978 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36936979 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36889486 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36908791 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.3695796  1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36893366 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.3692297  1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36953127 1.
  0.76622232 1.         1.        ]
 [1.         0.         1.         1.         0.36970459 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36912064 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36936314 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36991709 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36962494 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36926386 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36931544 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36870465 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36931682 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36979711 1.
  1.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.8571428656578064
#####################         POISON         ###############################################

############################################################################################

comm_round: 12 | global_test_acc: 88.889% | global_f1: 0.9411764705882353 | global_precision: 0.8888888888888888
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.89      1.00      0.94         8

    accuracy                           0.89         9
   macro avg       0.44      0.50      0.47         9
weighted avg       0.79      0.89      0.84         9

Accuracy per class:
[[8 0]
 [1 0]]
[1. 0.]
poison scaling shape: (29, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 29 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clients
y shape (29,)
[0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (29,)
[1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_fg shape (29,)
[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0.]
wv_mn shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ed shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_lg shape (29, 1)
[[0.36495901]
 [0.36030783]
 [0.36611654]
 [0.37836271]
 [0.37053414]
 [0.37013448]
 [0.36966345]
 [0.36984894]
 [0.36986494]
 [0.36985999]
 [0.37129936]
 [0.37024396]
 [0.37048143]
 [0.37063329]
 [0.37033883]
 [0.36966136]
 [0.36980691]
 [0.37035638]
 [0.3707992 ]
 [0.36961499]
 [0.37036223]
 [0.37030733]
 [0.36988146]
 [0.36949469]
 [0.36954353]
 [0.37069093]
 [0.37016327]
 [0.37025834]
 [0.36974906]]
wv_jc shape (29,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ndT shape (29,)
[1.         0.         1.         0.         1.         0.
 0.8629465  0.21561114 0.         0.49538315 0.89365239 0.9554318
 0.         0.48804762 0.56098213 1.         0.         0.22109736
 0.4571743  0.02189204 0.07853827 0.17817758 0.49893405 0.
 0.         0.68198128 0.         0.41609083 0.        ]
wv_std shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
xy shape: (29, 9)
[[1.         0.         0.         0.         0.36495901 1.
  1.         0.         0.        ]
 [1.         0.         0.         0.         0.36030783 1.
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.36611654 1.
  1.         0.         0.        ]
 [0.         1.         0.         0.         0.37836271 1.
  0.         0.         0.        ]
 [1.         0.         1.         1.         0.37053414 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.37013448 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.36966345 1.
  0.8629465  1.         1.        ]
 [1.         0.         1.         1.         0.36984894 1.
  0.21561114 1.         1.        ]
 [1.         0.         1.         1.         0.36986494 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.36985999 1.
  0.49538315 1.         1.        ]
 [1.         0.         1.         1.         0.37129936 1.
  0.89365239 1.         1.        ]
 [1.         0.         1.         1.         0.37024396 1.
  0.9554318  1.         1.        ]
 [1.         0.         1.         1.         0.37048143 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37063329 1.
  0.48804762 1.         1.        ]
 [1.         0.         1.         1.         0.37033883 1.
  0.56098213 1.         1.        ]
 [1.         0.         1.         1.         0.36966136 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.36980691 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37035638 1.
  0.22109736 1.         1.        ]
 [1.         0.         1.         1.         0.3707992  1.
  0.4571743  1.         1.        ]
 [1.         0.         1.         1.         0.36961499 1.
  0.02189204 1.         1.        ]
 [1.         0.         1.         1.         0.37036223 1.
  0.07853827 1.         1.        ]
 [1.         0.         1.         1.         0.37030733 1.
  0.17817758 1.         1.        ]
 [1.         0.         1.         1.         0.36988146 1.
  0.49893405 1.         1.        ]
 [1.         0.         1.         1.         0.36949469 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.36954353 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37069093 1.
  0.68198128 1.         1.        ]
 [1.         0.         1.         1.         0.37016327 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37025834 1.
  0.41609083 1.         1.        ]
 [1.         0.         1.         1.         0.36974906 1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.8571428656578064
#####################         POISON         ###############################################

############################################################################################

comm_round: 13 | global_test_acc: 88.889% | global_f1: 0.9411764705882353 | global_precision: 0.8888888888888888
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.89      1.00      0.94         8

    accuracy                           0.89         9
   macro avg       0.44      0.50      0.47         9
weighted avg       0.79      0.89      0.84         9

Accuracy per class:
[[8 0]
 [1 0]]
[1. 0.]
poison scaling shape: (29, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 29 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clients
y shape (29,)
[0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (29,)
[1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_fg shape (29,)
[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0.]
wv_mn shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ed shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_lg shape (29, 1)
[[0.36568333]
 [0.3656776 ]
 [0.3651658 ]
 [0.37592113]
 [0.37093579]
 [0.37136881]
 [0.37027667]
 [0.37057552]
 [0.37012949]
 [0.37075579]
 [0.37080734]
 [0.3706914 ]
 [0.37053303]
 [0.37142697]
 [0.37043052]
 [0.37069925]
 [0.37065393]
 [0.37152997]
 [0.37074941]
 [0.37070938]
 [0.37078295]
 [0.37030992]
 [0.37083108]
 [0.36992519]
 [0.37176927]
 [0.37093002]
 [0.37009837]
 [0.37062411]
 [0.3706336 ]]
wv_jc shape (29,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ndT shape (29,)
[0.         0.21858799 0.         0.         1.         1.
 0.38900023 0.69687103 0.71334748 0.         1.         0.20806055
 0.6498233  1.         0.35091291 0.19518689 0.33554157 1.
 0.05165639 1.         0.91830162 0.98618802 0.74385483 0.19670884
 1.         0.33903649 1.         0.19756579 0.63984127]
wv_std shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
xy shape: (29, 9)
[[1.         0.         0.         0.         0.36568333 1.
  0.         0.         0.        ]
 [1.         0.         0.         0.         0.3656776  1.
  0.21858799 0.         0.        ]
 [0.         0.         0.         0.         0.3651658  1.
  0.         0.         0.        ]
 [0.         1.         0.         0.         0.37592113 1.
  0.         0.         0.        ]
 [1.         0.         1.         1.         0.37093579 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.37136881 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.37027667 1.
  0.38900023 1.         1.        ]
 [1.         0.         1.         1.         0.37057552 1.
  0.69687103 1.         1.        ]
 [1.         0.         1.         1.         0.37012949 1.
  0.71334748 1.         1.        ]
 [1.         0.         1.         1.         0.37075579 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37080734 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.3706914  1.
  0.20806055 1.         1.        ]
 [1.         0.         1.         1.         0.37053303 1.
  0.6498233  1.         1.        ]
 [1.         0.         1.         1.         0.37142697 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.37043052 1.
  0.35091291 1.         1.        ]
 [1.         0.         1.         1.         0.37069925 1.
  0.19518689 1.         1.        ]
 [1.         0.         1.         1.         0.37065393 1.
  0.33554157 1.         1.        ]
 [1.         0.         1.         1.         0.37152997 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.37074941 1.
  0.05165639 1.         1.        ]
 [1.         0.         1.         1.         0.37070938 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.37078295 1.
  0.91830162 1.         1.        ]
 [1.         0.         1.         1.         0.37030992 1.
  0.98618802 1.         1.        ]
 [1.         0.         1.         1.         0.37083108 1.
  0.74385483 1.         1.        ]
 [1.         0.         1.         1.         0.36992519 1.
  0.19670884 1.         1.        ]
 [1.         0.         1.         1.         0.37176927 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.37093002 1.
  0.33903649 1.         1.        ]
 [1.         0.         1.         1.         0.37009837 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.37062411 1.
  0.19756579 1.         1.        ]
 [1.         0.         1.         1.         0.3706336  1.
  0.63984127 1.         1.        ]]

Best Training Poisoning Accuracy:
0.7857142686843872
#####################         POISON         ###############################################

############################################################################################

comm_round: 14 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         9

    accuracy                           1.00         9
   macro avg       1.00      1.00      1.00         9
weighted avg       1.00      1.00      1.00         9

Accuracy per class:
[[9 0]
 [0 0]]
[ 1. nan]
poison scaling shape: (29, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 29 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clients
y shape (29,)
[0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (29,)
[0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_fg shape (29,)
[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0.]
wv_mn shape (29,)
[0.         0.22247885 0.         0.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.        ]
wv_ed shape (29,)
[0.         0.23010063 0.         0.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.        ]
wv_lg shape (29, 1)
[[0.36694043]
 [0.36767654]
 [0.36701892]
 [0.37602302]
 [0.37077327]
 [0.3709243 ]
 [0.37164743]
 [0.37134453]
 [0.37117062]
 [0.37160585]
 [0.37063389]
 [0.37189909]
 [0.37117051]
 [0.37133836]
 [0.37061785]
 [0.37116889]
 [0.37104243]
 [0.37138529]
 [0.37080468]
 [0.37134645]
 [0.37095178]
 [0.37205838]
 [0.37125384]
 [0.37097491]
 [0.37184548]
 [0.37182113]
 [0.37117301]
 [0.3708535 ]
 [0.37159735]]
wv_jc shape (29,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ndT shape (29,)
[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0.]
wv_std shape (29,)
[0.         0.         0.         0.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         0.         1.         1.         0.32557241
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.        ]
xy shape: (29, 9)
[[0.         0.         0.         0.         0.36694043 1.
  0.         0.         0.        ]
 [1.         0.         0.22247885 0.23010063 0.36767654 1.
  0.         0.         0.        ]
 [1.         0.         0.         0.         0.36701892 1.
  1.         0.         0.        ]
 [0.         1.         0.         0.         0.37602302 1.
  0.         0.         0.        ]
 [1.         0.         1.         1.         0.37077327 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.3709243  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37164743 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37134453 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37117062 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37160585 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37063389 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37189909 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37117051 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37133836 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37061785 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.37116889 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37104243 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37138529 1.
  0.         0.32557241 1.        ]
 [1.         0.         1.         1.         0.37080468 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37134645 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37095178 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37205838 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37125384 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37097491 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37184548 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37182113 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37117301 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.3708535  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37159735 1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.7857142686843872
#####################         POISON         ###############################################

############################################################################################

comm_round: 15 | global_test_acc: 88.889% | global_f1: 0.9411764705882353 | global_precision: 0.8888888888888888
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.89      1.00      0.94         8

    accuracy                           0.89         9
   macro avg       0.44      0.50      0.47         9
weighted avg       0.79      0.89      0.84         9

Accuracy per class:
[[8 0]
 [1 0]]
[1. 0.]
poison scaling shape: (29, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 29 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clients
y shape (29,)
[0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (29,)
[0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_fg shape (29,)
[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0.]
wv_mn shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ed shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_lg shape (29, 1)
[[0.36678946]
 [0.36817862]
 [0.36789779]
 [0.37929059]
 [0.37203367]
 [0.37187848]
 [0.37232914]
 [0.37129139]
 [0.37132392]
 [0.37157437]
 [0.37226842]
 [0.37128325]
 [0.37189149]
 [0.37232797]
 [0.37110886]
 [0.37136198]
 [0.37228816]
 [0.37226256]
 [0.37175998]
 [0.3715397 ]
 [0.37141716]
 [0.37232757]
 [0.37266781]
 [0.3713048 ]
 [0.37175192]
 [0.37135982]
 [0.37155028]
 [0.37211651]
 [0.37226723]]
wv_jc shape (29,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ndT shape (29,)
[0.26551736 0.11102316 1.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_std shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
xy shape: (29, 9)
[[0.         0.         0.         0.         0.36678946 1.
  0.26551736 0.         0.        ]
 [1.         0.         0.         0.         0.36817862 1.
  0.11102316 0.         0.        ]
 [1.         0.         0.         0.         0.36789779 1.
  1.         0.         0.        ]
 [0.         1.         0.         0.         0.37929059 1.
  0.         0.         0.        ]
 [1.         0.         1.         1.         0.37203367 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37187848 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37232914 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37129139 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37132392 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37157437 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37226842 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37128325 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37189149 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37232797 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37110886 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37136198 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37228816 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37226256 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37175998 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.3715397  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37141716 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37232757 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37266781 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.3713048  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37175192 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37135982 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37155028 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37211651 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37226723 1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.8571428656578064
#####################         POISON         ###############################################

############################################################################################

comm_round: 16 | global_test_acc: 88.889% | global_f1: 0.9411764705882353 | global_precision: 0.8888888888888888
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.89      1.00      0.94         8

    accuracy                           0.89         9
   macro avg       0.44      0.50      0.47         9
weighted avg       0.79      0.89      0.84         9

Accuracy per class:
[[8 0]
 [1 0]]
[1. 0.]
poison scaling shape: (29, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 29 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clients
y shape (29,)
[0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (29,)
[1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_fg shape (29,)
[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0.]
wv_mn shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ed shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_lg shape (29, 1)
[[0.36828982]
 [0.36698086]
 [0.36870546]
 [0.38384399]
 [0.37326338]
 [0.37190636]
 [0.37214307]
 [0.37296369]
 [0.37171572]
 [0.37289801]
 [0.37259468]
 [0.3723359 ]
 [0.37275601]
 [0.37271513]
 [0.37242747]
 [0.3723812 ]
 [0.37232406]
 [0.37223175]
 [0.37218527]
 [0.37236862]
 [0.37283893]
 [0.37189836]
 [0.37204137]
 [0.37225393]
 [0.37264132]
 [0.37234376]
 [0.3720949 ]
 [0.3735805 ]
 [0.37180448]]
wv_jc shape (29,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ndT shape (29,)
[0.         0.         1.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.13757101 0.         0.         0.         0.
 0.         0.         0.         0.         0.05561637 0.
 0.         0.         0.         0.         0.        ]
wv_std shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
xy shape: (29, 9)
[[1.         0.         0.         0.         0.36828982 1.
  0.         0.         0.        ]
 [1.         0.         0.         0.         0.36698086 1.
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.36870546 1.
  1.         0.         0.        ]
 [0.         1.         0.         0.         0.38384399 1.
  0.         0.         0.        ]
 [1.         0.         1.         1.         0.37326338 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37190636 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37214307 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37296369 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37171572 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37289801 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37259468 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.3723359  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37275601 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37271513 1.
  0.13757101 1.         1.        ]
 [1.         0.         1.         1.         0.37242747 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.3723812  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37232406 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37223175 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37218527 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37236862 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37283893 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37189836 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37204137 1.
  0.05561637 1.         1.        ]
 [1.         0.         1.         1.         0.37225393 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37264132 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37234376 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.3720949  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.3735805  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37180448 1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.9285714030265808
#####################         POISON         ###############################################

############################################################################################

comm_round: 17 | global_test_acc: 77.778% | global_f1: 0.8750000000000001 | global_precision: 0.7777777777777778
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.78      1.00      0.88         7

    accuracy                           0.78         9
   macro avg       0.39      0.50      0.44         9
weighted avg       0.60      0.78      0.68         9

Accuracy per class:
[[7 0]
 [2 0]]
[1. 0.]
poison scaling shape: (29, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 29 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clients
y shape (29,)
[0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (29,)
[0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_fg shape (29,)
[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0.]
wv_mn shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ed shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_lg shape (29, 1)
[[0.36815817]
 [0.36863571]
 [0.36987544]
 [0.38226954]
 [0.37335384]
 [0.37301354]
 [0.37310259]
 [0.37369452]
 [0.37302682]
 [0.37271367]
 [0.373669  ]
 [0.37261193]
 [0.37356134]
 [0.37372487]
 [0.373351  ]
 [0.37277023]
 [0.37353072]
 [0.37382268]
 [0.37371227]
 [0.37278944]
 [0.37352886]
 [0.37370154]
 [0.373596  ]
 [0.37273159]
 [0.37261893]
 [0.37292228]
 [0.37328995]
 [0.3739244 ]
 [0.37316075]]
wv_jc shape (29,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ndT shape (29,)
[0.         1.         1.         0.         1.         0.
 0.57935333 0.         0.         0.63084134 0.         0.
 0.81342418 0.52306625 0.         0.         0.28787754 0.0741441
 1.         0.33686929 0.         0.         0.         0.68775833
 0.         0.         0.65206687 1.         0.        ]
wv_std shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
xy shape: (29, 9)
[[0.         0.         0.         0.         0.36815817 1.
  0.         0.         0.        ]
 [1.         0.         0.         0.         0.36863571 1.
  1.         0.         0.        ]
 [1.         0.         0.         0.         0.36987544 1.
  1.         0.         0.        ]
 [0.         1.         0.         0.         0.38226954 1.
  0.         0.         0.        ]
 [1.         0.         1.         1.         0.37335384 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.37301354 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37310259 1.
  0.57935333 1.         1.        ]
 [1.         0.         1.         1.         0.37369452 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37302682 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37271367 1.
  0.63084134 1.         1.        ]
 [1.         0.         1.         1.         0.373669   1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37261193 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37356134 1.
  0.81342418 1.         1.        ]
 [1.         0.         1.         1.         0.37372487 1.
  0.52306625 1.         1.        ]
 [1.         0.         1.         1.         0.373351   1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37277023 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37353072 1.
  0.28787754 1.         1.        ]
 [1.         0.         1.         1.         0.37382268 1.
  0.0741441  1.         1.        ]
 [1.         0.         1.         1.         0.37371227 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.37278944 1.
  0.33686929 1.         1.        ]
 [1.         0.         1.         1.         0.37352886 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37370154 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.373596   1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37273159 1.
  0.68775833 1.         1.        ]
 [1.         0.         1.         1.         0.37261893 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37292228 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37328995 1.
  0.65206687 1.         1.        ]
 [1.         0.         1.         1.         0.3739244  1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.37316075 1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.9285714030265808
#####################         POISON         ###############################################

############################################################################################

comm_round: 18 | global_test_acc: 88.889% | global_f1: 0.9411764705882353 | global_precision: 0.8888888888888888
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.89      1.00      0.94         8

    accuracy                           0.89         9
   macro avg       0.44      0.50      0.47         9
weighted avg       0.79      0.89      0.84         9

Accuracy per class:
[[8 0]
 [1 0]]
[1. 0.]
poison scaling shape: (29, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 29 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clients
y shape (29,)
[0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (29,)
[0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_fg shape (29,)
[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0.]
wv_mn shape (29,)
[0.         0.23186471 0.         0.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.        ]
wv_ed shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_lg shape (29, 1)
[[0.36862983]
 [0.36977922]
 [0.37046745]
 [0.38168125]
 [0.37375758]
 [0.37474896]
 [0.37356925]
 [0.37451695]
 [0.37409156]
 [0.37329557]
 [0.37414897]
 [0.37325302]
 [0.37402818]
 [0.37345694]
 [0.37384395]
 [0.37392901]
 [0.37358177]
 [0.37355503]
 [0.37375745]
 [0.37320969]
 [0.37396381]
 [0.37410279]
 [0.37420052]
 [0.37433121]
 [0.37348649]
 [0.37387868]
 [0.37342395]
 [0.37362642]
 [0.37445472]]
wv_jc shape (29,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ndT shape (29,)
[1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0.]
wv_std shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
xy shape: (29, 9)
[[0.         0.         0.         0.         0.36862983 1.
  1.         0.         0.        ]
 [1.         0.         0.23186471 0.         0.36977922 1.
  0.         0.         0.        ]
 [1.         0.         0.         0.         0.37046745 1.
  1.         0.         0.        ]
 [0.         1.         0.         0.         0.38168125 1.
  0.         0.         0.        ]
 [1.         0.         1.         1.         0.37375758 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37474896 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37356925 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37451695 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37409156 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37329557 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37414897 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37325302 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37402818 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37345694 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37384395 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37392901 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37358177 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37355503 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37375745 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37320969 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37396381 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37410279 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37420052 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37433121 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37348649 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37387868 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37342395 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37362642 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37445472 1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.8571428656578064
#####################         POISON         ###############################################

############################################################################################

comm_round: 19 | global_test_acc: 88.889% | global_f1: 0.9411764705882353 | global_precision: 0.8888888888888888
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.89      1.00      0.94         8

    accuracy                           0.89         9
   macro avg       0.44      0.50      0.47         9
weighted avg       0.79      0.89      0.84         9

Accuracy per class:
[[8 0]
 [1 0]]
[1. 0.]
poison scaling shape: (29, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 29 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clients
y shape (29,)
[0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (29,)
[0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_fg shape (29,)
[0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0.]
wv_mn shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ed shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_lg shape (29, 1)
[[0.36890481]
 [0.37127811]
 [0.37084833]
 [0.38353823]
 [0.37423341]
 [0.37482827]
 [0.37477733]
 [0.37477829]
 [0.3739956 ]
 [0.37403118]
 [0.37479656]
 [0.37415005]
 [0.37459963]
 [0.37417744]
 [0.37435458]
 [0.37495663]
 [0.37430289]
 [0.37475654]
 [0.37410932]
 [0.37454248]
 [0.37402539]
 [0.3743464 ]
 [0.37437086]
 [0.37413968]
 [0.37497323]
 [0.37453281]
 [0.3749794 ]
 [0.37437935]
 [0.37403858]]
wv_jc shape (29,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ndT shape (29,)
[1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0.]
wv_std shape (29,)
[0.         0.05470126 0.         0.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.        ]
xy shape: (29, 9)
[[0.         0.         0.         0.         0.36890481 1.
  1.         0.         0.        ]
 [1.         0.         0.         0.         0.37127811 1.
  0.         0.05470126 0.        ]
 [1.         1.         0.         0.         0.37084833 1.
  0.         0.         0.        ]
 [0.         1.         0.         0.         0.38353823 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.37423341 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37482827 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37477733 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37477829 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.3739956  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37403118 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37479656 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37415005 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37459963 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37417744 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37435458 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37495663 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37430289 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37475654 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37410932 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37454248 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37402539 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.3743464  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37437086 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37413968 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37497323 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37453281 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.3749794  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37437935 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37403858 1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.8571428656578064
#####################         POISON         ###############################################

############################################################################################

comm_round: 20 | global_test_acc: 88.889% | global_f1: 0.9411764705882353 | global_precision: 0.8888888888888888
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.89      1.00      0.94         8

    accuracy                           0.89         9
   macro avg       0.44      0.50      0.47         9
weighted avg       0.79      0.89      0.84         9

Accuracy per class:
[[8 0]
 [1 0]]
[1. 0.]
poison scaling shape: (29, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 29 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clients
y shape (29,)
[0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (29,)
[0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_fg shape (29,)
[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0.]
wv_mn shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ed shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_lg shape (29, 1)
[[0.37223507]
 [0.36660558]
 [0.37230219]
 [0.38362919]
 [0.37473642]
 [0.37485351]
 [0.3754824 ]
 [0.37522777]
 [0.37534603]
 [0.37505324]
 [0.37430149]
 [0.37474725]
 [0.3751731 ]
 [0.37541217]
 [0.37534975]
 [0.37510366]
 [0.37497374]
 [0.37571021]
 [0.37445652]
 [0.37526087]
 [0.37446327]
 [0.374941  ]
 [0.37436588]
 [0.37499289]
 [0.37494467]
 [0.37500043]
 [0.37521783]
 [0.37497354]
 [0.37485538]]
wv_jc shape (29,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ndT shape (29,)
[0.         0.         0.31003452 1.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_std shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
xy shape: (29, 9)
[[0.         0.         0.         0.         0.37223507 1.
  0.         0.         0.        ]
 [1.         0.         0.         0.         0.36660558 1.
  0.         0.         0.        ]
 [1.         0.         0.         0.         0.37230219 1.
  0.31003452 0.         0.        ]
 [0.         1.         0.         0.         0.38362919 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.37473642 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37485351 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.3754824  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37522777 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37534603 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37505324 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37430149 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37474725 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.3751731  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37541217 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37534975 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37510366 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37497374 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37571021 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37445652 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37526087 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37446327 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.374941   1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37436588 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37499289 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37494467 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37500043 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37521783 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37497354 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37485538 1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.8571428656578064
#####################         POISON         ###############################################

############################################################################################

comm_round: 21 | global_test_acc: 77.778% | global_f1: 0.8750000000000001 | global_precision: 0.7777777777777778
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.78      1.00      0.88         7

    accuracy                           0.78         9
   macro avg       0.39      0.50      0.44         9
weighted avg       0.60      0.78      0.68         9

Accuracy per class:
[[7 0]
 [2 0]]
[1. 0.]
poison scaling shape: (29, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 29 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clients
y shape (29,)
[0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (29,)
[0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_fg shape (29,)
[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0.]
wv_mn shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ed shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_lg shape (29, 1)
[[0.37038833]
 [0.37096732]
 [0.37333106]
 [0.37841891]
 [0.37591786]
 [0.37615619]
 [0.37559861]
 [0.37563356]
 [0.3756864 ]
 [0.37569341]
 [0.37538286]
 [0.37560114]
 [0.37601224]
 [0.37544036]
 [0.37528782]
 [0.37594501]
 [0.37555257]
 [0.37594868]
 [0.37669015]
 [0.37532543]
 [0.37555234]
 [0.37608877]
 [0.37594173]
 [0.37558502]
 [0.37584126]
 [0.37528989]
 [0.3749016 ]
 [0.37505377]
 [0.37564756]]
wv_jc shape (29,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ndT shape (29,)
[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0.]
wv_std shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
xy shape: (29, 9)
[[0.         0.         0.         0.         0.37038833 1.
  0.         0.         0.        ]
 [1.         0.         0.         0.         0.37096732 1.
  0.         0.         0.        ]
 [1.         0.         0.         0.         0.37333106 1.
  1.         0.         0.        ]
 [0.         1.         0.         0.         0.37841891 1.
  0.         0.         0.        ]
 [1.         0.         1.         1.         0.37591786 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37615619 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37559861 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37563356 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.3756864  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37569341 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37538286 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37560114 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37601224 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37544036 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37528782 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37594501 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37555257 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37594868 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37669015 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37532543 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37555234 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37608877 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37594173 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37558502 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37584126 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37528989 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.3749016  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37505377 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37564756 1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.7857142686843872
#####################         POISON         ###############################################

############################################################################################

comm_round: 22 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         9

    accuracy                           1.00         9
   macro avg       1.00      1.00      1.00         9
weighted avg       1.00      1.00      1.00         9

Accuracy per class:
[[9 0]
 [0 0]]
[ 1. nan]
poison scaling shape: (29, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 29 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clients
y shape (29,)
[0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (29,)
[1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_fg shape (29,)
[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0.]
wv_mn shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ed shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_lg shape (29, 1)
[[0.37375611]
 [0.37147815]
 [0.37004503]
 [0.38221676]
 [0.37607951]
 [0.37629918]
 [0.37657089]
 [0.37535103]
 [0.37587622]
 [0.37591997]
 [0.37608259]
 [0.37608127]
 [0.37647333]
 [0.37591059]
 [0.37571725]
 [0.37556765]
 [0.37636287]
 [0.37643219]
 [0.37619326]
 [0.37612213]
 [0.37595445]
 [0.37595835]
 [0.3764224 ]
 [0.37569022]
 [0.37582285]
 [0.37625459]
 [0.37611331]
 [0.37564903]
 [0.37572249]]
wv_jc shape (29,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ndT shape (29,)
[0.         1.         0.         1.         0.2981598  0.94069772
 0.84645504 0.03771799 0.         1.         0.58752555 0.
 0.         0.30942913 0.10817708 0.44297297 0.27256078 0.41364433
 0.31099559 0.83528144 0.43808895 0.         0.         0.34071049
 0.70689192 0.4580424  0.         0.93797382 0.49687932]
wv_std shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
xy shape: (29, 9)
[[1.         0.         0.         0.         0.37375611 1.
  0.         0.         0.        ]
 [1.         0.         0.         0.         0.37147815 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.37004503 1.
  0.         0.         0.        ]
 [0.         1.         0.         0.         0.38221676 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.37607951 1.
  0.2981598  1.         1.        ]
 [1.         0.         1.         1.         0.37629918 1.
  0.94069772 1.         1.        ]
 [1.         0.         1.         1.         0.37657089 1.
  0.84645504 1.         1.        ]
 [1.         0.         1.         1.         0.37535103 1.
  0.03771799 1.         1.        ]
 [1.         0.         1.         1.         0.37587622 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37591997 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.37608259 1.
  0.58752555 1.         1.        ]
 [1.         0.         1.         1.         0.37608127 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37647333 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37591059 1.
  0.30942913 1.         1.        ]
 [1.         0.         1.         1.         0.37571725 1.
  0.10817708 1.         1.        ]
 [1.         0.         1.         1.         0.37556765 1.
  0.44297297 1.         1.        ]
 [1.         0.         1.         1.         0.37636287 1.
  0.27256078 1.         1.        ]
 [1.         0.         1.         1.         0.37643219 1.
  0.41364433 1.         1.        ]
 [1.         0.         1.         1.         0.37619326 1.
  0.31099559 1.         1.        ]
 [1.         0.         1.         1.         0.37612213 1.
  0.83528144 1.         1.        ]
 [1.         0.         1.         1.         0.37595445 1.
  0.43808895 1.         1.        ]
 [1.         0.         1.         1.         0.37595835 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.3764224  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37569022 1.
  0.34071049 1.         1.        ]
 [1.         0.         1.         1.         0.37582285 1.
  0.70689192 1.         1.        ]
 [1.         0.         1.         1.         0.37625459 1.
  0.4580424  1.         1.        ]
 [1.         0.         1.         1.         0.37611331 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37564903 1.
  0.93797382 1.         1.        ]
 [1.         0.         1.         1.         0.37572249 1.
  0.49687932 1.         1.        ]]

Best Training Poisoning Accuracy:
0.7857142686843872
#####################         POISON         ###############################################

############################################################################################

comm_round: 23 | global_test_acc: 88.889% | global_f1: 0.9411764705882353 | global_precision: 0.8888888888888888
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.89      1.00      0.94         8

    accuracy                           0.89         9
   macro avg       0.44      0.50      0.47         9
weighted avg       0.79      0.89      0.84         9

Accuracy per class:
[[8 0]
 [1 0]]
[1. 0.]
poison scaling shape: (29, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 29 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clients
y shape (29,)
[0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (29,)
[0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_fg shape (29,)
[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0.]
wv_mn shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ed shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_lg shape (29, 1)
[[0.3744832 ]
 [0.36975349]
 [0.37058053]
 [0.38291513]
 [0.37652161]
 [0.37726485]
 [0.37646141]
 [0.37712147]
 [0.3771577 ]
 [0.37638938]
 [0.37710714]
 [0.37651034]
 [0.37701242]
 [0.37601054]
 [0.37647597]
 [0.37568168]
 [0.37724066]
 [0.37624628]
 [0.37633029]
 [0.37624876]
 [0.37665495]
 [0.37643388]
 [0.37648002]
 [0.37727083]
 [0.37636511]
 [0.3767908 ]
 [0.37673018]
 [0.37653678]
 [0.37679316]]
wv_jc shape (29,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ndT shape (29,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0.]
wv_std shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
xy shape: (29, 9)
[[0.         0.         0.         0.         0.3744832  1.
  1.         0.         0.        ]
 [1.         0.         0.         0.         0.36975349 1.
  0.         0.         0.        ]
 [1.         0.         0.         0.         0.37058053 1.
  0.         0.         0.        ]
 [0.         1.         0.         0.         0.38291513 1.
  0.         0.         0.        ]
 [1.         0.         1.         1.         0.37652161 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37726485 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37646141 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37712147 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.3771577  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37638938 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37710714 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37651034 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37701242 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37601054 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37647597 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37568168 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37724066 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37624628 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37633029 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37624876 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37665495 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37643388 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37648002 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37727083 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37636511 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.3767908  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37673018 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37653678 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37679316 1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.7857142686843872
#####################         POISON         ###############################################

############################################################################################

comm_round: 24 | global_test_acc: 88.889% | global_f1: 0.9411764705882353 | global_precision: 0.8888888888888888
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.89      1.00      0.94         8

    accuracy                           0.89         9
   macro avg       0.44      0.50      0.47         9
weighted avg       0.79      0.89      0.84         9

Accuracy per class:
[[8 0]
 [1 0]]
[1. 0.]
poison scaling shape: (29, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 29 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clients
y shape (29,)
[0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (29,)
[1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_fg shape (29,)
[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0.]
wv_mn shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ed shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_lg shape (29, 1)
[[0.37296591]
 [0.37213815]
 [0.37375548]
 [0.3804867 ]
 [0.37693365]
 [0.37697983]
 [0.37719288]
 [0.37713291]
 [0.37655732]
 [0.37708178]
 [0.37646649]
 [0.37632555]
 [0.37699699]
 [0.37731667]
 [0.37692241]
 [0.37702525]
 [0.3767595 ]
 [0.37764014]
 [0.37680922]
 [0.37642758]
 [0.37747727]
 [0.37718261]
 [0.37675136]
 [0.37688828]
 [0.37714123]
 [0.37683527]
 [0.37775488]
 [0.37762186]
 [0.37767509]]
wv_jc shape (29,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ndT shape (29,)
[0.         0.         0.45797698 0.         1.         1.
 0.         0.         0.         0.         0.         0.32258
 0.30469539 1.         1.         1.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.34512066 1.        ]
wv_std shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
xy shape: (29, 9)
[[1.         0.         0.         0.         0.37296591 1.
  0.         0.         0.        ]
 [1.         0.         0.         0.         0.37213815 1.
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.37375548 1.
  0.45797698 0.         0.        ]
 [0.         1.         0.         0.         0.3804867  1.
  0.         0.         0.        ]
 [1.         0.         1.         1.         0.37693365 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.37697983 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.37719288 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37713291 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37655732 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37708178 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37646649 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37632555 1.
  0.32258    1.         1.        ]
 [1.         0.         1.         1.         0.37699699 1.
  0.30469539 1.         1.        ]
 [1.         0.         1.         1.         0.37731667 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.37692241 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.37702525 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.3767595  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37764014 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37680922 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37642758 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37747727 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37718261 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37675136 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37688828 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37714123 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37683527 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37775488 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37762186 1.
  0.34512066 1.         1.        ]
 [1.         0.         1.         1.         0.37767509 1.
  1.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.9285714030265808
#####################         POISON         ###############################################

############################################################################################

comm_round: 25 | global_test_acc: 77.778% | global_f1: 0.8750000000000001 | global_precision: 0.7777777777777778
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.78      1.00      0.88         7

    accuracy                           0.78         9
   macro avg       0.39      0.50      0.44         9
weighted avg       0.60      0.78      0.68         9

Accuracy per class:
[[7 0]
 [2 0]]
[1. 0.]
poison scaling shape: (29, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 29 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clients
y shape (29,)
[0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (29,)
[1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_fg shape (29,)
[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0.]
wv_mn shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ed shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_lg shape (29, 1)
[[0.37545043]
 [0.37628569]
 [0.37255534]
 [0.38130316]
 [0.37776522]
 [0.37755355]
 [0.37725437]
 [0.37737736]
 [0.37675933]
 [0.37706054]
 [0.37684017]
 [0.37734797]
 [0.37679046]
 [0.37683258]
 [0.37735506]
 [0.37772495]
 [0.37748113]
 [0.37686335]
 [0.37738279]
 [0.37701884]
 [0.37762574]
 [0.37705105]
 [0.37734385]
 [0.37706069]
 [0.37725502]
 [0.37766183]
 [0.37743363]
 [0.37697101]
 [0.37775893]]
wv_jc shape (29,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ndT shape (29,)
[1.         0.         0.67721054 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_std shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
xy shape: (29, 9)
[[1.         0.         0.         0.         0.37545043 1.
  1.         0.         0.        ]
 [1.         0.         0.         0.         0.37628569 1.
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.37255534 1.
  0.67721054 0.         0.        ]
 [0.         1.         0.         0.         0.38130316 1.
  0.         0.         0.        ]
 [1.         0.         1.         1.         0.37776522 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37755355 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37725437 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37737736 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37675933 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37706054 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37684017 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37734797 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37679046 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37683258 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37735506 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37772495 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37748113 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37686335 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37738279 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37701884 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37762574 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37705105 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37734385 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37706069 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37725502 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37766183 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37743363 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37697101 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37775893 1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.9285714030265808
#####################         POISON         ###############################################

############################################################################################

comm_round: 26 | global_test_acc: 66.667% | global_f1: 0.8 | global_precision: 0.6666666666666666
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.67      1.00      0.80         6

    accuracy                           0.67         9
   macro avg       0.33      0.50      0.40         9
weighted avg       0.44      0.67      0.53         9

Accuracy per class:
[[6 0]
 [3 0]]
[1. 0.]
poison scaling shape: (29, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 29 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clients
y shape (29,)
[0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (29,)
[1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_fg shape (29,)
[0.        0.4992716 0.        1.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.       ]
wv_mn shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ed shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_lg shape (29, 1)
[[0.37422563]
 [0.37433776]
 [0.37507557]
 [0.38598517]
 [0.37786473]
 [0.37751792]
 [0.37765189]
 [0.37815408]
 [0.37726215]
 [0.37754449]
 [0.37764678]
 [0.37747573]
 [0.37802517]
 [0.37761385]
 [0.37765995]
 [0.37803819]
 [0.37750487]
 [0.3780486 ]
 [0.37751779]
 [0.37666294]
 [0.37691287]
 [0.37805516]
 [0.37760451]
 [0.37825148]
 [0.3778565 ]
 [0.37819639]
 [0.3785891 ]
 [0.37837859]
 [0.37762891]]
wv_jc shape (29,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ndT shape (29,)
[0.51750667 0.         1.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_std shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
xy shape: (29, 9)
[[1.         0.         0.         0.         0.37422563 1.
  0.51750667 0.         0.        ]
 [1.         0.4992716  0.         0.         0.37433776 1.
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.37507557 1.
  1.         0.         0.        ]
 [0.         1.         0.         0.         0.38598517 1.
  0.         0.         0.        ]
 [1.         0.         1.         1.         0.37786473 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37751792 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37765189 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37815408 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37726215 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37754449 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37764678 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37747573 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37802517 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37761385 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37765995 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37803819 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37750487 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.3780486  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37751779 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37666294 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37691287 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37805516 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37760451 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37825148 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.3778565  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37819639 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.3785891  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37837859 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37762891 1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
1.0
#####################         POISON         ###############################################

############################################################################################

comm_round: 27 | global_test_acc: 77.778% | global_f1: 0.8750000000000001 | global_precision: 0.7777777777777778
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.78      1.00      0.88         7

    accuracy                           0.78         9
   macro avg       0.39      0.50      0.44         9
weighted avg       0.60      0.78      0.68         9

Accuracy per class:
[[7 0]
 [2 0]]
[1. 0.]
poison scaling shape: (29, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 29 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clients
y shape (29,)
[0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (29,)
[0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_fg shape (29,)
[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0.]
wv_mn shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ed shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_lg shape (29, 1)
[[0.37753445]
 [0.3731369 ]
 [0.37153886]
 [0.3817112 ]
 [0.37821238]
 [0.37811788]
 [0.37835627]
 [0.37793029]
 [0.37788098]
 [0.37817934]
 [0.37822652]
 [0.37759885]
 [0.37817873]
 [0.37822639]
 [0.37792628]
 [0.37826588]
 [0.37859928]
 [0.37852139]
 [0.37810494]
 [0.37862809]
 [0.37901672]
 [0.37851725]
 [0.37811024]
 [0.37789029]
 [0.37854433]
 [0.37837837]
 [0.37793335]
 [0.37824284]
 [0.37823146]]
wv_jc shape (29,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ndT shape (29,)
[0.58498364 0.         1.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_std shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
xy shape: (29, 9)
[[0.         0.         0.         0.         0.37753445 1.
  0.58498364 0.         0.        ]
 [1.         0.         0.         0.         0.3731369  1.
  0.         0.         0.        ]
 [1.         0.         0.         0.         0.37153886 1.
  1.         0.         0.        ]
 [0.         1.         0.         0.         0.3817112  1.
  0.         0.         0.        ]
 [1.         0.         1.         1.         0.37821238 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37811788 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37835627 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37793029 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37788098 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37817934 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37822652 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37759885 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37817873 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37822639 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37792628 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37826588 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37859928 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37852139 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37810494 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37862809 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37901672 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37851725 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37811024 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37789029 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37854433 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37837837 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37793335 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37824284 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37823146 1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.9285714030265808
#####################         POISON         ###############################################

############################################################################################

comm_round: 28 | global_test_acc: 88.889% | global_f1: 0.9411764705882353 | global_precision: 0.8888888888888888
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.89      1.00      0.94         8

    accuracy                           0.89         9
   macro avg       0.44      0.50      0.47         9
weighted avg       0.79      0.89      0.84         9

Accuracy per class:
[[8 0]
 [1 0]]
[1. 0.]
poison scaling shape: (29, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 29 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clients
y shape (29,)
[0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (29,)
[1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_fg shape (29,)
[0.         0.         0.19004251 1.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_mn shape (29,)
[0.         0.20393967 0.         0.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.        ]
wv_ed shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_lg shape (29, 1)
[[0.37555961]
 [0.37562585]
 [0.37651946]
 [0.38204786]
 [0.3784944 ]
 [0.37860746]
 [0.37804352]
 [0.37868378]
 [0.37853975]
 [0.37893437]
 [0.37890991]
 [0.37912556]
 [0.3783738 ]
 [0.37903565]
 [0.37875637]
 [0.37848209]
 [0.37845568]
 [0.37946283]
 [0.37884083]
 [0.37882876]
 [0.37843447]
 [0.37906304]
 [0.37891502]
 [0.37802699]
 [0.37859008]
 [0.3793089 ]
 [0.37876337]
 [0.37895822]
 [0.37843553]]
wv_jc shape (29,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
wv_ndT shape (29,)
[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0.]
wv_std shape (29,)
[0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1.]
xy shape: (29, 9)
[[1.         0.         0.         0.         0.37555961 1.
  0.         0.         0.        ]
 [1.         0.         0.20393967 0.         0.37562585 1.
  0.         0.         0.        ]
 [0.         0.19004251 0.         0.         0.37651946 1.
  1.         0.         0.        ]
 [0.         1.         0.         0.         0.38204786 1.
  0.         0.         0.        ]
 [1.         0.         1.         1.         0.3784944  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37860746 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37804352 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37868378 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37853975 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37893437 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37890991 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37912556 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.3783738  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37903565 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37875637 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37848209 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37845568 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37946283 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37884083 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37882876 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37843447 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37906304 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37891502 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37802699 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37859008 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.3793089  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37876337 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37895822 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.37843553 1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.9285714030265808
#####################         POISON         ###############################################

############################################################################################

comm_round: 29 | global_test_acc: 66.667% | global_f1: 0.8 | global_precision: 0.6666666666666666
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.67      1.00      0.80         6

    accuracy                           0.67         9
   macro avg       0.33      0.50      0.40         9
weighted avg       0.44      0.67      0.53         9

Accuracy per class:
[[6 0]
 [3 0]]
[1. 0.]
poison scaling shape: (29, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 29 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clients