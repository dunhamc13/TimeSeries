
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[0.14388936 1.         1.         0.34295388 0.         0.52713699
 0.         1.         0.1735639  0.51500315 0.         1.
 0.93625939 0.22029187 0.         1.         0.48095425 0.06489295
 0.9158433  0.         0.         0.79254358 1.         1.
 0.         0.         1.         1.         0.79121084 0.48394988
 0.         0.05153871 0.         1.         1.        ]
wv_fg shape (35,)
[0.         0.08079722 0.         0.         0.         0.27818516
 0.         0.43612487 1.         1.         0.         0.
 0.         0.         0.80924603 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_mn shape (35,)
[0.10387251 1.         0.93835511 0.10989002 0.01051147 0.40580946
 0.         1.         0.15076947 0.59477542 0.         1.
 0.77759246 0.11412596 0.         1.         0.39140985 0.
 0.67510213 0.         0.         0.44681742 1.         1.
 0.         0.         1.         1.         0.42333048 0.32355002
 0.         0.01760798 0.         1.         1.        ]
wv_ed shape (35,)
[0.15772876 1.         0.8269669  0.14224955 0.07196616 0.04510996
 0.         1.         0.3042489  0.68402317 0.         1.
 0.81205576 0.1335807  0.         1.         0.39093902 0.01554575
 0.71977544 0.         0.         0.4492145  1.         1.
 0.         0.         0.95907214 1.         0.4310108  0.34753906
 0.         0.10850901 0.         0.98415485 1.        ]
wv_lg shape (35, 1)
[[0.35730901]
 [0.35709383]
 [0.3572654 ]
 [0.35729574]
 [0.35733174]
 [0.35711498]
 [0.35735011]
 [0.35723797]
 [0.35708065]
 [0.35739037]
 [0.35634227]
 [0.35643168]
 [0.35629527]
 [0.35638499]
 [0.35643612]
 [0.35646609]
 [0.35637622]
 [0.35633559]
 [0.35641901]
 [0.35626104]
 [0.35633966]
 [0.35648245]
 [0.35628476]
 [0.3564293 ]
 [0.35637962]
 [0.35634284]
 [0.35647015]
 [0.35641681]
 [0.35644093]
 [0.35654352]
 [0.35631825]
 [0.35630707]
 [0.35632568]
 [0.35632282]
 [0.35647244]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[1.         1.         1.         1.         0.96779889 1.
 1.         1.         1.         1.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_std shape (35,)
[0.         0.86659532 0.51590235 0.         0.         0.69295265
 0.         1.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         1.        ]
xy shape: (35, 9)
[[0.14388936 0.         0.10387251 0.15772876 0.35730901 1.
  1.         0.         0.        ]
 [1.         0.08079722 1.         1.         0.35709383 1.
  1.         0.86659532 0.        ]
 [1.         0.         0.93835511 0.8269669  0.3572654  1.
  1.         0.51590235 0.        ]
 [0.34295388 0.         0.10989002 0.14224955 0.35729574 1.
  1.         0.         0.        ]
 [0.         0.         0.01051147 0.07196616 0.35733174 1.
  0.96779889 0.         0.        ]
 [0.52713699 0.27818516 0.40580946 0.04510996 0.35711498 1.
  1.         0.69295265 0.        ]
 [0.         0.         0.         0.         0.35735011 1.
  1.         0.         0.        ]
 [1.         0.43612487 1.         1.         0.35723797 1.
  1.         1.         0.        ]
 [0.1735639  1.         0.15076947 0.3042489  0.35708065 1.
  1.         0.         0.        ]
 [0.51500315 1.         0.59477542 0.68402317 0.35739037 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.35634227 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35643168 1.
  0.         0.         1.        ]
 [0.93625939 0.         0.77759246 0.81205576 0.35629527 1.
  0.         0.         1.        ]
 [0.22029187 0.         0.11412596 0.1335807  0.35638499 1.
  0.         0.         1.        ]
 [0.         0.80924603 0.         0.         0.35643612 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35646609 1.
  0.         0.         1.        ]
 [0.48095425 0.         0.39140985 0.39093902 0.35637622 1.
  0.         0.         1.        ]
 [0.06489295 0.         0.         0.01554575 0.35633559 1.
  0.         0.         1.        ]
 [0.9158433  0.         0.67510213 0.71977544 0.35641901 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35626104 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35633966 1.
  0.         0.         1.        ]
 [0.79254358 0.         0.44681742 0.4492145  0.35648245 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35628476 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.3564293  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35637962 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35634284 1.
  0.         0.         1.        ]
 [1.         0.         1.         0.95907214 0.35647015 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35641681 1.
  0.         0.         1.        ]
 [0.79121084 0.         0.42333048 0.4310108  0.35644093 1.
  0.         0.         1.        ]
 [0.48394988 0.         0.32355002 0.34753906 0.35654352 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35631825 1.
  0.         0.         1.        ]
 [0.05153871 0.         0.01760798 0.10850901 0.35630707 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35632568 1.
  0.         0.         1.        ]
 [1.         0.         1.         0.98415485 0.35632282 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35647244 1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.625
#####################         POISON         ###############################################

############################################################################################

comm_round: 0 | global_test_acc: 75.000% | global_f1: 0.8571428571428571 | global_precision: 0.75
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.75      1.00      0.86         9

    accuracy                           0.75        12
   macro avg       0.38      0.50      0.43        12
weighted avg       0.56      0.75      0.64        12

Accuracy per class:
[[9 0]
 [3 0]]
[1. 0.]
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[0.18649382 0.         1.         0.6514162  1.         1.
 0.86313685 0.8938213  0.45745513 1.         1.         0.70744198
 0.4206638  0.44437814 0.1810337  0.34783717 0.68882287 0.54615694
 0.03008641 0.15509195 0.57123362 0.57069477 1.         1.
 0.         0.59234852 0.61472985 0.71181564 1.         0.38195064
 0.32337063 1.         1.         0.         0.37408821]
wv_fg shape (35,)
[0.         0.49308374 1.         0.         0.         0.
 0.         1.         1.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_mn shape (35,)
[0.         0.         1.         0.48153106 0.94576839 0.79571275
 0.4304442  0.57620222 0.14145099 1.         0.74716434 0.51815244
 0.18388471 0.23066314 0.         0.08827711 0.37203893 0.3451428
 0.         0.         0.2637511  0.34522626 0.85820674 1.
 0.         0.3218109  0.42203573 0.51096904 1.         0.11632402
 0.03742086 1.         1.         0.         0.11825624]
wv_ed shape (35,)
[0.         0.         1.         0.50095665 0.9160265  0.8514446
 0.31780277 0.64858442 0.         1.         0.68707993 0.5282649
 0.04871745 0.15251591 0.         0.10635673 0.33048464 0.31261866
 0.         0.         0.20324569 0.25984693 0.76082839 1.
 0.         0.30846749 0.40564652 0.60735356 1.         0.
 0.09807535 1.         1.         0.         0.09051647]
wv_lg shape (35, 1)
[[0.35774863]
 [0.35763953]
 [0.35740963]
 [0.35766476]
 [0.35762213]
 [0.35770224]
 [0.35763966]
 [0.35746334]
 [0.35746825]
 [0.35761362]
 [0.3566835 ]
 [0.35668633]
 [0.3567679 ]
 [0.35674554]
 [0.35673537]
 [0.35668376]
 [0.35680315]
 [0.35659298]
 [0.35672057]
 [0.35666677]
 [0.35683271]
 [0.35673118]
 [0.35675929]
 [0.35675873]
 [0.35663869]
 [0.35676211]
 [0.35670473]
 [0.35675092]
 [0.35670237]
 [0.35675096]
 [0.35671811]
 [0.35674639]
 [0.35680327]
 [0.35670939]
 [0.35677822]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
wv_std shape (35,)
[0.45978483 0.         1.         0.48605011 1.         0.90184269
 0.9532638  0.26526834 1.         1.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         1.         0.         0.         0.        ]
xy shape: (35, 9)
[[0.18649382 0.         0.         0.         0.35774863 1.
  1.         0.45978483 0.        ]
 [0.         0.49308374 0.         0.         0.35763953 1.
  1.         0.         0.        ]
 [1.         1.         1.         1.         0.35740963 1.
  1.         1.         0.        ]
 [0.6514162  0.         0.48153106 0.50095665 0.35766476 1.
  1.         0.48605011 0.        ]
 [1.         0.         0.94576839 0.9160265  0.35762213 1.
  1.         1.         0.        ]
 [1.         0.         0.79571275 0.8514446  0.35770224 1.
  1.         0.90184269 0.        ]
 [0.86313685 0.         0.4304442  0.31780277 0.35763966 1.
  1.         0.9532638  0.        ]
 [0.8938213  1.         0.57620222 0.64858442 0.35746334 1.
  1.         0.26526834 0.        ]
 [0.45745513 1.         0.14145099 0.         0.35746825 1.
  1.         1.         0.        ]
 [1.         0.         1.         1.         0.35761362 1.
  1.         1.         0.        ]
 [1.         0.         0.74716434 0.68707993 0.3566835  1.
  0.         0.         1.        ]
 [0.70744198 0.         0.51815244 0.5282649  0.35668633 1.
  0.         0.         1.        ]
 [0.4206638  0.         0.18388471 0.04871745 0.3567679  1.
  0.         0.         1.        ]
 [0.44437814 0.         0.23066314 0.15251591 0.35674554 1.
  0.         0.         1.        ]
 [0.1810337  0.         0.         0.         0.35673537 1.
  0.         0.         1.        ]
 [0.34783717 0.         0.08827711 0.10635673 0.35668376 1.
  0.         0.         1.        ]
 [0.68882287 0.         0.37203893 0.33048464 0.35680315 1.
  0.         0.         1.        ]
 [0.54615694 0.         0.3451428  0.31261866 0.35659298 1.
  0.         0.         1.        ]
 [0.03008641 0.         0.         0.         0.35672057 1.
  0.         0.         1.        ]
 [0.15509195 0.         0.         0.         0.35666677 1.
  0.         0.         1.        ]
 [0.57123362 0.         0.2637511  0.20324569 0.35683271 1.
  0.         0.         1.        ]
 [0.57069477 0.         0.34522626 0.25984693 0.35673118 1.
  0.         0.         1.        ]
 [1.         0.         0.85820674 0.76082839 0.35675929 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35675873 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35663869 1.
  0.         0.         1.        ]
 [0.59234852 0.         0.3218109  0.30846749 0.35676211 1.
  0.         0.         1.        ]
 [0.61472985 0.         0.42203573 0.40564652 0.35670473 1.
  0.         0.         1.        ]
 [0.71181564 0.         0.51096904 0.60735356 0.35675092 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35670237 1.
  0.         0.         1.        ]
 [0.38195064 0.         0.11632402 0.         0.35675096 1.
  0.         0.         1.        ]
 [0.32337063 0.         0.03742086 0.09807535 0.35671811 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35674639 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.35680327 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35670939 1.
  0.         0.         1.        ]
 [0.37408821 0.         0.11825624 0.09051647 0.35677822 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.875
#####################         POISON         ###############################################

############################################################################################

comm_round: 1 | global_test_acc: 58.333% | global_f1: 0.7368421052631579 | global_precision: 0.5833333333333334
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         5
           1       0.58      1.00      0.74         7

    accuracy                           0.58        12
   macro avg       0.29      0.50      0.37        12
weighted avg       0.34      0.58      0.43        12

Accuracy per class:
[[7 0]
 [5 0]]
[1. 0.]
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[0.         0.46381018 0.83619619 0.         0.         1.
 1.         0.84010826 1.         1.         1.         0.39127298
 1.         0.7797583  1.         0.         0.01024799 1.
 0.4644653  1.         0.0524089  0.24578095 0.21759061 0.34765189
 0.         0.01438255 0.         1.         0.81833959 0.63706644
 0.         0.68310981 0.         0.24360363 1.        ]
wv_fg shape (35,)
[1.         0.         0.15892532 0.         1.         0.55927265
 0.         0.15892532 0.55927265 0.81043057 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_mn shape (35,)
[0.         0.17653232 0.5647308  0.         0.         1.
 1.         0.59590748 1.         1.         0.9360385  0.08553798
 1.         0.46858515 0.68055629 0.         0.         1.
 0.20402524 1.         0.         0.         0.         0.
 0.         0.         0.         0.81451352 0.42593597 0.24437272
 0.         0.28962313 0.         0.         0.56227966]
wv_ed shape (35,)
[0.         0.26948274 0.60703828 0.         0.         1.
 1.         0.63280195 1.         1.         0.80356755 0.06583304
 1.         0.42583741 0.69358007 0.         0.         1.
 0.16962464 0.98022345 0.         0.         0.         0.
 0.         0.         0.         0.72019694 0.34553793 0.28997868
 0.         0.36488309 0.         0.         0.54992037]
wv_lg shape (35, 1)
[[0.35802347]
 [0.35802422]
 [0.35791996]
 [0.35803931]
 [0.35810386]
 [0.35806226]
 [0.35799653]
 [0.3580163 ]
 [0.3580413 ]
 [0.35798185]
 [0.35727119]
 [0.3571642 ]
 [0.35720108]
 [0.35736043]
 [0.35726357]
 [0.35722204]
 [0.35715626]
 [0.35725076]
 [0.35722366]
 [0.35727629]
 [0.35715522]
 [0.35720007]
 [0.35716676]
 [0.35721943]
 [0.35718099]
 [0.35726943]
 [0.35719358]
 [0.35718915]
 [0.35726136]
 [0.35727769]
 [0.35715473]
 [0.35726567]
 [0.35727524]
 [0.35711558]
 [0.35727288]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[1.         1.         1.         0.88589775 1.         1.
 1.         1.         0.59725684 0.4658175  0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_std shape (35,)
[0.         0.         0.07125353 0.         0.         1.
 0.23806704 0.         1.         0.52543812 0.         0.
 1.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
xy shape: (35, 9)
[[0.         1.         0.         0.         0.35802347 1.
  1.         0.         0.        ]
 [0.46381018 0.         0.17653232 0.26948274 0.35802422 1.
  1.         0.         0.        ]
 [0.83619619 0.15892532 0.5647308  0.60703828 0.35791996 1.
  1.         0.07125353 0.        ]
 [0.         0.         0.         0.         0.35803931 1.
  0.88589775 0.         0.        ]
 [0.         1.         0.         0.         0.35810386 1.
  1.         0.         0.        ]
 [1.         0.55927265 1.         1.         0.35806226 1.
  1.         1.         0.        ]
 [1.         0.         1.         1.         0.35799653 1.
  1.         0.23806704 0.        ]
 [0.84010826 0.15892532 0.59590748 0.63280195 0.3580163  1.
  1.         0.         0.        ]
 [1.         0.55927265 1.         1.         0.3580413  1.
  0.59725684 1.         0.        ]
 [1.         0.81043057 1.         1.         0.35798185 1.
  0.4658175  0.52543812 0.        ]
 [1.         0.         0.9360385  0.80356755 0.35727119 1.
  0.         0.         1.        ]
 [0.39127298 0.         0.08553798 0.06583304 0.3571642  1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35720108 1.
  0.         1.         1.        ]
 [0.7797583  0.         0.46858515 0.42583741 0.35736043 1.
  0.         0.         1.        ]
 [1.         0.         0.68055629 0.69358007 0.35726357 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35722204 1.
  0.         0.         1.        ]
 [0.01024799 0.         0.         0.         0.35715626 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35725076 1.
  0.         0.         1.        ]
 [0.4644653  0.         0.20402524 0.16962464 0.35722366 1.
  0.         0.         1.        ]
 [1.         0.         1.         0.98022345 0.35727629 1.
  0.         0.         1.        ]
 [0.0524089  0.         0.         0.         0.35715522 1.
  0.         0.         1.        ]
 [0.24578095 0.         0.         0.         0.35720007 1.
  0.         0.         1.        ]
 [0.21759061 0.         0.         0.         0.35716676 1.
  0.         0.         1.        ]
 [0.34765189 0.         0.         0.         0.35721943 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35718099 1.
  0.         0.         1.        ]
 [0.01438255 0.         0.         0.         0.35726943 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35719358 1.
  0.         0.         1.        ]
 [1.         0.         0.81451352 0.72019694 0.35718915 1.
  0.         0.         1.        ]
 [0.81833959 0.         0.42593597 0.34553793 0.35726136 1.
  0.         0.         1.        ]
 [0.63706644 0.         0.24437272 0.28997868 0.35727769 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35715473 1.
  0.         0.         1.        ]
 [0.68310981 0.         0.28962313 0.36488309 0.35726567 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35727524 1.
  0.         0.         1.        ]
 [0.24360363 0.         0.         0.         0.35711558 1.
  0.         0.         1.        ]
 [1.         0.         0.56227966 0.54992037 0.35727288 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.6875
#####################         POISON         ###############################################

############################################################################################

comm_round: 2 | global_test_acc: 66.667% | global_f1: 0.8 | global_precision: 0.6666666666666666
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         4
           1       0.67      1.00      0.80         8

    accuracy                           0.67        12
   macro avg       0.33      0.50      0.40        12
weighted avg       0.44      0.67      0.53        12

Accuracy per class:
[[8 0]
 [4 0]]
[1. 0.]
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[1.         1.         0.         0.12773069 1.         1.
 1.         1.         0.         1.         0.65797917 0.
 0.85984897 0.88043482 0.         0.84361408 0.         0.
 0.         1.         0.         1.         0.         0.
 0.76082636 0.70556844 0.65695793 0.67267274 1.         0.
 0.69313907 0.76216772 0.         0.         0.99382638]
wv_fg shape (35,)
[0.         0.48382701 0.24668005 0.24668005 0.23353846 0.
 0.         0.         1.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_mn shape (35,)
[1.         1.         0.         0.         1.         0.72112068
 1.         1.         0.         1.         0.02605125 0.
 0.34001631 0.36798094 0.         0.34772422 0.         0.
 0.         0.90269734 0.         0.88418485 0.         0.
 0.19442321 0.04216147 0.         0.         0.65533466 0.
 0.         0.10800559 0.         0.         0.60680812]
wv_ed shape (35,)
[1.         1.         0.         0.         1.         0.66092104
 1.         1.         0.         1.         0.         0.
 0.2716784  0.37683492 0.         0.37281664 0.         0.
 0.         0.87186314 0.         0.76563852 0.         0.
 0.19100025 0.07402616 0.         0.         0.65220814 0.
 0.         0.01116554 0.         0.         0.61867373]
wv_lg shape (35, 1)
[[0.35839635]
 [0.35848675]
 [0.35835219]
 [0.35839586]
 [0.35847558]
 [0.35845369]
 [0.35833444]
 [0.35849371]
 [0.35837675]
 [0.35840151]
 [0.35757897]
 [0.35774338]
 [0.35761812]
 [0.35768233]
 [0.35764353]
 [0.35758299]
 [0.35769231]
 [0.35760088]
 [0.35761408]
 [0.35763941]
 [0.35757286]
 [0.35758887]
 [0.35757866]
 [0.35758929]
 [0.35762561]
 [0.35759769]
 [0.35760669]
 [0.35758989]
 [0.35764898]
 [0.35767627]
 [0.35765736]
 [0.3576925 ]
 [0.35756218]
 [0.35750245]
 [0.35755968]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[0.69599155 1.         1.         1.         1.         1.
 0.98259403 1.         1.         1.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_std shape (35,)
[1.         1.         0.         0.         1.         0.51667968
 1.         1.         0.         1.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
xy shape: (35, 9)
[[1.         0.         1.         1.         0.35839635 1.
  0.69599155 1.         0.        ]
 [1.         0.48382701 1.         1.         0.35848675 1.
  1.         1.         0.        ]
 [0.         0.24668005 0.         0.         0.35835219 1.
  1.         0.         0.        ]
 [0.12773069 0.24668005 0.         0.         0.35839586 1.
  1.         0.         0.        ]
 [1.         0.23353846 1.         1.         0.35847558 1.
  1.         1.         0.        ]
 [1.         0.         0.72112068 0.66092104 0.35845369 1.
  1.         0.51667968 0.        ]
 [1.         0.         1.         1.         0.35833444 1.
  0.98259403 1.         0.        ]
 [1.         0.         1.         1.         0.35849371 1.
  1.         1.         0.        ]
 [0.         1.         0.         0.         0.35837675 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.35840151 1.
  1.         1.         0.        ]
 [0.65797917 0.         0.02605125 0.         0.35757897 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35774338 1.
  0.         0.         1.        ]
 [0.85984897 0.         0.34001631 0.2716784  0.35761812 1.
  0.         0.         1.        ]
 [0.88043482 0.         0.36798094 0.37683492 0.35768233 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35764353 1.
  0.         0.         1.        ]
 [0.84361408 0.         0.34772422 0.37281664 0.35758299 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35769231 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35760088 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35761408 1.
  0.         0.         1.        ]
 [1.         0.         0.90269734 0.87186314 0.35763941 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35757286 1.
  0.         0.         1.        ]
 [1.         0.         0.88418485 0.76563852 0.35758887 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35757866 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35758929 1.
  0.         0.         1.        ]
 [0.76082636 0.         0.19442321 0.19100025 0.35762561 1.
  0.         0.         1.        ]
 [0.70556844 0.         0.04216147 0.07402616 0.35759769 1.
  0.         0.         1.        ]
 [0.65695793 0.         0.         0.         0.35760669 1.
  0.         0.         1.        ]
 [0.67267274 0.         0.         0.         0.35758989 1.
  0.         0.         1.        ]
 [1.         0.         0.65533466 0.65220814 0.35764898 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35767627 1.
  0.         0.         1.        ]
 [0.69313907 0.         0.         0.         0.35765736 1.
  0.         0.         1.        ]
 [0.76216772 0.         0.10800559 0.01116554 0.3576925  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35756218 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35750245 1.
  0.         0.         1.        ]
 [0.99382638 0.         0.60680812 0.61867373 0.35755968 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.75
#####################         POISON         ###############################################

############################################################################################

comm_round: 3 | global_test_acc: 83.333% | global_f1: 0.9090909090909091 | global_precision: 0.8333333333333334
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.83      1.00      0.91        10

    accuracy                           0.83        12
   macro avg       0.42      0.50      0.45        12
weighted avg       0.69      0.83      0.76        12

Accuracy per class:
[[10  0]
 [ 2  0]]
[1. 0.]
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[0.62888961 1.         0.         1.         1.         1.
 1.         1.         1.         1.         0.33763266 0.55026186
 0.05806437 0.21669455 1.         0.24211729 0.4196593  0.
 0.         0.88783671 0.31580142 0.27274366 0.42349839 0.84830251
 0.44428458 0.         0.         0.         1.         0.12694589
 1.         0.29732517 1.         0.55239779 0.44789925]
wv_fg shape (35,)
[0.         0.11796965 1.         0.         0.01354906 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_mn shape (35,)
[0.47794336 1.         0.         1.         1.         1.
 1.         1.         1.         1.         0.07248908 0.42236012
 0.         0.         1.         0.         0.15806348 0.
 0.         0.70449099 0.         0.         0.28604352 0.65177076
 0.22637834 0.         0.         0.         1.         0.
 1.         0.         0.98755358 0.44904416 0.32498989]
wv_ed shape (35,)
[0.60025104 1.         0.         1.         1.         1.
 1.         1.         1.         1.         0.24897628 0.39201986
 0.         0.         1.         0.         0.18847639 0.
 0.         0.73982817 0.         0.02465466 0.45550088 0.7195054
 0.27743821 0.         0.         0.         1.         0.
 1.         0.06209523 1.         0.53632803 0.50569045]
wv_lg shape (35, 1)
[[0.35876314]
 [0.35876341]
 [0.35894728]
 [0.35878262]
 [0.3588088 ]
 [0.35880962]
 [0.35880799]
 [0.35872382]
 [0.35879192]
 [0.35875092]
 [0.35806698]
 [0.35800147]
 [0.35795706]
 [0.35796403]
 [0.35802523]
 [0.35797432]
 [0.35800655]
 [0.35789553]
 [0.35800674]
 [0.35798112]
 [0.35806899]
 [0.35799382]
 [0.35811358]
 [0.3579949 ]
 [0.35797494]
 [0.35789195]
 [0.35800582]
 [0.35792874]
 [0.35815519]
 [0.35794945]
 [0.35811448]
 [0.35804588]
 [0.35798905]
 [0.35803192]
 [0.3581169 ]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[1.         1.         1.         1.         1.         1.
 1.         0.84965615 1.         1.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_std shape (35,)
[0.47980497 1.         0.         0.52530063 1.         0.54936601
 0.80454466 1.         0.1274382  0.46010867 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.94336049 0.         0.         0.         0.        ]
xy shape: (35, 9)
[[0.62888961 0.         0.47794336 0.60025104 0.35876314 1.
  1.         0.47980497 0.        ]
 [1.         0.11796965 1.         1.         0.35876341 1.
  1.         1.         0.        ]
 [0.         1.         0.         0.         0.35894728 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.35878262 1.
  1.         0.52530063 0.        ]
 [1.         0.01354906 1.         1.         0.3588088  1.
  1.         1.         0.        ]
 [1.         0.         1.         1.         0.35880962 1.
  1.         0.54936601 0.        ]
 [1.         0.         1.         1.         0.35880799 1.
  1.         0.80454466 0.        ]
 [1.         0.         1.         1.         0.35872382 1.
  0.84965615 1.         0.        ]
 [1.         0.         1.         1.         0.35879192 1.
  1.         0.1274382  0.        ]
 [1.         0.         1.         1.         0.35875092 1.
  1.         0.46010867 0.        ]
 [0.33763266 0.         0.07248908 0.24897628 0.35806698 1.
  0.         0.         1.        ]
 [0.55026186 0.         0.42236012 0.39201986 0.35800147 1.
  0.         0.         1.        ]
 [0.05806437 0.         0.         0.         0.35795706 1.
  0.         0.         1.        ]
 [0.21669455 0.         0.         0.         0.35796403 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35802523 1.
  0.         0.         1.        ]
 [0.24211729 0.         0.         0.         0.35797432 1.
  0.         0.         1.        ]
 [0.4196593  0.         0.15806348 0.18847639 0.35800655 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35789553 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35800674 1.
  0.         0.         1.        ]
 [0.88783671 0.         0.70449099 0.73982817 0.35798112 1.
  0.         0.         1.        ]
 [0.31580142 0.         0.         0.         0.35806899 1.
  0.         0.         1.        ]
 [0.27274366 0.         0.         0.02465466 0.35799382 1.
  0.         0.         1.        ]
 [0.42349839 0.         0.28604352 0.45550088 0.35811358 1.
  0.         0.         1.        ]
 [0.84830251 0.         0.65177076 0.7195054  0.3579949  1.
  0.         0.         1.        ]
 [0.44428458 0.         0.22637834 0.27743821 0.35797494 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35789195 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35800582 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35792874 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35815519 1.
  0.         0.         1.        ]
 [0.12694589 0.         0.         0.         0.35794945 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35811448 1.
  0.         0.94336049 1.        ]
 [0.29732517 0.         0.         0.06209523 0.35804588 1.
  0.         0.         1.        ]
 [1.         0.         0.98755358 1.         0.35798905 1.
  0.         0.         1.        ]
 [0.55239779 0.         0.44904416 0.53632803 0.35803192 1.
  0.         0.         1.        ]
 [0.44789925 0.         0.32498989 0.50569045 0.3581169  1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.5625
#####################         POISON         ###############################################

############################################################################################

comm_round: 4 | global_test_acc: 91.667% | global_f1: 0.9565217391304348 | global_precision: 0.9166666666666666
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.92      1.00      0.96        11

    accuracy                           0.92        12
   macro avg       0.46      0.50      0.48        12
weighted avg       0.84      0.92      0.88        12

Accuracy per class:
[[11  0]
 [ 1  0]]
[1. 0.]
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[1.         0.         1.         1.         0.6898335  1.
 0.         1.         1.         0.         0.         0.20045978
 1.         1.         0.         1.         1.         0.
 0.43717708 0.1887708  0.         0.53746371 0.63268895 0.5836092
 0.         0.35701918 0.48381478 1.         0.45888033 0.
 1.         0.96338463 0.16698645 0.         0.25674127]
wv_fg shape (35,)
[1.         0.05070219 0.47386279 1.         0.         0.
 1.         0.         0.         1.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_mn shape (35,)
[1.         0.         1.         1.         0.72082564 1.
 0.         1.         1.         0.         0.         0.
 1.         1.         0.         1.         1.         0.
 0.26652938 0.         0.         0.57937616 0.66689682 0.64368378
 0.         0.1063547  0.3404018  0.9082953  0.32837168 0.
 1.         0.72008653 0.         0.         0.        ]
wv_ed shape (35,)
[1.         0.         1.         1.         0.81041154 1.
 0.         1.         1.         0.         0.         0.
 1.         1.         0.         1.         1.         0.
 0.36562436 0.         0.         0.65883519 0.67356104 0.74869155
 0.         0.18535086 0.32071449 0.90556363 0.34347122 0.
 1.         0.74304902 0.         0.         0.        ]
wv_lg shape (35, 1)
[[0.35916965]
 [0.35924789]
 [0.35911766]
 [0.35917853]
 [0.35919806]
 [0.35912738]
 [0.35900691]
 [0.3591187 ]
 [0.35909455]
 [0.35914386]
 [0.35827299]
 [0.35831443]
 [0.35837336]
 [0.35838491]
 [0.35829401]
 [0.3583882 ]
 [0.35825647]
 [0.35839426]
 [0.35836707]
 [0.3583607 ]
 [0.35834131]
 [0.35844669]
 [0.35832887]
 [0.35837226]
 [0.35830416]
 [0.35833307]
 [0.35832682]
 [0.35833477]
 [0.35832926]
 [0.35830618]
 [0.35832835]
 [0.3583884 ]
 [0.35826578]
 [0.35837992]
 [0.35826818]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[1.         1.         1.         1.         0.9761769  1.
 1.         1.         0.95761266 1.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_std shape (35,)
[1.         0.         1.         1.         0.18381439 1.
 0.         1.         1.         0.04956165 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
xy shape: (35, 9)
[[1.         1.         1.         1.         0.35916965 1.
  1.         1.         0.        ]
 [0.         0.05070219 0.         0.         0.35924789 1.
  1.         0.         0.        ]
 [1.         0.47386279 1.         1.         0.35911766 1.
  1.         1.         0.        ]
 [1.         1.         1.         1.         0.35917853 1.
  1.         1.         0.        ]
 [0.6898335  0.         0.72082564 0.81041154 0.35919806 1.
  0.9761769  0.18381439 0.        ]
 [1.         0.         1.         1.         0.35912738 1.
  1.         1.         0.        ]
 [0.         1.         0.         0.         0.35900691 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.3591187  1.
  1.         1.         0.        ]
 [1.         0.         1.         1.         0.35909455 1.
  0.95761266 1.         0.        ]
 [0.         1.         0.         0.         0.35914386 1.
  1.         0.04956165 0.        ]
 [0.         0.         0.         0.         0.35827299 1.
  0.         0.         1.        ]
 [0.20045978 0.         0.         0.         0.35831443 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35837336 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35838491 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35829401 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.3583882  1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35825647 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35839426 1.
  0.         0.         1.        ]
 [0.43717708 0.         0.26652938 0.36562436 0.35836707 1.
  0.         0.         1.        ]
 [0.1887708  0.         0.         0.         0.3583607  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35834131 1.
  0.         0.         1.        ]
 [0.53746371 0.         0.57937616 0.65883519 0.35844669 1.
  0.         0.         1.        ]
 [0.63268895 0.         0.66689682 0.67356104 0.35832887 1.
  0.         0.         1.        ]
 [0.5836092  0.         0.64368378 0.74869155 0.35837226 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35830416 1.
  0.         0.         1.        ]
 [0.35701918 0.         0.1063547  0.18535086 0.35833307 1.
  0.         0.         1.        ]
 [0.48381478 0.         0.3404018  0.32071449 0.35832682 1.
  0.         0.         1.        ]
 [1.         0.         0.9082953  0.90556363 0.35833477 1.
  0.         0.         1.        ]
 [0.45888033 0.         0.32837168 0.34347122 0.35832926 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35830618 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35832835 1.
  0.         0.         1.        ]
 [0.96338463 0.         0.72008653 0.74304902 0.3583884  1.
  0.         0.         1.        ]
 [0.16698645 0.         0.         0.         0.35826578 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35837992 1.
  0.         0.         1.        ]
 [0.25674127 0.         0.         0.         0.35826818 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.75
#####################         POISON         ###############################################

############################################################################################

comm_round: 5 | global_test_acc: 75.000% | global_f1: 0.8571428571428571 | global_precision: 0.75
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.75      1.00      0.86         9

    accuracy                           0.75        12
   macro avg       0.38      0.50      0.43        12
weighted avg       0.56      0.75      0.64        12

Accuracy per class:
[[9 0]
 [3 0]]
[1. 0.]
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[0.         1.         0.57230171 1.         1.         0.21625446
 1.         0.         1.         0.99278173 0.31684818 0.90459471
 0.35472383 1.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         1.
 0.10429931 0.         0.         0.95404611 0.         1.
 0.         0.         0.         0.89987716 0.        ]
wv_fg shape (35,)
[0.50393003 0.         0.         0.         0.26363068 0.
 0.         0.4294067  0.         1.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_mn shape (35,)
[0.         1.         0.60263656 1.         1.         0.31020651
 1.         0.         1.         1.         0.30720973 1.
 0.5215787  1.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         1.
 0.15889839 0.         0.         1.         0.         1.
 0.         0.         0.         0.91386557 0.        ]
wv_ed shape (35,)
[0.         0.82763332 0.67489953 1.         1.         0.15514315
 1.         0.         1.         1.         0.38014906 1.
 0.64726976 1.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         1.
 0.33756727 0.         0.         1.         0.         1.
 0.         0.         0.         0.97697937 0.        ]
wv_lg shape (35, 1)
[[0.35960926]
 [0.35922994]
 [0.35945847]
 [0.35941329]
 [0.35938394]
 [0.35938471]
 [0.35934822]
 [0.35938108]
 [0.359336  ]
 [0.35925352]
 [0.35870954]
 [0.35873767]
 [0.35858226]
 [0.35871691]
 [0.35856245]
 [0.35857845]
 [0.35856092]
 [0.35856874]
 [0.35867705]
 [0.35851429]
 [0.35864739]
 [0.35863879]
 [0.35863014]
 [0.3586428 ]
 [0.35855938]
 [0.35860744]
 [0.35860771]
 [0.35859677]
 [0.35853517]
 [0.35861464]
 [0.35865552]
 [0.35863496]
 [0.35865945]
 [0.35854871]
 [0.35863729]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[1.         1.         0.97452089 1.         1.         1.
 1.         1.         1.         0.86003191 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_std shape (35,)
[0.         1.         0.         1.         1.         0.48763665
 1.         0.         1.         0.         0.         0.
 0.         1.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.47132902
 0.         0.         0.         0.         0.         1.
 0.         0.         0.         0.         0.        ]
xy shape: (35, 9)
[[0.         0.50393003 0.         0.         0.35960926 1.
  1.         0.         0.        ]
 [1.         0.         1.         0.82763332 0.35922994 1.
  1.         1.         0.        ]
 [0.57230171 0.         0.60263656 0.67489953 0.35945847 1.
  0.97452089 0.         0.        ]
 [1.         0.         1.         1.         0.35941329 1.
  1.         1.         0.        ]
 [1.         0.26363068 1.         1.         0.35938394 1.
  1.         1.         0.        ]
 [0.21625446 0.         0.31020651 0.15514315 0.35938471 1.
  1.         0.48763665 0.        ]
 [1.         0.         1.         1.         0.35934822 1.
  1.         1.         0.        ]
 [0.         0.4294067  0.         0.         0.35938108 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.359336   1.
  1.         1.         0.        ]
 [0.99278173 1.         1.         1.         0.35925352 1.
  0.86003191 0.         0.        ]
 [0.31684818 0.         0.30720973 0.38014906 0.35870954 1.
  0.         0.         1.        ]
 [0.90459471 0.         1.         1.         0.35873767 1.
  0.         0.         1.        ]
 [0.35472383 0.         0.5215787  0.64726976 0.35858226 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35871691 1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.35856245 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35857845 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35856092 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35856874 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35867705 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35851429 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35864739 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35863879 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35863014 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.3586428  1.
  0.         0.47132902 1.        ]
 [0.10429931 0.         0.15889839 0.33756727 0.35855938 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35860744 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35860771 1.
  0.         0.         1.        ]
 [0.95404611 0.         1.         1.         0.35859677 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35853517 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35861464 1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.35865552 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35863496 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35865945 1.
  0.         0.         1.        ]
 [0.89987716 0.         0.91386557 0.97697937 0.35854871 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35863729 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.8125
#####################         POISON         ###############################################

############################################################################################

comm_round: 6 | global_test_acc: 58.333% | global_f1: 0.7368421052631579 | global_precision: 0.5833333333333334
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         5
           1       0.58      1.00      0.74         7

    accuracy                           0.58        12
   macro avg       0.29      0.50      0.37        12
weighted avg       0.34      0.58      0.43        12

Accuracy per class:
[[7 0]
 [5 0]]
[1. 0.]
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[0.         0.1452819  0.         1.         0.33908282 0.
 1.         0.88885777 1.         0.         0.61575392 0.
 1.         1.         0.6360195  1.         0.         1.
 0.61940166 0.65352738 1.         0.         0.         0.64769622
 0.         0.2443914  0.         1.         1.         0.62886525
 0.         0.27866196 1.         1.         0.81487491]
wv_fg shape (35,)
[0.         1.         0.         0.99248616 1.         0.
 0.         0.         1.         0.         0.         0.
 0.         0.         0.         0.         0.         0.7813951
 0.         0.         0.         0.         0.         0.40019935
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_mn shape (35,)
[0.         0.         0.         1.         0.         0.
 0.65830109 0.3366874  1.         0.         0.         0.
 0.49201978 0.77867216 0.07779536 0.71928841 0.         1.
 0.         0.14134449 0.70311172 0.         0.         0.10129313
 0.         0.         0.         1.         0.4712949  0.03309169
 0.         0.         1.         1.         0.34366993]
wv_ed shape (35,)
[0.         0.         0.         1.         0.         0.
 0.73342708 0.37833061 1.         0.         0.         0.
 0.55844597 0.79159724 0.10932665 0.74002979 0.         1.
 0.03022325 0.13329947 0.7534573  0.         0.         0.12217574
 0.         0.         0.         1.         0.46538408 0.06762737
 0.         0.         1.         0.97331462 0.35387963]
wv_lg shape (35, 1)
[[0.35987175]
 [0.35987289]
 [0.35988931]
 [0.35964019]
 [0.35972295]
 [0.35990154]
 [0.35986659]
 [0.35979133]
 [0.35973355]
 [0.359892  ]
 [0.35901628]
 [0.35899991]
 [0.3590626 ]
 [0.35918131]
 [0.35902997]
 [0.3590111 ]
 [0.359103  ]
 [0.35902683]
 [0.35903581]
 [0.35894598]
 [0.35910335]
 [0.35908126]
 [0.35902639]
 [0.3591255 ]
 [0.35898966]
 [0.35906264]
 [0.35906696]
 [0.35902137]
 [0.35899771]
 [0.35904921]
 [0.35903817]
 [0.35903152]
 [0.35911557]
 [0.35911199]
 [0.35905808]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[1.         1.         1.         0.58693801 1.         1.
 1.         1.         0.25904653 1.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_std shape (35,)
[0.         0.         0.         1.         0.52983279 0.
 0.42435316 0.         1.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
xy shape: (35, 9)
[[0.         0.         0.         0.         0.35987175 1.
  1.         0.         0.        ]
 [0.1452819  1.         0.         0.         0.35987289 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.35988931 1.
  1.         0.         0.        ]
 [1.         0.99248616 1.         1.         0.35964019 1.
  0.58693801 1.         0.        ]
 [0.33908282 1.         0.         0.         0.35972295 1.
  1.         0.52983279 0.        ]
 [0.         0.         0.         0.         0.35990154 1.
  1.         0.         0.        ]
 [1.         0.         0.65830109 0.73342708 0.35986659 1.
  1.         0.42435316 0.        ]
 [0.88885777 0.         0.3366874  0.37833061 0.35979133 1.
  1.         0.         0.        ]
 [1.         1.         1.         1.         0.35973355 1.
  0.25904653 1.         0.        ]
 [0.         0.         0.         0.         0.359892   1.
  1.         0.         0.        ]
 [0.61575392 0.         0.         0.         0.35901628 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35899991 1.
  0.         0.         1.        ]
 [1.         0.         0.49201978 0.55844597 0.3590626  1.
  0.         0.         1.        ]
 [1.         0.         0.77867216 0.79159724 0.35918131 1.
  0.         0.         1.        ]
 [0.6360195  0.         0.07779536 0.10932665 0.35902997 1.
  0.         0.         1.        ]
 [1.         0.         0.71928841 0.74002979 0.3590111  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.359103   1.
  0.         0.         1.        ]
 [1.         0.7813951  1.         1.         0.35902683 1.
  0.         0.         1.        ]
 [0.61940166 0.         0.         0.03022325 0.35903581 1.
  0.         0.         1.        ]
 [0.65352738 0.         0.14134449 0.13329947 0.35894598 1.
  0.         0.         1.        ]
 [1.         0.         0.70311172 0.7534573  0.35910335 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35908126 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35902639 1.
  0.         0.         1.        ]
 [0.64769622 0.40019935 0.10129313 0.12217574 0.3591255  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35898966 1.
  0.         0.         1.        ]
 [0.2443914  0.         0.         0.         0.35906264 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35906696 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35902137 1.
  0.         0.         1.        ]
 [1.         0.         0.4712949  0.46538408 0.35899771 1.
  0.         0.         1.        ]
 [0.62886525 0.         0.03309169 0.06762737 0.35904921 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35903817 1.
  0.         0.         1.        ]
 [0.27866196 0.         0.         0.         0.35903152 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35911557 1.
  0.         0.         1.        ]
 [1.         0.         1.         0.97331462 0.35911199 1.
  0.         0.         1.        ]
 [0.81487491 0.         0.34366993 0.35387963 0.35905808 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.625
#####################         POISON         ###############################################

############################################################################################

comm_round: 7 | global_test_acc: 75.000% | global_f1: 0.8571428571428571 | global_precision: 0.75
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.75      1.00      0.86         9

    accuracy                           0.75        12
   macro avg       0.38      0.50      0.43        12
weighted avg       0.56      0.75      0.64        12

Accuracy per class:
[[9 0]
 [3 0]]
[1. 0.]
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[1.         1.         0.96589549 1.         1.         0.
 0.         0.51380824 1.         0.5067514  0.3231149  0.09732511
 0.37045846 0.         0.06839243 0.         0.730518   1.
 0.         1.         0.         0.1370337  0.         0.41511003
 0.         1.         0.35763567 0.         0.86399759 0.
 0.81747676 0.34999642 1.         0.82782829 0.84481362]
wv_fg shape (35,)
[1.         0.         0.58509359 0.58509359 1.         1.
 1.         1.         0.         0.86361917 0.         0.
 0.         0.         0.         1.         0.         0.
 0.         0.         0.         0.04416978 0.98744566 0.
 0.86105137 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_mn shape (35,)
[1.         1.         1.         1.         1.         0.
 0.         0.47937977 1.         0.65895748 0.42502011 0.
 0.54318074 0.         0.         0.         0.7158295  1.
 0.         1.         0.         0.03065071 0.         0.66452953
 0.         1.         0.39476834 0.         1.         0.
 0.94652547 0.5302833  1.         1.         1.        ]
wv_ed shape (35,)
[1.         1.         1.         1.         1.         0.
 0.         0.1723506  1.         0.82291748 0.43657718 0.07637209
 0.54066237 0.         0.         0.         0.77691432 1.
 0.         1.         0.         0.         0.         0.70680804
 0.         1.         0.39192651 0.         1.         0.
 0.92498694 0.56486762 1.         0.908663   1.        ]
wv_lg shape (35, 1)
[[0.36008046]
 [0.36015144]
 [0.36018606]
 [0.36018999]
 [0.36016464]
 [0.36029318]
 [0.36018257]
 [0.360214  ]
 [0.36019037]
 [0.3601928 ]
 [0.35953659]
 [0.35953479]
 [0.3594597 ]
 [0.35939617]
 [0.35958864]
 [0.3594819 ]
 [0.35957729]
 [0.3595585 ]
 [0.35951544]
 [0.35953178]
 [0.35939999]
 [0.35952934]
 [0.35960807]
 [0.35951045]
 [0.35956456]
 [0.35953726]
 [0.35950116]
 [0.35951866]
 [0.3596078 ]
 [0.35950619]
 [0.35957899]
 [0.35950273]
 [0.35960339]
 [0.35956172]
 [0.35953788]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[0.9625092  1.         1.         1.         0.83493031 1.
 1.         1.         1.         1.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_std shape (35,)
[1.         1.         0.92956607 1.         1.         0.
 0.         0.44563647 1.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         1.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
xy shape: (35, 9)
[[1.         1.         1.         1.         0.36008046 1.
  0.9625092  1.         0.        ]
 [1.         0.         1.         1.         0.36015144 1.
  1.         1.         0.        ]
 [0.96589549 0.58509359 1.         1.         0.36018606 1.
  1.         0.92956607 0.        ]
 [1.         0.58509359 1.         1.         0.36018999 1.
  1.         1.         0.        ]
 [1.         1.         1.         1.         0.36016464 1.
  0.83493031 1.         0.        ]
 [0.         1.         0.         0.         0.36029318 1.
  1.         0.         0.        ]
 [0.         1.         0.         0.         0.36018257 1.
  1.         0.         0.        ]
 [0.51380824 1.         0.47937977 0.1723506  0.360214   1.
  1.         0.44563647 0.        ]
 [1.         0.         1.         1.         0.36019037 1.
  1.         1.         0.        ]
 [0.5067514  0.86361917 0.65895748 0.82291748 0.3601928  1.
  1.         0.         0.        ]
 [0.3231149  0.         0.42502011 0.43657718 0.35953659 1.
  0.         0.         1.        ]
 [0.09732511 0.         0.         0.07637209 0.35953479 1.
  0.         0.         1.        ]
 [0.37045846 0.         0.54318074 0.54066237 0.3594597  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35939617 1.
  0.         0.         1.        ]
 [0.06839243 0.         0.         0.         0.35958864 1.
  0.         0.         1.        ]
 [0.         1.         0.         0.         0.3594819  1.
  0.         0.         1.        ]
 [0.730518   0.         0.7158295  0.77691432 0.35957729 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.3595585  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35951544 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35953178 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35939999 1.
  0.         0.         1.        ]
 [0.1370337  0.04416978 0.03065071 0.         0.35952934 1.
  0.         0.         1.        ]
 [0.         0.98744566 0.         0.         0.35960807 1.
  0.         0.         1.        ]
 [0.41511003 0.         0.66452953 0.70680804 0.35951045 1.
  0.         0.         1.        ]
 [0.         0.86105137 0.         0.         0.35956456 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35953726 1.
  0.         1.         1.        ]
 [0.35763567 0.         0.39476834 0.39192651 0.35950116 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35951866 1.
  0.         0.         1.        ]
 [0.86399759 0.         1.         1.         0.3596078  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35950619 1.
  0.         0.         1.        ]
 [0.81747676 0.         0.94652547 0.92498694 0.35957899 1.
  0.         0.         1.        ]
 [0.34999642 0.         0.5302833  0.56486762 0.35950273 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35960339 1.
  0.         0.         1.        ]
 [0.82782829 0.         1.         0.908663   0.35956172 1.
  0.         0.         1.        ]
 [0.84481362 0.         1.         1.         0.35953788 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.75
#####################         POISON         ###############################################

############################################################################################

comm_round: 8 | global_test_acc: 75.000% | global_f1: 0.8571428571428571 | global_precision: 0.75
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.75      1.00      0.86         9

    accuracy                           0.75        12
   macro avg       0.38      0.50      0.43        12
weighted avg       0.56      0.75      0.64        12

Accuracy per class:
[[9 0]
 [3 0]]
[1. 0.]
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[1.         0.8036404  1.         0.         0.         1.
 0.80124632 1.         0.         0.         0.         0.
 0.52610614 0.         0.         0.52920831 0.         0.
 0.         0.         0.         0.93969849 0.         0.
 0.         0.         0.         0.36878974 0.         0.
 0.41473646 0.         0.         0.         0.        ]
wv_fg shape (35,)
[1.         1.         1.         1.         1.         0.
 0.5585724  0.         0.         0.         0.09717094 0.
 0.05978747 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.82471132 0.         0.
 0.         0.         0.         0.         0.        ]
wv_mn shape (35,)
[0.85340636 0.54049512 1.         0.         0.         1.
 0.47530834 1.         0.         0.         0.         0.
 0.35271506 0.         0.         0.33819314 0.         0.
 0.         0.         0.         0.93980927 0.         0.
 0.         0.         0.         0.05501109 0.         0.
 0.12867845 0.         0.         0.         0.        ]
wv_ed shape (35,)
[0.69542523 0.207918   1.         0.         0.         1.
 0.29341713 1.         0.         0.         0.         0.
 0.24156791 0.         0.         0.28463297 0.         0.
 0.         0.         0.         0.91119099 0.         0.
 0.         0.         0.         0.06814124 0.         0.
 0.13528053 0.         0.         0.         0.        ]
wv_lg shape (35, 1)
[[0.36047968]
 [0.36055695]
 [0.36049774]
 [0.36049061]
 [0.36053914]
 [0.36047847]
 [0.36042548]
 [0.36055636]
 [0.36052944]
 [0.36057488]
 [0.35981751]
 [0.3599189 ]
 [0.35995107]
 [0.35978632]
 [0.35974625]
 [0.35982569]
 [0.35988315]
 [0.35971625]
 [0.35972538]
 [0.3597327 ]
 [0.35988988]
 [0.35975726]
 [0.35977297]
 [0.35978056]
 [0.35981232]
 [0.35982094]
 [0.35969662]
 [0.35985455]
 [0.3598292 ]
 [0.35981135]
 [0.35976687]
 [0.35983395]
 [0.35995224]
 [0.35976794]
 [0.35990764]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[1.         1.         0.47196092 0.75773712 1.         0.91559002
 1.         1.         1.         1.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_std shape (35,)
[0.76390998 1.         1.         0.40728345 0.         1.
 1.         1.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
xy shape: (35, 9)
[[1.         1.         0.85340636 0.69542523 0.36047968 1.
  1.         0.76390998 0.        ]
 [0.8036404  1.         0.54049512 0.207918   0.36055695 1.
  1.         1.         0.        ]
 [1.         1.         1.         1.         0.36049774 1.
  0.47196092 1.         0.        ]
 [0.         1.         0.         0.         0.36049061 1.
  0.75773712 0.40728345 0.        ]
 [0.         1.         0.         0.         0.36053914 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.36047847 1.
  0.91559002 1.         0.        ]
 [0.80124632 0.5585724  0.47530834 0.29341713 0.36042548 1.
  1.         1.         0.        ]
 [1.         0.         1.         1.         0.36055636 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.36052944 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.36057488 1.
  1.         0.         0.        ]
 [0.         0.09717094 0.         0.         0.35981751 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3599189  1.
  0.         0.         1.        ]
 [0.52610614 0.05978747 0.35271506 0.24156791 0.35995107 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35978632 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35974625 1.
  0.         0.         1.        ]
 [0.52920831 0.         0.33819314 0.28463297 0.35982569 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35988315 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35971625 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35972538 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3597327  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35988988 1.
  0.         0.         1.        ]
 [0.93969849 0.         0.93980927 0.91119099 0.35975726 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35977297 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35978056 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35981232 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35982094 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35969662 1.
  0.         0.         1.        ]
 [0.36878974 0.82471132 0.05501109 0.06814124 0.35985455 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3598292  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35981135 1.
  0.         0.         1.        ]
 [0.41473646 0.         0.12867845 0.13528053 0.35976687 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35983395 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35995224 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35976794 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35990764 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.625
#####################         POISON         ###############################################

############################################################################################

comm_round: 9 | global_test_acc: 91.667% | global_f1: 0.9565217391304348 | global_precision: 0.9166666666666666
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.92      1.00      0.96        11

    accuracy                           0.92        12
   macro avg       0.46      0.50      0.48        12
weighted avg       0.84      0.92      0.88        12

Accuracy per class:
[[11  0]
 [ 1  0]]
[1. 0.]
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[1.         0.49775079 0.85789322 1.         1.         0.
 1.         1.         0.94405524 1.         0.32495958 0.35185064
 0.20174051 1.         1.         1.         1.         1.
 0.68505829 0.         1.         1.         0.         0.89966125
 1.         0.20980966 0.06364841 0.         1.         0.
 1.         0.27673244 0.33478641 0.         0.13472056]
wv_fg shape (35,)
[0.         0.         0.         0.87836594 1.         0.4019588
 1.         0.01165668 1.         0.87836594 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_mn shape (35,)
[1.         0.05767933 0.38613562 1.         1.         0.
 0.95044469 1.         0.55820235 1.         0.         0.
 0.         1.         1.         1.         0.68003304 1.
 0.21798441 0.         0.5895689  0.59906959 0.         0.44157354
 1.         0.         0.         0.         1.         0.
 0.75321354 0.         0.         0.         0.        ]
wv_ed shape (35,)
[1.         0.01264073 0.4052543  1.         1.         0.
 0.89157194 1.         0.63050778 1.         0.         0.
 0.         1.         1.         1.         0.80066259 1.
 0.19535949 0.         0.59359498 0.71974813 0.         0.46494013
 1.         0.         0.         0.         1.         0.
 0.83448758 0.         0.         0.         0.        ]
wv_lg shape (35, 1)
[[0.36086912]
 [0.36074574]
 [0.36084015]
 [0.36067121]
 [0.3607374 ]
 [0.36087591]
 [0.36075838]
 [0.36072717]
 [0.36073041]
 [0.36089186]
 [0.3600745 ]
 [0.36014034]
 [0.36014818]
 [0.36007245]
 [0.36011811]
 [0.36015333]
 [0.36009371]
 [0.3601766 ]
 [0.36014229]
 [0.36003058]
 [0.36010618]
 [0.36003828]
 [0.36000895]
 [0.36015705]
 [0.36016081]
 [0.36015701]
 [0.36010872]
 [0.3600557 ]
 [0.3601733 ]
 [0.36009329]
 [0.36004698]
 [0.36012221]
 [0.36004321]
 [0.36009468]
 [0.36008681]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[1.         1.         1.         0.83389538 1.         1.
 1.         1.         0.59330305 1.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_std shape (35,)
[1.         0.         0.35253366 1.         1.         0.
 1.         1.         0.19246095 0.56177675 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
xy shape: (35, 9)
[[1.         0.         1.         1.         0.36086912 1.
  1.         1.         0.        ]
 [0.49775079 0.         0.05767933 0.01264073 0.36074574 1.
  1.         0.         0.        ]
 [0.85789322 0.         0.38613562 0.4052543  0.36084015 1.
  1.         0.35253366 0.        ]
 [1.         0.87836594 1.         1.         0.36067121 1.
  0.83389538 1.         0.        ]
 [1.         1.         1.         1.         0.3607374  1.
  1.         1.         0.        ]
 [0.         0.4019588  0.         0.         0.36087591 1.
  1.         0.         0.        ]
 [1.         1.         0.95044469 0.89157194 0.36075838 1.
  1.         1.         0.        ]
 [1.         0.01165668 1.         1.         0.36072717 1.
  1.         1.         0.        ]
 [0.94405524 1.         0.55820235 0.63050778 0.36073041 1.
  0.59330305 0.19246095 0.        ]
 [1.         0.87836594 1.         1.         0.36089186 1.
  1.         0.56177675 0.        ]
 [0.32495958 0.         0.         0.         0.3600745  1.
  0.         0.         1.        ]
 [0.35185064 0.         0.         0.         0.36014034 1.
  0.         0.         1.        ]
 [0.20174051 0.         0.         0.         0.36014818 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.36007245 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.36011811 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.36015333 1.
  0.         0.         1.        ]
 [1.         0.         0.68003304 0.80066259 0.36009371 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.3601766  1.
  0.         0.         1.        ]
 [0.68505829 0.         0.21798441 0.19535949 0.36014229 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36003058 1.
  0.         0.         1.        ]
 [1.         0.         0.5895689  0.59359498 0.36010618 1.
  0.         0.         1.        ]
 [1.         0.         0.59906959 0.71974813 0.36003828 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36000895 1.
  0.         0.         1.        ]
 [0.89966125 0.         0.44157354 0.46494013 0.36015705 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.36016081 1.
  0.         0.         1.        ]
 [0.20980966 0.         0.         0.         0.36015701 1.
  0.         0.         1.        ]
 [0.06364841 0.         0.         0.         0.36010872 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3600557  1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.3601733  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36009329 1.
  0.         0.         1.        ]
 [1.         0.         0.75321354 0.83448758 0.36004698 1.
  0.         0.         1.        ]
 [0.27673244 0.         0.         0.         0.36012221 1.
  0.         0.         1.        ]
 [0.33478641 0.         0.         0.         0.36004321 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36009468 1.
  0.         0.         1.        ]
 [0.13472056 0.         0.         0.         0.36008681 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.6875
#####################         POISON         ###############################################

############################################################################################

comm_round: 10 | global_test_acc: 66.667% | global_f1: 0.8 | global_precision: 0.6666666666666666
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         4
           1       0.67      1.00      0.80         8

    accuracy                           0.67        12
   macro avg       0.33      0.50      0.40        12
weighted avg       0.44      0.67      0.53        12

Accuracy per class:
[[8 0]
 [4 0]]
[1. 0.]
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[1.         1.         1.         0.         1.         1.
 0.37920525 0.         1.         1.         0.12353326 0.21056105
 0.         1.         0.67366558 0.         1.         0.16512855
 0.         0.         0.01221571 0.18821477 0.         0.
 0.         0.         0.65784627 0.16853442 0.         1.
 0.16119184 0.23571954 0.02826473 0.         0.        ]
wv_fg shape (35,)
[0.79385995 1.         1.         1.         0.79385995 0.39320727
 1.         1.         0.39320727 1.         0.         0.
 0.17460902 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         1.
 0.         0.         0.         0.         0.        ]
wv_mn shape (35,)
[1.         1.         1.         0.         1.         0.73669422
 0.3003989  0.         1.         1.         0.         0.
 0.         1.         0.32863952 0.         1.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.32433558 0.         0.         1.
 0.         0.08883789 0.         0.         0.        ]
wv_ed shape (35,)
[1.         1.         1.         0.         1.         0.78845425
 0.37918475 0.         1.         1.         0.         0.07659933
 0.         1.         0.47561104 0.         1.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.31316143 0.         0.         1.
 0.         0.09152021 0.         0.         0.        ]
wv_lg shape (35, 1)
[[0.36107834]
 [0.36124733]
 [0.36115992]
 [0.36114076]
 [0.36111191]
 [0.36120468]
 [0.36120871]
 [0.36128445]
 [0.36118819]
 [0.3611682 ]
 [0.36056841]
 [0.36059274]
 [0.36043572]
 [0.36066444]
 [0.36053403]
 [0.36049339]
 [0.36067854]
 [0.36055367]
 [0.36054803]
 [0.36050875]
 [0.3604959 ]
 [0.36053122]
 [0.3604608 ]
 [0.36047146]
 [0.36053064]
 [0.3604867 ]
 [0.36058943]
 [0.3605599 ]
 [0.36049968]
 [0.36058813]
 [0.36053394]
 [0.36056608]
 [0.36053872]
 [0.36048271]
 [0.36053353]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
wv_std shape (35,)
[1.         0.94365164 1.         0.         0.63084451 0.99832555
 0.         0.         1.         0.25295168 0.         0.
 0.         0.         0.         0.         0.32277979 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         1.
 0.         0.         0.         0.         0.        ]
xy shape: (35, 9)
[[1.         0.79385995 1.         1.         0.36107834 1.
  1.         1.         0.        ]
 [1.         1.         1.         1.         0.36124733 1.
  1.         0.94365164 0.        ]
 [1.         1.         1.         1.         0.36115992 1.
  1.         1.         0.        ]
 [0.         1.         0.         0.         0.36114076 1.
  1.         0.         0.        ]
 [1.         0.79385995 1.         1.         0.36111191 1.
  1.         0.63084451 0.        ]
 [1.         0.39320727 0.73669422 0.78845425 0.36120468 1.
  1.         0.99832555 0.        ]
 [0.37920525 1.         0.3003989  0.37918475 0.36120871 1.
  1.         0.         0.        ]
 [0.         1.         0.         0.         0.36128445 1.
  1.         0.         0.        ]
 [1.         0.39320727 1.         1.         0.36118819 1.
  1.         1.         0.        ]
 [1.         1.         1.         1.         0.3611682  1.
  1.         0.25295168 0.        ]
 [0.12353326 0.         0.         0.         0.36056841 1.
  0.         0.         1.        ]
 [0.21056105 0.         0.         0.07659933 0.36059274 1.
  0.         0.         1.        ]
 [0.         0.17460902 0.         0.         0.36043572 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.36066444 1.
  0.         0.         1.        ]
 [0.67366558 0.         0.32863952 0.47561104 0.36053403 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36049339 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.36067854 1.
  0.         0.32277979 1.        ]
 [0.16512855 0.         0.         0.         0.36055367 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36054803 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36050875 1.
  0.         0.         1.        ]
 [0.01221571 0.         0.         0.         0.3604959  1.
  0.         0.         1.        ]
 [0.18821477 0.         0.         0.         0.36053122 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3604608  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36047146 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36053064 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3604867  1.
  0.         0.         1.        ]
 [0.65784627 0.         0.32433558 0.31316143 0.36058943 1.
  0.         0.         1.        ]
 [0.16853442 0.         0.         0.         0.3605599  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36049968 1.
  0.         0.         1.        ]
 [1.         1.         1.         1.         0.36058813 1.
  0.         1.         1.        ]
 [0.16119184 0.         0.         0.         0.36053394 1.
  0.         0.         1.        ]
 [0.23571954 0.         0.08883789 0.09152021 0.36056608 1.
  0.         0.         1.        ]
 [0.02826473 0.         0.         0.         0.36053872 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36048271 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36053353 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.5
#####################         POISON         ###############################################

############################################################################################

comm_round: 11 | global_test_acc: 83.333% | global_f1: 0.9090909090909091 | global_precision: 0.8333333333333334
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.83      1.00      0.91        10

    accuracy                           0.83        12
   macro avg       0.42      0.50      0.45        12
weighted avg       0.69      0.83      0.76        12

Accuracy per class:
[[10  0]
 [ 2  0]]
[1. 0.]
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[0.         1.         1.         1.         1.         0.
 1.         1.         1.         0.         1.         0.83076286
 0.         0.         0.         0.62357483 0.         0.
 0.88764095 1.         0.         0.         0.57604423 0.
 0.63633776 0.67946841 0.64377386 0.         0.         1.
 0.71750418 0.         0.         0.         0.        ]
wv_fg shape (35,)
[0.12078807 0.         0.         0.         0.         1.
 0.         0.         0.         1.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_mn shape (35,)
[0.         1.         1.         1.         1.         0.
 1.         1.         0.95575902 0.         1.         0.4843908
 0.         0.         0.         0.07004887 0.         0.
 0.54175609 1.         0.         0.         0.         0.
 0.08938662 0.15468885 0.16174646 0.         0.         1.
 0.15716042 0.         0.         0.         0.        ]
wv_ed shape (35,)
[0.         1.         1.         1.         1.         0.
 1.         1.         0.95365858 0.         0.89965903 0.41690996
 0.         0.         0.         0.02207409 0.         0.
 0.37893007 1.         0.         0.         0.         0.
 0.         0.10701944 0.00351683 0.         0.         0.91646814
 0.         0.         0.         0.         0.        ]
wv_lg shape (35, 1)
[[0.36153791]
 [0.36144791]
 [0.3613732 ]
 [0.36151669]
 [0.36134608]
 [0.36143782]
 [0.36155685]
 [0.36135443]
 [0.36145742]
 [0.36132218]
 [0.36064751]
 [0.36076091]
 [0.36075857]
 [0.36070591]
 [0.36074075]
 [0.3606804 ]
 [0.3606724 ]
 [0.36065537]
 [0.36069374]
 [0.36075593]
 [0.36069467]
 [0.36069308]
 [0.36072859]
 [0.36069947]
 [0.3607459 ]
 [0.36076004]
 [0.36076064]
 [0.36072233]
 [0.36077946]
 [0.3607386 ]
 [0.36082393]
 [0.36077162]
 [0.36072916]
 [0.36073303]
 [0.36076817]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[1.         0.19341286 0.78206459 0.27654604 1.         1.
 0.02991793 0.95040913 1.         1.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_std shape (35,)
[0.         1.         1.         0.97317385 1.         0.
 0.81035971 1.         0.97454966 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
xy shape: (35, 9)
[[0.         0.12078807 0.         0.         0.36153791 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.36144791 1.
  0.19341286 1.         0.        ]
 [1.         0.         1.         1.         0.3613732  1.
  0.78206459 1.         0.        ]
 [1.         0.         1.         1.         0.36151669 1.
  0.27654604 0.97317385 0.        ]
 [1.         0.         1.         1.         0.36134608 1.
  1.         1.         0.        ]
 [0.         1.         0.         0.         0.36143782 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.36155685 1.
  0.02991793 0.81035971 0.        ]
 [1.         0.         1.         1.         0.36135443 1.
  0.95040913 1.         0.        ]
 [1.         0.         0.95575902 0.95365858 0.36145742 1.
  1.         0.97454966 0.        ]
 [0.         1.         0.         0.         0.36132218 1.
  1.         0.         0.        ]
 [1.         0.         1.         0.89965903 0.36064751 1.
  0.         0.         1.        ]
 [0.83076286 0.         0.4843908  0.41690996 0.36076091 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36075857 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36070591 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36074075 1.
  0.         0.         1.        ]
 [0.62357483 0.         0.07004887 0.02207409 0.3606804  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3606724  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36065537 1.
  0.         0.         1.        ]
 [0.88764095 0.         0.54175609 0.37893007 0.36069374 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.36075593 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36069467 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36069308 1.
  0.         0.         1.        ]
 [0.57604423 0.         0.         0.         0.36072859 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36069947 1.
  0.         0.         1.        ]
 [0.63633776 0.         0.08938662 0.         0.3607459  1.
  0.         0.         1.        ]
 [0.67946841 0.         0.15468885 0.10701944 0.36076004 1.
  0.         0.         1.        ]
 [0.64377386 0.         0.16174646 0.00351683 0.36076064 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36072233 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36077946 1.
  0.         0.         1.        ]
 [1.         0.         1.         0.91646814 0.3607386  1.
  0.         0.         1.        ]
 [0.71750418 0.         0.15716042 0.         0.36082393 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36077162 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36072916 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36073303 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36076817 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.625
#####################         POISON         ###############################################

############################################################################################

comm_round: 12 | global_test_acc: 83.333% | global_f1: 0.9090909090909091 | global_precision: 0.8333333333333334
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.83      1.00      0.91        10

    accuracy                           0.83        12
   macro avg       0.42      0.50      0.45        12
weighted avg       0.69      0.83      0.76        12

Accuracy per class:
[[10  0]
 [ 2  0]]
[1. 0.]
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[1.         1.         1.         1.         0.97132432 0.
 0.         0.         0.         0.05040211 0.54359568 0.
 0.70248353 0.54839468 0.74629408 0.         0.58821789 0.
 1.         0.         0.         0.         0.54691522 0.71392101
 0.         0.         0.         0.45484446 0.         0.
 0.5753296  0.62578654 0.03173297 0.         0.        ]
wv_fg shape (35,)
[0.         0.         0.         1.         1.         0.
 0.         0.         0.03002339 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.77823395 0.         0.         0.         0.        ]
wv_mn shape (35,)
[1.         1.         1.         1.         1.         0.0562445
 0.         0.         0.         0.2442196  0.45352976 0.
 0.88210308 0.55691363 0.98217194 0.         0.62939623 0.
 1.         0.         0.         0.         0.50961082 1.
 0.         0.         0.         0.29287005 0.         0.
 0.74713187 0.89607048 0.25587712 0.         0.        ]
wv_ed shape (35,)
[1.         1.         1.         1.         1.         0.
 0.         0.         0.         0.07283119 0.43502534 0.
 0.91653317 0.53581645 0.99096477 0.         0.69401815 0.
 1.         0.         0.         0.         0.50805125 1.
 0.         0.         0.         0.24117933 0.         0.
 0.84934003 0.87073894 0.28361131 0.         0.        ]
wv_lg shape (35, 1)
[[0.36185032]
 [0.36174365]
 [0.36168224]
 [0.36168302]
 [0.36179058]
 [0.3616706 ]
 [0.36176243]
 [0.36176334]
 [0.36184556]
 [0.36168388]
 [0.36101917]
 [0.36100726]
 [0.36105236]
 [0.36100692]
 [0.36115864]
 [0.36101   ]
 [0.36109194]
 [0.36107036]
 [0.36104016]
 [0.36111655]
 [0.3610454 ]
 [0.36111491]
 [0.36109623]
 [0.36104423]
 [0.36103911]
 [0.36097798]
 [0.36096332]
 [0.36104015]
 [0.36098463]
 [0.36111659]
 [0.36107203]
 [0.36114069]
 [0.3610056 ]
 [0.3610859 ]
 [0.36103867]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
wv_std shape (35,)
[1.         1.         1.         1.         0.55744774 1.
 0.         0.         0.         0.93566288 0.         0.
 0.         0.         0.         0.         0.         0.
 0.00950316 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
xy shape: (35, 9)
[[1.         0.         1.         1.         0.36185032 1.
  1.         1.         0.        ]
 [1.         0.         1.         1.         0.36174365 1.
  1.         1.         0.        ]
 [1.         0.         1.         1.         0.36168224 1.
  1.         1.         0.        ]
 [1.         1.         1.         1.         0.36168302 1.
  1.         1.         0.        ]
 [0.97132432 1.         1.         1.         0.36179058 1.
  1.         0.55744774 0.        ]
 [0.         0.         0.0562445  0.         0.3616706  1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.36176243 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.36176334 1.
  1.         0.         0.        ]
 [0.         0.03002339 0.         0.         0.36184556 1.
  1.         0.         0.        ]
 [0.05040211 0.         0.2442196  0.07283119 0.36168388 1.
  1.         0.93566288 0.        ]
 [0.54359568 0.         0.45352976 0.43502534 0.36101917 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36100726 1.
  0.         0.         1.        ]
 [0.70248353 0.         0.88210308 0.91653317 0.36105236 1.
  0.         0.         1.        ]
 [0.54839468 0.         0.55691363 0.53581645 0.36100692 1.
  0.         0.         1.        ]
 [0.74629408 0.         0.98217194 0.99096477 0.36115864 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36101    1.
  0.         0.         1.        ]
 [0.58821789 0.         0.62939623 0.69401815 0.36109194 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36107036 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.36104016 1.
  0.         0.00950316 1.        ]
 [0.         0.         0.         0.         0.36111655 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3610454  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36111491 1.
  0.         0.         1.        ]
 [0.54691522 0.         0.50961082 0.50805125 0.36109623 1.
  0.         0.         1.        ]
 [0.71392101 0.         1.         1.         0.36104423 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36103911 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36097798 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36096332 1.
  0.         0.         1.        ]
 [0.45484446 0.         0.29287005 0.24117933 0.36104015 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36098463 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36111659 1.
  0.         0.         1.        ]
 [0.5753296  0.77823395 0.74713187 0.84934003 0.36107203 1.
  0.         0.         1.        ]
 [0.62578654 0.         0.89607048 0.87073894 0.36114069 1.
  0.         0.         1.        ]
 [0.03173297 0.         0.25587712 0.28361131 0.3610056  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3610859  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36103867 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.6875
#####################         POISON         ###############################################

############################################################################################

comm_round: 13 | global_test_acc: 75.000% | global_f1: 0.8571428571428571 | global_precision: 0.75
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.75      1.00      0.86         9

    accuracy                           0.75        12
   macro avg       0.38      0.50      0.43        12
weighted avg       0.56      0.75      0.64        12

Accuracy per class:
[[9 0]
 [3 0]]
[1. 0.]
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[0.20903364 0.         0.34856014 0.         1.         0.
 0.98749584 0.         0.51014944 0.52490688 0.         0.31944284
 0.04561349 0.73209496 0.49134273 0.46234274 0.0315492  0.
 0.         0.         0.         1.         0.28136448 0.43494808
 0.         0.         0.         0.41256699 1.         0.
 0.07570641 0.         0.         1.         0.        ]
wv_fg shape (35,)
[0.         1.         0.         0.         1.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.14238397 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         1.         0.
 0.         0.         0.         0.         0.        ]
wv_mn shape (35,)
[0.51818892 0.         0.61294674 0.         1.         0.00839007
 1.         0.         1.         0.92663254 0.         0.80313681
 0.30955118 1.         0.99776727 0.88014887 0.25381516 0.
 0.         0.         0.         1.         0.69173691 0.81183724
 0.         0.         0.         0.8785834  1.         0.
 0.36088384 0.         0.         1.         0.        ]
wv_ed shape (35,)
[0.52133441 0.         0.3479931  0.         1.         0.
 1.         0.         0.70627456 0.94739203 0.         0.83603919
 0.02262577 0.98570808 0.89044185 0.8533205  0.29271687 0.
 0.         0.         0.         1.         0.73839293 0.91015022
 0.         0.         0.         0.74961292 1.         0.
 0.29059888 0.         0.         1.         0.        ]
wv_lg shape (35, 1)
[[0.36212819]
 [0.36209316]
 [0.36208956]
 [0.36215369]
 [0.36191218]
 [0.36213133]
 [0.36214361]
 [0.36216243]
 [0.36209326]
 [0.36213383]
 [0.3614503 ]
 [0.3613769 ]
 [0.36139541]
 [0.3613533 ]
 [0.36141766]
 [0.36155912]
 [0.36141622]
 [0.36141363]
 [0.36134878]
 [0.36141576]
 [0.36141021]
 [0.36139112]
 [0.36142609]
 [0.36146786]
 [0.36136426]
 [0.36139233]
 [0.36136296]
 [0.36145388]
 [0.36135832]
 [0.36138147]
 [0.36135096]
 [0.36140502]
 [0.36140546]
 [0.36143979]
 [0.36141319]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[1.         1.         1.         1.         0.89932609 1.
 1.         1.         1.         1.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_std shape (35,)
[0.82178918 0.         1.         0.         1.         0.
 1.         0.         1.         0.93101083 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         1.         0.         0.
 0.         0.         0.         0.27706324 0.         0.
 0.         0.         0.         0.39264657 0.        ]
xy shape: (35, 9)
[[0.20903364 0.         0.51818892 0.52133441 0.36212819 1.
  1.         0.82178918 0.        ]
 [0.         1.         0.         0.         0.36209316 1.
  1.         0.         0.        ]
 [0.34856014 0.         0.61294674 0.3479931  0.36208956 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.36215369 1.
  1.         0.         0.        ]
 [1.         1.         1.         1.         0.36191218 1.
  0.89932609 1.         0.        ]
 [0.         0.         0.00839007 0.         0.36213133 1.
  1.         0.         0.        ]
 [0.98749584 0.         1.         1.         0.36214361 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.36216243 1.
  1.         0.         0.        ]
 [0.51014944 0.         1.         0.70627456 0.36209326 1.
  1.         1.         0.        ]
 [0.52490688 0.         0.92663254 0.94739203 0.36213383 1.
  1.         0.93101083 0.        ]
 [0.         0.         0.         0.         0.3614503  1.
  0.         0.         1.        ]
 [0.31944284 0.         0.80313681 0.83603919 0.3613769  1.
  0.         0.         1.        ]
 [0.04561349 0.         0.30955118 0.02262577 0.36139541 1.
  0.         0.         1.        ]
 [0.73209496 0.14238397 1.         0.98570808 0.3613533  1.
  0.         0.         1.        ]
 [0.49134273 0.         0.99776727 0.89044185 0.36141766 1.
  0.         0.         1.        ]
 [0.46234274 0.         0.88014887 0.8533205  0.36155912 1.
  0.         0.         1.        ]
 [0.0315492  0.         0.25381516 0.29271687 0.36141622 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36141363 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36134878 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36141576 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36141021 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.36139112 1.
  0.         1.         1.        ]
 [0.28136448 0.         0.69173691 0.73839293 0.36142609 1.
  0.         0.         1.        ]
 [0.43494808 0.         0.81183724 0.91015022 0.36146786 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36136426 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36139233 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36136296 1.
  0.         0.         1.        ]
 [0.41256699 0.         0.8785834  0.74961292 0.36145388 1.
  0.         0.27706324 1.        ]
 [1.         1.         1.         1.         0.36135832 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36138147 1.
  0.         0.         1.        ]
 [0.07570641 0.         0.36088384 0.29059888 0.36135096 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36140502 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36140546 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.36143979 1.
  0.         0.39264657 1.        ]
 [0.         0.         0.         0.         0.36141319 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.6875
#####################         POISON         ###############################################

############################################################################################

comm_round: 14 | global_test_acc: 66.667% | global_f1: 0.8 | global_precision: 0.6666666666666666
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         4
           1       0.67      1.00      0.80         8

    accuracy                           0.67        12
   macro avg       0.33      0.50      0.40        12
weighted avg       0.44      0.67      0.53        12

Accuracy per class:
[[8 0]
 [4 0]]
[1. 0.]
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[0.94930307 0.         0.18592618 1.         1.         1.
 1.         0.         0.         1.         0.         0.
 0.81001753 0.         0.54898103 1.         0.62065287 1.
 0.65832948 0.         0.         0.75167724 0.         0.
 0.         0.99007301 0.         0.         1.         0.
 0.         0.         0.         0.08964743 0.86921945]
wv_fg shape (35,)
[0.         0.92642666 0.         0.         0.         0.
 1.         0.07955067 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_mn shape (35,)
[0.50536152 0.         0.         1.         1.         1.
 1.         0.         0.         0.66687735 0.         0.
 0.44920476 0.         0.         1.         0.12536437 1.
 0.18169917 0.         0.         0.38000334 0.         0.
 0.         0.70550791 0.         0.         0.96362762 0.
 0.         0.         0.         0.         0.53778177]
wv_ed shape (35,)
[0.29233123 0.         0.         1.         1.         1.
 1.         0.         0.         0.72600933 0.         0.
 0.47076515 0.         0.02180955 1.         0.11761761 1.
 0.27655499 0.         0.         0.36575845 0.         0.
 0.         0.77175779 0.         0.         1.         0.
 0.         0.         0.         0.         0.60062986]
wv_lg shape (35, 1)
[[0.36242386]
 [0.36250642]
 [0.36244032]
 [0.36244284]
 [0.36246986]
 [0.36243762]
 [0.36237415]
 [0.36250895]
 [0.36232744]
 [0.36241759]
 [0.36173337]
 [0.36164189]
 [0.36176581]
 [0.36167118]
 [0.36185505]
 [0.36178304]
 [0.36176599]
 [0.36174045]
 [0.36183048]
 [0.36166633]
 [0.36178986]
 [0.36171781]
 [0.36171386]
 [0.36174375]
 [0.36167475]
 [0.36179991]
 [0.36174602]
 [0.3617282 ]
 [0.36167249]
 [0.36175415]
 [0.3616796 ]
 [0.36176461]
 [0.36179466]
 [0.36173306]
 [0.36176585]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[1.         1.         1.         0.78455513 0.87891632 0.71684149
 1.         1.         1.         0.86766745 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_std shape (35,)
[0.8339576  0.32581157 0.15001763 1.         1.         1.
 1.         0.         0.37667096 0.60435817 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
xy shape: (35, 9)
[[0.94930307 0.         0.50536152 0.29233123 0.36242386 1.
  1.         0.8339576  0.        ]
 [0.         0.92642666 0.         0.         0.36250642 1.
  1.         0.32581157 0.        ]
 [0.18592618 0.         0.         0.         0.36244032 1.
  1.         0.15001763 0.        ]
 [1.         0.         1.         1.         0.36244284 1.
  0.78455513 1.         0.        ]
 [1.         0.         1.         1.         0.36246986 1.
  0.87891632 1.         0.        ]
 [1.         0.         1.         1.         0.36243762 1.
  0.71684149 1.         0.        ]
 [1.         1.         1.         1.         0.36237415 1.
  1.         1.         0.        ]
 [0.         0.07955067 0.         0.         0.36250895 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.36232744 1.
  1.         0.37667096 0.        ]
 [1.         0.         0.66687735 0.72600933 0.36241759 1.
  0.86766745 0.60435817 0.        ]
 [0.         0.         0.         0.         0.36173337 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36164189 1.
  0.         0.         1.        ]
 [0.81001753 0.         0.44920476 0.47076515 0.36176581 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36167118 1.
  0.         0.         1.        ]
 [0.54898103 0.         0.         0.02180955 0.36185505 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.36178304 1.
  0.         0.         1.        ]
 [0.62065287 0.         0.12536437 0.11761761 0.36176599 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.36174045 1.
  0.         0.         1.        ]
 [0.65832948 0.         0.18169917 0.27655499 0.36183048 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36166633 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36178986 1.
  0.         0.         1.        ]
 [0.75167724 0.         0.38000334 0.36575845 0.36171781 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36171386 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36174375 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36167475 1.
  0.         0.         1.        ]
 [0.99007301 0.         0.70550791 0.77175779 0.36179991 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36174602 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3617282  1.
  0.         0.         1.        ]
 [1.         0.         0.96362762 1.         0.36167249 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36175415 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3616796  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36176461 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36179466 1.
  0.         0.         1.        ]
 [0.08964743 0.         0.         0.         0.36173306 1.
  0.         0.         1.        ]
 [0.86921945 0.         0.53778177 0.60062986 0.36176585 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.6875
#####################         POISON         ###############################################

############################################################################################

comm_round: 15 | global_test_acc: 58.333% | global_f1: 0.7368421052631579 | global_precision: 0.5833333333333334
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         5
           1       0.58      1.00      0.74         7

    accuracy                           0.58        12
   macro avg       0.29      0.50      0.37        12
weighted avg       0.34      0.58      0.43        12

Accuracy per class:
[[7 0]
 [5 0]]
[1. 0.]
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[1.         0.         0.         1.         0.         0.
 1.         0.         0.15258186 0.         0.0767143  1.
 0.75287728 1.         1.         0.72060429 0.7001271  0.05927054
 1.         1.         0.80580883 0.         0.57753897 0.77235743
 0.         0.         1.         0.57604248 1.         1.
 0.69497432 0.67731281 0.         0.         0.03396143]
wv_fg shape (35,)
[1.         1.         1.         1.         1.         0.07360734
 0.         1.         1.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.41595634 0.         0.         0.         1.
 0.         0.         0.         0.         0.        ]
wv_mn shape (35,)
[1.         0.         0.         1.         0.         0.
 0.66629783 0.         0.         0.         0.         1.
 0.51065105 1.         0.97789616 0.47119729 0.37404213 0.00706674
 1.         1.         0.58982949 0.         0.21003221 0.49824878
 0.         0.         0.99211129 0.12558988 1.         1.
 0.37538038 0.40519853 0.         0.         0.        ]
wv_ed shape (35,)
[1.         0.         0.         1.         0.         0.
 0.45106597 0.         0.         0.         0.07836295 1.
 0.52236257 1.         1.         0.46266924 0.31249658 0.
 1.         1.         0.45898331 0.         0.30691348 0.45175602
 0.         0.         1.         0.15048281 0.82091371 1.
 0.40240744 0.43029519 0.         0.         0.010457  ]
wv_lg shape (35, 1)
[[0.36267359]
 [0.3627436 ]
 [0.36269186]
 [0.36259903]
 [0.36273878]
 [0.36279947]
 [0.36276948]
 [0.36275381]
 [0.36264121]
 [0.36282013]
 [0.3620445 ]
 [0.36217241]
 [0.36206319]
 [0.36217298]
 [0.36210883]
 [0.36210749]
 [0.36216122]
 [0.36220154]
 [0.36218247]
 [0.36223762]
 [0.36226714]
 [0.36202557]
 [0.3620656 ]
 [0.36210487]
 [0.36206529]
 [0.36197574]
 [0.36212175]
 [0.36212531]
 [0.36216692]
 [0.3620842 ]
 [0.36217252]
 [0.36210989]
 [0.36211986]
 [0.3620378 ]
 [0.36210062]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[0.90943967 0.39124709 1.         0.35141564 1.         1.
 1.         1.         1.         1.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_std shape (35,)
[0.81869865 0.         0.         1.         0.         0.
 0.47880153 0.         0.65547959 0.         0.         0.
 0.         1.         0.         0.         0.         0.
 0.64891647 1.         0.17148439 0.         0.         0.20015892
 0.         0.         0.         0.         0.99083874 1.
 0.         0.         0.         0.         0.        ]
xy shape: (35, 9)
[[1.         1.         1.         1.         0.36267359 1.
  0.90943967 0.81869865 0.        ]
 [0.         1.         0.         0.         0.3627436  1.
  0.39124709 0.         0.        ]
 [0.         1.         0.         0.         0.36269186 1.
  1.         0.         0.        ]
 [1.         1.         1.         1.         0.36259903 1.
  0.35141564 1.         0.        ]
 [0.         1.         0.         0.         0.36273878 1.
  1.         0.         0.        ]
 [0.         0.07360734 0.         0.         0.36279947 1.
  1.         0.         0.        ]
 [1.         0.         0.66629783 0.45106597 0.36276948 1.
  1.         0.47880153 0.        ]
 [0.         1.         0.         0.         0.36275381 1.
  1.         0.         0.        ]
 [0.15258186 1.         0.         0.         0.36264121 1.
  1.         0.65547959 0.        ]
 [0.         0.         0.         0.         0.36282013 1.
  1.         0.         0.        ]
 [0.0767143  0.         0.         0.07836295 0.3620445  1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.36217241 1.
  0.         0.         1.        ]
 [0.75287728 0.         0.51065105 0.52236257 0.36206319 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.36217298 1.
  0.         1.         1.        ]
 [1.         0.         0.97789616 1.         0.36210883 1.
  0.         0.         1.        ]
 [0.72060429 0.         0.47119729 0.46266924 0.36210749 1.
  0.         0.         1.        ]
 [0.7001271  0.         0.37404213 0.31249658 0.36216122 1.
  0.         0.         1.        ]
 [0.05927054 0.         0.00706674 0.         0.36220154 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.36218247 1.
  0.         0.64891647 1.        ]
 [1.         0.         1.         1.         0.36223762 1.
  0.         1.         1.        ]
 [0.80580883 0.         0.58982949 0.45898331 0.36226714 1.
  0.         0.17148439 1.        ]
 [0.         0.         0.         0.         0.36202557 1.
  0.         0.         1.        ]
 [0.57753897 0.         0.21003221 0.30691348 0.3620656  1.
  0.         0.         1.        ]
 [0.77235743 0.         0.49824878 0.45175602 0.36210487 1.
  0.         0.20015892 1.        ]
 [0.         0.         0.         0.         0.36206529 1.
  0.         0.         1.        ]
 [0.         0.41595634 0.         0.         0.36197574 1.
  0.         0.         1.        ]
 [1.         0.         0.99211129 1.         0.36212175 1.
  0.         0.         1.        ]
 [0.57604248 0.         0.12558988 0.15048281 0.36212531 1.
  0.         0.         1.        ]
 [1.         0.         1.         0.82091371 0.36216692 1.
  0.         0.99083874 1.        ]
 [1.         1.         1.         1.         0.3620842  1.
  0.         1.         1.        ]
 [0.69497432 0.         0.37538038 0.40240744 0.36217252 1.
  0.         0.         1.        ]
 [0.67731281 0.         0.40519853 0.43029519 0.36210989 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36211986 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3620378  1.
  0.         0.         1.        ]
 [0.03396143 0.         0.         0.010457   0.36210062 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.875
#####################         POISON         ###############################################

############################################################################################

comm_round: 16 | global_test_acc: 41.667% | global_f1: 0.5882352941176471 | global_precision: 0.4166666666666667
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         7
           1       0.42      1.00      0.59         5

    accuracy                           0.42        12
   macro avg       0.21      0.50      0.29        12
weighted avg       0.17      0.42      0.25        12

Accuracy per class:
[[5 0]
 [7 0]]
[1. 0.]
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[0.29426205 1.         1.         1.         0.         0.87248934
 1.         0.         0.61584288 1.         1.         1.
 0.         1.         0.18860223 1.         0.04848285 0.49432458
 0.56006941 1.         0.         0.81562769 0.1799434  1.
 0.         0.4921429  0.76055945 1.         0.         1.
 0.         1.         1.         1.         1.        ]
wv_fg shape (35,)
[1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
wv_mn shape (35,)
[0.         1.         1.         1.         0.         0.31471144
 1.         0.         0.14094147 0.76578034 0.40710104 1.
 0.         0.53032768 0.         0.95452532 0.         0.
 0.0811056  0.71022304 0.         0.24795032 0.         0.61929395
 0.         0.         0.23134852 0.35593108 0.         1.
 0.         0.70340328 0.85711247 0.46375765 0.68353364]
wv_ed shape (35,)
[0.         1.         1.         1.         0.         0.42875681
 1.         0.         0.3139246  0.89677787 0.47077277 1.
 0.         0.70547884 0.         1.         0.         0.
 0.16848286 0.76870222 0.         0.28077154 0.         0.64393111
 0.         0.         0.38305002 0.46011308 0.         1.
 0.         0.78920025 0.95755212 0.54435168 0.83134156]
wv_lg shape (35, 1)
[[0.36304971]
 [0.36288281]
 [0.36291457]
 [0.36307616]
 [0.36308404]
 [0.36298444]
 [0.36300872]
 [0.36310016]
 [0.36290058]
 [0.36293034]
 [0.36243222]
 [0.36239827]
 [0.36236185]
 [0.3624238 ]
 [0.36229841]
 [0.36241465]
 [0.36227866]
 [0.3622864 ]
 [0.36239869]
 [0.3623784 ]
 [0.36228505]
 [0.36229563]
 [0.36226628]
 [0.36238443]
 [0.36230559]
 [0.36239031]
 [0.36231839]
 [0.36238674]
 [0.36224529]
 [0.36236451]
 [0.36233942]
 [0.36231148]
 [0.3623854 ]
 [0.36233971]
 [0.36242195]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[1.         0.95892414 0.90780663 1.         1.         1.
 0.82504023 1.         0.85790354 0.9362248  0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_std shape (35,)
[0.38656719 1.         1.         0.8506433  0.         0.30519079
 1.         0.         0.09049841 0.37542618 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
xy shape: (35, 9)
[[0.29426205 1.         0.         0.         0.36304971 1.
  1.         0.38656719 0.        ]
 [1.         1.         1.         1.         0.36288281 1.
  0.95892414 1.         0.        ]
 [1.         0.         1.         1.         0.36291457 1.
  0.90780663 1.         0.        ]
 [1.         0.         1.         1.         0.36307616 1.
  1.         0.8506433  0.        ]
 [0.         1.         0.         0.         0.36308404 1.
  1.         0.         0.        ]
 [0.87248934 0.         0.31471144 0.42875681 0.36298444 1.
  1.         0.30519079 0.        ]
 [1.         0.         1.         1.         0.36300872 1.
  0.82504023 1.         0.        ]
 [0.         1.         0.         0.         0.36310016 1.
  1.         0.         0.        ]
 [0.61584288 0.         0.14094147 0.3139246  0.36290058 1.
  0.85790354 0.09049841 0.        ]
 [1.         0.         0.76578034 0.89677787 0.36293034 1.
  0.9362248  0.37542618 0.        ]
 [1.         0.         0.40710104 0.47077277 0.36243222 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.36239827 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36236185 1.
  0.         0.         1.        ]
 [1.         0.         0.53032768 0.70547884 0.3624238  1.
  0.         0.         1.        ]
 [0.18860223 0.         0.         0.         0.36229841 1.
  0.         0.         1.        ]
 [1.         0.         0.95452532 1.         0.36241465 1.
  0.         0.         1.        ]
 [0.04848285 0.         0.         0.         0.36227866 1.
  0.         0.         1.        ]
 [0.49432458 0.         0.         0.         0.3622864  1.
  0.         0.         1.        ]
 [0.56006941 0.         0.0811056  0.16848286 0.36239869 1.
  0.         0.         1.        ]
 [1.         0.         0.71022304 0.76870222 0.3623784  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36228505 1.
  0.         0.         1.        ]
 [0.81562769 0.         0.24795032 0.28077154 0.36229563 1.
  0.         0.         1.        ]
 [0.1799434  0.         0.         0.         0.36226628 1.
  0.         0.         1.        ]
 [1.         0.         0.61929395 0.64393111 0.36238443 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36230559 1.
  0.         0.         1.        ]
 [0.4921429  0.         0.         0.         0.36239031 1.
  0.         0.         1.        ]
 [0.76055945 0.         0.23134852 0.38305002 0.36231839 1.
  0.         0.         1.        ]
 [1.         0.         0.35593108 0.46011308 0.36238674 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36224529 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.36236451 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36233942 1.
  0.         0.         1.        ]
 [1.         0.         0.70340328 0.78920025 0.36231148 1.
  0.         0.         1.        ]
 [1.         0.         0.85711247 0.95755212 0.3623854  1.
  0.         0.         1.        ]
 [1.         0.         0.46375765 0.54435168 0.36233971 1.
  0.         0.         1.        ]
 [1.         0.         0.68353364 0.83134156 0.36242195 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.8125
#####################         POISON         ###############################################

############################################################################################

comm_round: 17 | global_test_acc: 66.667% | global_f1: 0.8 | global_precision: 0.6666666666666666
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         4
           1       0.67      1.00      0.80         8

    accuracy                           0.67        12
   macro avg       0.33      0.50      0.40        12
weighted avg       0.44      0.67      0.53        12

Accuracy per class:
[[8 0]
 [4 0]]
[1. 0.]
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[0.79656335 0.37622175 1.         1.         1.         0.
 1.         0.         1.         1.         0.         0.5390922
 0.         0.         0.15609709 0.1046329  0.65610291 0.66019047
 0.39514347 0.         0.9581488  0.16117062 0.         0.26964998
 0.         0.         0.54813389 1.         0.         1.
 1.         0.         0.         0.16757182 0.        ]
wv_fg shape (35,)
[0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
wv_mn shape (35,)
[0.         0.         0.89806573 0.65421661 0.27518205 0.
 0.38219737 0.         1.         1.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.18468742 0.         0.         0.
 0.         0.         0.         0.24720369 0.         0.43644389
 0.45285271 0.         0.         0.         0.        ]
wv_ed shape (35,)
[0.00393706 0.         0.91694229 0.73141734 0.32503066 0.
 0.16467153 0.         1.         1.         0.         0.
 0.         0.         0.         0.         0.         0.09170324
 0.         0.         0.19488202 0.         0.         0.
 0.         0.         0.         0.33359742 0.         0.36672646
 0.511609   0.         0.         0.         0.        ]
wv_lg shape (35, 1)
[[0.36335808]
 [0.36327802]
 [0.36327659]
 [0.36332635]
 [0.36339232]
 [0.36340469]
 [0.36331373]
 [0.36340183]
 [0.36319412]
 [0.36324224]
 [0.36263069]
 [0.3627377 ]
 [0.3626141 ]
 [0.36267574]
 [0.36266591]
 [0.36264667]
 [0.362628  ]
 [0.36262344]
 [0.36263146]
 [0.36254526]
 [0.36259301]
 [0.36265626]
 [0.36264371]
 [0.36276634]
 [0.36258081]
 [0.36268668]
 [0.36267083]
 [0.36272318]
 [0.36269245]
 [0.36273604]
 [0.36267396]
 [0.36279257]
 [0.36265135]
 [0.36267553]
 [0.36263358]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[1.         0.6223233  1.         0.96585389 1.         0.91683628
 1.         1.         0.48124367 0.68738105 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_std shape (35,)
[0.         0.         0.05215678 0.         0.         0.
 0.         0.         1.         0.99682157 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
xy shape: (35, 9)
[[0.79656335 0.         0.         0.00393706 0.36335808 1.
  1.         0.         0.        ]
 [0.37622175 0.         0.         0.         0.36327802 1.
  0.6223233  0.         0.        ]
 [1.         0.         0.89806573 0.91694229 0.36327659 1.
  1.         0.05215678 0.        ]
 [1.         0.         0.65421661 0.73141734 0.36332635 1.
  0.96585389 0.         0.        ]
 [1.         0.         0.27518205 0.32503066 0.36339232 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.36340469 1.
  0.91683628 0.         0.        ]
 [1.         1.         0.38219737 0.16467153 0.36331373 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.36340183 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.36319412 1.
  0.48124367 1.         0.        ]
 [1.         0.         1.         1.         0.36324224 1.
  0.68738105 0.99682157 0.        ]
 [0.         0.         0.         0.         0.36263069 1.
  0.         0.         1.        ]
 [0.5390922  0.         0.         0.         0.3627377  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3626141  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36267574 1.
  0.         0.         1.        ]
 [0.15609709 0.         0.         0.         0.36266591 1.
  0.         0.         1.        ]
 [0.1046329  0.         0.         0.         0.36264667 1.
  0.         0.         1.        ]
 [0.65610291 0.         0.         0.         0.362628   1.
  0.         0.         1.        ]
 [0.66019047 0.         0.         0.09170324 0.36262344 1.
  0.         0.         1.        ]
 [0.39514347 0.         0.         0.         0.36263146 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36254526 1.
  0.         0.         1.        ]
 [0.9581488  0.         0.18468742 0.19488202 0.36259301 1.
  0.         0.         1.        ]
 [0.16117062 0.         0.         0.         0.36265626 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36264371 1.
  0.         0.         1.        ]
 [0.26964998 0.         0.         0.         0.36276634 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36258081 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36268668 1.
  0.         0.         1.        ]
 [0.54813389 0.         0.         0.         0.36267083 1.
  0.         0.         1.        ]
 [1.         0.         0.24720369 0.33359742 0.36272318 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36269245 1.
  0.         0.         1.        ]
 [1.         0.         0.43644389 0.36672646 0.36273604 1.
  0.         0.         1.        ]
 [1.         0.         0.45285271 0.511609   0.36267396 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36279257 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36265135 1.
  0.         0.         1.        ]
 [0.16757182 0.         0.         0.         0.36267553 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36263358 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.6875
#####################         POISON         ###############################################

############################################################################################

comm_round: 18 | global_test_acc: 66.667% | global_f1: 0.8 | global_precision: 0.6666666666666666
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         4
           1       0.67      1.00      0.80         8

    accuracy                           0.67        12
   macro avg       0.33      0.50      0.40        12
weighted avg       0.44      0.67      0.53        12

Accuracy per class:
[[8 0]
 [4 0]]
[1. 0.]
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[0.         1.         0.75591515 1.         1.         0.
 1.         0.         0.         0.9143653  1.         1.
 0.36138162 0.         0.         0.         0.36667248 0.86862534
 0.         0.46933126 0.         1.         0.75862817 0.
 0.         0.87970709 0.73104073 0.85679104 0.         0.59441027
 0.         0.51640867 1.         1.         0.        ]
wv_fg shape (35,)
[0.21666985 1.         0.         0.35523185 1.         0.00986538
 0.00986538 1.         0.         0.35523185 0.54713359 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.24804263 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.37134073 0.        ]
wv_mn shape (35,)
[0.         1.         0.41213435 1.         1.         0.
 0.56664263 0.         0.         0.44842258 0.66354126 0.4658322
 0.         0.         0.         0.         0.         0.38536175
 0.         0.         0.         0.57641637 0.28343664 0.
 0.         0.36397306 0.25668503 0.43001611 0.         0.02508649
 0.         0.         1.         0.80980005 0.        ]
wv_ed shape (35,)
[0.         1.         0.41897746 1.         1.         0.
 0.71071925 0.         0.         0.41868421 0.79399407 0.51589237
 0.         0.         0.         0.         0.         0.45527908
 0.         0.02439089 0.         0.63092659 0.28712682 0.
 0.         0.39965184 0.34598567 0.55833178 0.         0.09858034
 0.         0.1042924  1.         0.9476119  0.        ]
wv_lg shape (35, 1)
[[0.36365867]
 [0.36358428]
 [0.36367729]
 [0.36365774]
 [0.36355856]
 [0.36367122]
 [0.36361714]
 [0.36362982]
 [0.36372893]
 [0.36370338]
 [0.36305646]
 [0.36292663]
 [0.36285462]
 [0.3630082 ]
 [0.36294461]
 [0.36305599]
 [0.36293324]
 [0.36292546]
 [0.36296741]
 [0.36302692]
 [0.36292213]
 [0.36298241]
 [0.36304496]
 [0.36300178]
 [0.36294395]
 [0.36303712]
 [0.36299453]
 [0.3629521 ]
 [0.36296307]
 [0.36299184]
 [0.36296386]
 [0.36298364]
 [0.36298482]
 [0.36293775]
 [0.36291318]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[1.         1.         1.         1.         0.97191141 1.
 1.         1.         1.         1.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_std shape (35,)
[0.         0.74109171 0.         1.         1.         0.
 0.43824923 0.         0.         0.33243617 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
xy shape: (35, 9)
[[0.         0.21666985 0.         0.         0.36365867 1.
  1.         0.         0.        ]
 [1.         1.         1.         1.         0.36358428 1.
  1.         0.74109171 0.        ]
 [0.75591515 0.         0.41213435 0.41897746 0.36367729 1.
  1.         0.         0.        ]
 [1.         0.35523185 1.         1.         0.36365774 1.
  1.         1.         0.        ]
 [1.         1.         1.         1.         0.36355856 1.
  0.97191141 1.         0.        ]
 [0.         0.00986538 0.         0.         0.36367122 1.
  1.         0.         0.        ]
 [1.         0.00986538 0.56664263 0.71071925 0.36361714 1.
  1.         0.43824923 0.        ]
 [0.         1.         0.         0.         0.36362982 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.36372893 1.
  1.         0.         0.        ]
 [0.9143653  0.35523185 0.44842258 0.41868421 0.36370338 1.
  1.         0.33243617 0.        ]
 [1.         0.54713359 0.66354126 0.79399407 0.36305646 1.
  0.         0.         1.        ]
 [1.         0.         0.4658322  0.51589237 0.36292663 1.
  0.         0.         1.        ]
 [0.36138162 0.         0.         0.         0.36285462 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3630082  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36294461 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36305599 1.
  0.         0.         1.        ]
 [0.36667248 0.         0.         0.         0.36293324 1.
  0.         0.         1.        ]
 [0.86862534 0.         0.38536175 0.45527908 0.36292546 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36296741 1.
  0.         0.         1.        ]
 [0.46933126 0.         0.         0.02439089 0.36302692 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36292213 1.
  0.         0.         1.        ]
 [1.         0.         0.57641637 0.63092659 0.36298241 1.
  0.         0.         1.        ]
 [0.75862817 0.24804263 0.28343664 0.28712682 0.36304496 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36300178 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36294395 1.
  0.         0.         1.        ]
 [0.87970709 0.         0.36397306 0.39965184 0.36303712 1.
  0.         0.         1.        ]
 [0.73104073 0.         0.25668503 0.34598567 0.36299453 1.
  0.         0.         1.        ]
 [0.85679104 0.         0.43001611 0.55833178 0.3629521  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36296307 1.
  0.         0.         1.        ]
 [0.59441027 0.         0.02508649 0.09858034 0.36299184 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36296386 1.
  0.         0.         1.        ]
 [0.51640867 0.         0.         0.1042924  0.36298364 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.36298482 1.
  0.         0.         1.        ]
 [1.         0.37134073 0.80980005 0.9476119  0.36293775 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36291318 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.8125
#####################         POISON         ###############################################

############################################################################################

comm_round: 19 | global_test_acc: 58.333% | global_f1: 0.7368421052631579 | global_precision: 0.5833333333333334
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         5
           1       0.58      1.00      0.74         7

    accuracy                           0.58        12
   macro avg       0.29      0.50      0.37        12
weighted avg       0.34      0.58      0.43        12

Accuracy per class:
[[7 0]
 [5 0]]
[1. 0.]
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[0.         0.         0.         0.         1.         0.67358458
 0.32850298 0.         1.         1.         1.         0.
 0.02322709 0.64825589 1.         1.         0.         0.53080366
 0.         0.         0.77924338 0.51300654 0.         0.5444793
 0.         0.22237416 0.         0.         0.         0.
 1.         0.13712149 0.         0.55132697 0.66769659]
wv_fg shape (35,)
[0.26794338 0.         0.92964177 0.83273178 0.         0.
 0.         1.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_mn shape (35,)
[0.         0.         0.         0.         0.9631191  0.75078011
 0.39303156 0.         1.         1.         1.         0.
 0.         1.         1.         1.         0.         0.59673653
 0.         0.         0.95456035 0.72175927 0.         0.73626526
 0.         0.49265065 0.         0.         0.         0.
 1.         0.32487487 0.         0.65826893 0.91131547]
wv_ed shape (35,)
[0.         0.         0.         0.         0.92990987 0.92658227
 0.50849591 0.         1.         1.         1.         0.
 0.02154179 1.         1.         1.         0.         0.61585941
 0.         0.         0.87179834 0.72506716 0.         0.63645158
 0.         0.47305382 0.         0.         0.         0.
 1.         0.29964313 0.         0.61725029 0.81908412]
wv_lg shape (35, 1)
[[0.3639064 ]
 [0.36392587]
 [0.3639301 ]
 [0.36385057]
 [0.36385561]
 [0.36393583]
 [0.36395595]
 [0.36400123]
 [0.36383801]
 [0.36392628]
 [0.36331715]
 [0.36328895]
 [0.36329226]
 [0.36323421]
 [0.36331501]
 [0.36326654]
 [0.36331062]
 [0.3632921 ]
 [0.36330468]
 [0.3634063 ]
 [0.36329411]
 [0.36327702]
 [0.3633356 ]
 [0.36326602]
 [0.36334599]
 [0.36332698]
 [0.36328934]
 [0.36326095]
 [0.36336919]
 [0.36327458]
 [0.36335743]
 [0.36324707]
 [0.36330601]
 [0.36339943]
 [0.36331544]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[1.         1.         1.         0.55456208 1.         0.99918688
 1.         0.53415734 1.         1.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_std shape (35,)
[0.         0.         0.         0.         0.26334569 0.
 0.         0.         1.         0.23525716 0.83061264 0.
 0.         0.         1.         0.87322556 0.         0.
 0.         0.         0.07420795 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 1.         0.         0.         0.47528827 0.73461231]
xy shape: (35, 9)
[[0.         0.26794338 0.         0.         0.3639064  1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.36392587 1.
  1.         0.         0.        ]
 [0.         0.92964177 0.         0.         0.3639301  1.
  1.         0.         0.        ]
 [0.         0.83273178 0.         0.         0.36385057 1.
  0.55456208 0.         0.        ]
 [1.         0.         0.9631191  0.92990987 0.36385561 1.
  1.         0.26334569 0.        ]
 [0.67358458 0.         0.75078011 0.92658227 0.36393583 1.
  0.99918688 0.         0.        ]
 [0.32850298 0.         0.39303156 0.50849591 0.36395595 1.
  1.         0.         0.        ]
 [0.         1.         0.         0.         0.36400123 1.
  0.53415734 0.         0.        ]
 [1.         0.         1.         1.         0.36383801 1.
  1.         1.         0.        ]
 [1.         0.         1.         1.         0.36392628 1.
  1.         0.23525716 0.        ]
 [1.         0.         1.         1.         0.36331715 1.
  0.         0.83061264 1.        ]
 [0.         0.         0.         0.         0.36328895 1.
  0.         0.         1.        ]
 [0.02322709 0.         0.         0.02154179 0.36329226 1.
  0.         0.         1.        ]
 [0.64825589 0.         1.         1.         0.36323421 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.36331501 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.36326654 1.
  0.         0.87322556 1.        ]
 [0.         0.         0.         0.         0.36331062 1.
  0.         0.         1.        ]
 [0.53080366 0.         0.59673653 0.61585941 0.3632921  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36330468 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3634063  1.
  0.         0.         1.        ]
 [0.77924338 0.         0.95456035 0.87179834 0.36329411 1.
  0.         0.07420795 1.        ]
 [0.51300654 0.         0.72175927 0.72506716 0.36327702 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3633356  1.
  0.         0.         1.        ]
 [0.5444793  0.         0.73626526 0.63645158 0.36326602 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36334599 1.
  0.         0.         1.        ]
 [0.22237416 0.         0.49265065 0.47305382 0.36332698 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36328934 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36326095 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36336919 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36327458 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.36335743 1.
  0.         1.         1.        ]
 [0.13712149 0.         0.32487487 0.29964313 0.36324707 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36330601 1.
  0.         0.         1.        ]
 [0.55132697 0.         0.65826893 0.61725029 0.36339943 1.
  0.         0.47528827 1.        ]
 [0.66769659 0.         0.91131547 0.81908412 0.36331544 1.
  0.         0.73461231 1.        ]]

Best Training Poisoning Accuracy:
0.6875
#####################         POISON         ###############################################

############################################################################################

comm_round: 20 | global_test_acc: 83.333% | global_f1: 0.9090909090909091 | global_precision: 0.8333333333333334
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.83      1.00      0.91        10

    accuracy                           0.83        12
   macro avg       0.42      0.50      0.45        12
weighted avg       0.69      0.83      0.76        12

Accuracy per class:
[[10  0]
 [ 2  0]]
[1. 0.]
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[0.         0.         1.         0.         0.         1.
 0.78465961 0.76794374 1.         0.         1.         0.
 0.65601613 0.         0.49993238 1.         0.34620421 0.30347811
 0.65476597 0.         0.18839376 0.26261286 1.         1.
 1.         0.59625467 0.99102239 1.         0.51424638 0.40457559
 1.         1.         0.61987478 0.73059276 1.        ]
wv_fg shape (35,)
[1.         1.         1.         0.65787797 1.         1.
 1.         1.         0.65787797 1.         1.         0.98241595
 0.         0.         1.         0.         1.         0.19316206
 0.         0.         0.         0.         0.         0.
 0.21140023 0.         0.         0.         0.         0.
 0.         0.         0.         0.21090092 0.65440727]
wv_mn shape (35,)
[0.         0.         1.         0.         0.         1.
 0.70720571 0.68871811 1.         0.         1.         0.
 0.69782919 0.         0.33215493 1.         0.18374853 0.
 0.70020619 0.         0.         0.         1.         1.
 1.         0.51920783 0.8885653  1.         0.39466837 0.23707216
 1.         1.         0.63854756 0.87147672 1.        ]
wv_ed shape (35,)
[0.         0.         1.         0.         0.         1.
 0.77712475 0.50335107 1.         0.         1.         0.
 0.78483155 0.         0.37284959 1.         0.31828933 0.
 0.69415239 0.         0.         0.         1.         1.
 1.         0.54396642 0.80328539 1.         0.45063868 0.38819525
 1.         1.         0.70272763 0.86051237 1.        ]
wv_lg shape (35, 1)
[[0.364224  ]
 [0.36408216]
 [0.36416135]
 [0.36424705]
 [0.36425852]
 [0.36403146]
 [0.36421213]
 [0.36423803]
 [0.36410312]
 [0.3641536 ]
 [0.36369251]
 [0.36353945]
 [0.36352658]
 [0.36352802]
 [0.36350633]
 [0.36357064]
 [0.36365182]
 [0.36367519]
 [0.36355095]
 [0.36358365]
 [0.36361039]
 [0.36350225]
 [0.36353737]
 [0.36355343]
 [0.36358651]
 [0.36358757]
 [0.36356575]
 [0.36356981]
 [0.36354583]
 [0.36347594]
 [0.36348665]
 [0.36350851]
 [0.36353476]
 [0.36360431]
 [0.36360582]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[0.99541921 1.         0.7855534  1.         1.         1.
 0.88430501 1.         1.         1.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_std shape (35,)
[0.         0.         0.54256947 0.         0.         1.
 0.32395353 1.         1.         0.         0.85737053 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         1.        ]
xy shape: (35, 9)
[[0.         1.         0.         0.         0.364224   1.
  0.99541921 0.         0.        ]
 [0.         1.         0.         0.         0.36408216 1.
  1.         0.         0.        ]
 [1.         1.         1.         1.         0.36416135 1.
  0.7855534  0.54256947 0.        ]
 [0.         0.65787797 0.         0.         0.36424705 1.
  1.         0.         0.        ]
 [0.         1.         0.         0.         0.36425852 1.
  1.         0.         0.        ]
 [1.         1.         1.         1.         0.36403146 1.
  1.         1.         0.        ]
 [0.78465961 1.         0.70720571 0.77712475 0.36421213 1.
  0.88430501 0.32395353 0.        ]
 [0.76794374 1.         0.68871811 0.50335107 0.36423803 1.
  1.         1.         0.        ]
 [1.         0.65787797 1.         1.         0.36410312 1.
  1.         1.         0.        ]
 [0.         1.         0.         0.         0.3641536  1.
  1.         0.         0.        ]
 [1.         1.         1.         1.         0.36369251 1.
  0.         0.85737053 1.        ]
 [0.         0.98241595 0.         0.         0.36353945 1.
  0.         0.         1.        ]
 [0.65601613 0.         0.69782919 0.78483155 0.36352658 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36352802 1.
  0.         0.         1.        ]
 [0.49993238 1.         0.33215493 0.37284959 0.36350633 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.36357064 1.
  0.         0.         1.        ]
 [0.34620421 1.         0.18374853 0.31828933 0.36365182 1.
  0.         0.         1.        ]
 [0.30347811 0.19316206 0.         0.         0.36367519 1.
  0.         0.         1.        ]
 [0.65476597 0.         0.70020619 0.69415239 0.36355095 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36358365 1.
  0.         0.         1.        ]
 [0.18839376 0.         0.         0.         0.36361039 1.
  0.         0.         1.        ]
 [0.26261286 0.         0.         0.         0.36350225 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.36353737 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.36355343 1.
  0.         0.         1.        ]
 [1.         0.21140023 1.         1.         0.36358651 1.
  0.         0.         1.        ]
 [0.59625467 0.         0.51920783 0.54396642 0.36358757 1.
  0.         0.         1.        ]
 [0.99102239 0.         0.8885653  0.80328539 0.36356575 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.36356981 1.
  0.         0.         1.        ]
 [0.51424638 0.         0.39466837 0.45063868 0.36354583 1.
  0.         0.         1.        ]
 [0.40457559 0.         0.23707216 0.38819525 0.36347594 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.36348665 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.36350851 1.
  0.         0.         1.        ]
 [0.61987478 0.         0.63854756 0.70272763 0.36353476 1.
  0.         0.         1.        ]
 [0.73059276 0.21090092 0.87147672 0.86051237 0.36360431 1.
  0.         0.         1.        ]
 [1.         0.65440727 1.         1.         0.36360582 1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.6875
#####################         POISON         ###############################################

############################################################################################

comm_round: 21 | global_test_acc: 66.667% | global_f1: 0.8 | global_precision: 0.6666666666666666
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         4
           1       0.67      1.00      0.80         8

    accuracy                           0.67        12
   macro avg       0.33      0.50      0.40        12
weighted avg       0.44      0.67      0.53        12

Accuracy per class:
[[8 0]
 [4 0]]
[1. 0.]
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[0.         0.95803761 1.         1.         1.         1.
 1.         1.         1.         1.         0.09514794 0.01545918
 0.40488588 0.3799654  0.6814802  0.         0.67275638 0.11657213
 0.41636953 0.         0.23401533 0.48455482 0.28757088 0.47294312
 0.         0.         0.62556247 0.87059487 0.23840573 0.75367452
 0.61769859 1.         0.72589921 0.39834272 0.        ]
wv_fg shape (35,)
[1.         1.         0.         0.         0.33774529 0.15885062
 0.         0.         0.         0.29928387 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_mn shape (35,)
[0.         0.65145514 1.         1.         1.         1.
 1.         1.         1.         1.         0.         0.
 0.         0.         0.19891128 0.         0.15401792 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.05714736 0.62151295 0.         0.41777906
 0.13893762 0.72548866 0.31829373 0.         0.        ]
wv_ed shape (35,)
[0.         0.44012028 1.         1.         1.         1.
 1.         1.         1.         1.         0.         0.
 0.         0.         0.19573314 0.         0.15865799 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.12445133 0.54701875 0.         0.31310809
 0.03067974 0.59620984 0.32123752 0.         0.        ]
wv_lg shape (35, 1)
[[0.36451466]
 [0.36441463]
 [0.36444214]
 [0.36441388]
 [0.36438117]
 [0.36454256]
 [0.3643934 ]
 [0.36452746]
 [0.36442673]
 [0.36455884]
 [0.36390214]
 [0.36373497]
 [0.36394663]
 [0.36383748]
 [0.36386801]
 [0.36380415]
 [0.36387198]
 [0.36381179]
 [0.3638236 ]
 [0.36379669]
 [0.36377556]
 [0.36389912]
 [0.36380881]
 [0.36383438]
 [0.36387026]
 [0.36385445]
 [0.36388   ]
 [0.36375227]
 [0.36381044]
 [0.36389627]
 [0.3638414 ]
 [0.36394616]
 [0.36377333]
 [0.36381909]
 [0.36384019]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[1.         1.         0.63815249 0.84453175 1.         0.71285584
 1.         0.71342905 0.90211319 0.66712004 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_std shape (35,)
[0.         1.         1.         1.         1.         1.
 1.         1.         1.         0.63480034 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
xy shape: (35, 9)
[[0.         1.         0.         0.         0.36451466 1.
  1.         0.         0.        ]
 [0.95803761 1.         0.65145514 0.44012028 0.36441463 1.
  1.         1.         0.        ]
 [1.         0.         1.         1.         0.36444214 1.
  0.63815249 1.         0.        ]
 [1.         0.         1.         1.         0.36441388 1.
  0.84453175 1.         0.        ]
 [1.         0.33774529 1.         1.         0.36438117 1.
  1.         1.         0.        ]
 [1.         0.15885062 1.         1.         0.36454256 1.
  0.71285584 1.         0.        ]
 [1.         0.         1.         1.         0.3643934  1.
  1.         1.         0.        ]
 [1.         0.         1.         1.         0.36452746 1.
  0.71342905 1.         0.        ]
 [1.         0.         1.         1.         0.36442673 1.
  0.90211319 1.         0.        ]
 [1.         0.29928387 1.         1.         0.36455884 1.
  0.66712004 0.63480034 0.        ]
 [0.09514794 0.         0.         0.         0.36390214 1.
  0.         0.         1.        ]
 [0.01545918 0.         0.         0.         0.36373497 1.
  0.         0.         1.        ]
 [0.40488588 0.         0.         0.         0.36394663 1.
  0.         0.         1.        ]
 [0.3799654  0.         0.         0.         0.36383748 1.
  0.         0.         1.        ]
 [0.6814802  0.         0.19891128 0.19573314 0.36386801 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36380415 1.
  0.         0.         1.        ]
 [0.67275638 0.         0.15401792 0.15865799 0.36387198 1.
  0.         0.         1.        ]
 [0.11657213 0.         0.         0.         0.36381179 1.
  0.         0.         1.        ]
 [0.41636953 0.         0.         0.         0.3638236  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36379669 1.
  0.         0.         1.        ]
 [0.23401533 0.         0.         0.         0.36377556 1.
  0.         0.         1.        ]
 [0.48455482 0.         0.         0.         0.36389912 1.
  0.         0.         1.        ]
 [0.28757088 0.         0.         0.         0.36380881 1.
  0.         0.         1.        ]
 [0.47294312 0.         0.         0.         0.36383438 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36387026 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36385445 1.
  0.         0.         1.        ]
 [0.62556247 0.         0.05714736 0.12445133 0.36388    1.
  0.         0.         1.        ]
 [0.87059487 0.         0.62151295 0.54701875 0.36375227 1.
  0.         0.         1.        ]
 [0.23840573 0.         0.         0.         0.36381044 1.
  0.         0.         1.        ]
 [0.75367452 0.         0.41777906 0.31310809 0.36389627 1.
  0.         0.         1.        ]
 [0.61769859 0.         0.13893762 0.03067974 0.3638414  1.
  0.         0.         1.        ]
 [1.         0.         0.72548866 0.59620984 0.36394616 1.
  0.         0.         1.        ]
 [0.72589921 0.         0.31829373 0.32123752 0.36377333 1.
  0.         0.         1.        ]
 [0.39834272 0.         0.         0.         0.36381909 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36384019 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.625
#####################         POISON         ###############################################

############################################################################################

comm_round: 22 | global_test_acc: 75.000% | global_f1: 0.8571428571428571 | global_precision: 0.75
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.75      1.00      0.86         9

    accuracy                           0.75        12
   macro avg       0.38      0.50      0.43        12
weighted avg       0.56      0.75      0.64        12

Accuracy per class:
[[9 0]
 [3 0]]
[1. 0.]
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[1.         1.         0.         1.         1.         1.
 1.         1.         1.         1.         0.56735647 1.
 0.67592314 0.53270688 0.44718152 0.66799053 0.60099004 0.37603777
 0.84200808 0.46534121 1.         0.49786834 0.66321341 0.80456481
 0.84549615 0.87812954 0.82373554 1.         1.         0.99458007
 0.         0.64997047 0.11071885 1.         0.45134691]
wv_fg shape (35,)
[1.         1.         0.         0.         0.07657033 1.
 0.07657033 0.76086303 0.76086303 0.45064711 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.7773304  0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_mn shape (35,)
[1.         1.         0.         0.9318635  0.52797117 0.9722326
 0.79598931 1.         1.         0.76802077 0.         0.55912176
 0.         0.         0.         0.         0.         0.
 0.         0.         0.7475     0.         0.         0.
 0.         0.         0.         1.         0.83506541 0.13377249
 0.         0.         0.         0.31845474 0.        ]
wv_ed shape (35,)
[1.         1.         0.         0.8539953  0.42748858 0.92940785
 0.74189941 1.         1.         0.712184   0.         0.42275097
 0.         0.         0.         0.         0.         0.
 0.         0.         0.6210145  0.         0.         0.
 0.         0.         0.         1.         0.79740413 0.15155553
 0.         0.         0.         0.33405108 0.        ]
wv_lg shape (35, 1)
[[0.36477319]
 [0.36463998]
 [0.36483267]
 [0.3648213 ]
 [0.36468851]
 [0.36474567]
 [0.36465902]
 [0.36485072]
 [0.3647429 ]
 [0.36479021]
 [0.36413331]
 [0.36423294]
 [0.36422817]
 [0.36414552]
 [0.36415901]
 [0.36411025]
 [0.36416358]
 [0.36411924]
 [0.36413423]
 [0.36410746]
 [0.36413778]
 [0.36415232]
 [0.36417776]
 [0.36413923]
 [0.36419595]
 [0.36409791]
 [0.36409524]
 [0.36413646]
 [0.36416981]
 [0.36416381]
 [0.3640844 ]
 [0.36414454]
 [0.36414978]
 [0.36412901]
 [0.36412866]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
wv_std shape (35,)
[1.         1.         0.         0.29895403 0.29629504 0.10778381
 0.61973224 0.34890598 1.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
xy shape: (35, 9)
[[1.         1.         1.         1.         0.36477319 1.
  1.         1.         0.        ]
 [1.         1.         1.         1.         0.36463998 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.36483267 1.
  1.         0.         0.        ]
 [1.         0.         0.9318635  0.8539953  0.3648213  1.
  1.         0.29895403 0.        ]
 [1.         0.07657033 0.52797117 0.42748858 0.36468851 1.
  1.         0.29629504 0.        ]
 [1.         1.         0.9722326  0.92940785 0.36474567 1.
  1.         0.10778381 0.        ]
 [1.         0.07657033 0.79598931 0.74189941 0.36465902 1.
  1.         0.61973224 0.        ]
 [1.         0.76086303 1.         1.         0.36485072 1.
  1.         0.34890598 0.        ]
 [1.         0.76086303 1.         1.         0.3647429  1.
  1.         1.         0.        ]
 [1.         0.45064711 0.76802077 0.712184   0.36479021 1.
  1.         0.         0.        ]
 [0.56735647 0.         0.         0.         0.36413331 1.
  0.         0.         1.        ]
 [1.         0.         0.55912176 0.42275097 0.36423294 1.
  0.         0.         1.        ]
 [0.67592314 0.         0.         0.         0.36422817 1.
  0.         0.         1.        ]
 [0.53270688 0.         0.         0.         0.36414552 1.
  0.         0.         1.        ]
 [0.44718152 0.         0.         0.         0.36415901 1.
  0.         0.         1.        ]
 [0.66799053 0.         0.         0.         0.36411025 1.
  0.         0.         1.        ]
 [0.60099004 0.         0.         0.         0.36416358 1.
  0.         0.         1.        ]
 [0.37603777 0.         0.         0.         0.36411924 1.
  0.         0.         1.        ]
 [0.84200808 0.         0.         0.         0.36413423 1.
  0.         0.         1.        ]
 [0.46534121 0.         0.         0.         0.36410746 1.
  0.         0.         1.        ]
 [1.         0.7773304  0.7475     0.6210145  0.36413778 1.
  0.         0.         1.        ]
 [0.49786834 0.         0.         0.         0.36415232 1.
  0.         0.         1.        ]
 [0.66321341 0.         0.         0.         0.36417776 1.
  0.         0.         1.        ]
 [0.80456481 0.         0.         0.         0.36413923 1.
  0.         0.         1.        ]
 [0.84549615 0.         0.         0.         0.36419595 1.
  0.         0.         1.        ]
 [0.87812954 0.         0.         0.         0.36409791 1.
  0.         0.         1.        ]
 [0.82373554 0.         0.         0.         0.36409524 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.36413646 1.
  0.         0.         1.        ]
 [1.         0.         0.83506541 0.79740413 0.36416981 1.
  0.         0.         1.        ]
 [0.99458007 0.         0.13377249 0.15155553 0.36416381 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3640844  1.
  0.         0.         1.        ]
 [0.64997047 0.         0.         0.         0.36414454 1.
  0.         0.         1.        ]
 [0.11071885 0.         0.         0.         0.36414978 1.
  0.         0.         1.        ]
 [1.         0.         0.31845474 0.33405108 0.36412901 1.
  0.         0.         1.        ]
 [0.45134691 0.         0.         0.         0.36412866 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.6875
#####################         POISON         ###############################################

############################################################################################

comm_round: 23 | global_test_acc: 75.000% | global_f1: 0.8571428571428571 | global_precision: 0.75
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.75      1.00      0.86         9

    accuracy                           0.75        12
   macro avg       0.38      0.50      0.43        12
weighted avg       0.56      0.75      0.64        12

Accuracy per class:
[[9 0]
 [3 0]]
[1. 0.]
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[0.51070854 0.         0.11183436 0.         1.         0.
 0.51646718 0.65457306 1.         1.         1.         0.5596079
 0.         0.         0.07911097 1.         1.         0.
 0.         1.         0.         0.59419202 0.07901047 1.
 0.         0.58220285 0.         1.         0.         0.57167526
 0.33505616 0.         0.05998962 1.         1.        ]
wv_fg shape (35,)
[0.         0.         0.14372335 0.         0.         0.
 1.         0.         1.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_mn shape (35,)
[0.30196523 0.         0.03743682 0.         1.         0.
 0.30400223 0.39493561 1.         1.         0.92780594 0.49040414
 0.         0.         0.         0.55875507 1.         0.
 0.         1.         0.         0.45500963 0.02940383 1.
 0.         0.47005303 0.         0.83687891 0.         0.39869649
 0.1011466  0.         0.         0.66782974 0.87976965]
wv_ed shape (35,)
[0.42677111 0.         0.26202533 0.         1.         0.
 0.40394645 0.51820601 1.         1.         0.97585354 0.54397121
 0.         0.         0.         0.61677531 1.         0.
 0.         1.         0.         0.57226584 0.1347376  1.
 0.         0.54702642 0.         0.90296781 0.         0.45493043
 0.2080166  0.         0.06033025 0.79272366 0.97824569]
wv_lg shape (35, 1)
[[0.36501548]
 [0.36488335]
 [0.36507983]
 [0.36499222]
 [0.36492613]
 [0.36508513]
 [0.36508784]
 [0.36502382]
 [0.36496276]
 [0.36499405]
 [0.36443739]
 [0.36449877]
 [0.3644479 ]
 [0.36453683]
 [0.36453839]
 [0.36447685]
 [0.3644296 ]
 [0.36452492]
 [0.36443344]
 [0.36455163]
 [0.36442342]
 [0.36442701]
 [0.36443536]
 [0.36446391]
 [0.36453495]
 [0.36447917]
 [0.36440375]
 [0.36440729]
 [0.3644088 ]
 [0.36446676]
 [0.36446968]
 [0.36442529]
 [0.36444707]
 [0.36445081]
 [0.36442403]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
wv_std shape (35,)
[0.         0.         0.         0.         1.         0.
 0.         0.34198739 0.36845288 1.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
xy shape: (35, 9)
[[0.51070854 0.         0.30196523 0.42677111 0.36501548 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.36488335 1.
  1.         0.         0.        ]
 [0.11183436 0.14372335 0.03743682 0.26202533 0.36507983 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.36499222 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.36492613 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.36508513 1.
  1.         0.         0.        ]
 [0.51646718 1.         0.30400223 0.40394645 0.36508784 1.
  1.         0.         0.        ]
 [0.65457306 0.         0.39493561 0.51820601 0.36502382 1.
  1.         0.34198739 0.        ]
 [1.         1.         1.         1.         0.36496276 1.
  1.         0.36845288 0.        ]
 [1.         0.         1.         1.         0.36499405 1.
  1.         1.         0.        ]
 [1.         0.         0.92780594 0.97585354 0.36443739 1.
  0.         0.         1.        ]
 [0.5596079  0.         0.49040414 0.54397121 0.36449877 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3644479  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36453683 1.
  0.         0.         1.        ]
 [0.07911097 0.         0.         0.         0.36453839 1.
  0.         0.         1.        ]
 [1.         0.         0.55875507 0.61677531 0.36447685 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.3644296  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36452492 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36443344 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.36455163 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36442342 1.
  0.         0.         1.        ]
 [0.59419202 0.         0.45500963 0.57226584 0.36442701 1.
  0.         0.         1.        ]
 [0.07901047 0.         0.02940383 0.1347376  0.36443536 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.36446391 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36453495 1.
  0.         0.         1.        ]
 [0.58220285 0.         0.47005303 0.54702642 0.36447917 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36440375 1.
  0.         0.         1.        ]
 [1.         0.         0.83687891 0.90296781 0.36440729 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3644088  1.
  0.         0.         1.        ]
 [0.57167526 0.         0.39869649 0.45493043 0.36446676 1.
  0.         0.         1.        ]
 [0.33505616 0.         0.1011466  0.2080166  0.36446968 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36442529 1.
  0.         0.         1.        ]
 [0.05998962 0.         0.         0.06033025 0.36444707 1.
  0.         0.         1.        ]
 [1.         0.         0.66782974 0.79272366 0.36445081 1.
  0.         0.         1.        ]
 [1.         0.         0.87976965 0.97824569 0.36442403 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.8125
#####################         POISON         ###############################################

############################################################################################

comm_round: 24 | global_test_acc: 58.333% | global_f1: 0.7368421052631579 | global_precision: 0.5833333333333334
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         5
           1       0.58      1.00      0.74         7

    accuracy                           0.58        12
   macro avg       0.29      0.50      0.37        12
weighted avg       0.34      0.58      0.43        12

Accuracy per class:
[[7 0]
 [5 0]]
[1. 0.]
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[1.         1.         0.6399049  1.         0.         0.
 1.         0.19576864 1.         1.         0.         0.
 0.         0.         0.         0.         0.         1.
 0.45489498 0.         0.16396393 0.         0.         0.
 0.         0.14483595 1.         0.57411762 0.         0.
 0.         1.         0.         0.45577828 0.99040701]
wv_fg shape (35,)
[0.         0.         0.17861506 1.         1.         0.17861506
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_mn shape (35,)
[1.         1.         0.29079808 1.         0.         0.
 1.         0.         0.85645332 1.         0.         0.
 0.         0.         0.         0.         0.         0.63478838
 0.07655301 0.         0.         0.         0.         0.
 0.         0.         0.37047758 0.19249054 0.         0.
 0.         0.43644848 0.         0.06781446 0.377137  ]
wv_ed shape (35,)
[1.         1.         0.         1.         0.         0.
 1.         0.         0.80910726 1.         0.         0.
 0.         0.         0.         0.         0.         0.70259684
 0.21579646 0.         0.         0.         0.         0.
 0.         0.         0.37340586 0.34546232 0.         0.
 0.         0.37540974 0.         0.01710457 0.41166529]
wv_lg shape (35, 1)
[[0.36533477]
 [0.36525686]
 [0.36534301]
 [0.36533854]
 [0.36531124]
 [0.36538765]
 [0.36521764]
 [0.3653483 ]
 [0.36526152]
 [0.36519251]
 [0.36465629]
 [0.36464902]
 [0.36465781]
 [0.36470064]
 [0.36470581]
 [0.36470612]
 [0.3646791 ]
 [0.36467101]
 [0.36473442]
 [0.36466657]
 [0.36476938]
 [0.36466421]
 [0.36468005]
 [0.36479006]
 [0.36463936]
 [0.36472205]
 [0.36468198]
 [0.36472022]
 [0.36464464]
 [0.36471082]
 [0.36463695]
 [0.36467955]
 [0.36464488]
 [0.36466203]
 [0.3646993 ]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[0.40619791 0.9973079  1.         0.62901874 1.         1.
 0.05197987 1.         0.40698618 0.41843318 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_std shape (35,)
[1.        1.        1.        1.        0.6972043 0.        1.
 0.        1.        1.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.       ]
xy shape: (35, 9)
[[1.         0.         1.         1.         0.36533477 1.
  0.40619791 1.         0.        ]
 [1.         0.         1.         1.         0.36525686 1.
  0.9973079  1.         0.        ]
 [0.6399049  0.17861506 0.29079808 0.         0.36534301 1.
  1.         1.         0.        ]
 [1.         1.         1.         1.         0.36533854 1.
  0.62901874 1.         0.        ]
 [0.         1.         0.         0.         0.36531124 1.
  1.         0.6972043  0.        ]
 [0.         0.17861506 0.         0.         0.36538765 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.36521764 1.
  0.05197987 1.         0.        ]
 [0.19576864 0.         0.         0.         0.3653483  1.
  1.         0.         0.        ]
 [1.         0.         0.85645332 0.80910726 0.36526152 1.
  0.40698618 1.         0.        ]
 [1.         0.         1.         1.         0.36519251 1.
  0.41843318 1.         0.        ]
 [0.         0.         0.         0.         0.36465629 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36464902 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36465781 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36470064 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36470581 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36470612 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3646791  1.
  0.         0.         1.        ]
 [1.         0.         0.63478838 0.70259684 0.36467101 1.
  0.         0.         1.        ]
 [0.45489498 0.         0.07655301 0.21579646 0.36473442 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36466657 1.
  0.         0.         1.        ]
 [0.16396393 0.         0.         0.         0.36476938 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36466421 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36468005 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36479006 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36463936 1.
  0.         0.         1.        ]
 [0.14483595 0.         0.         0.         0.36472205 1.
  0.         0.         1.        ]
 [1.         0.         0.37047758 0.37340586 0.36468198 1.
  0.         0.         1.        ]
 [0.57411762 0.         0.19249054 0.34546232 0.36472022 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36464464 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36471082 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36463695 1.
  0.         0.         1.        ]
 [1.         0.         0.43644848 0.37540974 0.36467955 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36464488 1.
  0.         0.         1.        ]
 [0.45577828 0.         0.06781446 0.01710457 0.36466203 1.
  0.         0.         1.        ]
 [0.99040701 0.         0.377137   0.41166529 0.3646993  1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.75
#####################         POISON         ###############################################

############################################################################################

comm_round: 25 | global_test_acc: 66.667% | global_f1: 0.8 | global_precision: 0.6666666666666666
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         4
           1       0.67      1.00      0.80         8

    accuracy                           0.67        12
   macro avg       0.33      0.50      0.40        12
weighted avg       0.44      0.67      0.53        12

Accuracy per class:
[[8 0]
 [4 0]]
[1. 0.]
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[0.         1.         0.51813042 0.5913755  0.98137278 1.
 0.19077514 1.         0.         1.         0.77439267 0.37678302
 0.80208558 0.91438131 0.         0.3730582  0.37638172 0.
 0.9599452  0.         0.         0.84871692 0.96663942 0.
 0.         1.         1.         0.         0.         0.
 0.         1.         0.         0.         0.        ]
wv_fg shape (35,)
[0.7219387  0.7219387  1.         0.         0.91451889 0.
 0.95681764 1.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_mn shape (35,)
[0.         1.         0.2831137  0.52592908 0.76256198 1.
 0.10722032 1.         0.         1.         0.36818827 0.12258982
 0.44830395 0.69888752 0.         0.1401118  0.13580063 0.
 0.75821525 0.         0.         0.4465638  0.6213741  0.
 0.         0.81202968 0.8247599  0.         0.         0.
 0.         1.         0.         0.         0.        ]
wv_ed shape (35,)
[0.         1.         0.31795643 0.70862306 0.90978081 1.
 0.29810864 1.         0.         1.         0.40475748 0.
 0.44448183 0.48677699 0.         0.         0.         0.
 0.4546728  0.         0.         0.23940632 0.33593712 0.
 0.         0.67908823 0.66365673 0.         0.         0.
 0.         0.98218654 0.         0.         0.        ]
wv_lg shape (35, 1)
[[0.36563867]
 [0.36554322]
 [0.36543092]
 [0.36552928]
 [0.36558517]
 [0.36544933]
 [0.36544734]
 [0.3655385 ]
 [0.36557305]
 [0.36551988]
 [0.36499506]
 [0.36490037]
 [0.36493409]
 [0.36485179]
 [0.36488663]
 [0.36498019]
 [0.36502738]
 [0.36497716]
 [0.36497112]
 [0.36488336]
 [0.36493277]
 [0.36492695]
 [0.36502262]
 [0.36494531]
 [0.3648844 ]
 [0.36487159]
 [0.36487698]
 [0.36496035]
 [0.36488557]
 [0.36491752]
 [0.36490994]
 [0.36491251]
 [0.36493752]
 [0.36491038]
 [0.36489179]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[1.         1.         1.         0.56216991 0.84145869 0.37553456
 0.83454143 0.07593158 0.98284225 0.50521158 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_std shape (35,)
[0.         1.         0.         0.         0.         1.
 0.         1.         0.         1.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.23360872 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
xy shape: (35, 9)
[[0.         0.7219387  0.         0.         0.36563867 1.
  1.         0.         0.        ]
 [1.         0.7219387  1.         1.         0.36554322 1.
  1.         1.         0.        ]
 [0.51813042 1.         0.2831137  0.31795643 0.36543092 1.
  1.         0.         0.        ]
 [0.5913755  0.         0.52592908 0.70862306 0.36552928 1.
  0.56216991 0.         0.        ]
 [0.98137278 0.91451889 0.76256198 0.90978081 0.36558517 1.
  0.84145869 0.         0.        ]
 [1.         0.         1.         1.         0.36544933 1.
  0.37553456 1.         0.        ]
 [0.19077514 0.95681764 0.10722032 0.29810864 0.36544734 1.
  0.83454143 0.         0.        ]
 [1.         1.         1.         1.         0.3655385  1.
  0.07593158 1.         0.        ]
 [0.         0.         0.         0.         0.36557305 1.
  0.98284225 0.         0.        ]
 [1.         0.         1.         1.         0.36551988 1.
  0.50521158 1.         0.        ]
 [0.77439267 0.         0.36818827 0.40475748 0.36499506 1.
  0.         0.         1.        ]
 [0.37678302 0.         0.12258982 0.         0.36490037 1.
  0.         0.         1.        ]
 [0.80208558 0.         0.44830395 0.44448183 0.36493409 1.
  0.         0.         1.        ]
 [0.91438131 0.         0.69888752 0.48677699 0.36485179 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36488663 1.
  0.         0.         1.        ]
 [0.3730582  0.         0.1401118  0.         0.36498019 1.
  0.         0.         1.        ]
 [0.37638172 0.         0.13580063 0.         0.36502738 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36497716 1.
  0.         0.         1.        ]
 [0.9599452  0.         0.75821525 0.4546728  0.36497112 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36488336 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36493277 1.
  0.         0.         1.        ]
 [0.84871692 0.         0.4465638  0.23940632 0.36492695 1.
  0.         0.         1.        ]
 [0.96663942 0.         0.6213741  0.33593712 0.36502262 1.
  0.         0.23360872 1.        ]
 [0.         0.         0.         0.         0.36494531 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3648844  1.
  0.         0.         1.        ]
 [1.         0.         0.81202968 0.67908823 0.36487159 1.
  0.         0.         1.        ]
 [1.         0.         0.8247599  0.66365673 0.36487698 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36496035 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36488557 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36491752 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36490994 1.
  0.         0.         1.        ]
 [1.         0.         1.         0.98218654 0.36491251 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36493752 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36491038 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36489179 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.8125
#####################         POISON         ###############################################

############################################################################################

comm_round: 26 | global_test_acc: 58.333% | global_f1: 0.7368421052631579 | global_precision: 0.5833333333333334
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         5
           1       0.58      1.00      0.74         7

    accuracy                           0.58        12
   macro avg       0.29      0.50      0.37        12
weighted avg       0.34      0.58      0.43        12

Accuracy per class:
[[7 0]
 [5 0]]
[1. 0.]
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[0.         0.50642698 0.27848314 1.         1.         1.
 0.         1.         1.         1.         1.         0.
 1.         0.         0.01889274 0.         1.         0.
 1.         0.11677781 0.         0.         0.13972418 0.
 0.         0.         0.         1.         0.4071118  0.01811283
 0.         1.         0.19196934 0.         0.        ]
wv_fg shape (35,)
[0.09236074 0.         1.         1.         1.         0.09236074
 1.         0.         1.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_mn shape (35,)
[0.         0.08805841 0.         1.         1.         1.
 0.         1.         1.         1.         0.21449714 0.
 0.64630389 0.         0.         0.         0.64714865 0.
 0.68492777 0.         0.         0.         0.         0.
 0.         0.         0.         0.64197407 0.07886909 0.
 0.         0.68049758 0.         0.         0.        ]
wv_ed shape (35,)
[0.         0.1125259  0.         1.         1.         1.
 0.         1.         1.         1.         0.21790772 0.
 0.61448063 0.         0.         0.         0.65675018 0.
 0.6159774  0.         0.         0.         0.         0.
 0.         0.         0.         0.61051018 0.12845456 0.
 0.         0.66903883 0.         0.         0.        ]
wv_lg shape (35, 1)
[[0.36586752]
 [0.36585851]
 [0.36588647]
 [0.36580434]
 [0.36583779]
 [0.36588901]
 [0.36588712]
 [0.36575944]
 [0.36589596]
 [0.3657289 ]
 [0.36526843]
 [0.36522963]
 [0.36521876]
 [0.36523089]
 [0.36526784]
 [0.36522853]
 [0.36526977]
 [0.36522751]
 [0.3652467 ]
 [0.36519586]
 [0.36524729]
 [0.3652393 ]
 [0.36522542]
 [0.36523226]
 [0.36519758]
 [0.36525878]
 [0.36528157]
 [0.36520162]
 [0.36522841]
 [0.36519328]
 [0.36520175]
 [0.36530278]
 [0.36523481]
 [0.36523457]
 [0.3652306 ]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[1.         1.         1.         0.39024002 1.         1.
 1.         1.         0.73479485 1.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_std shape (35,)
[0.         0.         0.         0.79892487 0.         1.
 0.         1.         0.9187992  0.83721283 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
xy shape: (35, 9)
[[0.         0.09236074 0.         0.         0.36586752 1.
  1.         0.         0.        ]
 [0.50642698 0.         0.08805841 0.1125259  0.36585851 1.
  1.         0.         0.        ]
 [0.27848314 1.         0.         0.         0.36588647 1.
  1.         0.         0.        ]
 [1.         1.         1.         1.         0.36580434 1.
  0.39024002 0.79892487 0.        ]
 [1.         1.         1.         1.         0.36583779 1.
  1.         0.         0.        ]
 [1.         0.09236074 1.         1.         0.36588901 1.
  1.         1.         0.        ]
 [0.         1.         0.         0.         0.36588712 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.36575944 1.
  1.         1.         0.        ]
 [1.         1.         1.         1.         0.36589596 1.
  0.73479485 0.9187992  0.        ]
 [1.         0.         1.         1.         0.3657289  1.
  1.         0.83721283 0.        ]
 [1.         0.         0.21449714 0.21790772 0.36526843 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36522963 1.
  0.         0.         1.        ]
 [1.         0.         0.64630389 0.61448063 0.36521876 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36523089 1.
  0.         0.         1.        ]
 [0.01889274 0.         0.         0.         0.36526784 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36522853 1.
  0.         0.         1.        ]
 [1.         0.         0.64714865 0.65675018 0.36526977 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36522751 1.
  0.         0.         1.        ]
 [1.         0.         0.68492777 0.6159774  0.3652467  1.
  0.         0.         1.        ]
 [0.11677781 0.         0.         0.         0.36519586 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36524729 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3652393  1.
  0.         0.         1.        ]
 [0.13972418 0.         0.         0.         0.36522542 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36523226 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36519758 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36525878 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36528157 1.
  0.         0.         1.        ]
 [1.         0.         0.64197407 0.61051018 0.36520162 1.
  0.         0.         1.        ]
 [0.4071118  0.         0.07886909 0.12845456 0.36522841 1.
  0.         0.         1.        ]
 [0.01811283 0.         0.         0.         0.36519328 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36520175 1.
  0.         0.         1.        ]
 [1.         0.         0.68049758 0.66903883 0.36530278 1.
  0.         0.         1.        ]
 [0.19196934 0.         0.         0.         0.36523481 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36523457 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3652306  1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.625
#####################         POISON         ###############################################

############################################################################################

comm_round: 27 | global_test_acc: 91.667% | global_f1: 0.9565217391304348 | global_precision: 0.9166666666666666
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.92      1.00      0.96        11

    accuracy                           0.92        12
   macro avg       0.46      0.50      0.48        12
weighted avg       0.84      0.92      0.88        12

Accuracy per class:
[[11  0]
 [ 1  0]]
[1. 0.]
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[1.         1.         1.         1.         1.         0.
 0.63342659 0.         1.         1.         0.         0.
 0.         0.         0.         0.26901513 0.         0.33055832
 1.         0.53334463 0.         0.         0.45875165 0.44090399
 0.         0.         0.         0.36603303 0.38712093 0.
 0.8827255  0.80990654 1.         1.         0.        ]
wv_fg shape (35,)
[1.         0.         0.         0.43493448 0.56447061 0.
 0.41441206 0.         1.         0.44231791 0.         0.
 0.         0.         0.         0.         0.         0.
 1.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_mn shape (35,)
[1.         0.44118324 0.6487307  0.90657676 1.         0.
 0.09256811 0.         1.         0.36997775 0.         0.
 0.         0.         0.         0.         0.         0.
 1.         0.09620031 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.4207693  0.23898052 1.         1.         0.        ]
wv_ed shape (35,)
[1.         0.45006898 0.62518444 0.90833361 1.         0.
 0.12222806 0.         1.         0.23612442 0.         0.
 0.         0.         0.         0.         0.         0.
 1.         0.18571172 0.         0.         0.07669583 0.
 0.         0.         0.         0.         0.         0.
 0.52537595 0.27933399 1.         1.         0.        ]
wv_lg shape (35, 1)
[[0.36606251]
 [0.36612224]
 [0.36609569]
 [0.3660834 ]
 [0.36601813]
 [0.36613149]
 [0.36612466]
 [0.36610488]
 [0.36595959]
 [0.36607699]
 [0.36553136]
 [0.36555235]
 [0.36558167]
 [0.36561795]
 [0.36553641]
 [0.36555994]
 [0.36556119]
 [0.36559819]
 [0.36551316]
 [0.36556009]
 [0.36556549]
 [0.36551487]
 [0.36554033]
 [0.36560573]
 [0.36562529]
 [0.36558758]
 [0.3655268 ]
 [0.36558635]
 [0.36552452]
 [0.36547691]
 [0.36554339]
 [0.36559834]
 [0.36561846]
 [0.36560027]
 [0.3655363 ]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[1.         1.         1.         1.         1.         1.
 1.         1.         0.99369689 1.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_std shape (35,)
[1.         0.44743396 0.57825855 0.95914632 1.         0.
 0.25171826 0.         1.         0.44595705 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.51773851 0.48585788 0.        ]
xy shape: (35, 9)
[[1.         1.         1.         1.         0.36606251 1.
  1.         1.         0.        ]
 [1.         0.         0.44118324 0.45006898 0.36612224 1.
  1.         0.44743396 0.        ]
 [1.         0.         0.6487307  0.62518444 0.36609569 1.
  1.         0.57825855 0.        ]
 [1.         0.43493448 0.90657676 0.90833361 0.3660834  1.
  1.         0.95914632 0.        ]
 [1.         0.56447061 1.         1.         0.36601813 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.36613149 1.
  1.         0.         0.        ]
 [0.63342659 0.41441206 0.09256811 0.12222806 0.36612466 1.
  1.         0.25171826 0.        ]
 [0.         0.         0.         0.         0.36610488 1.
  1.         0.         0.        ]
 [1.         1.         1.         1.         0.36595959 1.
  0.99369689 1.         0.        ]
 [1.         0.44231791 0.36997775 0.23612442 0.36607699 1.
  1.         0.44595705 0.        ]
 [0.         0.         0.         0.         0.36553136 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36555235 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36558167 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36561795 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36553641 1.
  0.         0.         1.        ]
 [0.26901513 0.         0.         0.         0.36555994 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36556119 1.
  0.         0.         1.        ]
 [0.33055832 0.         0.         0.         0.36559819 1.
  0.         0.         1.        ]
 [1.         1.         1.         1.         0.36551316 1.
  0.         0.         1.        ]
 [0.53334463 0.         0.09620031 0.18571172 0.36556009 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36556549 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36551487 1.
  0.         0.         1.        ]
 [0.45875165 0.         0.         0.07669583 0.36554033 1.
  0.         0.         1.        ]
 [0.44090399 0.         0.         0.         0.36560573 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36562529 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36558758 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3655268  1.
  0.         0.         1.        ]
 [0.36603303 0.         0.         0.         0.36558635 1.
  0.         0.         1.        ]
 [0.38712093 0.         0.         0.         0.36552452 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36547691 1.
  0.         0.         1.        ]
 [0.8827255  0.         0.4207693  0.52537595 0.36554339 1.
  0.         0.         1.        ]
 [0.80990654 0.         0.23898052 0.27933399 0.36559834 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.36561846 1.
  0.         0.51773851 1.        ]
 [1.         0.         1.         1.         0.36560027 1.
  0.         0.48585788 1.        ]
 [0.         0.         0.         0.         0.3655363  1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.75
#####################         POISON         ###############################################

############################################################################################

comm_round: 28 | global_test_acc: 66.667% | global_f1: 0.8 | global_precision: 0.6666666666666666
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         4
           1       0.67      1.00      0.80         8

    accuracy                           0.67        12
   macro avg       0.33      0.50      0.40        12
weighted avg       0.44      0.67      0.53        12

Accuracy per class:
[[8 0]
 [4 0]]
[1. 0.]
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[0.27489062 1.         0.28708121 1.         1.         0.18363066
 0.         1.         0.07477379 0.12464464 0.         1.
 1.         1.         0.18750012 0.         0.         0.82379998
 1.         1.         0.9305586  0.         0.         0.
 0.         0.         0.75584677 0.         1.         0.
 0.88121317 0.         0.         1.         0.        ]
wv_fg shape (35,)
[1.         0.         0.95439673 1.         0.63446588 0.
 1.         0.         0.         0.5042781  0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_mn shape (35,)
[0.16654081 1.         0.19417249 1.         1.         0.17989084
 0.         1.         0.         0.09265874 0.         1.
 1.         1.         0.36436114 0.         0.         0.70014849
 1.         1.         0.94688258 0.         0.         0.01812551
 0.09216033 0.         0.53131582 0.         1.         0.
 0.78512386 0.         0.         1.         0.        ]
wv_ed shape (35,)
[0.17088968 1.         0.4943726  1.         1.         0.54657437
 0.         1.         0.33592531 0.3493592  0.         1.
 1.         1.         0.40414896 0.         0.         0.824465
 1.         1.         1.         0.         0.         0.01259859
 0.09408212 0.         0.77077673 0.         1.         0.
 0.99359409 0.         0.         1.         0.        ]
wv_lg shape (35, 1)
[[0.36632431]
 [0.36633059]
 [0.36639712]
 [0.36633688]
 [0.36636142]
 [0.36633563]
 [0.36635518]
 [0.36635272]
 [0.3664103 ]
 [0.36632283]
 [0.36580579]
 [0.36581103]
 [0.36576411]
 [0.36590843]
 [0.36580253]
 [0.3658307 ]
 [0.36585192]
 [0.36578052]
 [0.36579952]
 [0.36588826]
 [0.36580362]
 [0.36579943]
 [0.36581471]
 [0.36579803]
 [0.36579995]
 [0.36579254]
 [0.36581961]
 [0.36581771]
 [0.3659021 ]
 [0.36570862]
 [0.36582415]
 [0.36581473]
 [0.36580627]
 [0.36585615]
 [0.36584181]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[1.        1.        1.        1.        0.9787074 1.        1.
 1.        1.        1.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.       ]
wv_std shape (35,)
[0.         0.39310305 0.         0.07449025 0.46736495 0.
 0.         0.98344643 0.         0.         0.         0.31095637
 1.         1.         0.         0.         0.         0.
 1.         1.         0.         0.         0.         0.
 0.         0.         0.         0.         1.         0.
 0.         0.         0.         1.         0.        ]
xy shape: (35, 9)
[[0.27489062 1.         0.16654081 0.17088968 0.36632431 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.36633059 1.
  1.         0.39310305 0.        ]
 [0.28708121 0.95439673 0.19417249 0.4943726  0.36639712 1.
  1.         0.         0.        ]
 [1.         1.         1.         1.         0.36633688 1.
  1.         0.07449025 0.        ]
 [1.         0.63446588 1.         1.         0.36636142 1.
  0.9787074  0.46736495 0.        ]
 [0.18363066 0.         0.17989084 0.54657437 0.36633563 1.
  1.         0.         0.        ]
 [0.         1.         0.         0.         0.36635518 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.36635272 1.
  1.         0.98344643 0.        ]
 [0.07477379 0.         0.         0.33592531 0.3664103  1.
  1.         0.         0.        ]
 [0.12464464 0.5042781  0.09265874 0.3493592  0.36632283 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.36580579 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.36581103 1.
  0.         0.31095637 1.        ]
 [1.         0.         1.         1.         0.36576411 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.36590843 1.
  0.         1.         1.        ]
 [0.18750012 0.         0.36436114 0.40414896 0.36580253 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3658307  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36585192 1.
  0.         0.         1.        ]
 [0.82379998 0.         0.70014849 0.824465   0.36578052 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.36579952 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.36588826 1.
  0.         1.         1.        ]
 [0.9305586  0.         0.94688258 1.         0.36580362 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36579943 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36581471 1.
  0.         0.         1.        ]
 [0.         0.         0.01812551 0.01259859 0.36579803 1.
  0.         0.         1.        ]
 [0.         0.         0.09216033 0.09408212 0.36579995 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36579254 1.
  0.         0.         1.        ]
 [0.75584677 0.         0.53131582 0.77077673 0.36581961 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36581771 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.3659021  1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.36570862 1.
  0.         0.         1.        ]
 [0.88121317 0.         0.78512386 0.99359409 0.36582415 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36581473 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.36580627 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.36585615 1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.36584181 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.625
#####################         POISON         ###############################################

############################################################################################

comm_round: 29 | global_test_acc: 75.000% | global_f1: 0.8571428571428571 | global_precision: 0.75
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.75      1.00      0.86         9

    accuracy                           0.75        12
   macro avg       0.38      0.50      0.43        12
weighted avg       0.56      0.75      0.64        12

Accuracy per class:
[[9 0]
 [3 0]]
[1. 0.]
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[1.         0.         0.         1.         1.         1.
 1.         0.         1.         1.         1.         1.
 1.         1.         0.9520288  1.         0.         1.
 1.         1.         1.         0.         1.         1.
 1.         1.         1.         0.         0.95913527 1.
 1.         1.         1.         1.         1.        ]
wv_fg shape (35,)
[1.         0.         1.         1.         0.16898577 0.
 1.         0.         1.         0.         0.         0.
 0.         0.         0.01906642 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_mn shape (35,)
[1.         0.         0.         1.         1.         1.
 1.         0.         1.         1.         0.         0.39441326
 0.81289766 0.         0.         0.64339679 0.         0.7927573
 1.         0.         1.         0.         0.70390608 0.
 0.         0.         1.         0.         0.         0.08035723
 0.43709748 1.         0.32639079 0.74495958 0.16207455]
wv_ed shape (35,)
[1.         0.         0.         1.         1.         1.
 1.         0.         1.         1.         0.156134   0.6211921
 1.         0.         0.         0.82211315 0.         0.83669547
 1.         0.03563459 1.         0.         0.89435753 0.
 0.16899452 0.         1.         0.         0.         0.27895158
 0.50891842 1.         0.54130238 0.81766769 0.32173842]
wv_lg shape (35, 1)
[[0.35538335]
 [0.35525571]
 [0.35535657]
 [0.35555789]
 [0.35526629]
 [0.35534969]
 [0.35556683]
 [0.35525394]
 [0.35520839]
 [0.35540968]
 [0.35490623]
 [0.3547292 ]
 [0.35471813]
 [0.35468357]
 [0.35497814]
 [0.35467317]
 [0.35491301]
 [0.35513997]
 [0.35471908]
 [0.35483653]
 [0.3546962 ]
 [0.35486525]
 [0.35463738]
 [0.35505125]
 [0.35477845]
 [0.35493101]
 [0.35481347]
 [0.3549154 ]
 [0.35479494]
 [0.35467956]
 [0.35506844]
 [0.35507729]
 [0.35473178]
 [0.3545506 ]
 [0.35473617]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[1.        1.        1.        1.        1.        1.        1.
 1.        0.9852191 1.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.       ]
wv_std shape (35,)
[1.        0.        0.        0.5355441 1.        1.        1.
 0.        1.        1.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.       ]
xy shape: (35, 9)
[[1.         1.         1.         1.         0.35538335 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.35525571 1.
  1.         0.         0.        ]
 [0.         1.         0.         0.         0.35535657 1.
  1.         0.         0.        ]
 [1.         1.         1.         1.         0.35555789 1.
  1.         0.5355441  0.        ]
 [1.         0.16898577 1.         1.         0.35526629 1.
  1.         1.         0.        ]
 [1.         0.         1.         1.         0.35534969 1.
  1.         1.         0.        ]
 [1.         1.         1.         1.         0.35556683 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.35525394 1.
  1.         0.         0.        ]
 [1.         1.         1.         1.         0.35520839 1.
  0.9852191  1.         0.        ]
 [1.         0.         1.         1.         0.35540968 1.
  1.         1.         0.        ]
 [1.         0.         0.         0.156134   0.35490623 1.
  0.         0.         1.        ]
 [1.         0.         0.39441326 0.6211921  0.3547292  1.
  0.         0.         1.        ]
 [1.         0.         0.81289766 1.         0.35471813 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.35468357 1.
  0.         0.         1.        ]
 [0.9520288  0.01906642 0.         0.         0.35497814 1.
  0.         0.         1.        ]
 [1.         0.         0.64339679 0.82211315 0.35467317 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35491301 1.
  0.         0.         1.        ]
 [1.         0.         0.7927573  0.83669547 0.35513997 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35471908 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.03563459 0.35483653 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.3546962  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35486525 1.
  0.         0.         1.        ]
 [1.         0.         0.70390608 0.89435753 0.35463738 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.35505125 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.16899452 0.35477845 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.35493101 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35481347 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3549154  1.
  0.         0.         1.        ]
 [0.95913527 0.         0.         0.         0.35479494 1.
  0.         0.         1.        ]
 [1.         0.         0.08035723 0.27895158 0.35467956 1.
  0.         0.         1.        ]
 [1.         0.         0.43709748 0.50891842 0.35506844 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35507729 1.
  0.         0.         1.        ]
 [1.         0.         0.32639079 0.54130238 0.35473178 1.
  0.         0.         1.        ]
 [1.         0.         0.74495958 0.81766769 0.3545506  1.
  0.         0.         1.        ]
 [1.         0.         0.16207455 0.32173842 0.35473617 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.625
#####################         POISON         ###############################################

############################################################################################

comm_round: 0 | global_test_acc: 58.333% | global_f1: 0.7058823529411765 | global_precision: 0.6666666666666666
              precision    recall  f1-score   support

           0       0.33      0.25      0.29         4
           1       0.67      0.75      0.71         8

    accuracy                           0.58        12
   macro avg       0.50      0.50      0.50        12
weighted avg       0.56      0.58      0.57        12
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[1.         1.         1.         1.         1.         1.
 0.         1.         1.         1.         1.         1.
 1.         0.51796267 0.93944834 0.02846409 0.34728038 0.75727597
 0.44527617 0.87506435 1.         0.75882011 0.50787324 0.56879966
 1.         1.         0.28911986 0.59355631 0.         0.3687997
 0.69395113 0.3831215  0.         0.72775012 1.        ]
wv_fg shape (35,)
[0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
wv_mn shape (35,)
[1.         1.         1.         1.         1.         1.
 0.         0.25833559 1.         1.         0.03898463 0.65125546
 0.18179062 0.         0.         0.         0.         0.
 0.         0.         0.49186255 0.         0.         0.
 0.9154751  0.77545335 0.         0.         0.         0.
 0.         0.         0.         0.         0.15281223]
wv_ed shape (35,)
[1.         1.         1.         1.         1.         1.
 0.         0.37535827 1.         1.         0.10446188 0.66871698
 0.30872289 0.         0.00907768 0.         0.         0.
 0.         0.         0.28371004 0.         0.         0.
 0.99696396 0.78010676 0.         0.         0.         0.
 0.         0.         0.         0.         0.08268488]
wv_lg shape (35, 1)
[[0.35578487]
 [0.35535839]
 [0.35535016]
 [0.35564952]
 [0.35525417]
 [0.3554523 ]
 [0.35545537]
 [0.35561958]
 [0.35555675]
 [0.35536905]
 [0.35477418]
 [0.35501016]
 [0.35490106]
 [0.35506439]
 [0.35491133]
 [0.35484107]
 [0.35493925]
 [0.3552587 ]
 [0.35501254]
 [0.35485428]
 [0.35491856]
 [0.35508012]
 [0.35502573]
 [0.35484536]
 [0.35488245]
 [0.3551683 ]
 [0.35506127]
 [0.35481368]
 [0.35509915]
 [0.35480279]
 [0.35504247]
 [0.35538187]
 [0.35495998]
 [0.35488667]
 [0.35493334]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[1.         0.45159041 0.40966888 0.43469123 0.37896055 0.12767762
 1.         0.4582455  0.53544458 1.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_std shape (35,)
[1.         1.         0.99601742 0.6772405  1.         0.
 0.         0.         1.         1.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
xy shape: (35, 9)
[[1.         0.         1.         1.         0.35578487 1.
  1.         1.         0.        ]
 [1.         0.         1.         1.         0.35535839 1.
  0.45159041 1.         0.        ]
 [1.         0.         1.         1.         0.35535016 1.
  0.40966888 0.99601742 0.        ]
 [1.         0.         1.         1.         0.35564952 1.
  0.43469123 0.6772405  0.        ]
 [1.         0.         1.         1.         0.35525417 1.
  0.37896055 1.         0.        ]
 [1.         0.         1.         1.         0.3554523  1.
  0.12767762 0.         0.        ]
 [0.         1.         0.         0.         0.35545537 1.
  1.         0.         0.        ]
 [1.         0.         0.25833559 0.37535827 0.35561958 1.
  0.4582455  0.         0.        ]
 [1.         0.         1.         1.         0.35555675 1.
  0.53544458 1.         0.        ]
 [1.         0.         1.         1.         0.35536905 1.
  1.         1.         0.        ]
 [1.         0.         0.03898463 0.10446188 0.35477418 1.
  0.         0.         1.        ]
 [1.         0.         0.65125546 0.66871698 0.35501016 1.
  0.         0.         1.        ]
 [1.         0.         0.18179062 0.30872289 0.35490106 1.
  0.         0.         1.        ]
 [0.51796267 0.         0.         0.         0.35506439 1.
  0.         0.         1.        ]
 [0.93944834 0.         0.         0.00907768 0.35491133 1.
  0.         0.         1.        ]
 [0.02846409 0.         0.         0.         0.35484107 1.
  0.         0.         1.        ]
 [0.34728038 0.         0.         0.         0.35493925 1.
  0.         0.         1.        ]
 [0.75727597 0.         0.         0.         0.3552587  1.
  0.         0.         1.        ]
 [0.44527617 0.         0.         0.         0.35501254 1.
  0.         0.         1.        ]
 [0.87506435 0.         0.         0.         0.35485428 1.
  0.         0.         1.        ]
 [1.         0.         0.49186255 0.28371004 0.35491856 1.
  0.         0.         1.        ]
 [0.75882011 0.         0.         0.         0.35508012 1.
  0.         0.         1.        ]
 [0.50787324 0.         0.         0.         0.35502573 1.
  0.         0.         1.        ]
 [0.56879966 0.         0.         0.         0.35484536 1.
  0.         0.         1.        ]
 [1.         0.         0.9154751  0.99696396 0.35488245 1.
  0.         0.         1.        ]
 [1.         0.         0.77545335 0.78010676 0.3551683  1.
  0.         0.         1.        ]
 [0.28911986 0.         0.         0.         0.35506127 1.
  0.         0.         1.        ]
 [0.59355631 0.         0.         0.         0.35481368 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35509915 1.
  0.         0.         1.        ]
 [0.3687997  0.         0.         0.         0.35480279 1.
  0.         0.         1.        ]
 [0.69395113 0.         0.         0.         0.35504247 1.
  0.         0.         1.        ]
 [0.3831215  0.         0.         0.         0.35538187 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35495998 1.
  0.         0.         1.        ]
 [0.72775012 0.         0.         0.         0.35488667 1.
  0.         0.         1.        ]
 [1.         0.         0.15281223 0.08268488 0.35493334 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.5
#####################         POISON         ###############################################

############################################################################################

comm_round: 1 | global_test_acc: 83.333% | global_f1: 0.9090909090909091 | global_precision: 0.8333333333333334
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.83      1.00      0.91        10

    accuracy                           0.83        12
   macro avg       0.42      0.50      0.45        12
weighted avg       0.69      0.83      0.76        12
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[0.         1.         1.         1.         1.         1.
 1.         0.         1.         1.         0.93293673 1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         0.         0.81149452 1.
 0.98722794 0.82929347 1.         1.         1.         1.
 1.         0.9401676  0.         1.         0.74248645]
wv_fg shape (35,)
[0.35793467 0.         0.02513501 0.35793467 1.         0.02513501
 0.02688791 1.         0.         0.76707687 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         1.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_mn shape (35,)
[0.         1.         1.         0.9584943  0.4030226  1.
 1.         0.         1.         1.         0.         1.
 0.54689449 1.         0.06442987 0.17883916 0.12789933 0.69183947
 0.93120682 1.         0.74837419 0.         0.         0.1088764
 0.         0.         1.         0.         0.0902194  0.86095412
 1.         0.         0.         1.         0.        ]
wv_ed shape (35,)
[0.         1.         1.         0.9959894  0.07997369 1.
 1.         0.         1.         1.         0.         1.
 0.71501168 1.         0.14351    0.34162124 0.17018055 0.72870941
 1.         1.         0.75751629 0.         0.         0.14279111
 0.         0.         1.         0.         0.27361308 0.78264803
 1.         0.         0.         1.         0.        ]
wv_lg shape (35, 1)
[[0.35611397]
 [0.35564447]
 [0.35609878]
 [0.35565141]
 [0.35580943]
 [0.3558218 ]
 [0.35567357]
 [0.35564206]
 [0.35551973]
 [0.35544758]
 [0.35501879]
 [0.3550086 ]
 [0.35512989]
 [0.35495698]
 [0.35502921]
 [0.3550836 ]
 [0.35499076]
 [0.35541873]
 [0.35496184]
 [0.35520156]
 [0.35494769]
 [0.3550165 ]
 [0.35539775]
 [0.35511314]
 [0.35515247]
 [0.35504086]
 [0.35509042]
 [0.35507031]
 [0.35506754]
 [0.35485195]
 [0.35503805]
 [0.35512952]
 [0.355246  ]
 [0.35513474]
 [0.35538646]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[1.         1.         1.         1.         1.         1.
 0.80118062 1.         1.         0.97958604 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_std shape (35,)
[0.         1.         1.         0.33648695 0.74015361 0.96799508
 1.         0.         1.         1.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
xy shape: (35, 9)
[[0.         0.35793467 0.         0.         0.35611397 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.35564447 1.
  1.         1.         0.        ]
 [1.         0.02513501 1.         1.         0.35609878 1.
  1.         1.         0.        ]
 [1.         0.35793467 0.9584943  0.9959894  0.35565141 1.
  1.         0.33648695 0.        ]
 [1.         1.         0.4030226  0.07997369 0.35580943 1.
  1.         0.74015361 0.        ]
 [1.         0.02513501 1.         1.         0.3558218  1.
  1.         0.96799508 0.        ]
 [1.         0.02688791 1.         1.         0.35567357 1.
  0.80118062 1.         0.        ]
 [0.         1.         0.         0.         0.35564206 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.35551973 1.
  1.         1.         0.        ]
 [1.         0.76707687 1.         1.         0.35544758 1.
  0.97958604 1.         0.        ]
 [0.93293673 0.         0.         0.         0.35501879 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.3550086  1.
  0.         0.         1.        ]
 [1.         0.         0.54689449 0.71501168 0.35512989 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35495698 1.
  0.         0.         1.        ]
 [1.         0.         0.06442987 0.14351    0.35502921 1.
  0.         0.         1.        ]
 [1.         0.         0.17883916 0.34162124 0.3550836  1.
  0.         0.         1.        ]
 [1.         0.         0.12789933 0.17018055 0.35499076 1.
  0.         0.         1.        ]
 [1.         0.         0.69183947 0.72870941 0.35541873 1.
  0.         0.         1.        ]
 [1.         0.         0.93120682 1.         0.35496184 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35520156 1.
  0.         0.         1.        ]
 [1.         0.         0.74837419 0.75751629 0.35494769 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3550165  1.
  0.         0.         1.        ]
 [0.81149452 0.         0.         0.         0.35539775 1.
  0.         0.         1.        ]
 [1.         0.         0.1088764  0.14279111 0.35511314 1.
  0.         0.         1.        ]
 [0.98722794 0.         0.         0.         0.35515247 1.
  0.         0.         1.        ]
 [0.82929347 0.         0.         0.         0.35504086 1.
  0.         0.         1.        ]
 [1.         1.         1.         1.         0.35509042 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.35507031 1.
  0.         0.         1.        ]
 [1.         0.         0.0902194  0.27361308 0.35506754 1.
  0.         0.         1.        ]
 [1.         0.         0.86095412 0.78264803 0.35485195 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35503805 1.
  0.         0.         1.        ]
 [0.9401676  0.         0.         0.         0.35512952 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.355246   1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35513474 1.
  0.         0.         1.        ]
 [0.74248645 0.         0.         0.         0.35538646 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.6875
#####################         POISON         ###############################################

############################################################################################

comm_round: 2 | global_test_acc: 66.667% | global_f1: 0.8 | global_precision: 0.6666666666666666
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         4
           1       0.67      1.00      0.80         8

    accuracy                           0.67        12
   macro avg       0.33      0.50      0.40        12
weighted avg       0.44      0.67      0.53        12
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[1.         1.         1.         1.         1.         1.
 0.         0.         1.         0.         1.         1.
 0.75653305 0.73296871 0.97228556 1.         0.6603225  0.
 1.         0.51937985 0.75929581 0.         0.52768656 0.42848736
 0.77900373 1.         1.         0.51111457 0.40100261 0.
 1.         1.         1.         1.         0.        ]
wv_fg shape (35,)
[1.         0.90750698 0.04726908 0.16459555 1.         0.04726908
 0.90750698 0.52933954 0.16459555 1.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         1.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_mn shape (35,)
[1.         0.82333755 1.         0.82870239 0.76058731 1.
 0.         0.         0.63934684 0.         0.93617877 0.67073595
 0.         0.         0.08468202 1.         0.         0.
 1.         0.         0.         0.         0.         0.
 0.         0.74578962 1.         0.         0.         0.
 0.44829161 1.         0.58690339 1.         0.        ]
wv_ed shape (35,)
[1.         0.75321011 1.         0.9325255  0.75488945 1.
 0.         0.         0.64007731 0.         0.68754322 0.7440287
 0.         0.         0.07454538 1.         0.         0.
 1.         0.         0.         0.         0.         0.
 0.         0.40207206 1.         0.         0.         0.
 0.35435179 1.         0.38993153 0.70922541 0.        ]
wv_lg shape (35, 1)
[[0.35609251]
 [0.35614268]
 [0.35613998]
 [0.35626009]
 [0.35571541]
 [0.35609226]
 [0.35607504]
 [0.35616986]
 [0.35614526]
 [0.35618819]
 [0.35569276]
 [0.35570052]
 [0.35582655]
 [0.35552847]
 [0.35556538]
 [0.35554723]
 [0.35600024]
 [0.35558785]
 [0.35581127]
 [0.3556559 ]
 [0.35542024]
 [0.3556107 ]
 [0.35574784]
 [0.35568641]
 [0.35577041]
 [0.35573914]
 [0.3553776 ]
 [0.35603741]
 [0.35551013]
 [0.35553328]
 [0.35561013]
 [0.35570973]
 [0.35585074]
 [0.35559779]
 [0.35572323]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[1.         0.72774227 0.92387296 1.         0.73553855 0.79655143
 1.         1.         1.         1.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_std shape (35,)
[1.         0.82348172 1.         0.55588148 0.42435949 1.
 0.         0.         1.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         1.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
xy shape: (35, 9)
[[1.         1.         1.         1.         0.35609251 1.
  1.         1.         0.        ]
 [1.         0.90750698 0.82333755 0.75321011 0.35614268 1.
  0.72774227 0.82348172 0.        ]
 [1.         0.04726908 1.         1.         0.35613998 1.
  0.92387296 1.         0.        ]
 [1.         0.16459555 0.82870239 0.9325255  0.35626009 1.
  1.         0.55588148 0.        ]
 [1.         1.         0.76058731 0.75488945 0.35571541 1.
  0.73553855 0.42435949 0.        ]
 [1.         0.04726908 1.         1.         0.35609226 1.
  0.79655143 1.         0.        ]
 [0.         0.90750698 0.         0.         0.35607504 1.
  1.         0.         0.        ]
 [0.         0.52933954 0.         0.         0.35616986 1.
  1.         0.         0.        ]
 [1.         0.16459555 0.63934684 0.64007731 0.35614526 1.
  1.         1.         0.        ]
 [0.         1.         0.         0.         0.35618819 1.
  1.         0.         0.        ]
 [1.         0.         0.93617877 0.68754322 0.35569276 1.
  0.         0.         1.        ]
 [1.         0.         0.67073595 0.7440287  0.35570052 1.
  0.         0.         1.        ]
 [0.75653305 0.         0.         0.         0.35582655 1.
  0.         0.         1.        ]
 [0.73296871 0.         0.         0.         0.35552847 1.
  0.         0.         1.        ]
 [0.97228556 0.         0.08468202 0.07454538 0.35556538 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35554723 1.
  0.         0.         1.        ]
 [0.6603225  0.         0.         0.         0.35600024 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35558785 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35581127 1.
  0.         0.         1.        ]
 [0.51937985 0.         0.         0.         0.3556559  1.
  0.         0.         1.        ]
 [0.75929581 0.         0.         0.         0.35542024 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3556107  1.
  0.         0.         1.        ]
 [0.52768656 0.         0.         0.         0.35574784 1.
  0.         0.         1.        ]
 [0.42848736 0.         0.         0.         0.35568641 1.
  0.         0.         1.        ]
 [0.77900373 0.         0.         0.         0.35577041 1.
  0.         0.         1.        ]
 [1.         0.         0.74578962 0.40207206 0.35573914 1.
  0.         0.         1.        ]
 [1.         1.         1.         1.         0.3553776  1.
  0.         1.         1.        ]
 [0.51111457 0.         0.         0.         0.35603741 1.
  0.         0.         1.        ]
 [0.40100261 0.         0.         0.         0.35551013 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35553328 1.
  0.         0.         1.        ]
 [1.         0.         0.44829161 0.35435179 0.35561013 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35570973 1.
  0.         0.         1.        ]
 [1.         0.         0.58690339 0.38993153 0.35585074 1.
  0.         0.         1.        ]
 [1.         0.         1.         0.70922541 0.35559779 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35572323 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.875
#####################         POISON         ###############################################

############################################################################################

comm_round: 3 | global_test_acc: 66.667% | global_f1: 0.8 | global_precision: 0.6666666666666666
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         4
           1       0.67      1.00      0.80         8

    accuracy                           0.67        12
   macro avg       0.33      0.50      0.40        12
weighted avg       0.44      0.67      0.53        12
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[0.         1.         1.         1.         1.         1.
 1.         1.         0.71204848 1.         0.         1.
 1.         1.         1.         1.         0.         0.37279057
 0.         1.         0.53108445 1.         0.36960843 1.
 1.         0.         1.         0.07703859 1.         0.22778842
 0.49870124 1.         1.         0.35289968 1.        ]
wv_fg shape (35,)
[1.         1.         1.         0.         1.         0.
 0.         1.         1.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.01103817
 0.         0.         1.         0.         0.         0.
 0.         0.74940302 0.         0.         0.        ]
wv_mn shape (35,)
[0.         0.73958027 1.         1.         0.71356754 1.
 1.         1.         0.         1.         0.         0.45862789
 0.03300444 0.73020422 0.02129574 0.7034517  0.         0.
 0.         0.77893631 0.         1.         0.         0.55602136
 0.20125536 0.         1.         0.         0.04110475 0.
 0.         1.         0.33509579 0.         0.67225895]
wv_ed shape (35,)
[0.         0.53707975 1.         0.99856455 0.62597332 1.
 1.         1.         0.05048331 1.         0.         0.45354865
 0.08672323 0.80934547 0.01186581 0.70909641 0.         0.
 0.         0.84817126 0.         1.         0.         0.44770695
 0.15807086 0.         1.         0.         0.0251167  0.
 0.         1.         0.30814571 0.         0.60912335]
wv_lg shape (35, 1)
[[0.35638259]
 [0.35618258]
 [0.35648436]
 [0.35615983]
 [0.35619907]
 [0.35592263]
 [0.35640382]
 [0.35627858]
 [0.35654984]
 [0.3564439 ]
 [0.35569935]
 [0.35586293]
 [0.35593974]
 [0.35578121]
 [0.35575658]
 [0.35580226]
 [0.35572215]
 [0.35591675]
 [0.3558017 ]
 [0.35576638]
 [0.35580697]
 [0.35601759]
 [0.35601934]
 [0.35592093]
 [0.35582231]
 [0.35590341]
 [0.35587882]
 [0.3557881 ]
 [0.35582253]
 [0.3558021 ]
 [0.35597653]
 [0.35564896]
 [0.35588311]
 [0.35583294]
 [0.35577449]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[1.         0.83491332 0.37170802 0.47458971 1.         0.24835564
 0.01924767 1.         1.         0.29143494 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_std shape (35,)
[0.         0.72474634 1.         0.78923255 0.68029445 1.
 1.         1.         0.         1.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
xy shape: (35, 9)
[[0.         1.         0.         0.         0.35638259 1.
  1.         0.         0.        ]
 [1.         1.         0.73958027 0.53707975 0.35618258 1.
  0.83491332 0.72474634 0.        ]
 [1.         1.         1.         1.         0.35648436 1.
  0.37170802 1.         0.        ]
 [1.         0.         1.         0.99856455 0.35615983 1.
  0.47458971 0.78923255 0.        ]
 [1.         1.         0.71356754 0.62597332 0.35619907 1.
  1.         0.68029445 0.        ]
 [1.         0.         1.         1.         0.35592263 1.
  0.24835564 1.         0.        ]
 [1.         0.         1.         1.         0.35640382 1.
  0.01924767 1.         0.        ]
 [1.         1.         1.         1.         0.35627858 1.
  1.         1.         0.        ]
 [0.71204848 1.         0.         0.05048331 0.35654984 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.3564439  1.
  0.29143494 1.         0.        ]
 [0.         0.         0.         0.         0.35569935 1.
  0.         0.         1.        ]
 [1.         0.         0.45862789 0.45354865 0.35586293 1.
  0.         0.         1.        ]
 [1.         0.         0.03300444 0.08672323 0.35593974 1.
  0.         0.         1.        ]
 [1.         0.         0.73020422 0.80934547 0.35578121 1.
  0.         0.         1.        ]
 [1.         0.         0.02129574 0.01186581 0.35575658 1.
  0.         0.         1.        ]
 [1.         0.         0.7034517  0.70909641 0.35580226 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35572215 1.
  0.         0.         1.        ]
 [0.37279057 0.         0.         0.         0.35591675 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3558017  1.
  0.         0.         1.        ]
 [1.         0.         0.77893631 0.84817126 0.35576638 1.
  0.         0.         1.        ]
 [0.53108445 0.         0.         0.         0.35580697 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35601759 1.
  0.         0.         1.        ]
 [0.36960843 0.         0.         0.         0.35601934 1.
  0.         0.         1.        ]
 [1.         0.01103817 0.55602136 0.44770695 0.35592093 1.
  0.         0.         1.        ]
 [1.         0.         0.20125536 0.15807086 0.35582231 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35590341 1.
  0.         0.         1.        ]
 [1.         1.         1.         1.         0.35587882 1.
  0.         0.         1.        ]
 [0.07703859 0.         0.         0.         0.3557881  1.
  0.         0.         1.        ]
 [1.         0.         0.04110475 0.0251167  0.35582253 1.
  0.         0.         1.        ]
 [0.22778842 0.         0.         0.         0.3558021  1.
  0.         0.         1.        ]
 [0.49870124 0.         0.         0.         0.35597653 1.
  0.         0.         1.        ]
 [1.         0.74940302 1.         1.         0.35564896 1.
  0.         0.         1.        ]
 [1.         0.         0.33509579 0.30814571 0.35588311 1.
  0.         0.         1.        ]
 [0.35289968 0.         0.         0.         0.35583294 1.
  0.         0.         1.        ]
 [1.         0.         0.67225895 0.60912335 0.35577449 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.75
#####################         POISON         ###############################################

############################################################################################

comm_round: 4 | global_test_acc: 75.000% | global_f1: 0.8571428571428571 | global_precision: 0.75
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.75      1.00      0.86         9

    accuracy                           0.75        12
   macro avg       0.38      0.50      0.43        12
weighted avg       0.56      0.75      0.64        12
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[0.         1.         0.         1.         1.         1.
 0.67977253 0.         1.         1.         0.10080253 0.61779109
 0.         0.         1.         0.         0.28347933 1.
 0.         0.         0.13969229 0.42135679 0.         0.10992095
 0.90763968 1.         1.         0.21137406 0.63479059 0.68961644
 0.38278074 0.         0.36370148 0.         0.        ]
wv_fg shape (35,)
[1.         0.         0.05427973 0.         0.61222984 1.
 0.         1.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.25638467 0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_mn shape (35,)
[0.         0.44282704 0.         0.40419714 0.71780794 1.
 0.14555228 0.         0.76013122 0.74868131 0.         0.06983082
 0.         0.         1.         0.         0.         0.73961208
 0.         0.         0.         0.0374146  0.         0.
 0.4945258  0.99276774 1.         0.         0.31517404 0.37550161
 0.         0.         0.         0.         0.        ]
wv_ed shape (35,)
[0.         0.59726844 0.         0.3459263  0.86948591 1.
 0.32567134 0.         0.84576185 0.57767908 0.         0.
 0.         0.         1.         0.         0.         0.75696263
 0.         0.         0.         0.26852687 0.         0.
 0.67183522 0.78753978 1.         0.         0.55560563 0.47828778
 0.         0.         0.         0.         0.        ]
wv_lg shape (35, 1)
[[0.35648467]
 [0.35666153]
 [0.35661235]
 [0.35650663]
 [0.35658085]
 [0.35673883]
 [0.35658035]
 [0.35624664]
 [0.3566479 ]
 [0.35648879]
 [0.35615662]
 [0.35615272]
 [0.35622219]
 [0.35643214]
 [0.3560181 ]
 [0.35617574]
 [0.3563005 ]
 [0.35632948]
 [0.35621264]
 [0.35616117]
 [0.3563859 ]
 [0.35627422]
 [0.35638439]
 [0.35625604]
 [0.35619253]
 [0.35636971]
 [0.35613056]
 [0.35604661]
 [0.35612126]
 [0.3559433 ]
 [0.35612032]
 [0.35619758]
 [0.35627956]
 [0.35609271]
 [0.3560374 ]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[1.         1.         1.         1.         1.         1.
 1.         1.         0.96092878 1.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_std shape (35,)
[0.         0.1269796  0.         0.80083838 1.         1.
 0.         0.         0.26592565 0.90737057 0.         0.
 0.         0.         1.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         1.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
xy shape: (35, 9)
[[0.         1.         0.         0.         0.35648467 1.
  1.         0.         0.        ]
 [1.         0.         0.44282704 0.59726844 0.35666153 1.
  1.         0.1269796  0.        ]
 [0.         0.05427973 0.         0.         0.35661235 1.
  1.         0.         0.        ]
 [1.         0.         0.40419714 0.3459263  0.35650663 1.
  1.         0.80083838 0.        ]
 [1.         0.61222984 0.71780794 0.86948591 0.35658085 1.
  1.         1.         0.        ]
 [1.         1.         1.         1.         0.35673883 1.
  1.         1.         0.        ]
 [0.67977253 0.         0.14555228 0.32567134 0.35658035 1.
  1.         0.         0.        ]
 [0.         1.         0.         0.         0.35624664 1.
  1.         0.         0.        ]
 [1.         0.         0.76013122 0.84576185 0.3566479  1.
  0.96092878 0.26592565 0.        ]
 [1.         0.         0.74868131 0.57767908 0.35648879 1.
  1.         0.90737057 0.        ]
 [0.10080253 0.         0.         0.         0.35615662 1.
  0.         0.         1.        ]
 [0.61779109 0.         0.06983082 0.         0.35615272 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35622219 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35643214 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.3560181  1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.35617574 1.
  0.         0.         1.        ]
 [0.28347933 0.         0.         0.         0.3563005  1.
  0.         0.         1.        ]
 [1.         0.         0.73961208 0.75696263 0.35632948 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35621264 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35616117 1.
  0.         0.         1.        ]
 [0.13969229 0.         0.         0.         0.3563859  1.
  0.         0.         1.        ]
 [0.42135679 0.         0.0374146  0.26852687 0.35627422 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35638439 1.
  0.         0.         1.        ]
 [0.10992095 0.         0.         0.         0.35625604 1.
  0.         0.         1.        ]
 [0.90763968 0.         0.4945258  0.67183522 0.35619253 1.
  0.         0.         1.        ]
 [1.         0.         0.99276774 0.78753978 0.35636971 1.
  0.         0.         1.        ]
 [1.         0.25638467 1.         1.         0.35613056 1.
  0.         1.         1.        ]
 [0.21137406 0.         0.         0.         0.35604661 1.
  0.         0.         1.        ]
 [0.63479059 0.         0.31517404 0.55560563 0.35612126 1.
  0.         0.         1.        ]
 [0.68961644 0.         0.37550161 0.47828778 0.3559433  1.
  0.         0.         1.        ]
 [0.38278074 0.         0.         0.         0.35612032 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35619758 1.
  0.         0.         1.        ]
 [0.36370148 0.         0.         0.         0.35627956 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35609271 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3560374  1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.6875
#####################         POISON         ###############################################

############################################################################################

comm_round: 5 | global_test_acc: 75.000% | global_f1: 0.8571428571428571 | global_precision: 0.75
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.75      1.00      0.86         9

    accuracy                           0.75        12
   macro avg       0.38      0.50      0.43        12
weighted avg       0.56      0.75      0.64        12
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[1.         0.         0.13924068 1.         1.         1.
 1.         1.         0.         1.         1.         1.
 1.         0.         1.         1.         1.         1.
 1.         1.         1.         1.         0.971023   0.
 0.         1.         1.         0.         1.         0.98144819
 1.         0.14310798 1.         1.         0.        ]
wv_fg shape (35,)
[0.         1.         1.         1.         0.         1.
 0.         0.20979361 0.20979361 0.         0.         0.
 0.         0.         0.         1.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_mn shape (35,)
[1.         0.         0.         1.         1.         1.
 1.         0.45563917 0.         1.         0.81327723 0.
 0.77843658 0.         1.         1.         1.         1.
 0.48578576 0.1328284  0.28484552 0.4075468  0.         0.
 0.         0.         0.53918446 0.         0.39738246 0.
 0.77587589 0.         0.32200871 0.4768929  0.        ]
wv_ed shape (35,)
[1.         0.         0.         1.         1.         1.
 1.         0.36476191 0.         1.         0.97255613 0.
 0.97060603 0.         1.         1.         1.         1.
 0.68595791 0.27033755 0.41389878 0.61110339 0.         0.
 0.         0.         0.69469192 0.         0.49405503 0.
 0.93731003 0.         0.32002699 0.59767696 0.        ]
wv_lg shape (35, 1)
[[0.35689584]
 [0.35651866]
 [0.35696786]
 [0.35618164]
 [0.35663507]
 [0.35654897]
 [0.35674422]
 [0.35669013]
 [0.35664677]
 [0.35700008]
 [0.35613545]
 [0.35600293]
 [0.35620841]
 [0.35614194]
 [0.35628994]
 [0.35604182]
 [0.35618588]
 [0.35628639]
 [0.35610962]
 [0.35622491]
 [0.35631686]
 [0.35624141]
 [0.35608934]
 [0.35610579]
 [0.35602942]
 [0.3562201 ]
 [0.3561737 ]
 [0.35623443]
 [0.3563032 ]
 [0.35626934]
 [0.35610746]
 [0.35625284]
 [0.35600304]
 [0.35617313]
 [0.356212  ]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[0.51883768 1.         0.89071026 0.49416961 0.21694349 0.31727211
 0.36319411 1.         1.         0.89688025 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_std shape (35,)
[1.         0.         0.         0.59896598 1.         1.
 1.         0.71366943 0.         0.80493478 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
xy shape: (35, 9)
[[1.         0.         1.         1.         0.35689584 1.
  0.51883768 1.         0.        ]
 [0.         1.         0.         0.         0.35651866 1.
  1.         0.         0.        ]
 [0.13924068 1.         0.         0.         0.35696786 1.
  0.89071026 0.         0.        ]
 [1.         1.         1.         1.         0.35618164 1.
  0.49416961 0.59896598 0.        ]
 [1.         0.         1.         1.         0.35663507 1.
  0.21694349 1.         0.        ]
 [1.         1.         1.         1.         0.35654897 1.
  0.31727211 1.         0.        ]
 [1.         0.         1.         1.         0.35674422 1.
  0.36319411 1.         0.        ]
 [1.         0.20979361 0.45563917 0.36476191 0.35669013 1.
  1.         0.71366943 0.        ]
 [0.         0.20979361 0.         0.         0.35664677 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.35700008 1.
  0.89688025 0.80493478 0.        ]
 [1.         0.         0.81327723 0.97255613 0.35613545 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.35600293 1.
  0.         0.         1.        ]
 [1.         0.         0.77843658 0.97060603 0.35620841 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35614194 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35628994 1.
  0.         0.         1.        ]
 [1.         1.         1.         1.         0.35604182 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35618588 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35628639 1.
  0.         0.         1.        ]
 [1.         0.         0.48578576 0.68595791 0.35610962 1.
  0.         0.         1.        ]
 [1.         0.         0.1328284  0.27033755 0.35622491 1.
  0.         0.         1.        ]
 [1.         0.         0.28484552 0.41389878 0.35631686 1.
  0.         0.         1.        ]
 [1.         0.         0.4075468  0.61110339 0.35624141 1.
  0.         0.         1.        ]
 [0.971023   0.         0.         0.         0.35608934 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35610579 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35602942 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.3562201  1.
  0.         0.         1.        ]
 [1.         0.         0.53918446 0.69469192 0.3561737  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35623443 1.
  0.         0.         1.        ]
 [1.         0.         0.39738246 0.49405503 0.3563032  1.
  0.         0.         1.        ]
 [0.98144819 0.         0.         0.         0.35626934 1.
  0.         0.         1.        ]
 [1.         0.         0.77587589 0.93731003 0.35610746 1.
  0.         0.         1.        ]
 [0.14310798 0.         0.         0.         0.35625284 1.
  0.         0.         1.        ]
 [1.         0.         0.32200871 0.32002699 0.35600304 1.
  0.         0.         1.        ]
 [1.         0.         0.4768929  0.59767696 0.35617313 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.356212   1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.6875
#####################         POISON         ###############################################

############################################################################################

comm_round: 6 | global_test_acc: 75.000% | global_f1: 0.8571428571428571 | global_precision: 0.75
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.75      1.00      0.86         9

    accuracy                           0.75        12
   macro avg       0.38      0.50      0.43        12
weighted avg       0.56      0.75      0.64        12
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[0.         1.         0.71967278 0.         1.         1.
 0.         0.         0.         1.         0.42240992 0.47769139
 0.56788852 1.         1.         1.         0.53906652 1.
 0.65858708 1.         0.75197618 0.58040338 0.         1.
 0.         1.         0.63754313 0.64238275 0.         1.
 0.73345292 1.         1.         1.         0.50937757]
wv_fg shape (35,)
[0.         0.         0.         0.84438555 0.         0.
 0.         0.         0.         1.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.18597757
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_mn shape (35,)
[0.         0.05506778 0.         0.         0.60801174 0.52400514
 0.         0.         0.         1.         0.         0.
 0.         0.         0.51619141 0.56116736 0.         0.19846132
 0.         0.21258503 0.         0.         0.         0.82726311
 0.         0.52643793 0.         0.         0.         0.57278034
 0.         0.24018289 0.44509363 0.70112623 0.        ]
wv_ed shape (35,)
[0.         0.31061329 0.         0.         0.70786322 0.77224377
 0.         0.         0.         1.         0.         0.
 0.         0.         0.71320824 0.59996903 0.         0.45410571
 0.         0.40543222 0.         0.         0.         1.
 0.         0.53854866 0.         0.         0.         0.59275432
 0.14206185 0.29404807 0.58892908 0.81972321 0.        ]
wv_lg shape (35, 1)
[[0.35701434]
 [0.35703649]
 [0.35659655]
 [0.35677902]
 [0.35708412]
 [0.35699691]
 [0.35683177]
 [0.35688311]
 [0.35702226]
 [0.35701994]
 [0.35644072]
 [0.35651366]
 [0.35638519]
 [0.35664377]
 [0.35656204]
 [0.35633073]
 [0.35659828]
 [0.35651808]
 [0.35648221]
 [0.35648224]
 [0.35641583]
 [0.35659816]
 [0.35664992]
 [0.3564004 ]
 [0.35632768]
 [0.35655684]
 [0.35643186]
 [0.35639399]
 [0.35637169]
 [0.35644993]
 [0.35654977]
 [0.35649054]
 [0.35670495]
 [0.3566968 ]
 [0.35653993]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
wv_std shape (35,)
[0.         0.         0.         0.         0.10985603 0.
 0.         0.         0.         1.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
xy shape: (35, 9)
[[0.         0.         0.         0.         0.35701434 1.
  1.         0.         0.        ]
 [1.         0.         0.05506778 0.31061329 0.35703649 1.
  1.         0.         0.        ]
 [0.71967278 0.         0.         0.         0.35659655 1.
  1.         0.         0.        ]
 [0.         0.84438555 0.         0.         0.35677902 1.
  1.         0.         0.        ]
 [1.         0.         0.60801174 0.70786322 0.35708412 1.
  1.         0.10985603 0.        ]
 [1.         0.         0.52400514 0.77224377 0.35699691 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.35683177 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.35688311 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.35702226 1.
  1.         0.         0.        ]
 [1.         1.         1.         1.         0.35701994 1.
  0.         1.         0.        ]
 [0.42240992 0.         0.         0.         0.35644072 1.
  0.         0.         1.        ]
 [0.47769139 0.         0.         0.         0.35651366 1.
  0.         0.         1.        ]
 [0.56788852 0.         0.         0.         0.35638519 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.35664377 1.
  0.         0.         1.        ]
 [1.         0.         0.51619141 0.71320824 0.35656204 1.
  0.         0.         1.        ]
 [1.         0.         0.56116736 0.59996903 0.35633073 1.
  0.         0.         1.        ]
 [0.53906652 0.         0.         0.         0.35659828 1.
  0.         0.         1.        ]
 [1.         0.         0.19846132 0.45410571 0.35651808 1.
  0.         0.         1.        ]
 [0.65858708 0.         0.         0.         0.35648221 1.
  0.         0.         1.        ]
 [1.         0.         0.21258503 0.40543222 0.35648224 1.
  0.         0.         1.        ]
 [0.75197618 0.         0.         0.         0.35641583 1.
  0.         0.         1.        ]
 [0.58040338 0.         0.         0.         0.35659816 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35664992 1.
  0.         0.         1.        ]
 [1.         0.18597757 0.82726311 1.         0.3564004  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35632768 1.
  0.         0.         1.        ]
 [1.         0.         0.52643793 0.53854866 0.35655684 1.
  0.         0.         1.        ]
 [0.63754313 0.         0.         0.         0.35643186 1.
  0.         0.         1.        ]
 [0.64238275 0.         0.         0.         0.35639399 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35637169 1.
  0.         0.         1.        ]
 [1.         0.         0.57278034 0.59275432 0.35644993 1.
  0.         0.         1.        ]
 [0.73345292 0.         0.         0.14206185 0.35654977 1.
  0.         0.         1.        ]
 [1.         0.         0.24018289 0.29404807 0.35649054 1.
  0.         0.         1.        ]
 [1.         0.         0.44509363 0.58892908 0.35670495 1.
  0.         0.         1.        ]
 [1.         0.         0.70112623 0.81972321 0.3566968  1.
  0.         0.         1.        ]
 [0.50937757 0.         0.         0.         0.35653993 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.5625
#####################         POISON         ###############################################

############################################################################################

comm_round: 7 | global_test_acc: 83.333% | global_f1: 0.9090909090909091 | global_precision: 0.8333333333333334
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.83      1.00      0.91        10

    accuracy                           0.83        12
   macro avg       0.42      0.50      0.45        12
weighted avg       0.69      0.83      0.76        12
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[0.37940909 0.         1.         1.         0.37000286 1.
 0.         1.         0.         1.         1.         0.8223021
 0.90194505 1.         1.         1.         1.         1.
 0.44775504 0.         1.         1.         1.         0.
 0.80743816 1.         1.         0.94072593 1.         1.
 0.85156152 0.26683329 0.77661921 0.86653391 0.68615406]
wv_fg shape (35,)
[0.         0.         0.04478919 0.         0.         0.
 1.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_mn shape (35,)
[0.12603589 0.         0.91402404 0.29521722 0.12886131 1.
 0.         0.80196718 0.         1.         1.         0.
 0.00619212 1.         0.41246659 0.64878338 0.46469669 1.
 0.         0.         0.50510185 0.9320938  0.41966386 0.
 0.         0.22553661 0.47990667 0.09840482 0.89461227 1.
 0.         0.         0.         0.         0.        ]
wv_ed shape (35,)
[0.         0.         0.70374767 0.3941772  0.         1.
 0.         1.         0.         1.         1.         0.
 0.08347356 1.         0.24965888 0.57024104 0.49343663 1.
 0.         0.         0.55118143 0.81318819 0.32181604 0.
 0.         0.         0.39666857 0.02138745 0.74617461 1.
 0.         0.         0.         0.         0.        ]
wv_lg shape (35, 1)
[[0.35746334]
 [0.35690704]
 [0.35651833]
 [0.35721072]
 [0.35731004]
 [0.35688972]
 [0.35694712]
 [0.35697581]
 [0.35666876]
 [0.35674628]
 [0.3564891 ]
 [0.35649637]
 [0.35642948]
 [0.35647249]
 [0.35632093]
 [0.35652539]
 [0.35625303]
 [0.35650656]
 [0.35680792]
 [0.35651994]
 [0.35651313]
 [0.35634819]
 [0.3564769 ]
 [0.35659169]
 [0.35642442]
 [0.35644834]
 [0.35643599]
 [0.3565861 ]
 [0.35646059]
 [0.35655084]
 [0.35671239]
 [0.35644889]
 [0.35642502]
 [0.35663164]
 [0.35640166]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[0.54210118 0.56413476 0.00747472 1.         0.33082443 0.
 1.         1.         0.18412484 0.72016517 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_std shape (35,)
[0.         0.         0.34114785 0.         0.         1.
 0.         0.19042001 0.         0.66614757 0.         0.
 0.         1.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         1.
 0.         0.         0.         0.         0.        ]
xy shape: (35, 9)
[[0.37940909 0.         0.12603589 0.         0.35746334 1.
  0.54210118 0.         0.        ]
 [0.         0.         0.         0.         0.35690704 1.
  0.56413476 0.         0.        ]
 [1.         0.04478919 0.91402404 0.70374767 0.35651833 1.
  0.00747472 0.34114785 0.        ]
 [1.         0.         0.29521722 0.3941772  0.35721072 1.
  1.         0.         0.        ]
 [0.37000286 0.         0.12886131 0.         0.35731004 1.
  0.33082443 0.         0.        ]
 [1.         0.         1.         1.         0.35688972 1.
  0.         1.         0.        ]
 [0.         1.         0.         0.         0.35694712 1.
  1.         0.         0.        ]
 [1.         0.         0.80196718 1.         0.35697581 1.
  1.         0.19042001 0.        ]
 [0.         0.         0.         0.         0.35666876 1.
  0.18412484 0.         0.        ]
 [1.         0.         1.         1.         0.35674628 1.
  0.72016517 0.66614757 0.        ]
 [1.         0.         1.         1.         0.3564891  1.
  0.         0.         1.        ]
 [0.8223021  0.         0.         0.         0.35649637 1.
  0.         0.         1.        ]
 [0.90194505 0.         0.00619212 0.08347356 0.35642948 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35647249 1.
  0.         1.         1.        ]
 [1.         0.         0.41246659 0.24965888 0.35632093 1.
  0.         0.         1.        ]
 [1.         0.         0.64878338 0.57024104 0.35652539 1.
  0.         0.         1.        ]
 [1.         0.         0.46469669 0.49343663 0.35625303 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35650656 1.
  0.         0.         1.        ]
 [0.44775504 0.         0.         0.         0.35680792 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35651994 1.
  0.         0.         1.        ]
 [1.         0.         0.50510185 0.55118143 0.35651313 1.
  0.         0.         1.        ]
 [1.         0.         0.9320938  0.81318819 0.35634819 1.
  0.         0.         1.        ]
 [1.         0.         0.41966386 0.32181604 0.3564769  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35659169 1.
  0.         0.         1.        ]
 [0.80743816 0.         0.         0.         0.35642442 1.
  0.         0.         1.        ]
 [1.         0.         0.22553661 0.         0.35644834 1.
  0.         0.         1.        ]
 [1.         0.         0.47990667 0.39666857 0.35643599 1.
  0.         0.         1.        ]
 [0.94072593 0.         0.09840482 0.02138745 0.3565861  1.
  0.         0.         1.        ]
 [1.         0.         0.89461227 0.74617461 0.35646059 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35655084 1.
  0.         1.         1.        ]
 [0.85156152 0.         0.         0.         0.35671239 1.
  0.         0.         1.        ]
 [0.26683329 0.         0.         0.         0.35644889 1.
  0.         0.         1.        ]
 [0.77661921 0.         0.         0.         0.35642502 1.
  0.         0.         1.        ]
 [0.86653391 0.         0.         0.         0.35663164 1.
  0.         0.         1.        ]
 [0.68615406 0.         0.         0.         0.35640166 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.75
#####################         POISON         ###############################################

############################################################################################

comm_round: 8 | global_test_acc: 58.333% | global_f1: 0.7368421052631579 | global_precision: 0.5833333333333334
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         5
           1       0.58      1.00      0.74         7

    accuracy                           0.58        12
   macro avg       0.29      0.50      0.37        12
weighted avg       0.34      0.58      0.43        12
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[0.12134233 1.         1.         1.         0.81243566 0.
 1.         0.64161715 0.90963343 0.         0.         0.
 0.46157204 0.         0.46245545 0.         0.83166451 1.
 0.         0.         0.         0.         0.4884492  1.
 1.         1.         1.         0.         0.         0.40307314
 1.         1.         1.         0.         1.        ]
wv_fg shape (35,)
[0.         0.         1.         0.59598882 0.         0.
 0.         1.         0.19305944 1.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.33886771 0.         0.         0.        ]
wv_mn shape (35,)
[0.         1.         1.         1.         0.10068007 0.
 0.70707553 0.21316712 0.46274451 0.         0.         0.
 0.         0.         0.         0.         0.22938095 0.38106085
 0.         0.         0.         0.         0.         0.40816953
 1.         0.55659039 0.52775113 0.         0.         0.
 1.         1.         1.         0.         1.        ]
wv_ed shape (35,)
[0.         1.         1.         1.         0.         0.
 0.37650983 0.32379733 0.26884642 0.         0.         0.
 0.14608245 0.         0.0586581  0.         0.29573645 0.38010479
 0.         0.         0.         0.         0.         0.45011593
 1.         0.69399344 0.59986109 0.         0.         0.
 1.         1.         1.         0.         1.        ]
wv_lg shape (35, 1)
[[0.35752193]
 [0.35714298]
 [0.35721537]
 [0.35753386]
 [0.35713217]
 [0.35726079]
 [0.35716813]
 [0.35723118]
 [0.35725098]
 [0.35704008]
 [0.35690558]
 [0.35675786]
 [0.35693802]
 [0.35677681]
 [0.35679008]
 [0.35687227]
 [0.35677126]
 [0.35680276]
 [0.35679857]
 [0.356889  ]
 [0.35699024]
 [0.35681203]
 [0.35703334]
 [0.35699481]
 [0.3568754 ]
 [0.35665078]
 [0.35697029]
 [0.3570412 ]
 [0.35668217]
 [0.35656214]
 [0.35683608]
 [0.35657966]
 [0.35693778]
 [0.35664923]
 [0.35688314]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[1.         0.47167886 0.67026194 0.03137298 1.         1.
 0.66607217 1.         0.69826259 1.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_std shape (35,)
[0.         1.         1.         0.48147929 0.23722593 0.
 0.26607059 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.47890474 0.         0.        ]
xy shape: (35, 9)
[[0.12134233 0.         0.         0.         0.35752193 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.35714298 1.
  0.47167886 1.         0.        ]
 [1.         1.         1.         1.         0.35721537 1.
  0.67026194 1.         0.        ]
 [1.         0.59598882 1.         1.         0.35753386 1.
  0.03137298 0.48147929 0.        ]
 [0.81243566 0.         0.10068007 0.         0.35713217 1.
  1.         0.23722593 0.        ]
 [0.         0.         0.         0.         0.35726079 1.
  1.         0.         0.        ]
 [1.         0.         0.70707553 0.37650983 0.35716813 1.
  0.66607217 0.26607059 0.        ]
 [0.64161715 1.         0.21316712 0.32379733 0.35723118 1.
  1.         0.         0.        ]
 [0.90963343 0.19305944 0.46274451 0.26884642 0.35725098 1.
  0.69826259 0.         0.        ]
 [0.         1.         0.         0.         0.35704008 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.35690558 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35675786 1.
  0.         0.         1.        ]
 [0.46157204 0.         0.         0.14608245 0.35693802 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35677681 1.
  0.         0.         1.        ]
 [0.46245545 0.         0.         0.0586581  0.35679008 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35687227 1.
  0.         0.         1.        ]
 [0.83166451 0.         0.22938095 0.29573645 0.35677126 1.
  0.         0.         1.        ]
 [1.         0.         0.38106085 0.38010479 0.35680276 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35679857 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.356889   1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35699024 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35681203 1.
  0.         0.         1.        ]
 [0.4884492  0.         0.         0.         0.35703334 1.
  0.         0.         1.        ]
 [1.         0.         0.40816953 0.45011593 0.35699481 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.3568754  1.
  0.         0.         1.        ]
 [1.         0.         0.55659039 0.69399344 0.35665078 1.
  0.         0.         1.        ]
 [1.         0.         0.52775113 0.59986109 0.35697029 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3570412  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35668217 1.
  0.         0.         1.        ]
 [0.40307314 0.         0.         0.         0.35656214 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35683608 1.
  0.         0.         1.        ]
 [1.         0.33886771 1.         1.         0.35657966 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35693778 1.
  0.         0.47890474 1.        ]
 [0.         0.         0.         0.         0.35664923 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35688314 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.75
#####################         POISON         ###############################################

############################################################################################

comm_round: 9 | global_test_acc: 58.333% | global_f1: 0.7368421052631579 | global_precision: 0.5833333333333334
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         5
           1       0.58      1.00      0.74         7

    accuracy                           0.58        12
   macro avg       0.29      0.50      0.37        12
weighted avg       0.34      0.58      0.43        12
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[0.         1.         0.         0.29946184 0.81920026 1.
 1.         1.         1.         1.         1.         1.
 1.         0.21586784 1.         0.58357878 1.         0.53276364
 1.         1.         0.24113047 1.         1.         0.
 0.09607257 1.         1.         1.         1.         1.
 1.         1.         1.         0.5016068  1.        ]
wv_fg shape (35,)
[0.         1.         0.         0.         1.         0.
 0.40040698 0.69337606 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.04900884 0.         0.
 0.         0.         0.         0.         1.         0.
 0.         0.         0.         0.         0.        ]
wv_mn shape (35,)
[0.         1.         0.         0.         0.48336204 1.
 0.96791903 1.         1.         1.         0.59557263 0.60141648
 0.36797073 0.         1.         0.         0.82312233 0.
 0.56815919 0.77545034 0.         1.         1.         0.
 0.         1.         0.35065733 1.         1.         0.30141937
 0.65318796 0.1661397  0.23411842 0.         0.16784705]
wv_ed shape (35,)
[0.         1.         0.         0.         0.         0.85759794
 0.91376936 1.         1.         1.         0.81537968 0.76409261
 0.47703332 0.         1.         0.         1.         0.
 0.81825074 0.90535701 0.         1.         1.         0.
 0.         1.         0.52693396 1.         1.         0.52187914
 0.65785417 0.18394419 0.41223095 0.         0.38230955]
wv_lg shape (35, 1)
[[0.35760561]
 [0.35764977]
 [0.35746766]
 [0.35754443]
 [0.35751392]
 [0.35748949]
 [0.35780198]
 [0.35742752]
 [0.3574211 ]
 [0.356962  ]
 [0.35722591]
 [0.35714848]
 [0.35708316]
 [0.35714395]
 [0.35704943]
 [0.35719987]
 [0.35708875]
 [0.35715405]
 [0.35701134]
 [0.35706956]
 [0.35700717]
 [0.35719976]
 [0.3569679 ]
 [0.35716346]
 [0.35712312]
 [0.35696327]
 [0.35712955]
 [0.35714621]
 [0.35712351]
 [0.35710773]
 [0.35702897]
 [0.35722581]
 [0.35724573]
 [0.35720761]
 [0.35714583]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[1.         1.         1.         1.         0.42894026 1.
 1.         0.96592607 0.69671194 0.76083891 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_std shape (35,)
[0.         1.         0.         0.         0.         0.87053531
 0.         0.77147627 0.         0.5848959  0.         0.
 0.         0.         0.44080496 0.         0.         0.
 0.         0.         0.         0.         0.69171329 0.
 0.         0.         0.         0.         1.         0.
 0.         0.         0.         0.         0.        ]
xy shape: (35, 9)
[[0.         0.         0.         0.         0.35760561 1.
  1.         0.         0.        ]
 [1.         1.         1.         1.         0.35764977 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.35746766 1.
  1.         0.         0.        ]
 [0.29946184 0.         0.         0.         0.35754443 1.
  1.         0.         0.        ]
 [0.81920026 1.         0.48336204 0.         0.35751392 1.
  0.42894026 0.         0.        ]
 [1.         0.         1.         0.85759794 0.35748949 1.
  1.         0.87053531 0.        ]
 [1.         0.40040698 0.96791903 0.91376936 0.35780198 1.
  1.         0.         0.        ]
 [1.         0.69337606 1.         1.         0.35742752 1.
  0.96592607 0.77147627 0.        ]
 [1.         0.         1.         1.         0.3574211  1.
  0.69671194 0.         0.        ]
 [1.         0.         1.         1.         0.356962   1.
  0.76083891 0.5848959  0.        ]
 [1.         0.         0.59557263 0.81537968 0.35722591 1.
  0.         0.         1.        ]
 [1.         0.         0.60141648 0.76409261 0.35714848 1.
  0.         0.         1.        ]
 [1.         0.         0.36797073 0.47703332 0.35708316 1.
  0.         0.         1.        ]
 [0.21586784 0.         0.         0.         0.35714395 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35704943 1.
  0.         0.44080496 1.        ]
 [0.58357878 0.         0.         0.         0.35719987 1.
  0.         0.         1.        ]
 [1.         0.         0.82312233 1.         0.35708875 1.
  0.         0.         1.        ]
 [0.53276364 0.         0.         0.         0.35715405 1.
  0.         0.         1.        ]
 [1.         0.         0.56815919 0.81825074 0.35701134 1.
  0.         0.         1.        ]
 [1.         0.         0.77545034 0.90535701 0.35706956 1.
  0.         0.         1.        ]
 [0.24113047 0.         0.         0.         0.35700717 1.
  0.         0.         1.        ]
 [1.         0.04900884 1.         1.         0.35719976 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.3569679  1.
  0.         0.69171329 1.        ]
 [0.         0.         0.         0.         0.35716346 1.
  0.         0.         1.        ]
 [0.09607257 0.         0.         0.         0.35712312 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35696327 1.
  0.         0.         1.        ]
 [1.         0.         0.35065733 0.52693396 0.35712955 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35714621 1.
  0.         0.         1.        ]
 [1.         1.         1.         1.         0.35712351 1.
  0.         1.         1.        ]
 [1.         0.         0.30141937 0.52187914 0.35710773 1.
  0.         0.         1.        ]
 [1.         0.         0.65318796 0.65785417 0.35702897 1.
  0.         0.         1.        ]
 [1.         0.         0.1661397  0.18394419 0.35722581 1.
  0.         0.         1.        ]
 [1.         0.         0.23411842 0.41223095 0.35724573 1.
  0.         0.         1.        ]
 [0.5016068  0.         0.         0.         0.35720761 1.
  0.         0.         1.        ]
 [1.         0.         0.16784705 0.38230955 0.35714583 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.6875
#####################         POISON         ###############################################

############################################################################################

comm_round: 10 | global_test_acc: 75.000% | global_f1: 0.8571428571428571 | global_precision: 0.75
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.75      1.00      0.86         9

    accuracy                           0.75        12
   macro avg       0.38      0.50      0.43        12
weighted avg       0.56      0.75      0.64        12
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[1.         0.45588849 1.         1.         1.         1.
 0.         1.         1.         1.         1.         0.
 0.         0.33455078 0.15403922 0.         0.25818225 0.
 0.         1.         1.         0.         1.         0.
 0.         1.         0.37336762 0.         1.         0.34674015
 0.11438127 0.22979754 0.         0.14965469 0.        ]
wv_fg shape (35,)
[1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
wv_mn shape (35,)
[1.         0.         0.69407331 1.         1.         1.
 0.         1.         0.77627164 1.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.36780006 0.         0.         0.
 0.         0.         0.         0.         0.67338482 0.
 0.         0.         0.         0.         0.        ]
wv_ed shape (35,)
[1.         0.         0.4626203  1.         1.         1.
 0.         1.         0.71841797 1.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.47169404 0.         0.00588213 0.
 0.         0.         0.         0.         0.82448109 0.
 0.         0.         0.         0.         0.        ]
wv_lg shape (35, 1)
[[0.35744298]
 [0.35747336]
 [0.35747062]
 [0.35746209]
 [0.35745689]
 [0.35747032]
 [0.35746479]
 [0.3574712 ]
 [0.3574665 ]
 [0.35745362]
 [0.35742329]
 [0.3574279 ]
 [0.35741382]
 [0.35742749]
 [0.3573904 ]
 [0.35743028]
 [0.35743066]
 [0.35741545]
 [0.35742774]
 [0.35741371]
 [0.35742558]
 [0.35742685]
 [0.35742033]
 [0.35742821]
 [0.3574154 ]
 [0.35741825]
 [0.35742357]
 [0.3574287 ]
 [0.35742759]
 [0.35741811]
 [0.35744584]
 [0.35741664]
 [0.35742323]
 [0.35742421]
 [0.35741201]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[0.6082301  1.         1.         1.         0.51471993 0.26816844
 1.         0.65624067 1.         0.64217771 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_std shape (35,)
[1.         0.         0.28306653 0.67983259 1.         1.
 0.         1.         0.35686008 0.97059026 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
xy shape: (35, 9)
[[1.         1.         1.         1.         0.35744298 1.
  0.6082301  1.         0.        ]
 [0.45588849 0.         0.         0.         0.35747336 1.
  1.         0.         0.        ]
 [1.         0.         0.69407331 0.4626203  0.35747062 1.
  1.         0.28306653 0.        ]
 [1.         0.         1.         1.         0.35746209 1.
  1.         0.67983259 0.        ]
 [1.         0.         1.         1.         0.35745689 1.
  0.51471993 1.         0.        ]
 [1.         0.         1.         1.         0.35747032 1.
  0.26816844 1.         0.        ]
 [0.         1.         0.         0.         0.35746479 1.
  1.         0.         0.        ]
 [1.         1.         1.         1.         0.3574712  1.
  0.65624067 1.         0.        ]
 [1.         0.         0.77627164 0.71841797 0.3574665  1.
  1.         0.35686008 0.        ]
 [1.         1.         1.         1.         0.35745362 1.
  0.64217771 0.97059026 0.        ]
 [1.         0.         0.         0.         0.35742329 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3574279  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35741382 1.
  0.         0.         1.        ]
 [0.33455078 0.         0.         0.         0.35742749 1.
  0.         0.         1.        ]
 [0.15403922 0.         0.         0.         0.3573904  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35743028 1.
  0.         0.         1.        ]
 [0.25818225 0.         0.         0.         0.35743066 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35741545 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35742774 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.35741371 1.
  0.         0.         1.        ]
 [1.         0.         0.36780006 0.47169404 0.35742558 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35742685 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.00588213 0.35742033 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35742821 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3574154  1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.35741825 1.
  0.         0.         1.        ]
 [0.37336762 0.         0.         0.         0.35742357 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3574287  1.
  0.         0.         1.        ]
 [1.         0.         0.67338482 0.82448109 0.35742759 1.
  0.         0.         1.        ]
 [0.34674015 0.         0.         0.         0.35741811 1.
  0.         0.         1.        ]
 [0.11438127 0.         0.         0.         0.35744584 1.
  0.         0.         1.        ]
 [0.22979754 0.         0.         0.         0.35741664 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35742323 1.
  0.         0.         1.        ]
 [0.14965469 0.         0.         0.         0.35742421 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35741201 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.3125
#####################         POISON         ###############################################

############################################################################################

comm_round: 0 | global_test_acc: 25.000% | global_f1: 0.0 | global_precision: 0.0
              precision    recall  f1-score   support

           0       0.25      1.00      0.40         3
           1       0.00      0.00      0.00         9

    accuracy                           0.25        12
   macro avg       0.12      0.50      0.20        12
weighted avg       0.06      0.25      0.10        12
poison scaling shape: (35, 1)
[[0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]]scaled_weight_list: Rows 35 cols 21
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[0.         1.         0.         0.31106224 1.         1.
 1.         1.         0.         0.         0.20453198 0.78769309
 0.77612263 1.         0.         0.85536917 0.         0.19084212
 0.15477783 0.         0.         0.78662089 0.         0.73845918
 0.         0.94114752 0.99992203 0.2702347  0.10824341 0.77735847
 0.97937416 0.14359497 0.         1.         1.        ]
wv_fg shape (35,)
[0.         1.         0.44427241 0.         0.23376644 0.
 0.         0.         0.         1.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_mn shape (35,)
[0.         1.         0.         0.13656481 0.74563173 1.
 1.         1.         0.         0.         0.01146441 0.33400205
 0.24633957 0.80213586 0.         0.38038944 0.         0.
 0.         0.         0.         0.12505552 0.         0.27832214
 0.         0.40111022 0.62451144 0.09010011 0.         0.07642056
 0.52246993 0.         0.         1.         1.        ]
wv_ed shape (35,)
[0.         1.         0.         0.67714735 0.92662996 1.
 1.         1.         0.2372414  0.         0.         0.
 0.22408916 0.5156838  0.         0.18310372 0.         0.
 0.         0.         0.         0.         0.         0.09776168
 0.         0.04723712 0.52074917 0.         0.         0.03835355
 0.42969387 0.         0.         0.93357855 1.        ]
wv_lg shape (35, 1)
[[0.35746675]
 [0.35742915]
 [0.35746032]
 [0.35743377]
 [0.35742217]
 [0.35742579]
 [0.35747264]
 [0.35746731]
 [0.35747512]
 [0.35745759]
 [0.35739485]
 [0.35740394]
 [0.35738292]
 [0.35739739]
 [0.35739422]
 [0.35740142]
 [0.35739841]
 [0.35740887]
 [0.35736539]
 [0.35739906]
 [0.35739501]
 [0.35738987]
 [0.35740348]
 [0.35740896]
 [0.35739496]
 [0.35740587]
 [0.35737731]
 [0.35738403]
 [0.35738939]
 [0.35738782]
 [0.35739475]
 [0.35741718]
 [0.35740312]
 [0.35738848]
 [0.35740309]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
wv_std shape (35,)
[0.         1.         0.1667521  0.         0.96386849 1.
 1.         1.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.25367453]
xy shape: (35, 9)
[[0.         0.         0.         0.         0.35746675 1.
  1.         0.         0.        ]
 [1.         1.         1.         1.         0.35742915 1.
  1.         1.         0.        ]
 [0.         0.44427241 0.         0.         0.35746032 1.
  1.         0.1667521  0.        ]
 [0.31106224 0.         0.13656481 0.67714735 0.35743377 1.
  1.         0.         0.        ]
 [1.         0.23376644 0.74563173 0.92662996 0.35742217 1.
  1.         0.96386849 0.        ]
 [1.         0.         1.         1.         0.35742579 1.
  1.         1.         0.        ]
 [1.         0.         1.         1.         0.35747264 1.
  1.         1.         0.        ]
 [1.         0.         1.         1.         0.35746731 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.2372414  0.35747512 1.
  1.         0.         0.        ]
 [0.         1.         0.         0.         0.35745759 1.
  1.         0.         0.        ]
 [0.20453198 0.         0.01146441 0.         0.35739485 1.
  0.         0.         1.        ]
 [0.78769309 0.         0.33400205 0.         0.35740394 1.
  0.         0.         1.        ]
 [0.77612263 0.         0.24633957 0.22408916 0.35738292 1.
  0.         0.         1.        ]
 [1.         0.         0.80213586 0.5156838  0.35739739 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35739422 1.
  0.         0.         1.        ]
 [0.85536917 0.         0.38038944 0.18310372 0.35740142 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35739841 1.
  0.         0.         1.        ]
 [0.19084212 0.         0.         0.         0.35740887 1.
  0.         0.         1.        ]
 [0.15477783 0.         0.         0.         0.35736539 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35739906 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35739501 1.
  0.         0.         1.        ]
 [0.78662089 0.         0.12505552 0.         0.35738987 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35740348 1.
  0.         0.         1.        ]
 [0.73845918 0.         0.27832214 0.09776168 0.35740896 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35739496 1.
  0.         0.         1.        ]
 [0.94114752 0.         0.40111022 0.04723712 0.35740587 1.
  0.         0.         1.        ]
 [0.99992203 0.         0.62451144 0.52074917 0.35737731 1.
  0.         0.         1.        ]
 [0.2702347  0.         0.09010011 0.         0.35738403 1.
  0.         0.         1.        ]
 [0.10824341 0.         0.         0.         0.35738939 1.
  0.         0.         1.        ]
 [0.77735847 0.         0.07642056 0.03835355 0.35738782 1.
  0.         0.         1.        ]
 [0.97937416 0.         0.52246993 0.42969387 0.35739475 1.
  0.         0.         1.        ]
 [0.14359497 0.         0.         0.         0.35741718 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35740312 1.
  0.         0.         1.        ]
 [1.         0.         1.         0.93357855 0.35738848 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35740309 1.
  0.         0.25367453 1.        ]]

Best Training Poisoning Accuracy:
0.5
#####################         POISON         ###############################################

############################################################################################

comm_round: 1 | global_test_acc: 58.333% | global_f1: 0.7368421052631579 | global_precision: 0.5833333333333334
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         5
           1       0.58      1.00      0.74         7

    accuracy                           0.58        12
   macro avg       0.29      0.50      0.37        12
weighted avg       0.34      0.58      0.43        12
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[0.         1.         1.         1.         1.         1.
 1.         1.         1.         0.         1.         1.
 0.8223755  0.         0.96481184 0.6980668  0.60572958 1.
 0.9374216  0.         1.         0.69776765 0.83169026 0.73527449
 0.         0.54972149 0.         0.78284437 0.76078391 0.48315765
 1.         1.         0.         0.         0.74772248]
wv_fg shape (35,)
[0.         0.         1.         1.         0.         0.29394114
 0.         0.36428602 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_mn shape (35,)
[0.         1.         1.         0.53904697 1.         1.
 1.         1.         1.         0.         0.79465444 0.60439046
 0.15448082 0.         0.37953432 0.         0.         0.90695414
 0.38596661 0.         0.64730221 0.01083209 0.14127184 0.
 0.         0.         0.         0.18895235 0.27085702 0.
 0.67018454 0.92956107 0.         0.         0.        ]
wv_ed shape (35,)
[0.         1.         1.         0.78322453 1.         1.
 1.         1.         1.         0.         0.80891144 0.40003494
 0.03661793 0.         0.14731301 0.         0.         1.
 0.01945996 0.         0.27610661 0.         0.         0.
 0.         0.         0.         0.15083923 0.         0.
 0.4447149  0.86233802 0.         0.         0.        ]
wv_lg shape (35, 1)
[[0.35748789]
 [0.35748131]
 [0.3575031 ]
 [0.35749546]
 [0.35748654]
 [0.35748168]
 [0.35747042]
 [0.35748478]
 [0.35746024]
 [0.35749739]
 [0.35742611]
 [0.35745545]
 [0.35740314]
 [0.35742434]
 [0.35742041]
 [0.35741012]
 [0.35741523]
 [0.35742034]
 [0.35740399]
 [0.35740759]
 [0.35743122]
 [0.35738871]
 [0.35741407]
 [0.35741429]
 [0.35741954]
 [0.35741378]
 [0.35741972]
 [0.35740123]
 [0.35741519]
 [0.35742978]
 [0.35743126]
 [0.35741662]
 [0.35743816]
 [0.35740365]
 [0.35742022]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[1.         0.96975962 0.98755343 1.         1.         1.
 0.79248138 0.9435696  1.         1.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_std shape (35,)
[0.         0.95356291 1.         0.03427076 1.         1.
 1.         1.         1.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
xy shape: (35, 9)
[[0.         0.         0.         0.         0.35748789 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.35748131 1.
  0.96975962 0.95356291 0.        ]
 [1.         1.         1.         1.         0.3575031  1.
  0.98755343 1.         0.        ]
 [1.         1.         0.53904697 0.78322453 0.35749546 1.
  1.         0.03427076 0.        ]
 [1.         0.         1.         1.         0.35748654 1.
  1.         1.         0.        ]
 [1.         0.29394114 1.         1.         0.35748168 1.
  1.         1.         0.        ]
 [1.         0.         1.         1.         0.35747042 1.
  0.79248138 1.         0.        ]
 [1.         0.36428602 1.         1.         0.35748478 1.
  0.9435696  1.         0.        ]
 [1.         0.         1.         1.         0.35746024 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.35749739 1.
  1.         0.         0.        ]
 [1.         0.         0.79465444 0.80891144 0.35742611 1.
  0.         0.         1.        ]
 [1.         0.         0.60439046 0.40003494 0.35745545 1.
  0.         0.         1.        ]
 [0.8223755  0.         0.15448082 0.03661793 0.35740314 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35742434 1.
  0.         0.         1.        ]
 [0.96481184 0.         0.37953432 0.14731301 0.35742041 1.
  0.         0.         1.        ]
 [0.6980668  0.         0.         0.         0.35741012 1.
  0.         0.         1.        ]
 [0.60572958 0.         0.         0.         0.35741523 1.
  0.         0.         1.        ]
 [1.         0.         0.90695414 1.         0.35742034 1.
  0.         0.         1.        ]
 [0.9374216  0.         0.38596661 0.01945996 0.35740399 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35740759 1.
  0.         0.         1.        ]
 [1.         0.         0.64730221 0.27610661 0.35743122 1.
  0.         0.         1.        ]
 [0.69776765 0.         0.01083209 0.         0.35738871 1.
  0.         0.         1.        ]
 [0.83169026 0.         0.14127184 0.         0.35741407 1.
  0.         0.         1.        ]
 [0.73527449 0.         0.         0.         0.35741429 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35741954 1.
  0.         0.         1.        ]
 [0.54972149 0.         0.         0.         0.35741378 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35741972 1.
  0.         0.         1.        ]
 [0.78284437 0.         0.18895235 0.15083923 0.35740123 1.
  0.         0.         1.        ]
 [0.76078391 0.         0.27085702 0.         0.35741519 1.
  0.         0.         1.        ]
 [0.48315765 0.         0.         0.         0.35742978 1.
  0.         0.         1.        ]
 [1.         0.         0.67018454 0.4447149  0.35743126 1.
  0.         0.         1.        ]
 [1.         0.         0.92956107 0.86233802 0.35741662 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35743816 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35740365 1.
  0.         0.         1.        ]
 [0.74772248 0.         0.         0.         0.35742022 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.6875
#####################         POISON         ###############################################

############################################################################################

comm_round: 2 | global_test_acc: 58.333% | global_f1: 0.7368421052631579 | global_precision: 0.5833333333333334
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         5
           1       0.58      1.00      0.74         7

    accuracy                           0.58        12
   macro avg       0.29      0.50      0.37        12
weighted avg       0.34      0.58      0.43        12
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[0.72255714 1.         1.         1.         1.         1.
 0.         0.         1.         0.28004885 0.20209032 0.
 0.59329408 0.         0.         0.         0.67831724 0.
 0.64996529 1.         1.         0.         0.         0.
 0.         0.49785183 0.60712622 1.         0.04659248 0.00474523
 0.         0.         0.72508438 0.         1.        ]
wv_fg shape (35,)
[0.         0.         0.08830141 0.         0.         0.
 1.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_mn shape (35,)
[0.         1.         1.         1.         1.         1.
 0.         0.         1.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.10892712 0.1962058  0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.32258253]
wv_ed shape (35,)
[0.         1.         1.         0.96187868 1.         1.
 0.         0.         1.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.27131824 0.21685753 0.         0.         0.
 0.         0.         0.         0.08388068 0.         0.
 0.         0.         0.         0.         0.23470107]
wv_lg shape (35, 1)
[[0.35749912]
 [0.35748914]
 [0.35751249]
 [0.3575196 ]
 [0.35752011]
 [0.35750775]
 [0.35748227]
 [0.35751344]
 [0.35750038]
 [0.35753017]
 [0.35745764]
 [0.35744755]
 [0.35745292]
 [0.3574463 ]
 [0.35746072]
 [0.35745808]
 [0.35746457]
 [0.35747173]
 [0.35743051]
 [0.3574445 ]
 [0.35748635]
 [0.35745681]
 [0.35744888]
 [0.35745255]
 [0.35743476]
 [0.35745659]
 [0.35743919]
 [0.35743935]
 [0.35742883]
 [0.3574572 ]
 [0.35745956]
 [0.35746035]
 [0.35746   ]
 [0.35744488]
 [0.35746536]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[1.         1.         0.         1.         1.         1.
 1.         0.67507013 0.49291615 1.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_std shape (35,)
[0.63655769 1.         1.         1.         0.92995318 1.
 0.         0.         0.72071785 0.07942313 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
xy shape: (35, 9)
[[0.72255714 0.         0.         0.         0.35749912 1.
  1.         0.63655769 0.        ]
 [1.         0.         1.         1.         0.35748914 1.
  1.         1.         0.        ]
 [1.         0.08830141 1.         1.         0.35751249 1.
  0.         1.         0.        ]
 [1.         0.         1.         0.96187868 0.3575196  1.
  1.         1.         0.        ]
 [1.         0.         1.         1.         0.35752011 1.
  1.         0.92995318 0.        ]
 [1.         0.         1.         1.         0.35750775 1.
  1.         1.         0.        ]
 [0.         1.         0.         0.         0.35748227 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.35751344 1.
  0.67507013 0.         0.        ]
 [1.         0.         1.         1.         0.35750038 1.
  0.49291615 0.72071785 0.        ]
 [0.28004885 0.         0.         0.         0.35753017 1.
  1.         0.07942313 0.        ]
 [0.20209032 0.         0.         0.         0.35745764 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35744755 1.
  0.         0.         1.        ]
 [0.59329408 0.         0.         0.         0.35745292 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3574463  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35746072 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35745808 1.
  0.         0.         1.        ]
 [0.67831724 0.         0.         0.         0.35746457 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35747173 1.
  0.         0.         1.        ]
 [0.64996529 0.         0.         0.         0.35743051 1.
  0.         0.         1.        ]
 [1.         0.         0.10892712 0.27131824 0.3574445  1.
  0.         0.         1.        ]
 [1.         0.         0.1962058  0.21685753 0.35748635 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35745681 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35744888 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35745255 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35743476 1.
  0.         0.         1.        ]
 [0.49785183 0.         0.         0.         0.35745659 1.
  0.         0.         1.        ]
 [0.60712622 0.         0.         0.         0.35743919 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.08388068 0.35743935 1.
  0.         0.         1.        ]
 [0.04659248 0.         0.         0.         0.35742883 1.
  0.         0.         1.        ]
 [0.00474523 0.         0.         0.         0.3574572  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35745956 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35746035 1.
  0.         0.         1.        ]
 [0.72508438 0.         0.         0.         0.35746    1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35744488 1.
  0.         0.         1.        ]
 [1.         0.         0.32258253 0.23470107 0.35746536 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.8125
#####################         POISON         ###############################################

############################################################################################

comm_round: 3 | global_test_acc: 66.667% | global_f1: 0.8 | global_precision: 0.6666666666666666
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         4
           1       0.67      1.00      0.80         8

    accuracy                           0.67        12
   macro avg       0.33      0.50      0.40        12
weighted avg       0.44      0.67      0.53        12
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[0.05290772 0.58507383 0.67740747 0.         0.         1.
 0.31222826 0.4780432  1.         0.         0.         0.
 0.30183148 1.         0.56320828 0.92931594 0.42807232 0.59100051
 1.         0.1455149  0.59366722 1.         0.         0.20077385
 1.         0.05475574 0.01196611 0.         0.41906169 0.46484421
 1.         0.         1.         1.         1.        ]
wv_fg shape (35,)
[0.98225028 0.46023134 1.         1.         0.46023134 1.
 1.         1.         1.         0.98225028 0.         0.
 0.         0.         0.         0.         0.         0.
 0.3987723  0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.09831399]
wv_mn shape (35,)
[0.04785627 0.45174966 0.29450118 0.08092603 0.15249712 0.80373384
 0.62111577 0.58046485 1.         0.         0.         0.
 0.19978172 1.         0.61582647 0.56201808 0.43072929 0.53855781
 1.         0.14376734 0.49428272 1.         0.         0.07213887
 1.         0.         0.         0.         0.39531797 0.36384814
 1.         0.         0.94474294 1.         1.        ]
wv_ed shape (35,)
[0.         0.46644071 0.39646392 0.06609208 0.18483311 0.94164248
 0.78177895 1.         1.         0.         0.         0.
 0.2337109  1.         0.64203908 0.75044599 0.35321305 0.85996247
 1.         0.2518544  0.72173644 1.         0.         0.13818381
 1.         0.19697448 0.         0.         0.55009383 0.37325323
 1.         0.         1.         1.         1.        ]
wv_lg shape (35, 1)
[[0.3575192 ]
 [0.3575267 ]
 [0.35752554]
 [0.35754406]
 [0.35752624]
 [0.3575306 ]
 [0.35754578]
 [0.35754753]
 [0.35748309]
 [0.35753274]
 [0.357493  ]
 [0.35748078]
 [0.35749112]
 [0.35747808]
 [0.35749888]
 [0.3574802 ]
 [0.35745602]
 [0.35748434]
 [0.35748952]
 [0.35747055]
 [0.35747828]
 [0.35747777]
 [0.35748091]
 [0.35746487]
 [0.35745593]
 [0.35748901]
 [0.3574556 ]
 [0.35746608]
 [0.35746451]
 [0.35747413]
 [0.35749206]
 [0.35748186]
 [0.3574701 ]
 [0.35747945]
 [0.35747884]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
wv_std shape (35,)
[0.         0.         0.         0.         0.         0.15715723
 0.         0.         1.         0.         0.         0.
 0.         0.44836681 0.         0.         0.         0.
 1.         0.         0.         0.         0.         0.
 0.11078187 0.         0.         0.         0.         0.
 1.         0.         0.         0.90543604 0.23935074]
xy shape: (35, 9)
[[0.05290772 0.98225028 0.04785627 0.         0.3575192  1.
  1.         0.         0.        ]
 [0.58507383 0.46023134 0.45174966 0.46644071 0.3575267  1.
  1.         0.         0.        ]
 [0.67740747 1.         0.29450118 0.39646392 0.35752554 1.
  1.         0.         0.        ]
 [0.         1.         0.08092603 0.06609208 0.35754406 1.
  1.         0.         0.        ]
 [0.         0.46023134 0.15249712 0.18483311 0.35752624 1.
  1.         0.         0.        ]
 [1.         1.         0.80373384 0.94164248 0.3575306  1.
  1.         0.15715723 0.        ]
 [0.31222826 1.         0.62111577 0.78177895 0.35754578 1.
  1.         0.         0.        ]
 [0.4780432  1.         0.58046485 1.         0.35754753 1.
  1.         0.         0.        ]
 [1.         1.         1.         1.         0.35748309 1.
  1.         1.         0.        ]
 [0.         0.98225028 0.         0.         0.35753274 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.357493   1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35748078 1.
  0.         0.         1.        ]
 [0.30183148 0.         0.19978172 0.2337109  0.35749112 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35747808 1.
  0.         0.44836681 1.        ]
 [0.56320828 0.         0.61582647 0.64203908 0.35749888 1.
  0.         0.         1.        ]
 [0.92931594 0.         0.56201808 0.75044599 0.3574802  1.
  0.         0.         1.        ]
 [0.42807232 0.         0.43072929 0.35321305 0.35745602 1.
  0.         0.         1.        ]
 [0.59100051 0.         0.53855781 0.85996247 0.35748434 1.
  0.         0.         1.        ]
 [1.         0.3987723  1.         1.         0.35748952 1.
  0.         1.         1.        ]
 [0.1455149  0.         0.14376734 0.2518544  0.35747055 1.
  0.         0.         1.        ]
 [0.59366722 0.         0.49428272 0.72173644 0.35747828 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35747777 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35748091 1.
  0.         0.         1.        ]
 [0.20077385 0.         0.07213887 0.13818381 0.35746487 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35745593 1.
  0.         0.11078187 1.        ]
 [0.05475574 0.         0.         0.19697448 0.35748901 1.
  0.         0.         1.        ]
 [0.01196611 0.         0.         0.         0.3574556  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35746608 1.
  0.         0.         1.        ]
 [0.41906169 0.         0.39531797 0.55009383 0.35746451 1.
  0.         0.         1.        ]
 [0.46484421 0.         0.36384814 0.37325323 0.35747413 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35749206 1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.35748186 1.
  0.         0.         1.        ]
 [1.         0.         0.94474294 1.         0.3574701  1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35747945 1.
  0.         0.90543604 1.        ]
 [1.         0.09831399 1.         1.         0.35747884 1.
  0.         0.23935074 1.        ]]

Best Training Poisoning Accuracy:
0.625
#####################         POISON         ###############################################

############################################################################################

comm_round: 4 | global_test_acc: 83.333% | global_f1: 0.9090909090909091 | global_precision: 0.8333333333333334
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.83      1.00      0.91        10

    accuracy                           0.83        12
   macro avg       0.42      0.50      0.45        12
weighted avg       0.69      0.83      0.76        12
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[0.         1.         1.         1.         1.         0.
 0.         1.         1.         0.         1.         1.
 0.54337333 0.70804595 0.66959389 0.         0.67133731 0.70045877
 0.95393702 0.43660289 0.55239687 0.20525743 0.9608708  1.
 0.25437825 0.85148945 1.         0.45663231 0.10892522 1.
 1.         0.42049415 1.         0.12717355 0.96437727]
wv_fg shape (35,)
[0.         0.         0.         0.         0.         1.
 0.         1.         0.86502139 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_mn shape (35,)
[0.         1.         0.53070319 1.         0.32128522 0.
 0.         0.14152128 1.         0.         0.79217321 1.
 0.         0.         0.         0.         0.         0.
 0.28434772 0.         0.         0.         0.38955928 0.48272535
 0.         0.12602561 0.33494349 0.         0.         0.88471204
 0.97176338 0.         1.         0.         0.21468131]
wv_ed shape (35,)
[0.         1.         0.79645985 1.         0.67845172 0.
 0.         0.34825273 1.         0.         0.64548158 1.
 0.         0.         0.04938165 0.         0.         0.0150895
 0.26500183 0.         0.         0.         0.22669928 0.36227775
 0.         0.         0.35051992 0.         0.         0.7897836
 0.99056959 0.         1.         0.         0.11574784]
wv_lg shape (35, 1)
[[0.35755927]
 [0.35750604]
 [0.35752474]
 [0.35753804]
 [0.35756993]
 [0.35756936]
 [0.35756407]
 [0.35750724]
 [0.35750258]
 [0.35753392]
 [0.35750409]
 [0.35747556]
 [0.35749339]
 [0.35750407]
 [0.35747861]
 [0.35748342]
 [0.35746964]
 [0.35749036]
 [0.35746192]
 [0.35747347]
 [0.3574951 ]
 [0.35749324]
 [0.35747385]
 [0.35747284]
 [0.35750159]
 [0.35747272]
 [0.35750008]
 [0.35749167]
 [0.35748871]
 [0.35749757]
 [0.35749753]
 [0.35748188]
 [0.35748057]
 [0.35746392]
 [0.35747517]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[1.         0.42864784 0.61390304 1.         1.         0.77384602
 1.         1.         0.4743881  1.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_std shape (35,)
[0.         1.         0.         0.81210092 0.         0.
 0.         0.34868954 1.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
xy shape: (35, 9)
[[0.         0.         0.         0.         0.35755927 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.35750604 1.
  0.42864784 1.         0.        ]
 [1.         0.         0.53070319 0.79645985 0.35752474 1.
  0.61390304 0.         0.        ]
 [1.         0.         1.         1.         0.35753804 1.
  1.         0.81210092 0.        ]
 [1.         0.         0.32128522 0.67845172 0.35756993 1.
  1.         0.         0.        ]
 [0.         1.         0.         0.         0.35756936 1.
  0.77384602 0.         0.        ]
 [0.         0.         0.         0.         0.35756407 1.
  1.         0.         0.        ]
 [1.         1.         0.14152128 0.34825273 0.35750724 1.
  1.         0.34868954 0.        ]
 [1.         0.86502139 1.         1.         0.35750258 1.
  0.4743881  1.         0.        ]
 [0.         0.         0.         0.         0.35753392 1.
  1.         0.         0.        ]
 [1.         0.         0.79217321 0.64548158 0.35750409 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35747556 1.
  0.         0.         1.        ]
 [0.54337333 0.         0.         0.         0.35749339 1.
  0.         0.         1.        ]
 [0.70804595 0.         0.         0.         0.35750407 1.
  0.         0.         1.        ]
 [0.66959389 0.         0.         0.04938165 0.35747861 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35748342 1.
  0.         0.         1.        ]
 [0.67133731 0.         0.         0.         0.35746964 1.
  0.         0.         1.        ]
 [0.70045877 0.         0.         0.0150895  0.35749036 1.
  0.         0.         1.        ]
 [0.95393702 0.         0.28434772 0.26500183 0.35746192 1.
  0.         0.         1.        ]
 [0.43660289 0.         0.         0.         0.35747347 1.
  0.         0.         1.        ]
 [0.55239687 0.         0.         0.         0.3574951  1.
  0.         0.         1.        ]
 [0.20525743 0.         0.         0.         0.35749324 1.
  0.         0.         1.        ]
 [0.9608708  0.         0.38955928 0.22669928 0.35747385 1.
  0.         0.         1.        ]
 [1.         0.         0.48272535 0.36227775 0.35747284 1.
  0.         0.         1.        ]
 [0.25437825 0.         0.         0.         0.35750159 1.
  0.         0.         1.        ]
 [0.85148945 0.         0.12602561 0.         0.35747272 1.
  0.         0.         1.        ]
 [1.         0.         0.33494349 0.35051992 0.35750008 1.
  0.         0.         1.        ]
 [0.45663231 0.         0.         0.         0.35749167 1.
  0.         0.         1.        ]
 [0.10892522 0.         0.         0.         0.35748871 1.
  0.         0.         1.        ]
 [1.         0.         0.88471204 0.7897836  0.35749757 1.
  0.         0.         1.        ]
 [1.         0.         0.97176338 0.99056959 0.35749753 1.
  0.         0.         1.        ]
 [0.42049415 0.         0.         0.         0.35748188 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35748057 1.
  0.         0.         1.        ]
 [0.12717355 0.         0.         0.         0.35746392 1.
  0.         0.         1.        ]
 [0.96437727 0.         0.21468131 0.11574784 0.35747517 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.75
#####################         POISON         ###############################################

############################################################################################

comm_round: 5 | global_test_acc: 75.000% | global_f1: 0.8571428571428571 | global_precision: 0.75
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.75      1.00      0.86         9

    accuracy                           0.75        12
   macro avg       0.38      0.50      0.43        12
weighted avg       0.56      0.75      0.64        12
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[0.         0.         0.53161702 1.         1.         1.
 0.20166849 0.         1.         0.72764031 1.         1.
 1.         0.13276391 0.45196682 0.97233505 0.         0.
 0.52033499 0.37510072 0.         0.         0.         1.
 1.         0.         0.61852598 0.9429546  1.         0.38648731
 0.03858559 1.         1.         0.47452287 1.        ]
wv_fg shape (35,)
[0.         0.         0.         0.09868505 0.5178689  0.
 0.         1.         1.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_mn shape (35,)
[0.         0.         0.         0.57295406 0.93609109 0.27274194
 0.         0.         1.         0.16241465 0.38040811 1.
 0.06497666 0.         0.         0.13022231 0.         0.
 0.         0.         0.         0.         0.         0.82439023
 0.29342381 0.         0.         0.         0.35229512 0.
 0.         0.48614235 0.71753685 0.         0.45974199]
wv_ed shape (35,)
[0.         0.         0.28610172 1.         1.         0.41116109
 0.1063907  0.         1.         0.3335575  0.52691079 1.
 0.44416273 0.         0.16680988 0.47962937 0.         0.
 0.         0.09736491 0.         0.         0.         1.
 0.65426814 0.         0.         0.25506513 0.76413776 0.13021377
 0.         0.67764265 0.95479506 0.14879826 0.85900142]
wv_lg shape (35, 1)
[[0.35757319]
 [0.35756133]
 [0.35755493]
 [0.35756333]
 [0.35750787]
 [0.35757707]
 [0.35758971]
 [0.35758702]
 [0.35758166]
 [0.35757559]
 [0.35751115]
 [0.35748456]
 [0.35750541]
 [0.35754104]
 [0.35752939]
 [0.3575295 ]
 [0.35753787]
 [0.35752397]
 [0.35751838]
 [0.3575365 ]
 [0.35750369]
 [0.35749883]
 [0.35752562]
 [0.35748516]
 [0.35751892]
 [0.35752328]
 [0.3575143 ]
 [0.35750472]
 [0.35751404]
 [0.35752149]
 [0.35751488]
 [0.35751329]
 [0.35752791]
 [0.3575094 ]
 [0.35752306]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[1.        1.        1.        1.        1.        1.        1.
 1.        0.4904701 1.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.       ]
wv_std shape (35,)
[0.         0.         0.         0.         0.         0.
 0.         0.         1.         0.         0.         0.90182801
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.09942742
 0.         0.         0.         0.         0.         0.
 0.         0.         0.15102758 0.         0.        ]
xy shape: (35, 9)
[[0.         0.         0.         0.         0.35757319 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.35756133 1.
  1.         0.         0.        ]
 [0.53161702 0.         0.         0.28610172 0.35755493 1.
  1.         0.         0.        ]
 [1.         0.09868505 0.57295406 1.         0.35756333 1.
  1.         0.         0.        ]
 [1.         0.5178689  0.93609109 1.         0.35750787 1.
  1.         0.         0.        ]
 [1.         0.         0.27274194 0.41116109 0.35757707 1.
  1.         0.         0.        ]
 [0.20166849 0.         0.         0.1063907  0.35758971 1.
  1.         0.         0.        ]
 [0.         1.         0.         0.         0.35758702 1.
  1.         0.         0.        ]
 [1.         1.         1.         1.         0.35758166 1.
  0.4904701  1.         0.        ]
 [0.72764031 0.         0.16241465 0.3335575  0.35757559 1.
  1.         0.         0.        ]
 [1.         0.         0.38040811 0.52691079 0.35751115 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35748456 1.
  0.         0.90182801 1.        ]
 [1.         0.         0.06497666 0.44416273 0.35750541 1.
  0.         0.         1.        ]
 [0.13276391 0.         0.         0.         0.35754104 1.
  0.         0.         1.        ]
 [0.45196682 0.         0.         0.16680988 0.35752939 1.
  0.         0.         1.        ]
 [0.97233505 0.         0.13022231 0.47962937 0.3575295  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35753787 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35752397 1.
  0.         0.         1.        ]
 [0.52033499 0.         0.         0.         0.35751838 1.
  0.         0.         1.        ]
 [0.37510072 0.         0.         0.09736491 0.3575365  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35750369 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35749883 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35752562 1.
  0.         0.         1.        ]
 [1.         0.         0.82439023 1.         0.35748516 1.
  0.         0.09942742 1.        ]
 [1.         0.         0.29342381 0.65426814 0.35751892 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35752328 1.
  0.         0.         1.        ]
 [0.61852598 0.         0.         0.         0.3575143  1.
  0.         0.         1.        ]
 [0.9429546  0.         0.         0.25506513 0.35750472 1.
  0.         0.         1.        ]
 [1.         0.         0.35229512 0.76413776 0.35751404 1.
  0.         0.         1.        ]
 [0.38648731 0.         0.         0.13021377 0.35752149 1.
  0.         0.         1.        ]
 [0.03858559 0.         0.         0.         0.35751488 1.
  0.         0.         1.        ]
 [1.         0.         0.48614235 0.67764265 0.35751329 1.
  0.         0.         1.        ]
 [1.         0.         0.71753685 0.95479506 0.35752791 1.
  0.         0.15102758 1.        ]
 [0.47452287 0.         0.         0.14879826 0.3575094  1.
  0.         0.         1.        ]
 [1.         0.         0.45974199 0.85900142 0.35752306 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.75
#####################         POISON         ###############################################

############################################################################################

comm_round: 6 | global_test_acc: 83.333% | global_f1: 0.9090909090909091 | global_precision: 0.8333333333333334
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.83      1.00      0.91        10

    accuracy                           0.83        12
   macro avg       0.42      0.50      0.45        12
weighted avg       0.69      0.83      0.76        12
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[0.         1.         1.         0.46417479 1.         0.
 1.         1.         0.         0.         0.2408948  1.
 0.29118611 1.         0.47449012 0.39104615 0.         1.
 0.         0.21835329 0.25115535 1.         1.         0.
 1.         1.         0.         1.         0.         1.
 1.         1.         0.         0.         1.        ]
wv_fg shape (35,)
[0.         0.         0.         1.         1.         0.
 0.         0.         0.27962123 0.38372482 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_mn shape (35,)
[0.         1.         1.         0.         1.         0.
 1.         1.         0.         0.         0.         1.
 0.         0.5293133  0.2476246  0.03817161 0.         1.
 0.         0.         0.         0.78154702 0.71295233 0.
 0.62309322 0.23116155 0.         0.36820576 0.         1.
 0.32312434 0.33602945 0.         0.         1.        ]
wv_ed shape (35,)
[0.13905529 1.         1.         0.04342084 1.         0.
 1.         1.         0.         0.         0.         1.
 0.         0.4855955  0.         0.06212479 0.         1.
 0.         0.         0.         0.53369551 0.44912414 0.
 0.57921478 0.21672489 0.         0.18947923 0.         0.90006226
 0.36110983 0.04105687 0.         0.         1.        ]
wv_lg shape (35, 1)
[[0.35761662]
 [0.35757426]
 [0.35754428]
 [0.3576133 ]
 [0.35762438]
 [0.35760571]
 [0.35755669]
 [0.35759439]
 [0.35758413]
 [0.3575745 ]
 [0.35751265]
 [0.35749994]
 [0.3575258 ]
 [0.35753206]
 [0.357504  ]
 [0.35752798]
 [0.35750763]
 [0.35751612]
 [0.35751836]
 [0.35750389]
 [0.3575087 ]
 [0.35751768]
 [0.3575175 ]
 [0.35752606]
 [0.35751563]
 [0.35751357]
 [0.35748393]
 [0.35750863]
 [0.35751049]
 [0.3575161 ]
 [0.35750427]
 [0.35750898]
 [0.35751342]
 [0.35750942]
 [0.35754987]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[1.         1.         0.69285867 1.         1.         0.61685336
 0.85500142 0.64172584 1.         1.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_std shape (35,)
[0.         0.85544701 1.         0.2089388  0.17983328 0.
 1.         1.         0.         0.         0.         1.
 0.         0.         0.         0.         0.         1.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.51332886
 0.         0.         0.         0.         0.89543829]
xy shape: (35, 9)
[[0.         0.         0.         0.13905529 0.35761662 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.35757426 1.
  1.         0.85544701 0.        ]
 [1.         0.         1.         1.         0.35754428 1.
  0.69285867 1.         0.        ]
 [0.46417479 1.         0.         0.04342084 0.3576133  1.
  1.         0.2089388  0.        ]
 [1.         1.         1.         1.         0.35762438 1.
  1.         0.17983328 0.        ]
 [0.         0.         0.         0.         0.35760571 1.
  0.61685336 0.         0.        ]
 [1.         0.         1.         1.         0.35755669 1.
  0.85500142 1.         0.        ]
 [1.         0.         1.         1.         0.35759439 1.
  0.64172584 1.         0.        ]
 [0.         0.27962123 0.         0.         0.35758413 1.
  1.         0.         0.        ]
 [0.         0.38372482 0.         0.         0.3575745  1.
  1.         0.         0.        ]
 [0.2408948  0.         0.         0.         0.35751265 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35749994 1.
  0.         1.         1.        ]
 [0.29118611 0.         0.         0.         0.3575258  1.
  0.         0.         1.        ]
 [1.         0.         0.5293133  0.4855955  0.35753206 1.
  0.         0.         1.        ]
 [0.47449012 0.         0.2476246  0.         0.357504   1.
  0.         0.         1.        ]
 [0.39104615 0.         0.03817161 0.06212479 0.35752798 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35750763 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35751612 1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.35751836 1.
  0.         0.         1.        ]
 [0.21835329 0.         0.         0.         0.35750389 1.
  0.         0.         1.        ]
 [0.25115535 0.         0.         0.         0.3575087  1.
  0.         0.         1.        ]
 [1.         0.         0.78154702 0.53369551 0.35751768 1.
  0.         0.         1.        ]
 [1.         0.         0.71295233 0.44912414 0.3575175  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35752606 1.
  0.         0.         1.        ]
 [1.         0.         0.62309322 0.57921478 0.35751563 1.
  0.         0.         1.        ]
 [1.         0.         0.23116155 0.21672489 0.35751357 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35748393 1.
  0.         0.         1.        ]
 [1.         0.         0.36820576 0.18947923 0.35750863 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35751049 1.
  0.         0.         1.        ]
 [1.         0.         1.         0.90006226 0.3575161  1.
  0.         0.51332886 1.        ]
 [1.         0.         0.32312434 0.36110983 0.35750427 1.
  0.         0.         1.        ]
 [1.         0.         0.33602945 0.04105687 0.35750898 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35751342 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35750942 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35754987 1.
  0.         0.89543829 1.        ]]

Best Training Poisoning Accuracy:
0.6875
#####################         POISON         ###############################################

############################################################################################

comm_round: 7 | global_test_acc: 75.000% | global_f1: 0.8571428571428571 | global_precision: 0.75
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.75      1.00      0.86         9

    accuracy                           0.75        12
   macro avg       0.38      0.50      0.43        12
weighted avg       0.56      0.75      0.64        12
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[0.72711632 0.46597842 1.         0.90543298 0.         0.96663278
 1.         1.         0.26962199 1.         0.85428364 1.
 1.         0.69553252 1.         1.         1.         1.
 0.65702094 0.85901353 1.         1.         1.         0.82930286
 1.         1.         0.         1.         1.         0.
 1.         0.64218534 0.84557023 0.         1.        ]
wv_fg shape (35,)
[1.         0.         0.         0.11257243 0.18346189 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_mn shape (35,)
[0.         0.04423318 1.         0.08796526 0.         0.13883722
 1.         1.         0.         0.2978158  0.25748001 0.82373627
 0.44867783 0.20177861 1.         0.76644375 1.         1.
 0.0899907  0.26965353 0.55870534 0.35371647 1.         0.22048907
 0.52652354 0.89262968 0.         0.91050761 1.         0.
 1.         0.0400313  0.29106306 0.         1.        ]
wv_ed shape (35,)
[0.         0.10838239 1.         0.30171406 0.         0.38690481
 1.         1.         0.         0.4692824  0.2352811  0.9600961
 0.29553076 0.08890096 1.         0.6095685  1.         1.
 0.07506577 0.05156183 0.5188036  0.35573976 1.         0.20376426
 0.64801535 0.86735256 0.         0.95941157 1.         0.
 1.         0.         0.34233699 0.         1.        ]
wv_lg shape (35, 1)
[[0.35761985]
 [0.35762066]
 [0.35759495]
 [0.35758293]
 [0.35762235]
 [0.35762301]
 [0.35762012]
 [0.35760381]
 [0.35762129]
 [0.35759693]
 [0.35757171]
 [0.35756551]
 [0.35755752]
 [0.35756369]
 [0.35755845]
 [0.35756446]
 [0.35755318]
 [0.3575657 ]
 [0.35755469]
 [0.35754513]
 [0.35755401]
 [0.35758792]
 [0.35757935]
 [0.35756354]
 [0.35756152]
 [0.35755498]
 [0.3575512 ]
 [0.35754674]
 [0.35759714]
 [0.3575677 ]
 [0.35757243]
 [0.35755203]
 [0.35757909]
 [0.35755091]
 [0.35757281]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[1.         0.37164891 0.43471335 1.         1.         1.
 0.14252711 0.11906156 1.         0.91276389 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_std shape (35,)
[0.06339358 0.         0.7089454  0.         0.         0.
 1.         1.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.00133948
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         1.         0.
 0.         0.         0.         0.         0.        ]
xy shape: (35, 9)
[[0.72711632 1.         0.         0.         0.35761985 1.
  1.         0.06339358 0.        ]
 [0.46597842 0.         0.04423318 0.10838239 0.35762066 1.
  0.37164891 0.         0.        ]
 [1.         0.         1.         1.         0.35759495 1.
  0.43471335 0.7089454  0.        ]
 [0.90543298 0.11257243 0.08796526 0.30171406 0.35758293 1.
  1.         0.         0.        ]
 [0.         0.18346189 0.         0.         0.35762235 1.
  1.         0.         0.        ]
 [0.96663278 0.         0.13883722 0.38690481 0.35762301 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.35762012 1.
  0.14252711 1.         0.        ]
 [1.         0.         1.         1.         0.35760381 1.
  0.11906156 1.         0.        ]
 [0.26962199 0.         0.         0.         0.35762129 1.
  1.         0.         0.        ]
 [1.         0.         0.2978158  0.4692824  0.35759693 1.
  0.91276389 0.         0.        ]
 [0.85428364 0.         0.25748001 0.2352811  0.35757171 1.
  0.         0.         1.        ]
 [1.         0.         0.82373627 0.9600961  0.35756551 1.
  0.         0.         1.        ]
 [1.         0.         0.44867783 0.29553076 0.35755752 1.
  0.         0.         1.        ]
 [0.69553252 0.         0.20177861 0.08890096 0.35756369 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35755845 1.
  0.         0.         1.        ]
 [1.         0.         0.76644375 0.6095685  0.35756446 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35755318 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.3575657  1.
  0.         0.00133948 1.        ]
 [0.65702094 0.         0.0899907  0.07506577 0.35755469 1.
  0.         0.         1.        ]
 [0.85901353 0.         0.26965353 0.05156183 0.35754513 1.
  0.         0.         1.        ]
 [1.         0.         0.55870534 0.5188036  0.35755401 1.
  0.         0.         1.        ]
 [1.         0.         0.35371647 0.35573976 0.35758792 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35757935 1.
  0.         0.         1.        ]
 [0.82930286 0.         0.22048907 0.20376426 0.35756354 1.
  0.         0.         1.        ]
 [1.         0.         0.52652354 0.64801535 0.35756152 1.
  0.         0.         1.        ]
 [1.         0.         0.89262968 0.86735256 0.35755498 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3575512  1.
  0.         0.         1.        ]
 [1.         0.         0.91050761 0.95941157 0.35754674 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35759714 1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.3575677  1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35757243 1.
  0.         0.         1.        ]
 [0.64218534 0.         0.0400313  0.         0.35755203 1.
  0.         0.         1.        ]
 [0.84557023 0.         0.29106306 0.34233699 0.35757909 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35755091 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35757281 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.3125
#####################         POISON         ###############################################

############################################################################################

comm_round: 8 | global_test_acc: 25.000% | global_f1: 0.0 | global_precision: 0.0
              precision    recall  f1-score   support

           0       0.25      1.00      0.40         3
           1       0.00      0.00      0.00         9

    accuracy                           0.25        12
   macro avg       0.12      0.50      0.20        12
weighted avg       0.06      0.25      0.10        12
poison scaling shape: (35, 1)
[[0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]]scaled_weight_list: Rows 35 cols 21
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[1.         1.         0.57220396 1.         1.         0.52378212
 0.19763334 0.11769739 0.         0.23473978 0.         0.17227341
 0.         1.         0.         1.         0.22684618 0.02295199
 0.         0.38276591 0.91840341 0.         0.971738   0.
 0.34920948 0.         1.         0.         1.         1.
 0.15058246 0.         0.898542   0.         0.        ]
wv_fg shape (35,)
[1.         1.         0.         0.         0.         0.
 0.         0.         0.24500298 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_mn shape (35,)
[1.         1.         0.41154666 1.         1.         0.3078809
 0.0925078  0.01052956 0.         0.         0.         0.
 0.         1.         0.         0.76369968 0.         0.
 0.         0.20565446 0.49220923 0.         0.29206327 0.
 0.         0.         0.48049001 0.         0.79103718 1.
 0.         0.         0.27572331 0.         0.        ]
wv_ed shape (35,)
[0.76250578 1.         0.25765682 1.         1.         0.39276297
 0.19457916 0.04110247 0.         0.         0.         0.
 0.         1.         0.         0.84720469 0.         0.
 0.         0.15910034 0.24693114 0.         0.17829147 0.
 0.         0.         0.62503232 0.         0.72308542 1.
 0.         0.         0.28794385 0.         0.        ]
wv_lg shape (35, 1)
[[0.35761849]
 [0.35761396]
 [0.35760533]
 [0.35755988]
 [0.35762488]
 [0.35760789]
 [0.35764598]
 [0.35759317]
 [0.35762861]
 [0.3576188 ]
 [0.3575699 ]
 [0.35755321]
 [0.35754548]
 [0.35756097]
 [0.35757294]
 [0.35755401]
 [0.35756036]
 [0.35753997]
 [0.35757134]
 [0.3575656 ]
 [0.35754859]
 [0.35755097]
 [0.35754691]
 [0.35756234]
 [0.35756124]
 [0.35757324]
 [0.35753878]
 [0.35757808]
 [0.35756817]
 [0.35758424]
 [0.35754299]
 [0.35756637]
 [0.35755789]
 [0.35756273]
 [0.35756851]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[0.74043271 0.50420342 1.         0.88562197 0.96976284 1.
 1.         1.         1.         1.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_std shape (35,)
[1.         1.         0.36133562 1.         0.68445913 0.
 0.         0.         0.         0.         0.         0.
 0.         0.56047946 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.55708499
 0.         0.         0.         0.         0.        ]
xy shape: (35, 9)
[[1.         1.         1.         0.76250578 0.35761849 1.
  0.74043271 1.         0.        ]
 [1.         1.         1.         1.         0.35761396 1.
  0.50420342 1.         0.        ]
 [0.57220396 0.         0.41154666 0.25765682 0.35760533 1.
  1.         0.36133562 0.        ]
 [1.         0.         1.         1.         0.35755988 1.
  0.88562197 1.         0.        ]
 [1.         0.         1.         1.         0.35762488 1.
  0.96976284 0.68445913 0.        ]
 [0.52378212 0.         0.3078809  0.39276297 0.35760789 1.
  1.         0.         0.        ]
 [0.19763334 0.         0.0925078  0.19457916 0.35764598 1.
  1.         0.         0.        ]
 [0.11769739 0.         0.01052956 0.04110247 0.35759317 1.
  1.         0.         0.        ]
 [0.         0.24500298 0.         0.         0.35762861 1.
  1.         0.         0.        ]
 [0.23473978 0.         0.         0.         0.3576188  1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.3575699  1.
  0.         0.         1.        ]
 [0.17227341 0.         0.         0.         0.35755321 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35754548 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35756097 1.
  0.         0.56047946 1.        ]
 [0.         0.         0.         0.         0.35757294 1.
  0.         0.         1.        ]
 [1.         0.         0.76369968 0.84720469 0.35755401 1.
  0.         0.         1.        ]
 [0.22684618 0.         0.         0.         0.35756036 1.
  0.         0.         1.        ]
 [0.02295199 0.         0.         0.         0.35753997 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35757134 1.
  0.         0.         1.        ]
 [0.38276591 0.         0.20565446 0.15910034 0.3575656  1.
  0.         0.         1.        ]
 [0.91840341 0.         0.49220923 0.24693114 0.35754859 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35755097 1.
  0.         0.         1.        ]
 [0.971738   0.         0.29206327 0.17829147 0.35754691 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35756234 1.
  0.         0.         1.        ]
 [0.34920948 0.         0.         0.         0.35756124 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35757324 1.
  0.         0.         1.        ]
 [1.         0.         0.48049001 0.62503232 0.35753878 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35757808 1.
  0.         0.         1.        ]
 [1.         0.         0.79103718 0.72308542 0.35756817 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35758424 1.
  0.         0.55708499 1.        ]
 [0.15058246 0.         0.         0.         0.35754299 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35756637 1.
  0.         0.         1.        ]
 [0.898542   0.         0.27572331 0.28794385 0.35755789 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35756273 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35756851 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.4375
#####################         POISON         ###############################################

############################################################################################

comm_round: 9 | global_test_acc: 66.667% | global_f1: 0.8 | global_precision: 0.6666666666666666
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         4
           1       0.67      1.00      0.80         8

    accuracy                           0.67        12
   macro avg       0.33      0.50      0.40        12
weighted avg       0.44      0.67      0.53        12
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[1.         1.         1.         0.17980667 1.         0.
 1.         1.         1.         0.4260927  0.41235087 1.
 1.         1.         0.01692459 1.         1.         0.4077291
 1.         1.         1.         1.         1.         0.07956354
 0.37925505 1.         1.         1.         0.10734748 1.
 0.         0.39290848 1.         0.93893752 1.        ]
wv_fg shape (35,)
[0.         1.         0.43487692 1.         0.         0.06285766
 0.43487692 0.         0.         0.06285766 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_mn shape (35,)
[1.         0.88407191 1.         0.         1.         0.
 1.         0.89512617 1.         0.         0.09504761 0.50289881
 0.82889982 0.22273953 0.         0.62545035 0.67503692 0.
 1.         0.80640638 1.         1.         1.         0.
 0.02388902 0.50266601 1.         0.79279423 0.         1.
 0.         0.08928465 1.         0.         0.52893363]
wv_ed shape (35,)
[1.         0.65962249 1.         0.08736903 1.         0.
 1.         1.         1.         0.         0.         0.45763519
 0.70585118 0.05333278 0.         0.31497474 0.71612956 0.02850465
 1.         0.77921753 1.         1.         1.         0.
 0.02541046 0.49089663 1.         0.56318104 0.         1.
 0.         0.         1.         0.         0.38252883]
wv_lg shape (35, 1)
[[0.35763301]
 [0.35764282]
 [0.35763973]
 [0.35760382]
 [0.35765482]
 [0.35765017]
 [0.35764224]
 [0.35763636]
 [0.35763225]
 [0.35764099]
 [0.3576012 ]
 [0.35759   ]
 [0.3575925 ]
 [0.35756873]
 [0.35758848]
 [0.35758344]
 [0.35761684]
 [0.35757157]
 [0.35758312]
 [0.35758483]
 [0.35757414]
 [0.35757514]
 [0.35759208]
 [0.35759514]
 [0.3575816 ]
 [0.35759319]
 [0.35759377]
 [0.35758667]
 [0.35759673]
 [0.35757021]
 [0.35758992]
 [0.35756779]
 [0.35759035]
 [0.35758483]
 [0.35757495]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[0.69679919 1.         0.27998267 1.         0.15494847 1.
 0.12308989 1.         0.38901843 1.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_std shape (35,)
[1.         1.         1.         0.         1.         0.
 1.         0.17486577 1.         0.87098263 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.08666959 1.         0.         0.
 0.         0.         0.         0.         0.         0.42972366
 0.         0.         1.         0.         0.        ]
xy shape: (35, 9)
[[1.         0.         1.         1.         0.35763301 1.
  0.69679919 1.         0.        ]
 [1.         1.         0.88407191 0.65962249 0.35764282 1.
  1.         1.         0.        ]
 [1.         0.43487692 1.         1.         0.35763973 1.
  0.27998267 1.         0.        ]
 [0.17980667 1.         0.         0.08736903 0.35760382 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.35765482 1.
  0.15494847 1.         0.        ]
 [0.         0.06285766 0.         0.         0.35765017 1.
  1.         0.         0.        ]
 [1.         0.43487692 1.         1.         0.35764224 1.
  0.12308989 1.         0.        ]
 [1.         0.         0.89512617 1.         0.35763636 1.
  1.         0.17486577 0.        ]
 [1.         0.         1.         1.         0.35763225 1.
  0.38901843 1.         0.        ]
 [0.4260927  0.06285766 0.         0.         0.35764099 1.
  1.         0.87098263 0.        ]
 [0.41235087 0.         0.09504761 0.         0.3576012  1.
  0.         0.         1.        ]
 [1.         0.         0.50289881 0.45763519 0.35759    1.
  0.         0.         1.        ]
 [1.         0.         0.82889982 0.70585118 0.3575925  1.
  0.         0.         1.        ]
 [1.         0.         0.22273953 0.05333278 0.35756873 1.
  0.         0.         1.        ]
 [0.01692459 0.         0.         0.         0.35758848 1.
  0.         0.         1.        ]
 [1.         0.         0.62545035 0.31497474 0.35758344 1.
  0.         0.         1.        ]
 [1.         0.         0.67503692 0.71612956 0.35761684 1.
  0.         0.         1.        ]
 [0.4077291  0.         0.         0.02850465 0.35757157 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35758312 1.
  0.         0.         1.        ]
 [1.         0.         0.80640638 0.77921753 0.35758483 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35757414 1.
  0.         0.08666959 1.        ]
 [1.         0.         1.         1.         0.35757514 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.35759208 1.
  0.         0.         1.        ]
 [0.07956354 0.         0.         0.         0.35759514 1.
  0.         0.         1.        ]
 [0.37925505 0.         0.02388902 0.02541046 0.3575816  1.
  0.         0.         1.        ]
 [1.         0.         0.50266601 0.49089663 0.35759319 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35759377 1.
  0.         0.         1.        ]
 [1.         0.         0.79279423 0.56318104 0.35758667 1.
  0.         0.         1.        ]
 [0.10734748 0.         0.         0.         0.35759673 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35757021 1.
  0.         0.42972366 1.        ]
 [0.         0.         0.         0.         0.35758992 1.
  0.         0.         1.        ]
 [0.39290848 0.         0.08928465 0.         0.35756779 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35759035 1.
  0.         1.         1.        ]
 [0.93893752 0.         0.         0.         0.35758483 1.
  0.         0.         1.        ]
 [1.         0.         0.52893363 0.38252883 0.35757495 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.8125
#####################         POISON         ###############################################

############################################################################################

comm_round: 10 | global_test_acc: 66.667% | global_f1: 0.8 | global_precision: 0.6666666666666666
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         4
           1       0.67      1.00      0.80         8

    accuracy                           0.67        12
   macro avg       0.33      0.50      0.40        12
weighted avg       0.44      0.67      0.53        12
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[1.         1.         1.         1.         1.         1.
 1.         1.         0.         1.         0.89035042 1.
 1.         1.         1.         1.         0.         1.
 0.95115526 1.         1.         1.         1.         1.
 0.51639371 1.         1.         1.         1.         1.
 1.         1.         1.         0.81762796 1.        ]
wv_fg shape (35,)
[0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
wv_mn shape (35,)
[1.         1.         1.         1.         1.         1.
 1.         1.         0.         1.         0.         0.
 0.82531599 0.         0.         0.         0.         0.
 0.         0.36234948 0.         0.         0.         0.16452832
 0.         0.         0.         0.         0.66967819 0.
 0.         0.07062743 0.74783974 0.         0.16714663]
wv_ed shape (35,)
[1.         1.         1.         1.         1.         1.
 1.         1.         0.         1.         0.         0.
 0.77863705 0.         0.         0.00406824 0.         0.
 0.         0.46750705 0.         0.         0.         0.15324369
 0.         0.         0.         0.         0.48122555 0.
 0.         0.         0.72663393 0.         0.19158239]
wv_lg shape (35, 1)
[[0.35765685]
 [0.35766271]
 [0.35766019]
 [0.35767089]
 [0.35765199]
 [0.35767513]
 [0.35766189]
 [0.35766577]
 [0.3576063 ]
 [0.35764966]
 [0.35759381]
 [0.35760961]
 [0.35759606]
 [0.35763592]
 [0.35761525]
 [0.35758996]
 [0.35760299]
 [0.35760869]
 [0.35760871]
 [0.35759681]
 [0.3576109 ]
 [0.35760432]
 [0.35760886]
 [0.35759744]
 [0.35759735]
 [0.35760185]
 [0.3575794 ]
 [0.35761249]
 [0.35761454]
 [0.35760374]
 [0.35758626]
 [0.35760287]
 [0.35757795]
 [0.35760608]
 [0.35760663]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[0.57404143 0.         0.08929664 0.71975009 0.04735228 0.53330735
 1.         0.55282646 1.         0.43914794 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_std shape (35,)
[1.         1.         0.52464491 0.24100057 0.10835967 0.94082231
 1.         1.         0.         0.20265635 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
xy shape: (35, 9)
[[1.         0.         1.         1.         0.35765685 1.
  0.57404143 1.         0.        ]
 [1.         0.         1.         1.         0.35766271 1.
  0.         1.         0.        ]
 [1.         0.         1.         1.         0.35766019 1.
  0.08929664 0.52464491 0.        ]
 [1.         0.         1.         1.         0.35767089 1.
  0.71975009 0.24100057 0.        ]
 [1.         0.         1.         1.         0.35765199 1.
  0.04735228 0.10835967 0.        ]
 [1.         0.         1.         1.         0.35767513 1.
  0.53330735 0.94082231 0.        ]
 [1.         0.         1.         1.         0.35766189 1.
  1.         1.         0.        ]
 [1.         0.         1.         1.         0.35766577 1.
  0.55282646 1.         0.        ]
 [0.         1.         0.         0.         0.3576063  1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.35764966 1.
  0.43914794 0.20265635 0.        ]
 [0.89035042 0.         0.         0.         0.35759381 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.35760961 1.
  0.         0.         1.        ]
 [1.         0.         0.82531599 0.77863705 0.35759606 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.35763592 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.35761525 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.00406824 0.35758996 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35760299 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.35760869 1.
  0.         0.         1.        ]
 [0.95115526 0.         0.         0.         0.35760871 1.
  0.         0.         1.        ]
 [1.         0.         0.36234948 0.46750705 0.35759681 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.3576109  1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.35760432 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.35760886 1.
  0.         0.         1.        ]
 [1.         0.         0.16452832 0.15324369 0.35759744 1.
  0.         0.         1.        ]
 [0.51639371 0.         0.         0.         0.35759735 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.35760185 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.3575794  1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.35761249 1.
  0.         0.         1.        ]
 [1.         0.         0.66967819 0.48122555 0.35761454 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.35760374 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.35758626 1.
  0.         0.         1.        ]
 [1.         0.         0.07062743 0.         0.35760287 1.
  0.         0.         1.        ]
 [1.         0.         0.74783974 0.72663393 0.35757795 1.
  0.         0.         1.        ]
 [0.81762796 0.         0.         0.         0.35760608 1.
  0.         0.         1.        ]
 [1.         0.         0.16714663 0.19158239 0.35760663 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.75
#####################         POISON         ###############################################

############################################################################################

comm_round: 11 | global_test_acc: 66.667% | global_f1: 0.8 | global_precision: 0.6666666666666666
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         4
           1       0.67      1.00      0.80         8

    accuracy                           0.67        12
   macro avg       0.33      0.50      0.40        12
weighted avg       0.44      0.67      0.53        12
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[1.         0.1755307  1.         1.         1.         1.
 0.         1.         1.         1.         0.         0.
 1.         0.00939022 0.         0.         0.73396768 1.
 0.         0.02211499 0.         0.         0.         0.
 1.         0.         0.98068849 0.         0.         0.
 0.         0.         0.         0.         0.94392409]
wv_fg shape (35,)
[0.         0.         0.         0.14316593 1.         1.
 0.         1.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.08566949
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_mn shape (35,)
[1.         0.         1.         1.         0.44687034 1.
 0.         0.40760537 1.         0.74183095 0.         0.
 1.         0.         0.         0.         0.21401887 1.
 0.         0.         0.         0.         0.         0.
 0.73352649 0.         0.53958193 0.         0.         0.
 0.         0.         0.         0.         0.64745085]
wv_ed shape (35,)
[1.         0.         1.         1.         0.276869   1.
 0.         0.08708573 1.         0.69882706 0.         0.
 1.         0.         0.         0.         0.22663259 1.
 0.         0.         0.         0.         0.         0.
 0.91764254 0.         0.42278998 0.         0.         0.
 0.         0.         0.         0.         0.54185175]
wv_lg shape (35, 1)
[[0.35765966]
 [0.35767249]
 [0.35769888]
 [0.35768835]
 [0.35770039]
 [0.35766268]
 [0.35767632]
 [0.35762727]
 [0.35768073]
 [0.35768733]
 [0.35765142]
 [0.35762704]
 [0.3576473 ]
 [0.35763143]
 [0.35761956]
 [0.35764891]
 [0.35761605]
 [0.35766003]
 [0.35765431]
 [0.35765152]
 [0.35763536]
 [0.35764363]
 [0.35765397]
 [0.35765368]
 [0.35765297]
 [0.35765336]
 [0.35766124]
 [0.35764316]
 [0.3576354 ]
 [0.35766097]
 [0.35764384]
 [0.35764416]
 [0.35765667]
 [0.35763545]
 [0.35764802]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[0.71645868 1.         0.6932117  0.49812995 1.         1.
 0.80897094 1.         0.50980468 1.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_std shape (35,)
[1.         0.3016462  1.         1.         1.         1.
 0.         1.         0.60541084 0.62429314 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
xy shape: (35, 9)
[[1.         0.         1.         1.         0.35765966 1.
  0.71645868 1.         0.        ]
 [0.1755307  0.         0.         0.         0.35767249 1.
  1.         0.3016462  0.        ]
 [1.         0.         1.         1.         0.35769888 1.
  0.6932117  1.         0.        ]
 [1.         0.14316593 1.         1.         0.35768835 1.
  0.49812995 1.         0.        ]
 [1.         1.         0.44687034 0.276869   0.35770039 1.
  1.         1.         0.        ]
 [1.         1.         1.         1.         0.35766268 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.35767632 1.
  0.80897094 0.         0.        ]
 [1.         1.         0.40760537 0.08708573 0.35762727 1.
  1.         1.         0.        ]
 [1.         0.         1.         1.         0.35768073 1.
  0.50980468 0.60541084 0.        ]
 [1.         0.         0.74183095 0.69882706 0.35768733 1.
  1.         0.62429314 0.        ]
 [0.         0.         0.         0.         0.35765142 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35762704 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.3576473  1.
  0.         0.         1.        ]
 [0.00939022 0.         0.         0.         0.35763143 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35761956 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35764891 1.
  0.         0.         1.        ]
 [0.73396768 0.         0.21401887 0.22663259 0.35761605 1.
  0.         0.         1.        ]
 [1.         0.08566949 1.         1.         0.35766003 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35765431 1.
  0.         0.         1.        ]
 [0.02211499 0.         0.         0.         0.35765152 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35763536 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35764363 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35765397 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35765368 1.
  0.         0.         1.        ]
 [1.         0.         0.73352649 0.91764254 0.35765297 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35765336 1.
  0.         0.         1.        ]
 [0.98068849 0.         0.53958193 0.42278998 0.35766124 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35764316 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3576354  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35766097 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35764384 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35764416 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35765667 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35763545 1.
  0.         0.         1.        ]
 [0.94392409 0.         0.64745085 0.54185175 0.35764802 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.6875
#####################         POISON         ###############################################

############################################################################################

comm_round: 12 | global_test_acc: 66.667% | global_f1: 0.8 | global_precision: 0.6666666666666666
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         4
           1       0.67      1.00      0.80         8

    accuracy                           0.67        12
   macro avg       0.33      0.50      0.40        12
weighted avg       0.44      0.67      0.53        12
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[0.         0.         1.         0.         1.         1.
 0.50703235 0.77673356 1.         0.         1.         0.81472945
 1.         1.         0.64779073 0.         0.44850733 1.
 1.         1.         0.         0.292198   1.         0.96014268
 1.         0.39945063 0.         1.         1.         0.94380284
 1.         0.3632069  1.         0.         0.49360708]
wv_fg shape (35,)
[1.         0.         0.         0.         0.         0.22383538
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_mn shape (35,)
[0.23082297 0.         0.88720044 0.         1.         1.
 0.53330062 0.76103272 1.         0.         1.         0.75077572
 1.         0.85014188 0.45331226 0.         0.34609405 1.
 0.88588201 1.         0.         0.0622927  1.         0.7681746
 1.         0.43537878 0.         1.         0.92856853 0.77843833
 1.         0.17158803 1.         0.         0.36208775]
wv_ed shape (35,)
[0.         0.         0.44038326 0.         1.         1.
 0.         0.01591988 0.91958545 0.         1.         1.
 1.         1.         0.70881499 0.         0.48534648 1.
 1.         1.         0.         0.         1.         0.70176579
 1.         0.23610678 0.         1.         0.90530901 0.76853823
 1.         0.28455677 1.         0.         0.38889841]
wv_lg shape (35, 1)
[[0.35774525]
 [0.35767126]
 [0.35766482]
 [0.3577005 ]
 [0.3576455 ]
 [0.35761096]
 [0.35769979]
 [0.35765323]
 [0.35764731]
 [0.35763465]
 [0.35760054]
 [0.35760716]
 [0.35759428]
 [0.35761932]
 [0.35759318]
 [0.35759978]
 [0.35761187]
 [0.35759726]
 [0.35762159]
 [0.35759637]
 [0.35762409]
 [0.35758922]
 [0.35761063]
 [0.35759584]
 [0.35758815]
 [0.35756902]
 [0.35759493]
 [0.35759594]
 [0.3575821 ]
 [0.35760319]
 [0.35759736]
 [0.35759947]
 [0.35759589]
 [0.35761614]
 [0.35762265]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
wv_std shape (35,)
[0.         0.         1.         0.2146639  1.         1.
 0.56996944 1.         1.         0.         0.76778513 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.73861113 0.         0.
 0.         0.         0.         0.         0.        ]
xy shape: (35, 9)
[[0.         1.         0.23082297 0.         0.35774525 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.35767126 1.
  1.         0.         0.        ]
 [1.         0.         0.88720044 0.44038326 0.35766482 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.3577005  1.
  1.         0.2146639  0.        ]
 [1.         0.         1.         1.         0.3576455  1.
  1.         1.         0.        ]
 [1.         0.22383538 1.         1.         0.35761096 1.
  1.         1.         0.        ]
 [0.50703235 0.         0.53330062 0.         0.35769979 1.
  1.         0.56996944 0.        ]
 [0.77673356 0.         0.76103272 0.01591988 0.35765323 1.
  1.         1.         0.        ]
 [1.         0.         1.         0.91958545 0.35764731 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.35763465 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.35760054 1.
  0.         0.76778513 1.        ]
 [0.81472945 0.         0.75077572 1.         0.35760716 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35759428 1.
  0.         0.         1.        ]
 [1.         0.         0.85014188 1.         0.35761932 1.
  0.         0.         1.        ]
 [0.64779073 0.         0.45331226 0.70881499 0.35759318 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35759978 1.
  0.         0.         1.        ]
 [0.44850733 0.         0.34609405 0.48534648 0.35761187 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35759726 1.
  0.         0.         1.        ]
 [1.         0.         0.88588201 1.         0.35762159 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35759637 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35762409 1.
  0.         0.         1.        ]
 [0.292198   0.         0.0622927  0.         0.35758922 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35761063 1.
  0.         0.         1.        ]
 [0.96014268 0.         0.7681746  0.70176579 0.35759584 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35758815 1.
  0.         0.         1.        ]
 [0.39945063 0.         0.43537878 0.23610678 0.35756902 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35759493 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35759594 1.
  0.         0.73861113 1.        ]
 [1.         0.         0.92856853 0.90530901 0.3575821  1.
  0.         0.         1.        ]
 [0.94380284 0.         0.77843833 0.76853823 0.35760319 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35759736 1.
  0.         0.         1.        ]
 [0.3632069  0.         0.17158803 0.28455677 0.35759947 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35759589 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35761614 1.
  0.         0.         1.        ]
 [0.49360708 0.         0.36208775 0.38889841 0.35762265 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.75
#####################         POISON         ###############################################

############################################################################################

comm_round: 13 | global_test_acc: 66.667% | global_f1: 0.8 | global_precision: 0.6666666666666666
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         4
           1       0.67      1.00      0.80         8

    accuracy                           0.67        12
   macro avg       0.33      0.50      0.40        12
weighted avg       0.44      0.67      0.53        12
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[1.         1.         1.         1.         1.         1.
 0.         0.22547457 1.         1.         0.         0.
 0.         0.17785976 0.         1.         0.79011466 0.
 0.20586183 0.24742473 0.08420198 0.         0.         0.
 0.         0.         0.91969721 0.         0.         0.2298579
 1.         0.         0.         0.         0.83561845]
wv_fg shape (35,)
[0.         0.         0.         0.40090324 0.         0.
 1.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_mn shape (35,)
[1.         0.10921701 0.5246635  1.         0.21361283 1.
 0.         0.         1.         1.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.10168492 0.         0.         0.         0.        ]
wv_ed shape (35,)
[1.         0.34844422 0.80539006 1.         0.39543574 1.
 0.         0.         1.         1.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.11861172 0.         0.         0.         0.        ]
wv_lg shape (35, 1)
[[0.3577551 ]
 [0.35770363]
 [0.35768572]
 [0.35769794]
 [0.35765563]
 [0.35773183]
 [0.35778571]
 [0.35766912]
 [0.35769741]
 [0.35766144]
 [0.35764049]
 [0.35764915]
 [0.35764214]
 [0.35764846]
 [0.35764998]
 [0.35766926]
 [0.35764702]
 [0.35762419]
 [0.35764056]
 [0.35762834]
 [0.35762118]
 [0.35764092]
 [0.35763387]
 [0.35762045]
 [0.35764949]
 [0.35763012]
 [0.35765065]
 [0.35763479]
 [0.35762786]
 [0.35764444]
 [0.35763905]
 [0.35762957]
 [0.35765026]
 [0.35763522]
 [0.357641  ]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[0.06041421 1.         0.42379364 0.17473862 1.         0.57036558
 1.         1.         0.         0.02325235 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_std shape (35,)
[1.         0.         0.         0.26079958 0.         1.
 0.         0.         1.         0.83002623 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
xy shape: (35, 9)
[[1.         0.         1.         1.         0.3577551  1.
  0.06041421 1.         0.        ]
 [1.         0.         0.10921701 0.34844422 0.35770363 1.
  1.         0.         0.        ]
 [1.         0.         0.5246635  0.80539006 0.35768572 1.
  0.42379364 0.         0.        ]
 [1.         0.40090324 1.         1.         0.35769794 1.
  0.17473862 0.26079958 0.        ]
 [1.         0.         0.21361283 0.39543574 0.35765563 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.35773183 1.
  0.57036558 1.         0.        ]
 [0.         1.         0.         0.         0.35778571 1.
  1.         0.         0.        ]
 [0.22547457 0.         0.         0.         0.35766912 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.35769741 1.
  0.         1.         0.        ]
 [1.         0.         1.         1.         0.35766144 1.
  0.02325235 0.83002623 0.        ]
 [0.         0.         0.         0.         0.35764049 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35764915 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35764214 1.
  0.         0.         1.        ]
 [0.17785976 0.         0.         0.         0.35764846 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35764998 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.35766926 1.
  0.         0.         1.        ]
 [0.79011466 0.         0.         0.         0.35764702 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35762419 1.
  0.         0.         1.        ]
 [0.20586183 0.         0.         0.         0.35764056 1.
  0.         0.         1.        ]
 [0.24742473 0.         0.         0.         0.35762834 1.
  0.         0.         1.        ]
 [0.08420198 0.         0.         0.         0.35762118 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35764092 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35763387 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35762045 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35764949 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35763012 1.
  0.         0.         1.        ]
 [0.91969721 0.         0.         0.         0.35765065 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35763479 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35762786 1.
  0.         0.         1.        ]
 [0.2298579  0.         0.         0.         0.35764444 1.
  0.         0.         1.        ]
 [1.         0.         0.10168492 0.11861172 0.35763905 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35762957 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35765026 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35763522 1.
  0.         0.         1.        ]
 [0.83561845 0.         0.         0.         0.357641   1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.625
#####################         POISON         ###############################################

############################################################################################

comm_round: 14 | global_test_acc: 83.333% | global_f1: 0.9090909090909091 | global_precision: 0.8333333333333334
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.83      1.00      0.91        10

    accuracy                           0.83        12
   macro avg       0.42      0.50      0.45        12
weighted avg       0.69      0.83      0.76        12
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[0.         1.         1.         1.         1.         1.
 1.         1.         1.         0.99929779 0.10611294 0.93089773
 0.8792275  0.61906802 0.44189538 1.         0.87855908 0.
 0.89641142 0.83212927 0.84344902 0.77512672 0.84907766 1.
 0.39683128 0.40375095 1.         0.79886365 0.60385922 1.
 1.         1.         0.9545396  1.         0.61989499]
wv_fg shape (35,)
[1.         0.         0.23288194 0.2932747  0.         0.
 0.         0.         0.23288194 1.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_mn shape (35,)
[0.         0.92016042 1.         0.33867526 1.         0.91068708
 0.42583539 1.         1.         0.29203579 0.         0.
 0.         0.         0.         0.19314475 0.         0.
 0.         0.         0.         0.         0.         0.81679481
 0.         0.         0.12509826 0.         0.         0.
 0.21132551 0.60747929 0.01069049 1.         0.        ]
wv_ed shape (35,)
[0.         0.84969079 1.         0.26546641 1.         1.
 0.31532399 1.         1.         0.53758133 0.         0.00559947
 0.         0.         0.         0.29722666 0.00545836 0.
 0.02296415 0.         0.00681177 0.         0.         0.82902897
 0.         0.         0.18153424 0.01785433 0.         0.
 0.11926567 0.56099182 0.05235336 1.         0.        ]
wv_lg shape (35, 1)
[[0.35774237]
 [0.3577085 ]
 [0.35773722]
 [0.35775118]
 [0.35772783]
 [0.35775208]
 [0.35772421]
 [0.35775863]
 [0.35775354]
 [0.35778827]
 [0.35769542]
 [0.35769607]
 [0.3577223 ]
 [0.35770995]
 [0.35769691]
 [0.35767949]
 [0.35768451]
 [0.35771378]
 [0.35770851]
 [0.35772107]
 [0.35770623]
 [0.35768874]
 [0.35769342]
 [0.35770437]
 [0.35769536]
 [0.35768776]
 [0.3577115 ]
 [0.35770139]
 [0.35769514]
 [0.35770967]
 [0.35769938]
 [0.35770855]
 [0.35771124]
 [0.35770023]
 [0.35769928]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[1.         1.         1.         0.46601212 0.116186   0.49329267
 0.91286894 0.11758055 0.77487282 0.8624419  0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_std shape (35,)
[0.         0.78472328 1.         0.         1.         0.
 0.20730174 1.         0.54353422 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
xy shape: (35, 9)
[[0.         1.         0.         0.         0.35774237 1.
  1.         0.         0.        ]
 [1.         0.         0.92016042 0.84969079 0.3577085  1.
  1.         0.78472328 0.        ]
 [1.         0.23288194 1.         1.         0.35773722 1.
  1.         1.         0.        ]
 [1.         0.2932747  0.33867526 0.26546641 0.35775118 1.
  0.46601212 0.         0.        ]
 [1.         0.         1.         1.         0.35772783 1.
  0.116186   1.         0.        ]
 [1.         0.         0.91068708 1.         0.35775208 1.
  0.49329267 0.         0.        ]
 [1.         0.         0.42583539 0.31532399 0.35772421 1.
  0.91286894 0.20730174 0.        ]
 [1.         0.         1.         1.         0.35775863 1.
  0.11758055 1.         0.        ]
 [1.         0.23288194 1.         1.         0.35775354 1.
  0.77487282 0.54353422 0.        ]
 [0.99929779 1.         0.29203579 0.53758133 0.35778827 1.
  0.8624419  0.         0.        ]
 [0.10611294 0.         0.         0.         0.35769542 1.
  0.         0.         1.        ]
 [0.93089773 0.         0.         0.00559947 0.35769607 1.
  0.         0.         1.        ]
 [0.8792275  0.         0.         0.         0.3577223  1.
  0.         0.         1.        ]
 [0.61906802 0.         0.         0.         0.35770995 1.
  0.         0.         1.        ]
 [0.44189538 0.         0.         0.         0.35769691 1.
  0.         0.         1.        ]
 [1.         0.         0.19314475 0.29722666 0.35767949 1.
  0.         0.         1.        ]
 [0.87855908 0.         0.         0.00545836 0.35768451 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35771378 1.
  0.         0.         1.        ]
 [0.89641142 0.         0.         0.02296415 0.35770851 1.
  0.         0.         1.        ]
 [0.83212927 0.         0.         0.         0.35772107 1.
  0.         0.         1.        ]
 [0.84344902 0.         0.         0.00681177 0.35770623 1.
  0.         0.         1.        ]
 [0.77512672 0.         0.         0.         0.35768874 1.
  0.         0.         1.        ]
 [0.84907766 0.         0.         0.         0.35769342 1.
  0.         0.         1.        ]
 [1.         0.         0.81679481 0.82902897 0.35770437 1.
  0.         0.         1.        ]
 [0.39683128 0.         0.         0.         0.35769536 1.
  0.         0.         1.        ]
 [0.40375095 0.         0.         0.         0.35768776 1.
  0.         0.         1.        ]
 [1.         0.         0.12509826 0.18153424 0.3577115  1.
  0.         0.         1.        ]
 [0.79886365 0.         0.         0.01785433 0.35770139 1.
  0.         0.         1.        ]
 [0.60385922 0.         0.         0.         0.35769514 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.35770967 1.
  0.         0.         1.        ]
 [1.         0.         0.21132551 0.11926567 0.35769938 1.
  0.         0.         1.        ]
 [1.         0.         0.60747929 0.56099182 0.35770855 1.
  0.         0.         1.        ]
 [0.9545396  0.         0.01069049 0.05235336 0.35771124 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35770023 1.
  0.         0.         1.        ]
 [0.61989499 0.         0.         0.         0.35769928 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.8125
#####################         POISON         ###############################################

############################################################################################

comm_round: 15 | global_test_acc: 58.333% | global_f1: 0.7368421052631579 | global_precision: 0.5833333333333334
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         5
           1       0.58      1.00      0.74         7

    accuracy                           0.58        12
   macro avg       0.29      0.50      0.37        12
weighted avg       0.34      0.58      0.43        12
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[1.         0.         1.         1.         1.         1.
 0.         1.         0.         0.         0.         0.68210744
 0.88483254 0.         0.         0.89910954 0.67373545 1.
 0.         0.85833972 0.77143158 0.         0.         0.
 0.         0.         1.         0.60420495 0.68491176 0.88044299
 0.         0.         0.         0.         0.        ]
wv_fg shape (35,)
[0.         0.         0.         0.04093143 0.         0.
 0.         1.         0.         0.69793586 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_mn shape (35,)
[0.36178613 0.         0.33083138 1.         1.         1.
 0.         1.         0.         0.         0.         0.
 0.19714254 0.         0.         0.36701022 0.         0.49249368
 0.         0.18359817 0.         0.         0.         0.
 0.         0.         1.         0.         0.         0.19550601
 0.         0.         0.         0.         0.        ]
wv_ed shape (35,)
[0.30587828 0.         0.53584138 1.         1.         1.
 0.         1.         0.         0.         0.         0.
 0.49520757 0.         0.         0.17094742 0.         0.68341337
 0.         0.24223278 0.24800981 0.         0.         0.
 0.         0.         1.         0.05644805 0.0335472  0.23140526
 0.         0.         0.         0.         0.        ]
wv_lg shape (35, 1)
[[0.35774458]
 [0.35775951]
 [0.35776975]
 [0.3577803 ]
 [0.3577559 ]
 [0.35777062]
 [0.3577659 ]
 [0.35777726]
 [0.35776108]
 [0.35778272]
 [0.35774471]
 [0.35772948]
 [0.35774519]
 [0.357722  ]
 [0.35774847]
 [0.35773597]
 [0.35773446]
 [0.35774283]
 [0.35775097]
 [0.35774122]
 [0.35773213]
 [0.35774559]
 [0.35773628]
 [0.35774776]
 [0.35773948]
 [0.35771955]
 [0.35775183]
 [0.3577376 ]
 [0.35774125]
 [0.35774558]
 [0.35772801]
 [0.35772515]
 [0.35774574]
 [0.3577338 ]
 [0.35774894]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
wv_std shape (35,)
[0.53600839 0.         0.39213702 0.87886865 1.         1.
 0.         1.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
xy shape: (35, 9)
[[1.         0.         0.36178613 0.30587828 0.35774458 1.
  1.         0.53600839 0.        ]
 [0.         0.         0.         0.         0.35775951 1.
  1.         0.         0.        ]
 [1.         0.         0.33083138 0.53584138 0.35776975 1.
  1.         0.39213702 0.        ]
 [1.         0.04093143 1.         1.         0.3577803  1.
  1.         0.87886865 0.        ]
 [1.         0.         1.         1.         0.3577559  1.
  1.         1.         0.        ]
 [1.         0.         1.         1.         0.35777062 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.3577659  1.
  1.         0.         0.        ]
 [1.         1.         1.         1.         0.35777726 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.35776108 1.
  1.         0.         0.        ]
 [0.         0.69793586 0.         0.         0.35778272 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.35774471 1.
  0.         0.         1.        ]
 [0.68210744 0.         0.         0.         0.35772948 1.
  0.         0.         1.        ]
 [0.88483254 0.         0.19714254 0.49520757 0.35774519 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.357722   1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35774847 1.
  0.         0.         1.        ]
 [0.89910954 0.         0.36701022 0.17094742 0.35773597 1.
  0.         0.         1.        ]
 [0.67373545 0.         0.         0.         0.35773446 1.
  0.         0.         1.        ]
 [1.         0.         0.49249368 0.68341337 0.35774283 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35775097 1.
  0.         0.         1.        ]
 [0.85833972 0.         0.18359817 0.24223278 0.35774122 1.
  0.         0.         1.        ]
 [0.77143158 0.         0.         0.24800981 0.35773213 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35774559 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35773628 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35774776 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35773948 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35771955 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35775183 1.
  0.         0.         1.        ]
 [0.60420495 0.         0.         0.05644805 0.3577376  1.
  0.         0.         1.        ]
 [0.68491176 0.         0.         0.0335472  0.35774125 1.
  0.         0.         1.        ]
 [0.88044299 0.         0.19550601 0.23140526 0.35774558 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35772801 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35772515 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35774574 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3577338  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35774894 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.75
#####################         POISON         ###############################################

############################################################################################

comm_round: 16 | global_test_acc: 75.000% | global_f1: 0.8571428571428571 | global_precision: 0.75
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.75      1.00      0.86         9

    accuracy                           0.75        12
   macro avg       0.38      0.50      0.43        12
weighted avg       0.56      0.75      0.64        12
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[1.         1.         0.         1.         1.         0.
 1.         0.23750314 0.         1.         1.         0.
 0.15783187 0.90939344 1.         1.         0.24074792 0.83478929
 1.         1.         1.         0.82741867 1.         0.18021867
 0.         1.         1.         0.93799827 1.         0.
 1.         0.         1.         1.         0.        ]
wv_fg shape (35,)
[0.         0.         0.22677373 0.         1.         0.
 0.22677373 1.         1.         1.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.49506385 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_mn shape (35,)
[1.         1.         0.         1.         1.         0.
 1.         0.09462822 0.         1.         0.81990796 0.
 0.         0.         0.39708052 1.         0.         0.
 0.60605424 0.60051202 1.         0.         1.         0.
 0.         1.         0.60399848 0.04957803 0.4184536  0.
 0.34599028 0.         0.8961149  0.43966683 0.        ]
wv_ed shape (35,)
[1.         1.         0.         1.         1.         0.15603652
 1.         0.         0.         1.         0.80796783 0.
 0.         0.         0.42870346 1.         0.         0.
 0.77759474 0.64653365 1.         0.         0.98335528 0.
 0.         1.         0.6940916  0.12543821 0.43066406 0.
 0.48443963 0.         0.85163394 0.47159813 0.        ]
wv_lg shape (35, 1)
[[0.35781522]
 [0.35778129]
 [0.35773859]
 [0.35776808]
 [0.35772958]
 [0.3577957 ]
 [0.3577542 ]
 [0.35773744]
 [0.35775751]
 [0.3577984 ]
 [0.35772699]
 [0.35771894]
 [0.35770761]
 [0.35772238]
 [0.35771071]
 [0.3577085 ]
 [0.35770586]
 [0.35772023]
 [0.35770241]
 [0.35771176]
 [0.35773331]
 [0.35772036]
 [0.35772558]
 [0.35769953]
 [0.35770047]
 [0.35769689]
 [0.35770801]
 [0.35769344]
 [0.35769104]
 [0.3577017 ]
 [0.35770356]
 [0.35770646]
 [0.35771685]
 [0.35768744]
 [0.35772312]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[1.         1.         0.74479443 0.56791486 0.65775347 1.
 0.66165398 1.         1.         1.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_std shape (35,)
[0.10799187 0.42849712 0.         1.         1.         0.
 1.         0.         0.         0.15612584 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.69257768 0.         0.07468539 0.
 0.         1.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
xy shape: (35, 9)
[[1.         0.         1.         1.         0.35781522 1.
  1.         0.10799187 0.        ]
 [1.         0.         1.         1.         0.35778129 1.
  1.         0.42849712 0.        ]
 [0.         0.22677373 0.         0.         0.35773859 1.
  0.74479443 0.         0.        ]
 [1.         0.         1.         1.         0.35776808 1.
  0.56791486 1.         0.        ]
 [1.         1.         1.         1.         0.35772958 1.
  0.65775347 1.         0.        ]
 [0.         0.         0.         0.15603652 0.3577957  1.
  1.         0.         0.        ]
 [1.         0.22677373 1.         1.         0.3577542  1.
  0.66165398 1.         0.        ]
 [0.23750314 1.         0.09462822 0.         0.35773744 1.
  1.         0.         0.        ]
 [0.         1.         0.         0.         0.35775751 1.
  1.         0.         0.        ]
 [1.         1.         1.         1.         0.3577984  1.
  1.         0.15612584 0.        ]
 [1.         0.         0.81990796 0.80796783 0.35772699 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35771894 1.
  0.         0.         1.        ]
 [0.15783187 0.         0.         0.         0.35770761 1.
  0.         0.         1.        ]
 [0.90939344 0.         0.         0.         0.35772238 1.
  0.         0.         1.        ]
 [1.         0.         0.39708052 0.42870346 0.35771071 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.3577085  1.
  0.         0.         1.        ]
 [0.24074792 0.         0.         0.         0.35770586 1.
  0.         0.         1.        ]
 [0.83478929 0.         0.         0.         0.35772023 1.
  0.         0.         1.        ]
 [1.         0.         0.60605424 0.77759474 0.35770241 1.
  0.         0.         1.        ]
 [1.         0.         0.60051202 0.64653365 0.35771176 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35773331 1.
  0.         0.69257768 1.        ]
 [0.82741867 0.         0.         0.         0.35772036 1.
  0.         0.         1.        ]
 [1.         0.         1.         0.98335528 0.35772558 1.
  0.         0.07468539 1.        ]
 [0.18021867 0.         0.         0.         0.35769953 1.
  0.         0.         1.        ]
 [0.         0.49506385 0.         0.         0.35770047 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35769689 1.
  0.         1.         1.        ]
 [1.         0.         0.60399848 0.6940916  0.35770801 1.
  0.         0.         1.        ]
 [0.93799827 0.         0.04957803 0.12543821 0.35769344 1.
  0.         0.         1.        ]
 [1.         0.         0.4184536  0.43066406 0.35769104 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3577017  1.
  0.         0.         1.        ]
 [1.         0.         0.34599028 0.48443963 0.35770356 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35770646 1.
  0.         0.         1.        ]
 [1.         0.         0.8961149  0.85163394 0.35771685 1.
  0.         0.         1.        ]
 [1.         0.         0.43966683 0.47159813 0.35768744 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35772312 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.6875
#####################         POISON         ###############################################

############################################################################################

comm_round: 17 | global_test_acc: 75.000% | global_f1: 0.8571428571428571 | global_precision: 0.75
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.75      1.00      0.86         9

    accuracy                           0.75        12
   macro avg       0.38      0.50      0.43        12
weighted avg       0.56      0.75      0.64        12
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients
y shape (35,)
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (35,)
[1.         1.         1.         0.         1.         0.39326837
 0.         1.         1.         1.         0.69620112 0.
 0.22480454 0.         0.31931893 0.72631693 0.7658056  0.
 1.         1.         0.         0.69537901 0.90905004 0.
 0.18524221 0.         0.         0.30719931 1.         0.
 0.03633501 0.         1.         0.         0.        ]
wv_fg shape (35,)
[0.         0.         0.         0.         0.00869366 0.
 1.         0.58051551 0.         1.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_mn shape (35,)
[0.87134932 1.         0.00740752 0.         0.88169735 0.
 0.         1.         1.         1.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.38318209 0.35250613 0.         0.         0.20654369 0.
 0.         0.         0.         0.         0.62528379 0.
 0.         0.         0.37478838 0.         0.        ]
wv_ed shape (35,)
[0.79468814 1.         0.29218513 0.         1.         0.
 0.         1.         1.         1.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.23756633 0.45539497 0.         0.         0.         0.
 0.         0.         0.         0.         0.65537579 0.
 0.         0.         0.21108938 0.         0.        ]
wv_lg shape (35, 1)
[[0.35779748]
 [0.35781526]
 [0.35781174]
 [0.357809  ]
 [0.35783019]
 [0.35779449]
 [0.35779619]
 [0.35779818]
 [0.35781727]
 [0.35783158]
 [0.35778934]
 [0.35777791]
 [0.3577721 ]
 [0.35777704]
 [0.35775005]
 [0.35776629]
 [0.35776251]
 [0.35779726]
 [0.35777   ]
 [0.35777036]
 [0.35778337]
 [0.35778344]
 [0.35775478]
 [0.35779494]
 [0.35777214]
 [0.35775762]
 [0.35778807]
 [0.35777119]
 [0.35777002]
 [0.35778406]
 [0.35776582]
 [0.35777104]
 [0.35779871]
 [0.35777087]
 [0.35776586]]
wv_jc shape (35,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
wv_ndT shape (35,)
[1.         1.         1.         1.         1.         1.
 1.         0.88161293 0.91522    1.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
wv_std shape (35,)
[0.15994186 0.59797982 0.         0.         0.01786373 0.
 0.         1.         0.82000056 1.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.        ]
xy shape: (35, 9)
[[1.         0.         0.87134932 0.79468814 0.35779748 1.
  1.         0.15994186 0.        ]
 [1.         0.         1.         1.         0.35781526 1.
  1.         0.59797982 0.        ]
 [1.         0.         0.00740752 0.29218513 0.35781174 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.357809   1.
  1.         0.         0.        ]
 [1.         0.00869366 0.88169735 1.         0.35783019 1.
  1.         0.01786373 0.        ]
 [0.39326837 0.         0.         0.         0.35779449 1.
  1.         0.         0.        ]
 [0.         1.         0.         0.         0.35779619 1.
  1.         0.         0.        ]
 [1.         0.58051551 1.         1.         0.35779818 1.
  0.88161293 1.         0.        ]
 [1.         0.         1.         1.         0.35781727 1.
  0.91522    0.82000056 0.        ]
 [1.         1.         1.         1.         0.35783158 1.
  1.         1.         0.        ]
 [0.69620112 0.         0.         0.         0.35778934 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35777791 1.
  0.         0.         1.        ]
 [0.22480454 0.         0.         0.         0.3577721  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35777704 1.
  0.         0.         1.        ]
 [0.31931893 0.         0.         0.         0.35775005 1.
  0.         0.         1.        ]
 [0.72631693 0.         0.         0.         0.35776629 1.
  0.         0.         1.        ]
 [0.7658056  0.         0.         0.         0.35776251 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35779726 1.
  0.         0.         1.        ]
 [1.         0.         0.38318209 0.23756633 0.35777    1.
  0.         0.         1.        ]
 [1.         0.         0.35250613 0.45539497 0.35777036 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35778337 1.
  0.         0.         1.        ]
 [0.69537901 0.         0.         0.         0.35778344 1.
  0.         0.         1.        ]
 [0.90905004 0.         0.20654369 0.         0.35775478 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35779494 1.
  0.         0.         1.        ]
 [0.18524221 0.         0.         0.         0.35777214 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35775762 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35778807 1.
  0.         0.         1.        ]
 [0.30719931 0.         0.         0.         0.35777119 1.
  0.         0.         1.        ]
 [1.         0.         0.62528379 0.65537579 0.35777002 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35778406 1.
  0.         0.         1.        ]
 [0.03633501 0.         0.         0.         0.35776582 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35777104 1.
  0.         0.         1.        ]
 [1.         0.         0.37478838 0.21108938 0.35779871 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35777087 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35776586 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.8125
#####################         POISON         ###############################################

############################################################################################

comm_round: 18 | global_test_acc: 50.000% | global_f1: 0.6666666666666666 | global_precision: 0.5
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         6
           1       0.50      1.00      0.67         6

    accuracy                           0.50        12
   macro avg       0.25      0.50      0.33        12
weighted avg       0.25      0.50      0.33        12
poison scaling shape: (35, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 35 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAdding node: 30 value: [1] to honest_clientsAdding node: 31 value: [1] to honest_clientsAdding node: 32 value: [1] to honest_clientsAdding node: 33 value: [1] to honest_clientsAdding node: 34 value: [1] to honest_clients

Best Training Poisoning Accuracy:
0.9342549443244934

Best Training Poisoning Accuracy:
0.9257354140281677

Best Training Poisoning Accuracy:
0.8952369093894958

Best Training Poisoning Accuracy:
0.912739098072052

Best Training Poisoning Accuracy:
0.898737370967865

Best Training Poisoning Accuracy:
0.9458682537078857