
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         1.         0.         1.         0.78595925 0.
 0.         1.         1.         1.         0.14574432 0.56702109
 0.         1.         0.         1.         0.         0.20615755
 0.         0.37803358 0.84401916 0.         0.7116359  0.5391498
 0.2183555  0.40029442]
wv_ed shape (26,)
[0.         1.         0.         1.         0.99672519 0.
 0.         1.         1.         1.         0.591532   0.80294856
 0.         1.         0.         1.         0.         0.02844075
 0.         0.52562051 0.77162671 0.         0.72051761 1.
 0.37929619 0.20612275]
wv_lg shape (26, 1)
[[0.29600018]
 [0.22671743]
 [0.22699693]
 [0.22672144]
 [0.22697287]
 [0.22727059]
 [0.22752179]
 [0.2271522 ]
 [0.22673069]
 [0.22681305]
 [0.22676196]
 [0.2275134 ]
 [0.22687179]
 [0.22748119]
 [0.22694942]
 [0.22701963]
 [0.22696895]
 [0.226674  ]
 [0.22625665]
 [0.22701514]
 [0.22666542]
 [0.22670745]
 [0.22689874]
 [0.22694542]
 [0.2265137 ]
 [0.22695944]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_std shape (26,)
[0.         1.         0.         1.         1.         0.76955919
 1.         0.73195206 0.89473842 0.         0.         1.
 1.         1.         0.396844   1.         0.         1.
 0.         1.         1.         0.3083606  0.26114539 1.
 0.32029559 1.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.29600018 1.
  0.         0.         0.        ]
 [1.         0.         1.         1.         0.22671743 1.
  1.         1.         1.        ]
 [1.         0.         0.         0.         0.22699693 1.
  1.         0.         1.        ]
 [1.         0.         1.         1.         0.22672144 1.
  1.         1.         1.        ]
 [1.         0.         0.78595925 0.99672519 0.22697287 1.
  1.         1.         1.        ]
 [1.         0.         0.         0.         0.22727059 1.
  1.         0.76955919 1.        ]
 [1.         0.         0.         0.         0.22752179 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.2271522  1.
  1.         0.73195206 1.        ]
 [1.         0.         1.         1.         0.22673069 1.
  1.         0.89473842 1.        ]
 [1.         0.         1.         1.         0.22681305 1.
  1.         0.         1.        ]
 [1.         0.         0.14574432 0.591532   0.22676196 1.
  1.         0.         1.        ]
 [1.         0.         0.56702109 0.80294856 0.2275134  1.
  1.         1.         1.        ]
 [1.         0.         0.         0.         0.22687179 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.22748119 1.
  1.         1.         1.        ]
 [1.         0.         0.         0.         0.22694942 1.
  1.         0.396844   1.        ]
 [1.         0.         1.         1.         0.22701963 1.
  1.         1.         1.        ]
 [1.         0.         0.         0.         0.22696895 1.
  1.         0.         1.        ]
 [1.         0.         0.20615755 0.02844075 0.226674   1.
  1.         1.         1.        ]
 [0.         0.         0.         0.         0.22625665 1.
  1.         0.         1.        ]
 [1.         0.         0.37803358 0.52562051 0.22701514 1.
  1.         1.         1.        ]
 [1.         0.         0.84401916 0.77162671 0.22666542 1.
  1.         1.         1.        ]
 [1.         0.         0.         0.         0.22670745 1.
  1.         0.3083606  1.        ]
 [1.         0.         0.7116359  0.72051761 0.22689874 1.
  1.         0.26114539 1.        ]
 [1.         0.         0.5391498  1.         0.22694542 1.
  1.         1.         1.        ]
 [1.         0.         0.2183555  0.37929619 0.2265137  1.
  1.         0.32029559 1.        ]
 [1.         0.         0.40029442 0.20612275 0.22695944 1.
  1.         1.         1.        ]]

Best Training Poisoning Accuracy:
1.0
#####################         POISON         ###############################################

############################################################################################

comm_round: 0 | global_test_acc: 87.500% | global_f1: 0.9333333333333333 | global_precision: 0.875
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.88      1.00      0.93         7

    accuracy                           0.88         8
   macro avg       0.44      0.50      0.47         8
weighted avg       0.77      0.88      0.82         8

Accuracy per class:
[[7 0]
 [1 0]]
[1. 0.]
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         1.         0.         1.         0.79338965 1.
 1.         1.         1.         0.08429429 1.         1.
 1.         0.54055543 1.         0.19883074 1.         1.
 0.45192359 0.         0.68343253 0.         1.         0.
 0.         1.        ]
wv_ed shape (26,)
[0.         1.         0.         1.         0.62453824 0.84256467
 1.         1.         1.         0.24491693 1.         1.
 1.         0.77257976 1.         0.         1.         1.
 0.29428804 0.         1.         0.         1.         0.
 0.         1.        ]
wv_lg shape (26, 1)
[[0.2978217 ]
 [0.24046634]
 [0.24033908]
 [0.24031197]
 [0.24001545]
 [0.24027904]
 [0.24068763]
 [0.24059199]
 [0.24006057]
 [0.24042846]
 [0.24051441]
 [0.24059955]
 [0.24041048]
 [0.24063932]
 [0.24076922]
 [0.23960602]
 [0.23972458]
 [0.24001701]
 [0.24025832]
 [0.24006956]
 [0.24035168]
 [0.24069603]
 [0.24055121]
 [0.2405323 ]
 [0.24045644]
 [0.23972337]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_std shape (26,)
[0.         0.         0.         1.         0.         0.04140293
 1.         1.         0.45845368 0.         1.         1.
 0.         0.         1.         0.         0.06998899 0.61236512
 0.         0.         0.18623593 0.         0.91128875 0.
 0.         0.26664408]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.2978217  1.
  0.         0.         0.        ]
 [1.         0.         1.         1.         0.24046634 1.
  1.         0.         1.        ]
 [1.         0.         0.         0.         0.24033908 1.
  1.         0.         1.        ]
 [1.         0.         1.         1.         0.24031197 1.
  1.         1.         1.        ]
 [1.         0.         0.79338965 0.62453824 0.24001545 1.
  1.         0.         1.        ]
 [1.         0.         1.         0.84256467 0.24027904 1.
  1.         0.04140293 1.        ]
 [1.         0.         1.         1.         0.24068763 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.24059199 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.24006057 1.
  1.         0.45845368 1.        ]
 [1.         0.         0.08429429 0.24491693 0.24042846 1.
  1.         0.         1.        ]
 [1.         0.         1.         1.         0.24051441 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.24059955 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.24041048 1.
  1.         0.         1.        ]
 [1.         0.         0.54055543 0.77257976 0.24063932 1.
  1.         0.         1.        ]
 [1.         0.         1.         1.         0.24076922 1.
  1.         1.         1.        ]
 [1.         0.         0.19883074 0.         0.23960602 1.
  1.         0.         1.        ]
 [1.         0.         1.         1.         0.23972458 1.
  1.         0.06998899 1.        ]
 [1.         0.         1.         1.         0.24001701 1.
  1.         0.61236512 1.        ]
 [1.         0.         0.45192359 0.29428804 0.24025832 1.
  1.         0.         1.        ]
 [0.         0.         0.         0.         0.24006956 1.
  1.         0.         1.        ]
 [1.         0.         0.68343253 1.         0.24035168 1.
  1.         0.18623593 1.        ]
 [1.         0.         0.         0.         0.24069603 1.
  1.         0.         1.        ]
 [1.         0.         1.         1.         0.24055121 1.
  1.         0.91128875 1.        ]
 [1.         0.         0.         0.         0.2405323  1.
  1.         0.         1.        ]
 [1.         0.         0.         0.         0.24045644 1.
  1.         0.         1.        ]
 [1.         0.         1.         1.         0.23972337 1.
  1.         0.26664408 1.        ]]

Best Training Poisoning Accuracy:
0.9166666865348816
#####################         POISON         ###############################################

############################################################################################

comm_round: 0 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8

Accuracy per class:
[[8 0]
 [0 0]]
[ 1. nan]
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.43358721 1.         0.         0.         0.
 0.79382164 0.40440989 0.0594953  0.         0.         0.
 1.         0.11606844 0.02447466 0.         0.         0.62471989
 1.         0.85403945 0.         0.55133738 1.         0.
 0.48108409 0.20496229]
wv_ed shape (26,)
[0.         0.75074409 1.         0.         0.         0.
 1.         0.44142863 0.19905546 0.         0.         0.
 1.         0.65086285 0.06821008 0.         0.         0.93271758
 1.         0.85709709 0.27500746 0.85955454 1.         0.37165678
 0.79025376 0.39698806]
wv_lg shape (26, 1)
[[0.30170988]
 [0.24936815]
 [0.24943669]
 [0.24915344]
 [0.24941504]
 [0.24970541]
 [0.24954329]
 [0.24960789]
 [0.24972527]
 [0.2496092 ]
 [0.24951633]
 [0.24959271]
 [0.24962269]
 [0.24889531]
 [0.24940703]
 [0.24917193]
 [0.24976076]
 [0.24982587]
 [0.24934863]
 [0.2500949 ]
 [0.24988342]
 [0.24926948]
 [0.24996878]
 [0.24972324]
 [0.24880475]
 [0.24954661]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[0.         0.8090721  0.42684257 1.         1.         0.71867986
 0.82745546 0.41391013 1.         1.         0.62243674 0.74567326
 0.26212553 0.4278703  1.         1.         1.         0.87022653
 0.58315053 1.         1.         0.20444692 1.         0.77104255
 0.27391956 1.        ]
wv_std shape (26,)
[0.         0.         0.89961372 0.         0.22062957 0.
 0.03115566 0.         0.         0.         0.         0.35894008
 1.         0.         0.29954802 0.16457015 0.21437893 0.25559777
 1.         1.         0.         0.         1.         0.
 0.         0.85777952]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.30170988 1.
  0.         0.         0.        ]
 [1.         0.         0.43358721 0.75074409 0.24936815 1.
  0.8090721  0.         1.        ]
 [1.         0.         1.         1.         0.24943669 1.
  0.42684257 0.89961372 1.        ]
 [1.         0.         0.         0.         0.24915344 1.
  1.         0.         1.        ]
 [1.         0.         0.         0.         0.24941504 1.
  1.         0.22062957 1.        ]
 [1.         0.         0.         0.         0.24970541 1.
  0.71867986 0.         1.        ]
 [1.         0.         0.79382164 1.         0.24954329 1.
  0.82745546 0.03115566 1.        ]
 [1.         0.         0.40440989 0.44142863 0.24960789 1.
  0.41391013 0.         1.        ]
 [1.         0.         0.0594953  0.19905546 0.24972527 1.
  1.         0.         1.        ]
 [0.         0.         0.         0.         0.2496092  1.
  1.         0.         1.        ]
 [1.         0.         0.         0.         0.24951633 1.
  0.62243674 0.         1.        ]
 [1.         0.         0.         0.         0.24959271 1.
  0.74567326 0.35894008 1.        ]
 [1.         0.         1.         1.         0.24962269 1.
  0.26212553 1.         1.        ]
 [1.         0.         0.11606844 0.65086285 0.24889531 1.
  0.4278703  0.         1.        ]
 [1.         0.         0.02447466 0.06821008 0.24940703 1.
  1.         0.29954802 1.        ]
 [1.         0.         0.         0.         0.24917193 1.
  1.         0.16457015 1.        ]
 [1.         0.         0.         0.         0.24976076 1.
  1.         0.21437893 1.        ]
 [1.         0.         0.62471989 0.93271758 0.24982587 1.
  0.87022653 0.25559777 1.        ]
 [1.         0.         1.         1.         0.24934863 1.
  0.58315053 1.         1.        ]
 [1.         0.         0.85403945 0.85709709 0.2500949  1.
  1.         1.         1.        ]
 [1.         0.         0.         0.27500746 0.24988342 1.
  1.         0.         1.        ]
 [1.         0.         0.55133738 0.85955454 0.24926948 1.
  0.20444692 0.         1.        ]
 [1.         0.         1.         1.         0.24996878 1.
  1.         1.         1.        ]
 [1.         0.         0.         0.37165678 0.24972324 1.
  0.77104255 0.         1.        ]
 [1.         0.         0.48108409 0.79025376 0.24880475 1.
  0.27391956 0.         1.        ]
 [1.         0.         0.20496229 0.39698806 0.24954661 1.
  1.         0.85777952 1.        ]]

Best Training Poisoning Accuracy:
0.9166666865348816
#####################         POISON         ###############################################

############################################################################################

comm_round: 1 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8

Accuracy per class:
[[8 0]
 [0 0]]
[ 1. nan]
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.         0.44985128 0.         1.         1.
 0.56212041 0.23144858 0.         0.         0.93831022 1.
 0.25441979 0.         0.         0.         1.         0.
 0.52582678 0.         0.         0.         0.         0.17914341
 0.         0.14726961]
wv_ed shape (26,)
[0.         0.         0.7272307  0.         1.         1.
 0.48189354 0.16369974 0.         0.02230035 0.7282965  0.93494738
 0.19868429 0.         0.         0.         1.         0.
 0.64128286 0.         0.         0.         0.         0.15608705
 0.         0.        ]
wv_lg shape (26, 1)
[[0.30413064]
 [0.25812013]
 [0.25814675]
 [0.258407  ]
 [0.25863579]
 [0.2575912 ]
 [0.25850853]
 [0.257892  ]
 [0.25816086]
 [0.25812416]
 [0.25780941]
 [0.2583597 ]
 [0.25881996]
 [0.25851681]
 [0.25805143]
 [0.25806652]
 [0.25822144]
 [0.25756168]
 [0.25828816]
 [0.25821493]
 [0.25724632]
 [0.25790868]
 [0.25797601]
 [0.25792247]
 [0.25776093]
 [0.25791773]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.05608639 0.         0.36933372 1.         1.
 1.         0.54715728 0.         0.         0.45292386 1.
 0.59119391 0.49565644 0.63556231 0.         1.         0.
 0.         0.         0.         0.         0.         0.4695275
 0.         0.13321452]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.30413064 1.
  1.         0.         0.        ]
 [1.         0.         0.         0.         0.25812013 1.
  0.         0.05608639 1.        ]
 [1.         0.         0.44985128 0.7272307  0.25814675 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.258407   1.
  0.         0.36933372 1.        ]
 [1.         0.         1.         1.         0.25863579 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.2575912  1.
  0.         1.         1.        ]
 [1.         0.         0.56212041 0.48189354 0.25850853 1.
  0.         1.         1.        ]
 [1.         0.         0.23144858 0.16369974 0.257892   1.
  0.         0.54715728 1.        ]
 [1.         0.         0.         0.         0.25816086 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.02230035 0.25812416 1.
  0.         0.         1.        ]
 [1.         0.         0.93831022 0.7282965  0.25780941 1.
  0.         0.45292386 1.        ]
 [1.         0.         1.         0.93494738 0.2583597  1.
  0.         1.         1.        ]
 [1.         0.         0.25441979 0.19868429 0.25881996 1.
  0.         0.59119391 1.        ]
 [1.         0.         0.         0.         0.25851681 1.
  0.         0.49565644 1.        ]
 [1.         0.         0.         0.         0.25805143 1.
  0.         0.63556231 1.        ]
 [1.         0.         0.         0.         0.25806652 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.25822144 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.25756168 1.
  0.         0.         1.        ]
 [1.         0.         0.52582678 0.64128286 0.25828816 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.25821493 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.25724632 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.25790868 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.25797601 1.
  0.         0.         1.        ]
 [1.         0.         0.17914341 0.15608705 0.25792247 1.
  0.         0.4695275  1.        ]
 [1.         0.         0.         0.         0.25776093 1.
  0.         0.         1.        ]
 [1.         0.         0.14726961 0.         0.25791773 1.
  0.         0.13321452 1.        ]]

Best Training Poisoning Accuracy:
1.0
#####################         POISON         ###############################################

############################################################################################

comm_round: 2 | global_test_acc: 87.500% | global_f1: 0.9333333333333333 | global_precision: 0.875
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.88      1.00      0.93         7

    accuracy                           0.88         8
   macro avg       0.44      0.50      0.47         8
weighted avg       0.77      0.88      0.82         8

Accuracy per class:
[[7 0]
 [1 0]]
[1. 0.]
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.         0.22368118 0.62800386 0.         0.
 0.         0.07370923 1.         0.         0.46993924 0.
 0.         0.27159018 1.         1.         0.         0.
 1.         0.73834326 0.         0.97264894 0.         1.
 0.33584494 0.        ]
wv_ed shape (26,)
[0.         0.         0.24230644 0.33581201 0.         0.
 0.         0.03834691 1.         0.         0.49735907 0.
 0.         0.171525   1.         1.         0.         0.
 0.73060125 0.40672804 0.         0.66514618 0.         1.
 0.1205473  0.        ]
wv_lg shape (26, 1)
[[0.30636353]
 [0.26510351]
 [0.26485412]
 [0.2651322 ]
 [0.26578522]
 [0.26496944]
 [0.26530984]
 [0.2654526 ]
 [0.26507515]
 [0.26522529]
 [0.26506848]
 [0.26499461]
 [0.26573584]
 [0.26536132]
 [0.26575004]
 [0.26587682]
 [0.26521837]
 [0.26543356]
 [0.26549704]
 [0.26518233]
 [0.26550773]
 [0.26539951]
 [0.26577178]
 [0.26538463]
 [0.26536864]
 [0.26602395]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.         0.54982058 0.18626233 0.27471302 0.
 0.         0.65864359 0.726404   0.58290415 0.16703667 0.
 1.         0.         1.         1.         0.         0.06265807
 1.         0.09789794 0.         0.14707097 1.         0.9980426
 0.12910928 0.99127178]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.30636353 1.
  1.         0.         0.        ]
 [1.         0.         0.         0.         0.26510351 1.
  0.         0.         1.        ]
 [1.         0.         0.22368118 0.24230644 0.26485412 1.
  0.         0.54982058 1.        ]
 [1.         0.         0.62800386 0.33581201 0.2651322  1.
  0.         0.18626233 1.        ]
 [1.         0.         0.         0.         0.26578522 1.
  0.         0.27471302 1.        ]
 [1.         0.         0.         0.         0.26496944 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.26530984 1.
  0.         0.         1.        ]
 [1.         0.         0.07370923 0.03834691 0.2654526  1.
  0.         0.65864359 1.        ]
 [1.         0.         1.         1.         0.26507515 1.
  0.         0.726404   1.        ]
 [1.         0.         0.         0.         0.26522529 1.
  0.         0.58290415 1.        ]
 [1.         0.         0.46993924 0.49735907 0.26506848 1.
  0.         0.16703667 1.        ]
 [1.         0.         0.         0.         0.26499461 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.26573584 1.
  0.         1.         1.        ]
 [1.         0.         0.27159018 0.171525   0.26536132 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.26575004 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.26587682 1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.26521837 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.26543356 1.
  0.         0.06265807 1.        ]
 [1.         0.         1.         0.73060125 0.26549704 1.
  0.         1.         1.        ]
 [1.         0.         0.73834326 0.40672804 0.26518233 1.
  0.         0.09789794 1.        ]
 [1.         0.         0.         0.         0.26550773 1.
  0.         0.         1.        ]
 [1.         0.         0.97264894 0.66514618 0.26539951 1.
  0.         0.14707097 1.        ]
 [1.         0.         0.         0.         0.26577178 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.26538463 1.
  0.         0.9980426  1.        ]
 [1.         0.         0.33584494 0.1205473  0.26536864 1.
  0.         0.12910928 1.        ]
 [1.         0.         0.         0.         0.26602395 1.
  0.         0.99127178 1.        ]]

Best Training Poisoning Accuracy:
1.0
#####################         POISON         ###############################################

############################################################################################

comm_round: 3 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8

Accuracy per class:
[[8 0]
 [0 0]]
[ 1. nan]
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         1.         0.         0.         0.         1.
 1.         0.         1.         1.         1.         0.42184039
 0.         0.         0.53982341 1.         0.         0.
 1.         1.         0.28995357 1.         1.         0.
 1.         0.07718092]
wv_ed shape (26,)
[0.         1.         0.         0.         0.         1.
 1.         0.         1.         1.         1.         0.36416359
 0.         0.         0.61573855 1.         0.         0.
 1.         1.         0.11958141 1.         1.         0.
 1.         0.        ]
wv_lg shape (26, 1)
[[0.30879201]
 [0.27195673]
 [0.27099173]
 [0.27122033]
 [0.27104896]
 [0.27142203]
 [0.27174138]
 [0.27143784]
 [0.2716095 ]
 [0.27121172]
 [0.2714277 ]
 [0.2712083 ]
 [0.27138554]
 [0.27133451]
 [0.27160326]
 [0.27110696]
 [0.27107949]
 [0.27109566]
 [0.27113038]
 [0.271362  ]
 [0.27101997]
 [0.27146455]
 [0.27152381]
 [0.27097473]
 [0.27134513]
 [0.27145496]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         1.         0.         0.         0.22119249 1.
 1.         0.00355447 1.         1.         1.         0.39655924
 0.         0.29743481 0.         0.06437795 0.         0.
 0.77489591 1.         0.2353946  0.72113957 1.         0.
 0.99005703 0.0984176 ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.30879201 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.27195673 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.27099173 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.27122033 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.27104896 1.
  0.         0.22119249 1.        ]
 [1.         0.         1.         1.         0.27142203 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27174138 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.27143784 1.
  0.         0.00355447 1.        ]
 [1.         0.         1.         1.         0.2716095  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27121172 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.2714277  1.
  0.         1.         1.        ]
 [1.         0.         0.42184039 0.36416359 0.2712083  1.
  0.         0.39655924 1.        ]
 [1.         0.         0.         0.         0.27138554 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.27133451 1.
  0.         0.29743481 1.        ]
 [1.         0.         0.53982341 0.61573855 0.27160326 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.27110696 1.
  0.         0.06437795 1.        ]
 [1.         0.         0.         0.         0.27107949 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.27109566 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.27113038 1.
  0.         0.77489591 1.        ]
 [1.         0.         1.         1.         0.271362   1.
  0.         1.         1.        ]
 [1.         0.         0.28995357 0.11958141 0.27101997 1.
  0.         0.2353946  1.        ]
 [1.         0.         1.         1.         0.27146455 1.
  0.         0.72113957 1.        ]
 [1.         0.         1.         1.         0.27152381 1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.27097473 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.27134513 1.
  0.         0.99005703 1.        ]
 [1.         0.         0.07718092 0.         0.27145496 1.
  0.         0.0984176  1.        ]]

Best Training Poisoning Accuracy:
1.0
#####################         POISON         ###############################################

############################################################################################

comm_round: 4 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8

Accuracy per class:
[[8 0]
 [0 0]]
[ 1. nan]
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.         0.66053357 1.         1.         1.
 0.46642962 1.         1.         0.16171416 0.         0.96170275
 0.         1.         0.         1.         0.         1.
 0.49112157 0.06552238 1.         0.68181432 1.         0.99958615
 0.         0.        ]
wv_ed shape (26,)
[0.         0.         0.59240372 1.         1.         1.
 0.57997665 1.         1.         0.10062303 0.         1.
 0.         1.         0.         1.         0.         1.
 0.50520185 0.08884664 1.         0.66810791 1.         0.99499099
 0.         0.        ]
wv_lg shape (26, 1)
[[0.31032079]
 [0.27699718]
 [0.27743274]
 [0.27729744]
 [0.27775369]
 [0.27768899]
 [0.2776071 ]
 [0.27733941]
 [0.27766132]
 [0.27685445]
 [0.27675516]
 [0.27674997]
 [0.2770999 ]
 [0.27742588]
 [0.27695012]
 [0.27739844]
 [0.27698324]
 [0.27723259]
 [0.27745594]
 [0.27760117]
 [0.27739123]
 [0.2769938 ]
 [0.27722154]
 [0.27746617]
 [0.27736581]
 [0.27695782]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.         0.50493239 1.         1.         1.
 0.28690274 0.90147866 1.         0.715148   0.         0.70152567
 0.         1.         0.         1.         0.         1.
 1.         0.0801865  1.         0.92773074 1.         1.
 0.20262229 0.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.31032079 1.
  1.         0.         0.        ]
 [1.         0.         0.         0.         0.27699718 1.
  0.         0.         1.        ]
 [1.         0.         0.66053357 0.59240372 0.27743274 1.
  0.         0.50493239 1.        ]
 [1.         0.         1.         1.         0.27729744 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27775369 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.27768899 1.
  0.         1.         1.        ]
 [1.         0.         0.46642962 0.57997665 0.2776071  1.
  0.         0.28690274 1.        ]
 [1.         0.         1.         1.         0.27733941 1.
  0.         0.90147866 1.        ]
 [1.         0.         1.         1.         0.27766132 1.
  0.         1.         1.        ]
 [1.         0.         0.16171416 0.10062303 0.27685445 1.
  0.         0.715148   1.        ]
 [0.         0.         0.         0.         0.27675516 1.
  0.         0.         1.        ]
 [1.         0.         0.96170275 1.         0.27674997 1.
  0.         0.70152567 1.        ]
 [1.         0.         0.         0.         0.2770999  1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.27742588 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.27695012 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.27739844 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.27698324 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.27723259 1.
  0.         1.         1.        ]
 [1.         0.         0.49112157 0.50520185 0.27745594 1.
  0.         1.         1.        ]
 [1.         0.         0.06552238 0.08884664 0.27760117 1.
  0.         0.0801865  1.        ]
 [1.         0.         1.         1.         0.27739123 1.
  0.         1.         1.        ]
 [1.         0.         0.68181432 0.66810791 0.2769938  1.
  0.         0.92773074 1.        ]
 [1.         0.         1.         1.         0.27722154 1.
  0.         1.         1.        ]
 [1.         0.         0.99958615 0.99499099 0.27746617 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.27736581 1.
  0.         0.20262229 1.        ]
 [1.         0.         0.         0.         0.27695782 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.9166666865348816
#####################         POISON         ###############################################

############################################################################################

comm_round: 5 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8

Accuracy per class:
[[8 0]
 [0 0]]
[ 1. nan]
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         1.         0.29944751 0.         1.         0.
 0.         0.14087761 0.         1.         0.         0.
 0.         0.00931378 0.         0.         0.22623221 0.
 0.         0.         0.         0.         0.         0.
 0.         0.77317091]
wv_ed shape (26,)
[0.         1.         0.36448292 0.         1.         0.
 0.         0.13794808 0.04749535 1.         0.         0.
 0.         0.         0.         0.         0.24827231 0.
 0.         0.         0.         0.         0.         0.
 0.         0.68113642]
wv_lg shape (26, 1)
[[0.3126013 ]
 [0.28201317]
 [0.28162441]
 [0.28116761]
 [0.28197731]
 [0.28136378]
 [0.28112891]
 [0.28166347]
 [0.28195231]
 [0.2817672 ]
 [0.281842  ]
 [0.28162941]
 [0.28172405]
 [0.28149329]
 [0.28179524]
 [0.28118396]
 [0.28194212]
 [0.28126741]
 [0.28173539]
 [0.28159868]
 [0.2816513 ]
 [0.28168434]
 [0.28154002]
 [0.28156686]
 [0.28171516]
 [0.28170136]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         1.         0.26332199 0.         0.96505344 0.
 0.         0.25482731 0.1561509  1.         0.2665642  0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         1.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.3126013  1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.28201317 1.
  0.         1.         1.        ]
 [1.         0.         0.29944751 0.36448292 0.28162441 1.
  0.         0.26332199 1.        ]
 [1.         0.         0.         0.         0.28116761 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.28197731 1.
  0.         0.96505344 1.        ]
 [1.         0.         0.         0.         0.28136378 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.28112891 1.
  0.         0.         1.        ]
 [1.         0.         0.14087761 0.13794808 0.28166347 1.
  0.         0.25482731 1.        ]
 [1.         0.         0.         0.04749535 0.28195231 1.
  0.         0.1561509  1.        ]
 [1.         0.         1.         1.         0.2817672  1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.281842   1.
  0.         0.2665642  1.        ]
 [1.         0.         0.         0.         0.28162941 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.28172405 1.
  0.         0.         1.        ]
 [1.         0.         0.00931378 0.         0.28149329 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.28179524 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.28118396 1.
  0.         0.         1.        ]
 [1.         0.         0.22623221 0.24827231 0.28194212 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.28126741 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.28173539 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.28159868 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.2816513  1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.28168434 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.28154002 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.28156686 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.28171516 1.
  0.         0.         1.        ]
 [1.         0.         0.77317091 0.68113642 0.28170136 1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
1.0
#####################         POISON         ###############################################

############################################################################################

comm_round: 6 | global_test_acc: 87.500% | global_f1: 0.9333333333333333 | global_precision: 0.875
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.88      1.00      0.93         7

    accuracy                           0.88         8
   macro avg       0.44      0.50      0.47         8
weighted avg       0.77      0.88      0.82         8

Accuracy per class:
[[7 0]
 [1 0]]
[1. 0.]
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.         1.         0.         1.         1.
 0.32124962 0.88041949 0.         0.         0.         0.
 0.         0.         0.85473727 0.         0.         0.90981254
 1.         1.         0.57710815 0.         0.         0.
 1.         0.34289787]
wv_ed shape (26,)
[0.         0.         1.         0.         1.         1.
 0.32128305 0.8366867  0.         0.         0.         0.
 0.         0.         0.8126084  0.         0.         0.96993744
 0.82957683 1.         0.58670245 0.         0.         0.
 1.         0.4281404 ]
wv_lg shape (26, 1)
[[0.31460946]
 [0.28539302]
 [0.28575599]
 [0.28544517]
 [0.28605384]
 [0.28600847]
 [0.28557337]
 [0.2858281 ]
 [0.28568917]
 [0.28598782]
 [0.28570718]
 [0.2858112 ]
 [0.28588052]
 [0.2859485 ]
 [0.28567257]
 [0.28566644]
 [0.2854501 ]
 [0.28559878]
 [0.2857665 ]
 [0.28580212]
 [0.2860004 ]
 [0.28555705]
 [0.2855724 ]
 [0.28556583]
 [0.28575703]
 [0.28576213]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.         1.         0.68240026 1.         1.
 0.19916961 0.56825339 0.         0.         0.47796089 0.11609309
 0.12345823 0.7656935  1.         0.43663416 0.         1.
 1.         1.         1.         0.04218953 0.         0.
 1.         0.78162764]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.31460946 1.
  1.         0.         0.        ]
 [1.         0.         0.         0.         0.28539302 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.28575599 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.28544517 1.
  0.         0.68240026 1.        ]
 [1.         0.         1.         1.         0.28605384 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.28600847 1.
  0.         1.         1.        ]
 [1.         0.         0.32124962 0.32128305 0.28557337 1.
  0.         0.19916961 1.        ]
 [1.         0.         0.88041949 0.8366867  0.2858281  1.
  0.         0.56825339 1.        ]
 [1.         0.         0.         0.         0.28568917 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.28598782 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.28570718 1.
  0.         0.47796089 1.        ]
 [1.         0.         0.         0.         0.2858112  1.
  0.         0.11609309 1.        ]
 [1.         0.         0.         0.         0.28588052 1.
  0.         0.12345823 1.        ]
 [1.         0.         0.         0.         0.2859485  1.
  0.         0.7656935  1.        ]
 [1.         0.         0.85473727 0.8126084  0.28567257 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.28566644 1.
  0.         0.43663416 1.        ]
 [1.         0.         0.         0.         0.2854501  1.
  0.         0.         1.        ]
 [1.         0.         0.90981254 0.96993744 0.28559878 1.
  0.         1.         1.        ]
 [1.         0.         1.         0.82957683 0.2857665  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.28580212 1.
  0.         1.         1.        ]
 [1.         0.         0.57710815 0.58670245 0.2860004  1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.28555705 1.
  0.         0.04218953 1.        ]
 [1.         0.         0.         0.         0.2855724  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.28556583 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.28575703 1.
  0.         1.         1.        ]
 [1.         0.         0.34289787 0.4281404  0.28576213 1.
  0.         0.78162764 1.        ]]

Best Training Poisoning Accuracy:
0.9166666865348816
#####################         POISON         ###############################################

############################################################################################

comm_round: 7 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8

Accuracy per class:
[[8 0]
 [0 0]]
[ 1. nan]
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.         1.         0.47391163 1.         0.18219358
 0.38026801 0.         1.         1.         0.87300492 0.
 1.         0.10409523 1.         0.21792338 1.         0.09693343
 1.         1.         0.48036779 0.         0.63758988 1.
 0.2844716  0.        ]
wv_ed shape (26,)
[0.         0.         1.         0.32617806 1.         0.0459545
 0.34660305 0.         1.         1.         0.72452242 0.
 1.         0.         1.         0.         1.         0.15056732
 1.         1.         0.4447341  0.         0.53143084 0.97524034
 0.14041421 0.        ]
wv_lg shape (26, 1)
[[0.31670856]
 [0.28894555]
 [0.2893586 ]
 [0.28917961]
 [0.28945954]
 [0.28914764]
 [0.2891954 ]
 [0.28910257]
 [0.289272  ]
 [0.28952903]
 [0.28946951]
 [0.28915859]
 [0.28930721]
 [0.28951506]
 [0.28936955]
 [0.28912265]
 [0.28914782]
 [0.28938688]
 [0.28954895]
 [0.28942525]
 [0.28898705]
 [0.28920233]
 [0.28916555]
 [0.28925194]
 [0.28949764]
 [0.28926127]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.         1.         0.73310069 1.         0.99169235
 0.31634493 0.         1.         1.         1.         0.
 1.         0.81634338 1.         0.         1.         0.56941215
 1.         1.         0.01844296 0.31894194 0.33715998 0.86377937
 0.54073457 0.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.31670856 1.
  1.         0.         0.        ]
 [1.         0.         0.         0.         0.28894555 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.2893586  1.
  0.         1.         1.        ]
 [1.         0.         0.47391163 0.32617806 0.28917961 1.
  0.         0.73310069 1.        ]
 [1.         0.         1.         1.         0.28945954 1.
  0.         1.         1.        ]
 [1.         0.         0.18219358 0.0459545  0.28914764 1.
  0.         0.99169235 1.        ]
 [1.         0.         0.38026801 0.34660305 0.2891954  1.
  0.         0.31634493 1.        ]
 [0.         0.         0.         0.         0.28910257 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.289272   1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.28952903 1.
  0.         1.         1.        ]
 [1.         0.         0.87300492 0.72452242 0.28946951 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.28915859 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.28930721 1.
  0.         1.         1.        ]
 [1.         0.         0.10409523 0.         0.28951506 1.
  0.         0.81634338 1.        ]
 [1.         0.         1.         1.         0.28936955 1.
  0.         1.         1.        ]
 [1.         0.         0.21792338 0.         0.28912265 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.28914782 1.
  0.         1.         1.        ]
 [1.         0.         0.09693343 0.15056732 0.28938688 1.
  0.         0.56941215 1.        ]
 [1.         0.         1.         1.         0.28954895 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.28942525 1.
  0.         1.         1.        ]
 [1.         0.         0.48036779 0.4447341  0.28898705 1.
  0.         0.01844296 1.        ]
 [1.         0.         0.         0.         0.28920233 1.
  0.         0.31894194 1.        ]
 [1.         0.         0.63758988 0.53143084 0.28916555 1.
  0.         0.33715998 1.        ]
 [1.         0.         1.         0.97524034 0.28925194 1.
  0.         0.86377937 1.        ]
 [1.         0.         0.2844716  0.14041421 0.28949764 1.
  0.         0.54073457 1.        ]
 [1.         0.         0.         0.         0.28926127 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.9166666865348816
#####################         POISON         ###############################################

############################################################################################

comm_round: 8 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8

Accuracy per class:
[[8 0]
 [0 0]]
[ 1. nan]
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.         1.         0.3892648  1.         0.94141911
 0.74612347 0.         1.         0.51364949 0.82015212 0.
 0.         0.         1.         0.52387204 0.         0.64777287
 0.         0.43820353 0.44709519 0.84108535 1.         0.03167462
 0.         0.        ]
wv_ed shape (26,)
[0.         0.         1.         0.38574641 1.         1.
 0.72407721 0.         1.         0.6658122  0.93265812 0.0709964
 0.         0.         1.         0.53771162 0.06658434 0.69452092
 0.         0.48203851 0.48531662 0.99093259 1.         0.16468202
 0.         0.        ]
wv_lg shape (26, 1)
[[0.31790421]
 [0.29301941]
 [0.29358052]
 [0.29328586]
 [0.29338404]
 [0.29293197]
 [0.29344977]
 [0.2933034 ]
 [0.29320249]
 [0.2934334 ]
 [0.29305737]
 [0.29308901]
 [0.29338067]
 [0.29344819]
 [0.2930841 ]
 [0.29326019]
 [0.29296415]
 [0.29317775]
 [0.2930088 ]
 [0.29310246]
 [0.29304925]
 [0.29317214]
 [0.29322172]
 [0.2931025 ]
 [0.29327039]
 [0.29324249]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.         1.         0.23448892 1.         0.
 1.         0.         0.         0.70607649 0.37278531 0.
 0.         0.         0.50193603 0.         0.         0.
 0.         0.38632918 0.         0.         0.44571354 0.
 0.         0.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.31790421 1.
  1.         0.         0.        ]
 [1.         0.         0.         0.         0.29301941 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.29358052 1.
  0.         1.         1.        ]
 [1.         0.         0.3892648  0.38574641 0.29328586 1.
  0.         0.23448892 1.        ]
 [1.         0.         1.         1.         0.29338404 1.
  0.         1.         1.        ]
 [1.         0.         0.94141911 1.         0.29293197 1.
  0.         0.         1.        ]
 [1.         0.         0.74612347 0.72407721 0.29344977 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.2933034  1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.29320249 1.
  0.         0.         1.        ]
 [1.         0.         0.51364949 0.6658122  0.2934334  1.
  0.         0.70607649 1.        ]
 [1.         0.         0.82015212 0.93265812 0.29305737 1.
  0.         0.37278531 1.        ]
 [1.         0.         0.         0.0709964  0.29308901 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.29338067 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.29344819 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.2930841  1.
  0.         0.50193603 1.        ]
 [1.         0.         0.52387204 0.53771162 0.29326019 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.06658434 0.29296415 1.
  0.         0.         1.        ]
 [1.         0.         0.64777287 0.69452092 0.29317775 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.2930088  1.
  0.         0.         1.        ]
 [1.         0.         0.43820353 0.48203851 0.29310246 1.
  0.         0.38632918 1.        ]
 [1.         0.         0.44709519 0.48531662 0.29304925 1.
  0.         0.         1.        ]
 [1.         0.         0.84108535 0.99093259 0.29317214 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.29322172 1.
  0.         0.44571354 1.        ]
 [1.         0.         0.03167462 0.16468202 0.2931025  1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.29327039 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.29324249 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
1.0
#####################         POISON         ###############################################

############################################################################################

comm_round: 9 | global_test_acc: 87.500% | global_f1: 0.9333333333333333 | global_precision: 0.875
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.88      1.00      0.93         7

    accuracy                           0.88         8
   macro avg       0.44      0.50      0.47         8
weighted avg       0.77      0.88      0.82         8

Accuracy per class:
[[7 0]
 [1 0]]
[1. 0.]
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.46947694 1.         0.         0.463458   0.87359011
 0.         1.         0.         0.         1.         0.93371924
 0.         1.         1.         1.         1.         0.
 0.64220009 0.         0.99599102 1.         0.68449468 0.91847381
 1.         0.07886481]
wv_ed shape (26,)
[0.         0.58905639 1.         0.         0.7125158  1.
 0.         1.         0.         0.         1.         0.96767385
 0.10283719 1.         1.         1.         1.         0.
 0.76653426 0.         1.         1.         0.61438438 0.97674574
 1.         0.        ]
wv_lg shape (26, 1)
[[0.3196113 ]
 [0.29644821]
 [0.29634753]
 [0.29607635]
 [0.29626556]
 [0.29636563]
 [0.29623247]
 [0.29641274]
 [0.29616863]
 [0.29633932]
 [0.29666088]
 [0.29639434]
 [0.29629593]
 [0.29642396]
 [0.2963337 ]
 [0.29656974]
 [0.29652628]
 [0.29627562]
 [0.29660303]
 [0.29644268]
 [0.29620584]
 [0.29644358]
 [0.29621733]
 [0.29617636]
 [0.29660275]
 [0.29598217]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         1.         1.         0.         0.         0.50149435
 0.         1.         0.         0.         1.         1.
 0.         0.76916381 1.         1.         1.         0.
 1.         0.         0.48010662 1.         0.82809147 0.59929364
 1.         0.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.3196113  1.
  1.         0.         0.        ]
 [1.         0.         0.46947694 0.58905639 0.29644821 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.29634753 1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.29607635 1.
  0.         0.         1.        ]
 [1.         0.         0.463458   0.7125158  0.29626556 1.
  0.         0.         1.        ]
 [1.         0.         0.87359011 1.         0.29636563 1.
  0.         0.50149435 1.        ]
 [1.         0.         0.         0.         0.29623247 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.29641274 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.29616863 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.29633932 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.29666088 1.
  0.         1.         1.        ]
 [1.         0.         0.93371924 0.96767385 0.29639434 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.10283719 0.29629593 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.29642396 1.
  0.         0.76916381 1.        ]
 [1.         0.         1.         1.         0.2963337  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.29656974 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.29652628 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.29627562 1.
  0.         0.         1.        ]
 [1.         0.         0.64220009 0.76653426 0.29660303 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.29644268 1.
  0.         0.         1.        ]
 [1.         0.         0.99599102 1.         0.29620584 1.
  0.         0.48010662 1.        ]
 [1.         0.         1.         1.         0.29644358 1.
  0.         1.         1.        ]
 [1.         0.         0.68449468 0.61438438 0.29621733 1.
  0.         0.82809147 1.        ]
 [1.         0.         0.91847381 0.97674574 0.29617636 1.
  0.         0.59929364 1.        ]
 [1.         0.         1.         1.         0.29660275 1.
  0.         1.         1.        ]
 [1.         0.         0.07886481 0.         0.29598217 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.9166666865348816
#####################         POISON         ###############################################

############################################################################################

comm_round: 10 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8

Accuracy per class:
[[8 0]
 [0 0]]
[ 1. nan]
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.         1.         1.         0.         0.92792814
 0.46182867 0.67628788 0.         0.         0.         0.08001054
 0.         0.         0.12584773 1.         0.87524346 0.77630249
 0.1519267  0.         1.         0.         0.81513546 0.
 0.52171171 0.        ]
wv_ed shape (26,)
[0.         0.         1.         1.         0.         0.98772765
 0.51655277 0.74939714 0.         0.         0.         0.22290307
 0.         0.         0.19570909 1.         0.89905501 0.72936659
 0.30371634 0.         1.         0.         0.89151787 0.
 0.60904094 0.        ]
wv_lg shape (26, 1)
[[0.32124777]
 [0.29905637]
 [0.29936992]
 [0.29911141]
 [0.29885284]
 [0.29927511]
 [0.29930696]
 [0.29906753]
 [0.29895607]
 [0.29911436]
 [0.29898538]
 [0.29917446]
 [0.29924207]
 [0.29905988]
 [0.29915087]
 [0.29935234]
 [0.29938294]
 [0.29915716]
 [0.29892762]
 [0.29927446]
 [0.29921282]
 [0.29921625]
 [0.29893268]
 [0.2992799 ]
 [0.29900359]
 [0.29894403]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.10610578 1.         1.         0.22569677 1.
 1.         1.         0.         0.         0.71908838 0.5268779
 0.88216641 0.         0.         1.         1.         1.
 0.2850001  0.15059743 1.         0.76237583 1.         0.94933576
 0.         0.31413165]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.32124777 1.
  1.         0.         0.        ]
 [1.         0.         0.         0.         0.29905637 1.
  0.         0.10610578 1.        ]
 [1.         0.         1.         1.         0.29936992 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.29911141 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.29885284 1.
  0.         0.22569677 1.        ]
 [1.         0.         0.92792814 0.98772765 0.29927511 1.
  0.         1.         1.        ]
 [1.         0.         0.46182867 0.51655277 0.29930696 1.
  0.         1.         1.        ]
 [1.         0.         0.67628788 0.74939714 0.29906753 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.29895607 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.29911436 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.29898538 1.
  0.         0.71908838 1.        ]
 [1.         0.         0.08001054 0.22290307 0.29917446 1.
  0.         0.5268779  1.        ]
 [1.         0.         0.         0.         0.29924207 1.
  0.         0.88216641 1.        ]
 [1.         0.         0.         0.         0.29905988 1.
  0.         0.         1.        ]
 [1.         0.         0.12584773 0.19570909 0.29915087 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.29935234 1.
  0.         1.         1.        ]
 [1.         0.         0.87524346 0.89905501 0.29938294 1.
  0.         1.         1.        ]
 [1.         0.         0.77630249 0.72936659 0.29915716 1.
  0.         1.         1.        ]
 [1.         0.         0.1519267  0.30371634 0.29892762 1.
  0.         0.2850001  1.        ]
 [1.         0.         0.         0.         0.29927446 1.
  0.         0.15059743 1.        ]
 [1.         0.         1.         1.         0.29921282 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.29921625 1.
  0.         0.76237583 1.        ]
 [1.         0.         0.81513546 0.89151787 0.29893268 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.2992799  1.
  0.         0.94933576 1.        ]
 [1.         0.         0.52171171 0.60904094 0.29900359 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.29894403 1.
  0.         0.31413165 1.        ]]

Best Training Poisoning Accuracy:
0.9166666865348816
#####################         POISON         ###############################################

############################################################################################

comm_round: 11 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8

Accuracy per class:
[[8 0]
 [0 0]]
[ 1. nan]
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.32971442 0.         1.         0.28016861 0.17308994
 0.37912823 1.         0.86626103 0.23202746 1.         0.52715939
 1.         0.87535172 1.         1.         0.         0.37773443
 1.         0.08761833 1.         1.         1.         0.
 0.78640458 0.61321236]
wv_ed shape (26,)
[0.         0.45356815 0.         1.         0.34515984 0.23785826
 0.330746   1.         0.95186674 0.18637477 0.98120585 0.52231323
 1.         0.81147461 1.         1.         0.         0.39383823
 1.         0.03960253 1.         1.         1.         0.
 0.79937044 0.64311436]
wv_lg shape (26, 1)
[[0.32239785]
 [0.30232909]
 [0.30204162]
 [0.3025174 ]
 [0.3019691 ]
 [0.30190646]
 [0.30225088]
 [0.30238997]
 [0.30201306]
 [0.30210753]
 [0.30192519]
 [0.30203169]
 [0.30232341]
 [0.30231063]
 [0.30204258]
 [0.30215701]
 [0.30207264]
 [0.30213733]
 [0.3020493 ]
 [0.30188325]
 [0.30212121]
 [0.30238897]
 [0.30226536]
 [0.30216024]
 [0.30224691]
 [0.30210645]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.         0.         1.         0.         0.36437786
 0.38596599 1.         0.         0.0738146  0.89437551 1.
 1.         0.79600663 0.80173275 1.         0.         0.4283188
 0.50479647 0.         0.99535142 1.         0.82951271 0.
 0.67865845 0.39464675]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.32239785 1.
  1.         0.         0.        ]
 [1.         0.         0.32971442 0.45356815 0.30232909 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.30204162 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.3025174  1.
  0.         1.         1.        ]
 [1.         0.         0.28016861 0.34515984 0.3019691  1.
  0.         0.         1.        ]
 [1.         0.         0.17308994 0.23785826 0.30190646 1.
  0.         0.36437786 1.        ]
 [1.         0.         0.37912823 0.330746   0.30225088 1.
  0.         0.38596599 1.        ]
 [1.         0.         1.         1.         0.30238997 1.
  0.         1.         1.        ]
 [1.         0.         0.86626103 0.95186674 0.30201306 1.
  0.         0.         1.        ]
 [1.         0.         0.23202746 0.18637477 0.30210753 1.
  0.         0.0738146  1.        ]
 [1.         0.         1.         0.98120585 0.30192519 1.
  0.         0.89437551 1.        ]
 [1.         0.         0.52715939 0.52231323 0.30203169 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.30232341 1.
  0.         1.         1.        ]
 [1.         0.         0.87535172 0.81147461 0.30231063 1.
  0.         0.79600663 1.        ]
 [1.         0.         1.         1.         0.30204258 1.
  0.         0.80173275 1.        ]
 [1.         0.         1.         1.         0.30215701 1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.30207264 1.
  0.         0.         1.        ]
 [1.         0.         0.37773443 0.39383823 0.30213733 1.
  0.         0.4283188  1.        ]
 [1.         0.         1.         1.         0.3020493  1.
  0.         0.50479647 1.        ]
 [1.         0.         0.08761833 0.03960253 0.30188325 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.30212121 1.
  0.         0.99535142 1.        ]
 [1.         0.         1.         1.         0.30238897 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.30226536 1.
  0.         0.82951271 1.        ]
 [1.         0.         0.         0.         0.30216024 1.
  0.         0.         1.        ]
 [1.         0.         0.78640458 0.79937044 0.30224691 1.
  0.         0.67865845 1.        ]
 [1.         0.         0.61321236 0.64311436 0.30210645 1.
  0.         0.39464675 1.        ]]

Best Training Poisoning Accuracy:
1.0
#####################         POISON         ###############################################

############################################################################################

comm_round: 12 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8

Accuracy per class:
[[8 0]
 [0 0]]
[ 1. nan]
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.         0.         0.         0.80747163 0.47381271
 1.         0.         0.         1.         0.61833107 0.
 0.73165788 0.         0.         0.94291423 0.         0.
 0.18980526 0.         0.         1.         0.5496031  0.07508106
 1.         0.79063398]
wv_ed shape (26,)
[0.         0.         0.14493857 0.         0.90066306 0.75284382
 1.         0.         0.         1.         0.71579087 0.
 0.79880017 0.         0.         1.         0.         0.05061667
 0.26566903 0.         0.         1.         0.50858145 0.23239475
 1.         0.99623487]
wv_lg shape (26, 1)
[[0.32388503]
 [0.30438714]
 [0.30453698]
 [0.30445524]
 [0.30455145]
 [0.30435472]
 [0.30478077]
 [0.30430429]
 [0.30454232]
 [0.30457502]
 [0.3046236 ]
 [0.30442727]
 [0.30505426]
 [0.30426328]
 [0.30432715]
 [0.30464027]
 [0.30440795]
 [0.30411559]
 [0.30466578]
 [0.30453856]
 [0.30455457]
 [0.30467717]
 [0.30471538]
 [0.30459855]
 [0.30441   ]
 [0.30450887]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.         0.25280127 0.         1.         0.87255547
 1.         0.         0.         1.         1.         0.
 1.         0.         0.         1.         0.21690277 0.
 0.96654706 0.39243671 0.93580155 1.         1.         0.57531832
 1.         0.55213025]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.32388503 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.30438714 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.14493857 0.30453698 1.
  0.         0.25280127 1.        ]
 [1.         0.         0.         0.         0.30445524 1.
  0.         0.         1.        ]
 [1.         0.         0.80747163 0.90066306 0.30455145 1.
  0.         1.         1.        ]
 [1.         0.         0.47381271 0.75284382 0.30435472 1.
  0.         0.87255547 1.        ]
 [1.         0.         1.         1.         0.30478077 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.30430429 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.30454232 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.30457502 1.
  0.         1.         1.        ]
 [1.         0.         0.61833107 0.71579087 0.3046236  1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.30442727 1.
  0.         0.         1.        ]
 [1.         0.         0.73165788 0.79880017 0.30505426 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.30426328 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.30432715 1.
  0.         0.         1.        ]
 [1.         0.         0.94291423 1.         0.30464027 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.30440795 1.
  0.         0.21690277 1.        ]
 [1.         0.         0.         0.05061667 0.30411559 1.
  0.         0.         1.        ]
 [1.         0.         0.18980526 0.26566903 0.30466578 1.
  0.         0.96654706 1.        ]
 [1.         0.         0.         0.         0.30453856 1.
  0.         0.39243671 1.        ]
 [1.         0.         0.         0.         0.30455457 1.
  0.         0.93580155 1.        ]
 [1.         0.         1.         1.         0.30467717 1.
  0.         1.         1.        ]
 [1.         0.         0.5496031  0.50858145 0.30471538 1.
  0.         1.         1.        ]
 [1.         0.         0.07508106 0.23239475 0.30459855 1.
  0.         0.57531832 1.        ]
 [1.         0.         1.         1.         0.30441    1.
  0.         1.         1.        ]
 [1.         0.         0.79063398 0.99623487 0.30450887 1.
  0.         0.55213025 1.        ]]

Best Training Poisoning Accuracy:
1.0
#####################         POISON         ###############################################

############################################################################################

comm_round: 13 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8

Accuracy per class:
[[8 0]
 [0 0]]
[ 1. nan]
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.18426848 1.         0.         0.         0.
 0.         0.16419798 0.         1.         0.         1.
 0.         1.         0.1527061  1.         0.         0.
 0.10337152 0.         0.29159484 0.         1.         0.
 0.81044639 1.        ]
wv_ed shape (26,)
[0.         0.34972836 1.         0.         0.         0.
 0.         0.22592511 0.         1.         0.         1.
 0.         1.         0.20575799 1.         0.         0.1090055
 0.11312447 0.         0.28106798 0.         1.         0.
 0.72079346 1.        ]
wv_lg shape (26, 1)
[[0.32482317]
 [0.30734519]
 [0.3072339 ]
 [0.30718961]
 [0.30715343]
 [0.30705828]
 [0.30733945]
 [0.30731612]
 [0.30713926]
 [0.3074146 ]
 [0.30706692]
 [0.30735352]
 [0.30718914]
 [0.30732419]
 [0.30695012]
 [0.30745475]
 [0.3072355 ]
 [0.3070581 ]
 [0.30713349]
 [0.30705914]
 [0.30733829]
 [0.3070283 ]
 [0.3075946 ]
 [0.30722544]
 [0.30696069]
 [0.30756333]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.96895352 1.         0.         0.         0.23598238
 0.08077766 0.43610891 0.48226816 1.         0.19542984 1.
 0.89743873 1.         0.27853235 1.         0.         0.13949928
 0.59301813 0.17551799 0.59401438 0.         1.         0.
 1.         1.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.32482317 1.
  1.         0.         0.        ]
 [1.         0.         0.18426848 0.34972836 0.30734519 1.
  0.         0.96895352 1.        ]
 [1.         0.         1.         1.         0.3072339  1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.30718961 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.30715343 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.30705828 1.
  0.         0.23598238 1.        ]
 [1.         0.         0.         0.         0.30733945 1.
  0.         0.08077766 1.        ]
 [1.         0.         0.16419798 0.22592511 0.30731612 1.
  0.         0.43610891 1.        ]
 [1.         0.         0.         0.         0.30713926 1.
  0.         0.48226816 1.        ]
 [1.         0.         1.         1.         0.3074146  1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.30706692 1.
  0.         0.19542984 1.        ]
 [1.         0.         1.         1.         0.30735352 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.30718914 1.
  0.         0.89743873 1.        ]
 [1.         0.         1.         1.         0.30732419 1.
  0.         1.         1.        ]
 [1.         0.         0.1527061  0.20575799 0.30695012 1.
  0.         0.27853235 1.        ]
 [1.         0.         1.         1.         0.30745475 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.3072355  1.
  0.         0.         1.        ]
 [1.         0.         0.         0.1090055  0.3070581  1.
  0.         0.13949928 1.        ]
 [1.         0.         0.10337152 0.11312447 0.30713349 1.
  0.         0.59301813 1.        ]
 [1.         0.         0.         0.         0.30705914 1.
  0.         0.17551799 1.        ]
 [1.         0.         0.29159484 0.28106798 0.30733829 1.
  0.         0.59401438 1.        ]
 [0.         0.         0.         0.         0.3070283  1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.3075946  1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.30722544 1.
  0.         0.         1.        ]
 [1.         0.         0.81044639 0.72079346 0.30696069 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.30756333 1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.9166666865348816
#####################         POISON         ###############################################

############################################################################################

comm_round: 14 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8

Accuracy per class:
[[8 0]
 [0 0]]
[ 1. nan]
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 0.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.         1.         0.         1.         0.
 1.         0.17884709 0.45392654 1.         0.         1.
 0.26620288 0.         0.79502711 0.         0.         0.49794765
 0.         0.48994873 0.         0.72027689 1.         0.
 0.         0.        ]
wv_ed shape (26,)
[0.         0.02718926 1.         0.         1.         0.
 1.         0.28052955 0.4975792  1.         0.         1.
 0.35340455 0.         0.89457016 0.         0.         0.58792799
 0.         0.43796947 0.         0.75787004 1.         0.
 0.         0.        ]
wv_lg shape (26, 1)
[[0.32639297]
 [0.30900215]
 [0.30954887]
 [0.30885942]
 [0.30882254]
 [0.3089613 ]
 [0.30893908]
 [0.30906592]
 [0.30898328]
 [0.30926575]
 [0.30894605]
 [0.30940809]
 [0.30915078]
 [0.3091738 ]
 [0.30901821]
 [0.30907001]
 [0.30912104]
 [0.30897467]
 [0.30878421]
 [0.30926181]
 [0.30906779]
 [0.30933563]
 [0.30923851]
 [0.30881728]
 [0.30916152]
 [0.30890385]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.         1.         0.         1.         0.
 0.94332533 0.         0.61624642 0.97169175 0.         1.
 0.29103363 0.         0.3138923  0.         0.         0.75954199
 0.17324533 1.         0.         1.         1.         0.
 0.29727472 0.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.32639297 1.
  1.         0.         0.        ]
 [1.         0.         0.         0.02718926 0.30900215 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.30954887 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.30885942 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.30882254 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.3089613  1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.30893908 1.
  0.         0.94332533 1.        ]
 [1.         0.         0.17884709 0.28052955 0.30906592 1.
  0.         0.         1.        ]
 [1.         0.         0.45392654 0.4975792  0.30898328 1.
  0.         0.61624642 1.        ]
 [1.         0.         1.         1.         0.30926575 1.
  0.         0.97169175 1.        ]
 [1.         0.         0.         0.         0.30894605 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.30940809 1.
  0.         1.         1.        ]
 [1.         0.         0.26620288 0.35340455 0.30915078 1.
  0.         0.29103363 1.        ]
 [1.         0.         0.         0.         0.3091738  1.
  0.         0.         1.        ]
 [1.         0.         0.79502711 0.89457016 0.30901821 1.
  0.         0.3138923  1.        ]
 [1.         0.         0.         0.         0.30907001 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.30912104 1.
  0.         0.         1.        ]
 [1.         0.         0.49794765 0.58792799 0.30897467 1.
  0.         0.75954199 1.        ]
 [1.         0.         0.         0.         0.30878421 1.
  0.         0.17324533 1.        ]
 [1.         0.         0.48994873 0.43796947 0.30926181 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.30906779 1.
  0.         0.         1.        ]
 [1.         0.         0.72027689 0.75787004 0.30933563 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.30923851 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.30881728 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.30916152 1.
  0.         0.29727472 1.        ]
 [0.         0.         0.         0.         0.30890385 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
1.0
#####################         POISON         ###############################################

############################################################################################

comm_round: 15 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8

Accuracy per class:
[[8 0]
 [0 0]]
[ 1. nan]
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         1.         0.         1.         0.         0.4427297
 0.37962125 1.         0.         0.         0.47418218 0.
 0.15322528 0.         0.         0.24390106 0.         0.
 0.         0.         0.         0.         1.         0.
 0.         1.        ]
wv_ed shape (26,)
[0.         1.         0.         1.         0.00696678 0.47483713
 0.54410366 1.         0.         0.         0.47239544 0.
 0.         0.         0.         0.36992441 0.         0.14189419
 0.         0.         0.         0.         1.         0.
 0.         1.        ]
wv_lg shape (26, 1)
[[0.32752397]
 [0.31137106]
 [0.31103517]
 [0.31142861]
 [0.31105051]
 [0.31102081]
 [0.31126661]
 [0.31123329]
 [0.31100716]
 [0.31118155]
 [0.311249  ]
 [0.31116288]
 [0.31137727]
 [0.31120775]
 [0.31100561]
 [0.3113011 ]
 [0.31106902]
 [0.31119339]
 [0.31126802]
 [0.31097624]
 [0.31144977]
 [0.31096181]
 [0.31137975]
 [0.31116274]
 [0.31106174]
 [0.31107678]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         1.         0.         1.         0.14760443 1.
 0.         1.         0.         0.         1.         0.
 0.95108842 0.43468159 0.         1.         0.         0.24787416
 0.         0.         1.         0.         0.92476336 0.16396675
 0.         0.53615702]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.32752397 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.31137106 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.31103517 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.31142861 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.00696678 0.31105051 1.
  0.         0.14760443 1.        ]
 [1.         0.         0.4427297  0.47483713 0.31102081 1.
  0.         1.         1.        ]
 [1.         0.         0.37962125 0.54410366 0.31126661 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.31123329 1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.31100716 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.31118155 1.
  0.         0.         1.        ]
 [1.         0.         0.47418218 0.47239544 0.311249   1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.31116288 1.
  0.         0.         1.        ]
 [1.         0.         0.15322528 0.         0.31137727 1.
  0.         0.95108842 1.        ]
 [1.         0.         0.         0.         0.31120775 1.
  0.         0.43468159 1.        ]
 [1.         0.         0.         0.         0.31100561 1.
  0.         0.         1.        ]
 [1.         0.         0.24390106 0.36992441 0.3113011  1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.31106902 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.14189419 0.31119339 1.
  0.         0.24787416 1.        ]
 [1.         0.         0.         0.         0.31126802 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.31097624 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.31144977 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.31096181 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.31137975 1.
  0.         0.92476336 1.        ]
 [1.         0.         0.         0.         0.31116274 1.
  0.         0.16396675 1.        ]
 [1.         0.         0.         0.         0.31106174 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.31107678 1.
  0.         0.53615702 1.        ]]

Best Training Poisoning Accuracy:
1.0
#####################         POISON         ###############################################

############################################################################################

comm_round: 16 | global_test_acc: 87.500% | global_f1: 0.9333333333333333 | global_precision: 0.875
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.88      1.00      0.93         7

    accuracy                           0.88         8
   macro avg       0.44      0.50      0.47         8
weighted avg       0.77      0.88      0.82         8

Accuracy per class:
[[7 0]
 [1 0]]
[1. 0.]
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.34187955 0.         0.51401085 1.         1.
 0.         0.         0.28259243 1.         0.89701044 0.
 1.         1.         0.26701694 0.         0.88319782 1.
 0.81710671 0.         1.         0.17527567 0.26457371 1.
 1.         0.56586728]
wv_ed shape (26,)
[0.         0.17406497 0.         0.59962091 1.         1.
 0.         0.         0.35591373 1.         0.93930094 0.
 1.         1.         0.35009166 0.         0.90212514 1.
 0.79235343 0.03160693 1.         0.23428275 0.22965318 1.
 1.         0.6105476 ]
wv_lg shape (26, 1)
[[0.32855688]
 [0.31311932]
 [0.31313101]
 [0.31320043]
 [0.31299431]
 [0.31325808]
 [0.31311231]
 [0.31301916]
 [0.31329113]
 [0.31305234]
 [0.31320747]
 [0.31317085]
 [0.31326928]
 [0.31314481]
 [0.31318181]
 [0.31330762]
 [0.31321167]
 [0.31300436]
 [0.31304151]
 [0.31305598]
 [0.31341326]
 [0.31330323]
 [0.31336722]
 [0.3131153 ]
 [0.31329422]
 [0.3133664 ]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.86125428 0.         0.12351895 0.22850889 0.59681986
 0.         0.         0.44709297 1.         0.         0.
 1.         1.         0.         0.         0.80285718 0.31049203
 1.         0.         1.         0.24481956 0.33005318 0.52247038
 1.         0.11698403]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.32855688 1.
  1.         0.         0.        ]
 [1.         0.         0.34187955 0.17406497 0.31311932 1.
  0.         0.86125428 1.        ]
 [1.         0.         0.         0.         0.31313101 1.
  0.         0.         1.        ]
 [1.         0.         0.51401085 0.59962091 0.31320043 1.
  0.         0.12351895 1.        ]
 [1.         0.         1.         1.         0.31299431 1.
  0.         0.22850889 1.        ]
 [1.         0.         1.         1.         0.31325808 1.
  0.         0.59681986 1.        ]
 [1.         0.         0.         0.         0.31311231 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.31301916 1.
  0.         0.         1.        ]
 [1.         0.         0.28259243 0.35591373 0.31329113 1.
  0.         0.44709297 1.        ]
 [1.         0.         1.         1.         0.31305234 1.
  0.         1.         1.        ]
 [1.         0.         0.89701044 0.93930094 0.31320747 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.31317085 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.31326928 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.31314481 1.
  0.         1.         1.        ]
 [1.         0.         0.26701694 0.35009166 0.31318181 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.31330762 1.
  0.         0.         1.        ]
 [1.         0.         0.88319782 0.90212514 0.31321167 1.
  0.         0.80285718 1.        ]
 [1.         0.         1.         1.         0.31300436 1.
  0.         0.31049203 1.        ]
 [1.         0.         0.81710671 0.79235343 0.31304151 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.03160693 0.31305598 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.31341326 1.
  0.         1.         1.        ]
 [1.         0.         0.17527567 0.23428275 0.31330323 1.
  0.         0.24481956 1.        ]
 [1.         0.         0.26457371 0.22965318 0.31336722 1.
  0.         0.33005318 1.        ]
 [1.         0.         1.         1.         0.3131153  1.
  0.         0.52247038 1.        ]
 [1.         0.         1.         1.         0.31329422 1.
  0.         1.         1.        ]
 [1.         0.         0.56586728 0.6105476  0.3133664  1.
  0.         0.11698403 1.        ]]

Best Training Poisoning Accuracy:
0.9166666865348816
#####################         POISON         ###############################################

############################################################################################

comm_round: 17 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8

Accuracy per class:
[[8 0]
 [0 0]]
[ 1. nan]
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         1.         0.74987089 1.         1.         1.
 0.94455826 0.04721552 0.         0.         1.         0.
 0.81431093 1.         1.         0.         0.         0.18949189
 0.         0.81967322 0.35826496 0.83727858 1.         0.
 1.         0.        ]
wv_ed shape (26,)
[0.         1.         0.5984008  1.         0.90471602 1.
 0.91005336 0.         0.         0.         1.         0.
 0.70991955 1.         1.         0.         0.         0.23663977
 0.         0.84101815 0.28189768 0.82723476 1.         0.
 1.         0.        ]
wv_lg shape (26, 1)
[[0.32984311]
 [0.31500223]
 [0.31491923]
 [0.31482132]
 [0.31461102]
 [0.31494495]
 [0.31462997]
 [0.31455075]
 [0.31493169]
 [0.31490397]
 [0.31475953]
 [0.31489125]
 [0.31470014]
 [0.314778  ]
 [0.31449554]
 [0.3147476 ]
 [0.3144128 ]
 [0.3146906 ]
 [0.31471696]
 [0.31479798]
 [0.31503968]
 [0.31494893]
 [0.31466599]
 [0.31467997]
 [0.31473862]
 [0.31469222]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         1.         1.         1.         1.         1.
 0.58538218 0.01148207 0.         0.         1.         0.
 1.         1.         1.         0.         0.         0.
 0.         0.70505193 0.58071935 0.95381016 1.         0.
 1.         0.04883131]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.32984311 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.31500223 1.
  0.         1.         1.        ]
 [1.         0.         0.74987089 0.5984008  0.31491923 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.31482132 1.
  0.         1.         1.        ]
 [1.         0.         1.         0.90471602 0.31461102 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.31494495 1.
  0.         1.         1.        ]
 [1.         0.         0.94455826 0.91005336 0.31462997 1.
  0.         0.58538218 1.        ]
 [1.         0.         0.04721552 0.         0.31455075 1.
  0.         0.01148207 1.        ]
 [1.         0.         0.         0.         0.31493169 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.31490397 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.31475953 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.31489125 1.
  0.         0.         1.        ]
 [1.         0.         0.81431093 0.70991955 0.31470014 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.314778   1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.31449554 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.3147476  1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.3144128  1.
  0.         0.         1.        ]
 [1.         0.         0.18949189 0.23663977 0.3146906  1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.31471696 1.
  0.         0.         1.        ]
 [1.         0.         0.81967322 0.84101815 0.31479798 1.
  0.         0.70505193 1.        ]
 [1.         0.         0.35826496 0.28189768 0.31503968 1.
  0.         0.58071935 1.        ]
 [1.         0.         0.83727858 0.82723476 0.31494893 1.
  0.         0.95381016 1.        ]
 [1.         0.         1.         1.         0.31466599 1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.31467997 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.31473862 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.31469222 1.
  0.         0.04883131 1.        ]]

Best Training Poisoning Accuracy:
0.9166666865348816
#####################         POISON         ###############################################

############################################################################################

comm_round: 18 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8

Accuracy per class:
[[8 0]
 [0 0]]
[ 1. nan]
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.         0.25906604 1.         0.7088068  0.
 0.         0.         0.46809809 0.         0.         1.
 0.         0.         0.         0.         0.         0.18731453
 0.74949646 0.         0.02883138 0.         0.         0.27081278
 0.57953307 0.91867368]
wv_ed shape (26,)
[0.         0.         0.29300826 1.         0.74073929 0.
 0.         0.         0.44280281 0.         0.         1.
 0.         0.         0.         0.         0.         0.22943355
 0.69803428 0.         0.01113109 0.         0.         0.33004243
 0.68459681 1.        ]
wv_lg shape (26, 1)
[[0.33103277]
 [0.31613757]
 [0.31625858]
 [0.31671789]
 [0.31630524]
 [0.31625603]
 [0.31631799]
 [0.31626997]
 [0.31619285]
 [0.3162859 ]
 [0.31623036]
 [0.3162683 ]
 [0.31626326]
 [0.31648164]
 [0.31604106]
 [0.31646598]
 [0.31632297]
 [0.31640569]
 [0.31631863]
 [0.3162355 ]
 [0.31629274]
 [0.31643834]
 [0.31618876]
 [0.31641772]
 [0.31636733]
 [0.31626788]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.         0.         1.         0.84257554 0.
 0.         0.         0.80233643 0.         0.         1.
 0.         0.         0.         0.20961857 0.         0.12099807
 0.75412803 0.         0.         0.         0.         0.4756833
 0.21445169 0.26838209]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.33103277 1.
  1.         0.         0.        ]
 [1.         0.         0.         0.         0.31613757 1.
  0.         0.         1.        ]
 [1.         0.         0.25906604 0.29300826 0.31625858 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.31671789 1.
  0.         1.         1.        ]
 [1.         0.         0.7088068  0.74073929 0.31630524 1.
  0.         0.84257554 1.        ]
 [1.         0.         0.         0.         0.31625603 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.31631799 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.31626997 1.
  0.         0.         1.        ]
 [1.         0.         0.46809809 0.44280281 0.31619285 1.
  0.         0.80233643 1.        ]
 [1.         0.         0.         0.         0.3162859  1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.31623036 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.3162683  1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.31626326 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.31648164 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.31604106 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.31646598 1.
  0.         0.20961857 1.        ]
 [1.         0.         0.         0.         0.31632297 1.
  0.         0.         1.        ]
 [1.         0.         0.18731453 0.22943355 0.31640569 1.
  0.         0.12099807 1.        ]
 [1.         0.         0.74949646 0.69803428 0.31631863 1.
  0.         0.75412803 1.        ]
 [1.         0.         0.         0.         0.3162355  1.
  0.         0.         1.        ]
 [1.         0.         0.02883138 0.01113109 0.31629274 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.31643834 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.31618876 1.
  0.         0.         1.        ]
 [1.         0.         0.27081278 0.33004243 0.31641772 1.
  0.         0.4756833  1.        ]
 [1.         0.         0.57953307 0.68459681 0.31636733 1.
  0.         0.21445169 1.        ]
 [1.         0.         0.91867368 1.         0.31626788 1.
  0.         0.26838209 1.        ]]

Best Training Poisoning Accuracy:
1.0
#####################         POISON         ###############################################

############################################################################################

comm_round: 19 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8

Accuracy per class:
[[8 0]
 [0 0]]
[ 1. nan]
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.68797226 0.10184491 0.34198793 0.62992077 1.
 0.20492969 0.99658731 0.         0.0851236  0.         0.
 0.50074692 0.         0.         1.         0.71305855 1.
 1.         0.         1.         1.         1.         0.
 0.27395871 0.        ]
wv_ed shape (26,)
[0.         0.69422842 0.         0.45065163 0.74910167 1.
 0.1676228  0.88252295 0.         0.07188785 0.01773637 0.
 0.39645102 0.         0.         1.         0.78007869 1.
 1.         0.         1.         1.         1.         0.
 0.27797367 0.        ]
wv_lg shape (26, 1)
[[0.33182157]
 [0.31802622]
 [0.31811027]
 [0.31805859]
 [0.31804951]
 [0.31835113]
 [0.31800225]
 [0.31828601]
 [0.31808033]
 [0.31818559]
 [0.31805364]
 [0.3180415 ]
 [0.31843235]
 [0.31787927]
 [0.31791532]
 [0.31847688]
 [0.3183352 ]
 [0.31779893]
 [0.31824098]
 [0.31812009]
 [0.31843184]
 [0.31819492]
 [0.31840749]
 [0.31798881]
 [0.31836186]
 [0.31800996]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.         0.         0.         0.37395238 1.
 0.13557609 1.         0.         0.         0.         0.
 1.         0.         0.         0.96805806 0.15341957 1.
 0.75507019 0.         1.         1.         1.         0.
 0.35555706 0.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.33182157 1.
  1.         0.         0.        ]
 [1.         0.         0.68797226 0.69422842 0.31802622 1.
  0.         0.         1.        ]
 [1.         0.         0.10184491 0.         0.31811027 1.
  0.         0.         1.        ]
 [1.         0.         0.34198793 0.45065163 0.31805859 1.
  0.         0.         1.        ]
 [1.         0.         0.62992077 0.74910167 0.31804951 1.
  0.         0.37395238 1.        ]
 [1.         0.         1.         1.         0.31835113 1.
  0.         1.         1.        ]
 [1.         0.         0.20492969 0.1676228  0.31800225 1.
  0.         0.13557609 1.        ]
 [1.         0.         0.99658731 0.88252295 0.31828601 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.31808033 1.
  0.         0.         1.        ]
 [1.         0.         0.0851236  0.07188785 0.31818559 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.01773637 0.31805364 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.3180415  1.
  0.         0.         1.        ]
 [1.         0.         0.50074692 0.39645102 0.31843235 1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.31787927 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.31791532 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.31847688 1.
  0.         0.96805806 1.        ]
 [1.         0.         0.71305855 0.78007869 0.3183352  1.
  0.         0.15341957 1.        ]
 [1.         0.         1.         1.         0.31779893 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.31824098 1.
  0.         0.75507019 1.        ]
 [1.         0.         0.         0.         0.31812009 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.31843184 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.31819492 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.31840749 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.31798881 1.
  0.         0.         1.        ]
 [1.         0.         0.27395871 0.27797367 0.31836186 1.
  0.         0.35555706 1.        ]
 [1.         0.         0.         0.         0.31800996 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
1.0
#####################         POISON         ###############################################

############################################################################################

comm_round: 20 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8

Accuracy per class:
[[8 0]
 [0 0]]
[ 1. nan]
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.         1.         1.         0.         1.
 0.         0.17032741 0.68615479 1.         1.         0.12389009
 0.         1.         0.         1.         1.         0.
 0.91754449 0.         1.         1.         0.27915407 0.89383316
 1.         1.        ]
wv_ed shape (26,)
[0.         0.         1.         1.         0.         1.
 0.         0.         0.58847132 1.         1.         0.
 0.         1.         0.         1.         1.         0.
 0.75298701 0.         1.         1.         0.21408767 0.73782619
 1.         1.        ]
wv_lg shape (26, 1)
[[0.33288311]
 [0.31938753]
 [0.31991409]
 [0.31973159]
 [0.31958866]
 [0.31964008]
 [0.31943938]
 [0.31960099]
 [0.3195602 ]
 [0.31956905]
 [0.31972263]
 [0.31969444]
 [0.31994566]
 [0.3195691 ]
 [0.31967408]
 [0.31962166]
 [0.31966222]
 [0.31957722]
 [0.31962268]
 [0.31958575]
 [0.31983933]
 [0.31977689]
 [0.31944216]
 [0.31963534]
 [0.3196685 ]
 [0.31964002]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.         1.         1.         0.         1.
 0.         0.69965214 0.         1.         1.         1.
 0.44665551 1.         0.         1.         1.         0.
 1.         0.         1.         1.         0.         1.
 1.         1.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.33288311 1.
  1.         0.         0.        ]
 [1.         0.         0.         0.         0.31938753 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.31991409 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.31973159 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.31958866 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.31964008 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.31943938 1.
  0.         0.         1.        ]
 [1.         0.         0.17032741 0.         0.31960099 1.
  0.         0.69965214 1.        ]
 [1.         0.         0.68615479 0.58847132 0.3195602  1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.31956905 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.31972263 1.
  0.         1.         1.        ]
 [1.         0.         0.12389009 0.         0.31969444 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.31994566 1.
  0.         0.44665551 1.        ]
 [1.         0.         1.         1.         0.3195691  1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.31967408 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.31962166 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.31966222 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.31957722 1.
  0.         0.         1.        ]
 [1.         0.         0.91754449 0.75298701 0.31962268 1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.31958575 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.31983933 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.31977689 1.
  0.         1.         1.        ]
 [1.         0.         0.27915407 0.21408767 0.31944216 1.
  0.         0.         1.        ]
 [1.         0.         0.89383316 0.73782619 0.31963534 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.3196685  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.31964002 1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.9166666865348816
#####################         POISON         ###############################################

############################################################################################

comm_round: 21 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8

Accuracy per class:
[[8 0]
 [0 0]]
[ 1. nan]
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.59305847 0.1916275  0.         0.83458294 0.
 0.56145744 1.         0.         0.17729805 0.         0.27949783
 0.13475064 0.         1.         1.         0.75847238 0.
 1.         0.         0.84615293 0.48943321 0.6761226  1.
 1.         1.        ]
wv_ed shape (26,)
[0.         0.68073768 0.31873412 0.         0.90663782 0.
 0.65339551 1.         0.         0.22623532 0.         0.41088108
 0.26363371 0.         1.         1.         0.92094637 0.
 1.         0.         0.90444165 0.55058523 0.78396    1.
 1.         1.        ]
wv_lg shape (26, 1)
[[0.3339813 ]
 [0.32092633]
 [0.32105474]
 [0.32077071]
 [0.32097726]
 [0.32066164]
 [0.32080102]
 [0.32076636]
 [0.32087312]
 [0.32098426]
 [0.32084451]
 [0.32082816]
 [0.32105546]
 [0.32083294]
 [0.32110851]
 [0.32106874]
 [0.32105117]
 [0.32080665]
 [0.32096076]
 [0.32091386]
 [0.32095653]
 [0.32080823]
 [0.32095203]
 [0.32094278]
 [0.32109661]
 [0.32082066]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.48625054 0.6195285  0.         0.91674583 0.
 0.23694638 1.         0.         0.91087334 0.         0.
 0.         0.         1.         1.         0.66149465 0.
 1.         0.         0.68216131 0.40043514 0.93875098 1.
 1.         1.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.3339813  1.
  1.         0.         0.        ]
 [1.         0.         0.59305847 0.68073768 0.32092633 1.
  0.         0.48625054 1.        ]
 [1.         0.         0.1916275  0.31873412 0.32105474 1.
  0.         0.6195285  1.        ]
 [1.         0.         0.         0.         0.32077071 1.
  0.         0.         1.        ]
 [1.         0.         0.83458294 0.90663782 0.32097726 1.
  0.         0.91674583 1.        ]
 [1.         0.         0.         0.         0.32066164 1.
  0.         0.         1.        ]
 [1.         0.         0.56145744 0.65339551 0.32080102 1.
  0.         0.23694638 1.        ]
 [1.         0.         1.         1.         0.32076636 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.32087312 1.
  0.         0.         1.        ]
 [1.         0.         0.17729805 0.22623532 0.32098426 1.
  0.         0.91087334 1.        ]
 [1.         0.         0.         0.         0.32084451 1.
  0.         0.         1.        ]
 [1.         0.         0.27949783 0.41088108 0.32082816 1.
  0.         0.         1.        ]
 [1.         0.         0.13475064 0.26363371 0.32105546 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.32083294 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.32110851 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.32106874 1.
  0.         1.         1.        ]
 [1.         0.         0.75847238 0.92094637 0.32105117 1.
  0.         0.66149465 1.        ]
 [0.         0.         0.         0.         0.32080665 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.32096076 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.32091386 1.
  0.         0.         1.        ]
 [1.         0.         0.84615293 0.90444165 0.32095653 1.
  0.         0.68216131 1.        ]
 [1.         0.         0.48943321 0.55058523 0.32080823 1.
  0.         0.40043514 1.        ]
 [1.         0.         0.6761226  0.78396    0.32095203 1.
  0.         0.93875098 1.        ]
 [1.         0.         1.         1.         0.32094278 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.32109661 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.32082066 1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.9166666865348816
#####################         POISON         ###############################################

############################################################################################

comm_round: 22 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8

Accuracy per class:
[[8 0]
 [0 0]]
[ 1. nan]
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         1.         0.         0.56120763 1.         0.
 1.         0.4607881  0.         0.         1.         0.25769036
 0.30931207 0.80086495 0.75348414 1.         1.         0.54794845
 0.         0.53329831 1.         1.         1.         0.37952189
 0.         1.        ]
wv_ed shape (26,)
[0.         1.         0.         0.58755822 1.         0.
 1.         0.37300836 0.         0.         1.         0.11325691
 0.20638861 0.70681074 0.81697004 1.         1.         0.51386576
 0.         0.52024844 1.         1.         1.         0.35982512
 0.         1.        ]
wv_lg shape (26, 1)
[[0.33475588]
 [0.32240156]
 [0.32239818]
 [0.32258625]
 [0.32248649]
 [0.3222349 ]
 [0.32259941]
 [0.32244758]
 [0.32233958]
 [0.32237962]
 [0.32241499]
 [0.32244801]
 [0.32241322]
 [0.32252778]
 [0.32242812]
 [0.32246909]
 [0.32232774]
 [0.32238712]
 [0.32243346]
 [0.32240304]
 [0.32248727]
 [0.32253915]
 [0.32264523]
 [0.32237222]
 [0.32232789]
 [0.32255807]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         1.         0.         1.         1.         0.
 1.         0.9531213  0.         0.251494   1.         1.
 0.78309133 1.         1.         0.89430256 1.         0.92721497
 0.33838027 0.9085301  1.         1.         1.         1.
 0.         1.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.33475588 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.32240156 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.32239818 1.
  0.         0.         1.        ]
 [1.         0.         0.56120763 0.58755822 0.32258625 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.32248649 1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.3222349  1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.32259941 1.
  0.         1.         1.        ]
 [1.         0.         0.4607881  0.37300836 0.32244758 1.
  0.         0.9531213  1.        ]
 [1.         0.         0.         0.         0.32233958 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.32237962 1.
  0.         0.251494   1.        ]
 [1.         0.         1.         1.         0.32241499 1.
  0.         1.         1.        ]
 [1.         0.         0.25769036 0.11325691 0.32244801 1.
  0.         1.         1.        ]
 [1.         0.         0.30931207 0.20638861 0.32241322 1.
  0.         0.78309133 1.        ]
 [1.         0.         0.80086495 0.70681074 0.32252778 1.
  0.         1.         1.        ]
 [1.         0.         0.75348414 0.81697004 0.32242812 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.32246909 1.
  0.         0.89430256 1.        ]
 [1.         0.         1.         1.         0.32232774 1.
  0.         1.         1.        ]
 [1.         0.         0.54794845 0.51386576 0.32238712 1.
  0.         0.92721497 1.        ]
 [1.         0.         0.         0.         0.32243346 1.
  0.         0.33838027 1.        ]
 [1.         0.         0.53329831 0.52024844 0.32240304 1.
  0.         0.9085301  1.        ]
 [1.         0.         1.         1.         0.32248727 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.32253915 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.32264523 1.
  0.         1.         1.        ]
 [1.         0.         0.37952189 0.35982512 0.32237222 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.32232789 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.32255807 1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.9166666865348816
#####################         POISON         ###############################################

############################################################################################

comm_round: 23 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8

Accuracy per class:
[[8 0]
 [0 0]]
[ 1. nan]
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.         1.         1.         0.         0.
 1.         0.         1.         0.         0.         0.06631622
 0.82006623 1.         0.97986659 0.44685308 0.         1.
 0.         1.         0.         0.         0.13742653 0.16213335
 0.02019652 0.28583405]
wv_ed shape (26,)
[0.         0.         1.         1.         0.05860044 0.
 1.         0.         1.         0.         0.         0.16000724
 0.96071034 1.         1.         0.50858308 0.         1.
 0.         1.         0.         0.         0.20080257 0.08561017
 0.23913139 0.2816284 ]
wv_lg shape (26, 1)
[[0.3355306 ]
 [0.32362198]
 [0.32375613]
 [0.32386437]
 [0.32367265]
 [0.3237824 ]
 [0.32400249]
 [0.32379598]
 [0.32386693]
 [0.3237301 ]
 [0.32365253]
 [0.32384742]
 [0.32408691]
 [0.32398869]
 [0.3239979 ]
 [0.32409192]
 [0.32374957]
 [0.32393192]
 [0.32376024]
 [0.32387993]
 [0.3238418 ]
 [0.32383619]
 [0.32390581]
 [0.32383194]
 [0.32386659]
 [0.32391937]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.         1.         0.96447313 0.         0.
 1.         0.         1.         1.         0.         1.
 1.         1.         1.         1.         0.18935562 0.98922476
 0.         1.         0.         0.         0.37545487 0.19334158
 0.4386275  1.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.3355306  1.
  1.         0.         0.        ]
 [1.         0.         0.         0.         0.32362198 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.32375613 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.32386437 1.
  0.         0.96447313 1.        ]
 [1.         0.         0.         0.05860044 0.32367265 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.3237824  1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.32400249 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.32379598 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.32386693 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.3237301  1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.32365253 1.
  0.         0.         1.        ]
 [1.         0.         0.06631622 0.16000724 0.32384742 1.
  0.         1.         1.        ]
 [1.         0.         0.82006623 0.96071034 0.32408691 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.32398869 1.
  0.         1.         1.        ]
 [1.         0.         0.97986659 1.         0.3239979  1.
  0.         1.         1.        ]
 [1.         0.         0.44685308 0.50858308 0.32409192 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.32374957 1.
  0.         0.18935562 1.        ]
 [1.         0.         1.         1.         0.32393192 1.
  0.         0.98922476 1.        ]
 [1.         0.         0.         0.         0.32376024 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.32387993 1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.3238418  1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.32383619 1.
  0.         0.         1.        ]
 [1.         0.         0.13742653 0.20080257 0.32390581 1.
  0.         0.37545487 1.        ]
 [1.         0.         0.16213335 0.08561017 0.32383194 1.
  0.         0.19334158 1.        ]
 [1.         0.         0.02019652 0.23913139 0.32386659 1.
  0.         0.4386275  1.        ]
 [1.         0.         0.28583405 0.2816284  0.32391937 1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.9166666865348816
#####################         POISON         ###############################################

############################################################################################

comm_round: 24 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8

Accuracy per class:
[[8 0]
 [0 0]]
[ 1. nan]
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.02068602 0.30834808 0.05431109 0.         0.
 0.         0.41302183 1.         1.         0.         0.
 0.         0.         0.         0.52451956 0.28177311 0.
 0.5465124  0.13297765 0.         0.83706971 0.         0.
 0.         1.        ]
wv_ed shape (26,)
[0.         0.07994946 0.32378217 0.05935668 0.         0.
 0.         0.47255235 1.         1.         0.         0.
 0.         0.         0.         0.53014365 0.33316682 0.
 0.55552907 0.06518635 0.         0.84597023 0.         0.
 0.         1.        ]
wv_lg shape (26, 1)
[[0.33647935]
 [0.32484309]
 [0.3251127 ]
 [0.32500781]
 [0.32492342]
 [0.32497848]
 [0.32502626]
 [0.32516358]
 [0.32501592]
 [0.32501995]
 [0.32488154]
 [0.32486915]
 [0.32479578]
 [0.32508769]
 [0.32509186]
 [0.32504535]
 [0.32495551]
 [0.32498429]
 [0.3251511 ]
 [0.32509099]
 [0.32501146]
 [0.32510123]
 [0.32498303]
 [0.32513825]
 [0.32486554]
 [0.32513464]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.14969295 0.30343892 0.80764594 0.         0.
 0.         1.         1.         1.         0.         0.
 0.         0.23024074 0.02119303 1.         0.24685337 0.
 0.86092156 0.59416413 0.         1.         0.         0.
 0.         1.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.33647935 1.
  1.         0.         0.        ]
 [1.         0.         0.02068602 0.07994946 0.32484309 1.
  0.         0.14969295 1.        ]
 [1.         0.         0.30834808 0.32378217 0.3251127  1.
  0.         0.30343892 1.        ]
 [1.         0.         0.05431109 0.05935668 0.32500781 1.
  0.         0.80764594 1.        ]
 [1.         0.         0.         0.         0.32492342 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.32497848 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.32502626 1.
  0.         0.         1.        ]
 [1.         0.         0.41302183 0.47255235 0.32516358 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.32501592 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.32501995 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.32488154 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.32486915 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.32479578 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.32508769 1.
  0.         0.23024074 1.        ]
 [1.         0.         0.         0.         0.32509186 1.
  0.         0.02119303 1.        ]
 [1.         0.         0.52451956 0.53014365 0.32504535 1.
  0.         1.         1.        ]
 [1.         0.         0.28177311 0.33316682 0.32495551 1.
  0.         0.24685337 1.        ]
 [0.         0.         0.         0.         0.32498429 1.
  0.         0.         1.        ]
 [1.         0.         0.5465124  0.55552907 0.3251511  1.
  0.         0.86092156 1.        ]
 [1.         0.         0.13297765 0.06518635 0.32509099 1.
  0.         0.59416413 1.        ]
 [1.         0.         0.         0.         0.32501146 1.
  0.         0.         1.        ]
 [1.         0.         0.83706971 0.84597023 0.32510123 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.32498303 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.32513825 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.32486554 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.32513464 1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.9166666865348816
#####################         POISON         ###############################################

############################################################################################

comm_round: 25 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8

Accuracy per class:
[[8 0]
 [0 0]]
[ 1. nan]
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.14978587 1.         0.         1.         1.
 1.         0.28512427 0.10475386 0.17827424 0.         1.
 0.58609764 1.         0.62816838 0.50461869 1.         0.64521623
 0.12121497 0.26227154 0.56146871 0.         0.68654848 0.
 0.         0.        ]
wv_ed shape (26,)
[0.         0.07199989 1.         0.         1.         1.
 1.         0.14934304 0.04141558 0.08074192 0.         1.
 0.5751233  1.         0.58800922 0.51246644 1.         0.61307198
 0.01927985 0.19392711 0.42662161 0.         0.65168992 0.
 0.         0.        ]
wv_lg shape (26, 1)
[[0.33745809]
 [0.32596762]
 [0.32612195]
 [0.32587154]
 [0.32625516]
 [0.32599096]
 [0.32618347]
 [0.32605277]
 [0.32607405]
 [0.32612534]
 [0.3260917 ]
 [0.3260626 ]
 [0.32612391]
 [0.32604016]
 [0.32621433]
 [0.32615258]
 [0.32614262]
 [0.32601463]
 [0.325883  ]
 [0.32618376]
 [0.32622801]
 [0.32613856]
 [0.32613115]
 [0.32609111]
 [0.32588393]
 [0.32591011]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.16955622 1.         0.         1.         1.
 1.         0.73515362 0.89225511 0.84889379 0.         1.
 1.         1.         0.80272098 1.         1.         0.54824821
 0.31013911 0.63081084 1.         0.31529545 1.         0.
 1.         0.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.33745809 1.
  1.         0.         0.        ]
 [1.         0.         0.14978587 0.07199989 0.32596762 1.
  0.         0.16955622 1.        ]
 [1.         0.         1.         1.         0.32612195 1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.32587154 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.32625516 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.32599096 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.32618347 1.
  0.         1.         1.        ]
 [1.         0.         0.28512427 0.14934304 0.32605277 1.
  0.         0.73515362 1.        ]
 [1.         0.         0.10475386 0.04141558 0.32607405 1.
  0.         0.89225511 1.        ]
 [1.         0.         0.17827424 0.08074192 0.32612534 1.
  0.         0.84889379 1.        ]
 [1.         0.         0.         0.         0.3260917  1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.3260626  1.
  0.         1.         1.        ]
 [1.         0.         0.58609764 0.5751233  0.32612391 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.32604016 1.
  0.         1.         1.        ]
 [1.         0.         0.62816838 0.58800922 0.32621433 1.
  0.         0.80272098 1.        ]
 [1.         0.         0.50461869 0.51246644 0.32615258 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.32614262 1.
  0.         1.         1.        ]
 [1.         0.         0.64521623 0.61307198 0.32601463 1.
  0.         0.54824821 1.        ]
 [1.         0.         0.12121497 0.01927985 0.325883   1.
  0.         0.31013911 1.        ]
 [1.         0.         0.26227154 0.19392711 0.32618376 1.
  0.         0.63081084 1.        ]
 [1.         0.         0.56146871 0.42662161 0.32622801 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.32613856 1.
  0.         0.31529545 1.        ]
 [1.         0.         0.68654848 0.65168992 0.32613115 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.32609111 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.32588393 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.32591011 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.9166666865348816
#####################         POISON         ###############################################

############################################################################################

comm_round: 26 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8

Accuracy per class:
[[8 0]
 [0 0]]
[ 1. nan]
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         1.         1.         0.         1.         0.
 1.         1.         1.         1.         0.77840744 1.
 1.         1.         0.         1.         0.         1.
 0.         0.66697211 0.         0.         1.         0.89688118
 0.         1.        ]
wv_ed shape (26,)
[0.         1.         1.         0.         1.         0.
 1.         1.         1.         1.         0.67766126 1.
 1.         1.         0.         1.         0.         1.
 0.         0.68174624 0.         0.         1.         0.82501914
 0.         1.        ]
wv_lg shape (26, 1)
[[0.33815207]
 [0.32753041]
 [0.32727697]
 [0.32725887]
 [0.32728419]
 [0.32720093]
 [0.32750052]
 [0.32750254]
 [0.32737827]
 [0.3272904 ]
 [0.32736331]
 [0.32737436]
 [0.32752241]
 [0.3272769 ]
 [0.32746855]
 [0.32759314]
 [0.32714131]
 [0.3276006 ]
 [0.32728487]
 [0.32715449]
 [0.32731943]
 [0.32724222]
 [0.3274395 ]
 [0.32735266]
 [0.32734261]
 [0.32730723]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         1.         0.97082082 0.         1.         0.
 1.         1.         1.         1.         0.60209101 1.
 1.         1.         0.         1.         0.         1.
 0.         0.22101634 0.         0.05372076 1.         0.38200661
 0.         0.62147324]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.33815207 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.32753041 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.32727697 1.
  0.         0.97082082 1.        ]
 [1.         0.         0.         0.         0.32725887 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.32728419 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.32720093 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.32750052 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.32750254 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.32737827 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.3272904  1.
  0.         1.         1.        ]
 [1.         0.         0.77840744 0.67766126 0.32736331 1.
  0.         0.60209101 1.        ]
 [1.         0.         1.         1.         0.32737436 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.32752241 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.3272769  1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.32746855 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.32759314 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.32714131 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.3276006  1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.32728487 1.
  0.         0.         1.        ]
 [1.         0.         0.66697211 0.68174624 0.32715449 1.
  0.         0.22101634 1.        ]
 [1.         0.         0.         0.         0.32731943 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.32724222 1.
  0.         0.05372076 1.        ]
 [1.         0.         1.         1.         0.3274395  1.
  0.         1.         1.        ]
 [1.         0.         0.89688118 0.82501914 0.32735266 1.
  0.         0.38200661 1.        ]
 [1.         0.         0.         0.         0.32734261 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.32730723 1.
  0.         0.62147324 1.        ]]

Best Training Poisoning Accuracy:
0.9166666865348816
#####################         POISON         ###############################################

############################################################################################

comm_round: 27 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8

Accuracy per class:
[[8 0]
 [0 0]]
[ 1. nan]
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.93670002 0.         1.         0.28329529 1.
 0.85224227 0.         0.02788474 1.         0.         0.44630542
 0.00887325 0.11664338 0.         1.         0.         1.
 0.         0.         0.         1.         1.         0.
 0.         0.        ]
wv_ed shape (26,)
[0.         0.77525442 0.         0.99807747 0.2835051  1.
 0.74870537 0.         0.         1.         0.         0.48752622
 0.         0.03471063 0.         1.         0.         1.
 0.         0.         0.         1.         1.         0.
 0.         0.        ]
wv_lg shape (26, 1)
[[0.33908419]
 [0.32828581]
 [0.32816539]
 [0.32821625]
 [0.32830372]
 [0.32844855]
 [0.3284368 ]
 [0.32821977]
 [0.3282548 ]
 [0.32844734]
 [0.32833319]
 [0.32834347]
 [0.32832539]
 [0.32831781]
 [0.32846443]
 [0.32846119]
 [0.32825746]
 [0.32841088]
 [0.3282854 ]
 [0.32835058]
 [0.32830181]
 [0.32832768]
 [0.32840625]
 [0.32832458]
 [0.32834545]
 [0.32830333]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         1.         0.         1.         0.14783121 1.
 1.         0.         0.         1.         0.02341218 0.
 0.         0.2371965  0.45199254 1.         0.         1.
 0.         0.         0.         0.95361516 1.         0.
 0.26812648 0.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.33908419 1.
  1.         0.         0.        ]
 [1.         0.         0.93670002 0.77525442 0.32828581 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.32816539 1.
  0.         0.         1.        ]
 [1.         0.         1.         0.99807747 0.32821625 1.
  0.         1.         1.        ]
 [1.         0.         0.28329529 0.2835051  0.32830372 1.
  0.         0.14783121 1.        ]
 [1.         0.         1.         1.         0.32844855 1.
  0.         1.         1.        ]
 [1.         0.         0.85224227 0.74870537 0.3284368  1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.32821977 1.
  0.         0.         1.        ]
 [1.         0.         0.02788474 0.         0.3282548  1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.32844734 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.32833319 1.
  0.         0.02341218 1.        ]
 [1.         0.         0.44630542 0.48752622 0.32834347 1.
  0.         0.         1.        ]
 [1.         0.         0.00887325 0.         0.32832539 1.
  0.         0.         1.        ]
 [1.         0.         0.11664338 0.03471063 0.32831781 1.
  0.         0.2371965  1.        ]
 [1.         0.         0.         0.         0.32846443 1.
  0.         0.45199254 1.        ]
 [1.         0.         1.         1.         0.32846119 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.32825746 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.32841088 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.3282854  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.32835058 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.32830181 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.32832768 1.
  0.         0.95361516 1.        ]
 [1.         0.         1.         1.         0.32840625 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.32832458 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.32834545 1.
  0.         0.26812648 1.        ]
 [1.         0.         0.         0.         0.32830333 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
1.0
#####################         POISON         ###############################################

############################################################################################

comm_round: 28 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8

Accuracy per class:
[[8 0]
 [0 0]]
[ 1. nan]
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.02410237 0.         0.         0.54141858 0.
 0.         0.         1.         1.         1.         0.
 0.         1.         1.         0.         0.51637389 0.
 0.2582194  0.         0.55602732 1.         0.00516916 0.73749093
 0.21778864 0.46507175]
wv_ed shape (26,)
[0.         0.03759417 0.         0.         0.71068012 0.
 0.         0.         1.         1.         1.         0.
 0.         1.         1.         0.         0.49340801 0.
 0.34666955 0.         0.62977818 1.         0.09703903 0.94042538
 0.24926774 0.49157424]
wv_lg shape (26, 1)
[[0.3396369 ]
 [0.32951285]
 [0.32957143]
 [0.32968207]
 [0.32954441]
 [0.32954672]
 [0.3294751 ]
 [0.32952892]
 [0.32985938]
 [0.3295272 ]
 [0.32969061]
 [0.32949932]
 [0.32953654]
 [0.32963228]
 [0.32957244]
 [0.32956268]
 [0.32978098]
 [0.32958655]
 [0.32964435]
 [0.32947791]
 [0.32965961]
 [0.32948212]
 [0.32961005]
 [0.32958866]
 [0.32977726]
 [0.32982268]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.37588517 0.         0.         0.         0.
 0.         0.         1.         1.         1.         0.
 0.         1.         1.         0.         1.         0.
 0.32003575 0.16387963 0.92455223 1.         0.12608596 0.42687334
 0.50501354 1.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.3396369  1.
  1.         0.         0.        ]
 [1.         0.         0.02410237 0.03759417 0.32951285 1.
  0.         0.37588517 1.        ]
 [1.         0.         0.         0.         0.32957143 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.32968207 1.
  0.         0.         1.        ]
 [1.         0.         0.54141858 0.71068012 0.32954441 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.32954672 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.3294751  1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.32952892 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.32985938 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.3295272  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.32969061 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.32949932 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.32953654 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.32963228 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.32957244 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.32956268 1.
  0.         0.         1.        ]
 [1.         0.         0.51637389 0.49340801 0.32978098 1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.32958655 1.
  0.         0.         1.        ]
 [1.         0.         0.2582194  0.34666955 0.32964435 1.
  0.         0.32003575 1.        ]
 [1.         0.         0.         0.         0.32947791 1.
  0.         0.16387963 1.        ]
 [1.         0.         0.55602732 0.62977818 0.32965961 1.
  0.         0.92455223 1.        ]
 [1.         0.         1.         1.         0.32948212 1.
  0.         1.         1.        ]
 [1.         0.         0.00516916 0.09703903 0.32961005 1.
  0.         0.12608596 1.        ]
 [1.         0.         0.73749093 0.94042538 0.32958866 1.
  0.         0.42687334 1.        ]
 [1.         0.         0.21778864 0.24926774 0.32977726 1.
  0.         0.50501354 1.        ]
 [1.         0.         0.46507175 0.49157424 0.32982268 1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
1.0
#####################         POISON         ###############################################

############################################################################################

comm_round: 29 | global_test_acc: 87.500% | global_f1: 0.9333333333333333 | global_precision: 0.875
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.88      1.00      0.93         7

    accuracy                           0.88         8
   macro avg       0.44      0.50      0.47         8
weighted avg       0.77      0.88      0.82         8

Accuracy per class:
[[7 0]
 [1 0]]
[1. 0.]
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         1.         1.         1.         0.7943641  1.
 1.         1.         0.85937485 0.         1.         0.
 0.44804646 0.         0.50060454 0.19929143 0.         0.
 1.         1.         0.         0.6306719  0.         0.28032727
 1.         1.        ]
wv_ed shape (26,)
[0.         1.         1.         1.         0.00496668 0.65489265
 0.98193021 1.         0.         0.         0.41158248 0.
 0.         0.         0.         0.         0.         0.
 0.         0.37155032 0.         0.         0.         0.
 1.         0.62099155]
wv_lg shape (26, 1)
[[0.38639993]
 [0.38100434]
 [0.38125389]
 [0.38148533]
 [0.38131993]
 [0.38066021]
 [0.37962979]
 [0.38162466]
 [0.37949414]
 [0.37919633]
 [0.37970896]
 [0.37725735]
 [0.38026462]
 [0.37827411]
 [0.38045189]
 [0.37975362]
 [0.38110122]
 [0.37938575]
 [0.3814589 ]
 [0.3807398 ]
 [0.37879713]
 [0.37849229]
 [0.37720956]
 [0.37934706]
 [0.3807979 ]
 [0.38194338]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1.         0.         0.         0.         0.         0.
 0.         0.09041631 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.        ]
wv_std shape (26,)
[0.         1.         1.         1.         0.4176775  1.
 0.74742476 1.         0.7008563  0.         1.         0.
 0.06308694 0.         0.80122254 1.         0.         0.
 0.63077898 1.         0.         0.32803347 0.         0.12606981
 1.         1.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.38639993 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.38100434 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.38125389 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.38148533 1.
  0.         1.         1.        ]
 [1.         0.         0.7943641  0.00496668 0.38131993 1.
  0.         0.4176775  1.        ]
 [1.         0.         1.         0.65489265 0.38066021 1.
  0.         1.         1.        ]
 [1.         0.         1.         0.98193021 0.37962979 1.
  0.         0.74742476 1.        ]
 [1.         0.         1.         1.         0.38162466 1.
  0.09041631 1.         1.        ]
 [1.         0.         0.85937485 0.         0.37949414 1.
  0.         0.7008563  1.        ]
 [1.         0.         0.         0.         0.37919633 1.
  0.         0.         1.        ]
 [1.         0.         1.         0.41158248 0.37970896 1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.37725735 1.
  0.         0.         1.        ]
 [1.         0.         0.44804646 0.         0.38026462 1.
  0.         0.06308694 1.        ]
 [1.         0.         0.         0.         0.37827411 1.
  0.         0.         1.        ]
 [1.         0.         0.50060454 0.         0.38045189 1.
  0.         0.80122254 1.        ]
 [1.         0.         0.19929143 0.         0.37975362 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.38110122 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.37938575 1.
  0.         0.         1.        ]
 [1.         0.         1.         0.         0.3814589  1.
  0.         0.63077898 1.        ]
 [1.         0.         1.         0.37155032 0.3807398  1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.37879713 1.
  0.         0.         1.        ]
 [1.         0.         0.6306719  0.         0.37849229 1.
  0.         0.32803347 1.        ]
 [1.         0.         0.         0.         0.37720956 1.
  0.         0.         1.        ]
 [1.         0.         0.28032727 0.         0.37934706 1.
  0.         0.12606981 1.        ]
 [1.         0.         1.         1.         0.3807979  1.
  0.         1.         1.        ]
 [1.         0.         1.         0.62099155 0.38194338 1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
1.0
#####################         POISON         ###############################################

############################################################################################

comm_round: 0 | global_test_acc: 87.500% | global_f1: 0.9333333333333333 | global_precision: 0.875
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.88      1.00      0.93         7

    accuracy                           0.88         8
   macro avg       0.44      0.50      0.47         8
weighted avg       0.77      0.88      0.82         8

Accuracy per class:
[[7 0]
 [1 0]]
[1. 0.]
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         1.         1.         1.         1.         0.63517877
 0.10784743 0.4857013  0.67334908 0.         1.         1.
 1.         0.87712985 0.53059054 1.         0.41023852 1.
 1.         1.         1.         0.         0.57492478 1.
 0.74731391 0.23020344]
wv_ed shape (26,)
[0.         0.95714675 1.         1.         1.         0.76471432
 0.05817063 0.4013901  0.46982163 0.         1.         1.
 0.76116536 0.64717243 0.43543085 0.94372209 0.25578549 1.
 1.         1.         1.         0.         0.51918866 1.
 0.67198529 0.20965421]
wv_lg shape (26, 1)
[[0.38695156]
 [0.38082956]
 [0.38093793]
 [0.38105675]
 [0.3812714 ]
 [0.380997  ]
 [0.3811019 ]
 [0.38101833]
 [0.38123336]
 [0.38092087]
 [0.38094855]
 [0.3811342 ]
 [0.38063755]
 [0.38075416]
 [0.38123716]
 [0.38082928]
 [0.38110244]
 [0.38054193]
 [0.38107946]
 [0.38074017]
 [0.38161788]
 [0.38073405]
 [0.38094691]
 [0.38074224]
 [0.38075824]
 [0.38058303]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.98711421 1.         0.97413765 1.         0.23409164
 0.         0.47873303 0.78968828 0.24430205 1.         1.
 1.         0.82240312 0.27084036 1.         0.39466701 1.
 1.         1.         1.         0.         0.21246015 1.
 0.30181507 0.2144859 ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.38695156 1.
  1.         0.         0.        ]
 [1.         0.         1.         0.95714675 0.38082956 1.
  0.         0.98711421 1.        ]
 [1.         0.         1.         1.         0.38093793 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.38105675 1.
  0.         0.97413765 1.        ]
 [1.         0.         1.         1.         0.3812714  1.
  0.         1.         1.        ]
 [1.         0.         0.63517877 0.76471432 0.380997   1.
  0.         0.23409164 1.        ]
 [1.         0.         0.10784743 0.05817063 0.3811019  1.
  0.         0.         1.        ]
 [1.         0.         0.4857013  0.4013901  0.38101833 1.
  0.         0.47873303 1.        ]
 [1.         0.         0.67334908 0.46982163 0.38123336 1.
  0.         0.78968828 1.        ]
 [1.         0.         0.         0.         0.38092087 1.
  0.         0.24430205 1.        ]
 [1.         0.         1.         1.         0.38094855 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.3811342  1.
  0.         1.         1.        ]
 [1.         0.         1.         0.76116536 0.38063755 1.
  0.         1.         1.        ]
 [1.         0.         0.87712985 0.64717243 0.38075416 1.
  0.         0.82240312 1.        ]
 [1.         0.         0.53059054 0.43543085 0.38123716 1.
  0.         0.27084036 1.        ]
 [1.         0.         1.         0.94372209 0.38082928 1.
  0.         1.         1.        ]
 [1.         0.         0.41023852 0.25578549 0.38110244 1.
  0.         0.39466701 1.        ]
 [1.         0.         1.         1.         0.38054193 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.38107946 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.38074017 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.38161788 1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.38073405 1.
  0.         0.         1.        ]
 [1.         0.         0.57492478 0.51918866 0.38094691 1.
  0.         0.21246015 1.        ]
 [1.         0.         1.         1.         0.38074224 1.
  0.         1.         1.        ]
 [1.         0.         0.74731391 0.67198529 0.38075824 1.
  0.         0.30181507 1.        ]
 [1.         0.         0.23020344 0.20965421 0.38058303 1.
  0.         0.2144859  1.        ]]

Best Training Poisoning Accuracy:
1.0
#####################         POISON         ###############################################

############################################################################################

comm_round: 1 | global_test_acc: 87.500% | global_f1: 0.9333333333333333 | global_precision: 0.875
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.88      1.00      0.93         7

    accuracy                           0.88         8
   macro avg       0.44      0.50      0.47         8
weighted avg       0.77      0.88      0.82         8

Accuracy per class:
[[7 0]
 [1 0]]
[1. 0.]
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.93839786 1.         1.         0.         0.
 0.14798751 0.         1.         0.16722129 0.29924974 1.
 1.         0.73503253 0.60585635 1.         1.         0.48524972
 0.77798418 0.         0.31117618 0.         0.         1.
 0.70756949 0.3674886 ]
wv_ed shape (26,)
[0.         1.         1.         1.         0.         0.
 0.57335479 0.         1.         0.21964514 0.55979452 1.
 1.         0.52606406 0.70356539 1.         1.         0.53149946
 1.         0.         0.71231103 0.         0.         1.
 0.98642539 0.66609577]
wv_lg shape (26, 1)
[[0.38730284]
 [0.38157964]
 [0.38224254]
 [0.38215049]
 [0.38196847]
 [0.38184546]
 [0.38184968]
 [0.38191941]
 [0.38157249]
 [0.381722  ]
 [0.38181942]
 [0.38167178]
 [0.38208104]
 [0.3821273 ]
 [0.38218502]
 [0.38178227]
 [0.38158917]
 [0.38206556]
 [0.38158196]
 [0.38160396]
 [0.38144833]
 [0.38203522]
 [0.38174504]
 [0.38171239]
 [0.382331  ]
 [0.3818666 ]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.00000000e+00 2.72964793e-01 1.00000000e+00 1.00000000e+00
 0.00000000e+00 1.45382548e-01 2.55492642e-04 0.00000000e+00
 1.00000000e+00 3.62843579e-01 6.10081053e-02 1.00000000e+00
 7.44646473e-01 6.52728733e-01 1.00000000e+00 1.00000000e+00
 8.14592058e-01 5.53137143e-01 4.18358350e-01 0.00000000e+00
 0.00000000e+00 0.00000000e+00 2.47327325e-01 1.00000000e+00
 1.00000000e+00 0.00000000e+00]
xy shape: (26, 9)
[[0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00
  3.87302840e-01 1.00000000e+00 1.00000000e+00 0.00000000e+00
  0.00000000e+00]
 [1.00000000e+00 0.00000000e+00 9.38397856e-01 1.00000000e+00
  3.81579638e-01 1.00000000e+00 0.00000000e+00 2.72964793e-01
  1.00000000e+00]
 [1.00000000e+00 0.00000000e+00 1.00000000e+00 1.00000000e+00
  3.82242536e-01 1.00000000e+00 0.00000000e+00 1.00000000e+00
  1.00000000e+00]
 [1.00000000e+00 0.00000000e+00 1.00000000e+00 1.00000000e+00
  3.82150492e-01 1.00000000e+00 0.00000000e+00 1.00000000e+00
  1.00000000e+00]
 [1.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
  3.81968466e-01 1.00000000e+00 0.00000000e+00 0.00000000e+00
  1.00000000e+00]
 [1.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
  3.81845459e-01 1.00000000e+00 0.00000000e+00 1.45382548e-01
  1.00000000e+00]
 [1.00000000e+00 0.00000000e+00 1.47987506e-01 5.73354793e-01
  3.81849675e-01 1.00000000e+00 0.00000000e+00 2.55492642e-04
  1.00000000e+00]
 [1.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
  3.81919405e-01 1.00000000e+00 0.00000000e+00 0.00000000e+00
  1.00000000e+00]
 [1.00000000e+00 0.00000000e+00 1.00000000e+00 1.00000000e+00
  3.81572488e-01 1.00000000e+00 0.00000000e+00 1.00000000e+00
  1.00000000e+00]
 [1.00000000e+00 0.00000000e+00 1.67221286e-01 2.19645143e-01
  3.81722000e-01 1.00000000e+00 0.00000000e+00 3.62843579e-01
  1.00000000e+00]
 [1.00000000e+00 0.00000000e+00 2.99249744e-01 5.59794520e-01
  3.81819419e-01 1.00000000e+00 0.00000000e+00 6.10081053e-02
  1.00000000e+00]
 [1.00000000e+00 0.00000000e+00 1.00000000e+00 1.00000000e+00
  3.81671781e-01 1.00000000e+00 0.00000000e+00 1.00000000e+00
  1.00000000e+00]
 [1.00000000e+00 0.00000000e+00 1.00000000e+00 1.00000000e+00
  3.82081042e-01 1.00000000e+00 0.00000000e+00 7.44646473e-01
  1.00000000e+00]
 [1.00000000e+00 0.00000000e+00 7.35032527e-01 5.26064058e-01
  3.82127295e-01 1.00000000e+00 0.00000000e+00 6.52728733e-01
  1.00000000e+00]
 [1.00000000e+00 0.00000000e+00 6.05856354e-01 7.03565394e-01
  3.82185015e-01 1.00000000e+00 0.00000000e+00 1.00000000e+00
  1.00000000e+00]
 [1.00000000e+00 0.00000000e+00 1.00000000e+00 1.00000000e+00
  3.81782270e-01 1.00000000e+00 0.00000000e+00 1.00000000e+00
  1.00000000e+00]
 [1.00000000e+00 0.00000000e+00 1.00000000e+00 1.00000000e+00
  3.81589171e-01 1.00000000e+00 0.00000000e+00 8.14592058e-01
  1.00000000e+00]
 [1.00000000e+00 0.00000000e+00 4.85249717e-01 5.31499463e-01
  3.82065558e-01 1.00000000e+00 0.00000000e+00 5.53137143e-01
  1.00000000e+00]
 [1.00000000e+00 0.00000000e+00 7.77984184e-01 1.00000000e+00
  3.81581958e-01 1.00000000e+00 0.00000000e+00 4.18358350e-01
  1.00000000e+00]
 [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
  3.81603962e-01 1.00000000e+00 0.00000000e+00 0.00000000e+00
  1.00000000e+00]
 [1.00000000e+00 0.00000000e+00 3.11176177e-01 7.12311032e-01
  3.81448328e-01 1.00000000e+00 0.00000000e+00 0.00000000e+00
  1.00000000e+00]
 [1.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
  3.82035220e-01 1.00000000e+00 0.00000000e+00 0.00000000e+00
  1.00000000e+00]
 [1.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
  3.81745040e-01 1.00000000e+00 0.00000000e+00 2.47327325e-01
  1.00000000e+00]
 [1.00000000e+00 0.00000000e+00 1.00000000e+00 1.00000000e+00
  3.81712391e-01 1.00000000e+00 0.00000000e+00 1.00000000e+00
  1.00000000e+00]
 [1.00000000e+00 0.00000000e+00 7.07569491e-01 9.86425389e-01
  3.82330997e-01 1.00000000e+00 0.00000000e+00 1.00000000e+00
  1.00000000e+00]
 [1.00000000e+00 0.00000000e+00 3.67488598e-01 6.66095773e-01
  3.81866598e-01 1.00000000e+00 0.00000000e+00 0.00000000e+00
  1.00000000e+00]]

Best Training Poisoning Accuracy:
1.0
#####################         POISON         ###############################################

############################################################################################

comm_round: 2 | global_test_acc: 87.500% | global_f1: 0.9333333333333333 | global_precision: 0.875
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.88      1.00      0.93         7

    accuracy                           0.88         8
   macro avg       0.44      0.50      0.47         8
weighted avg       0.77      0.88      0.82         8

Accuracy per class:
[[7 0]
 [1 0]]
[1. 0.]
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.4978818  0.         0.         0.92047789
 0.         1.         1.         0.46319313 0.97617737 0.10639908
 0.75876308 0.         0.13001495 0.         0.79923592 1.
 1.         0.        ]
wv_ed shape (26,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.21452753 0.         0.         1.
 0.         1.         1.         0.5352114  0.4855825  0.26019247
 0.14217289 0.         0.         0.00559699 0.81410699 1.
 1.         0.        ]
wv_lg shape (26, 1)
[[0.38785493]
 [0.38234788]
 [0.38262504]
 [0.38265728]
 [0.38262601]
 [0.38271187]
 [0.38257206]
 [0.3823148 ]
 [0.38265299]
 [0.38234468]
 [0.38218736]
 [0.38244965]
 [0.3825532 ]
 [0.38188974]
 [0.38239484]
 [0.3823437 ]
 [0.38222061]
 [0.38224163]
 [0.38232143]
 [0.3824953 ]
 [0.38241917]
 [0.38243873]
 [0.38238074]
 [0.38216433]
 [0.38253017]
 [0.38206844]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.         0.         0.         0.14616161 0.4130971
 0.         0.         0.55466383 0.         0.         0.27247123
 0.         1.         1.         0.55631331 0.87475809 0.
 1.         0.55314518 0.33294029 0.         0.85151002 1.
 1.         0.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.38785493 1.
  1.         0.         0.        ]
 [1.         0.         0.         0.         0.38234788 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.38262504 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.38265728 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.38262601 1.
  0.         0.14616161 1.        ]
 [1.         0.         0.         0.         0.38271187 1.
  0.         0.4130971  1.        ]
 [0.         0.         0.         0.         0.38257206 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.3823148  1.
  0.         0.         1.        ]
 [1.         0.         0.4978818  0.21452753 0.38265299 1.
  0.         0.55466383 1.        ]
 [1.         0.         0.         0.         0.38234468 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.38218736 1.
  0.         0.         1.        ]
 [1.         0.         0.92047789 1.         0.38244965 1.
  0.         0.27247123 1.        ]
 [1.         0.         0.         0.         0.3825532  1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.38188974 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.38239484 1.
  0.         1.         1.        ]
 [1.         0.         0.46319313 0.5352114  0.3823437  1.
  0.         0.55631331 1.        ]
 [1.         0.         0.97617737 0.4855825  0.38222061 1.
  0.         0.87475809 1.        ]
 [1.         0.         0.10639908 0.26019247 0.38224163 1.
  0.         0.         1.        ]
 [1.         0.         0.75876308 0.14217289 0.38232143 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.3824953  1.
  0.         0.55314518 1.        ]
 [1.         0.         0.13001495 0.         0.38241917 1.
  0.         0.33294029 1.        ]
 [1.         0.         0.         0.00559699 0.38243873 1.
  0.         0.         1.        ]
 [1.         0.         0.79923592 0.81410699 0.38238074 1.
  0.         0.85151002 1.        ]
 [1.         0.         1.         1.         0.38216433 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.38253017 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.38206844 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.9166666865348816
#####################         POISON         ###############################################

############################################################################################

comm_round: 3 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8

Accuracy per class:
[[8 0]
 [0 0]]
[ 1. nan]
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 0.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.39801695 1.         1.         1.         1.
 0.34819071 0.60292216 0.         0.         0.9580689  0.88730445
 1.         0.         0.37950049 0.91723383 0.68857401 0.88261949
 1.         0.         0.04840957 0.60965339 0.         1.
 0.49520854 0.        ]
wv_ed shape (26,)
[0.         0.27931312 0.91339184 1.         1.         1.
 0.49387468 0.62460609 0.         0.         0.42733947 0.92442467
 1.         0.         0.71846075 0.82164813 0.82010999 1.
 0.8065383  0.         0.01638505 0.47718641 0.20564985 0.80720803
 0.48586667 0.        ]
wv_lg shape (26, 1)
[[0.38876048]
 [0.38246802]
 [0.38285483]
 [0.38237119]
 [0.38275993]
 [0.38295937]
 [0.38258281]
 [0.3830813 ]
 [0.3825738 ]
 [0.38261253]
 [0.38273799]
 [0.38225663]
 [0.38264296]
 [0.38240122]
 [0.38249473]
 [0.38254133]
 [0.38252763]
 [0.38219071]
 [0.38301191]
 [0.38285532]
 [0.38340316]
 [0.38267443]
 [0.38262578]
 [0.38289435]
 [0.38263674]
 [0.38236299]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.59543338 1.         1.         1.         1.
 0.05466621 0.577535   0.04088913 0.         0.85364467 0.62923675
 0.34236334 0.         0.         0.3882816  0.61477506 0.62444151
 1.         0.         0.54374183 0.23550725 0.         1.
 0.04956643 0.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.38876048 1.
  1.         0.         0.        ]
 [1.         0.         0.39801695 0.27931312 0.38246802 1.
  0.         0.59543338 1.        ]
 [1.         0.         1.         0.91339184 0.38285483 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.38237119 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.38275993 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.38295937 1.
  0.         1.         1.        ]
 [1.         0.         0.34819071 0.49387468 0.38258281 1.
  0.         0.05466621 1.        ]
 [1.         0.         0.60292216 0.62460609 0.3830813  1.
  0.         0.577535   1.        ]
 [1.         0.         0.         0.         0.3825738  1.
  0.         0.04088913 1.        ]
 [1.         0.         0.         0.         0.38261253 1.
  0.         0.         1.        ]
 [1.         0.         0.9580689  0.42733947 0.38273799 1.
  0.         0.85364467 1.        ]
 [1.         0.         0.88730445 0.92442467 0.38225663 1.
  0.         0.62923675 1.        ]
 [1.         0.         1.         1.         0.38264296 1.
  0.         0.34236334 1.        ]
 [1.         0.         0.         0.         0.38240122 1.
  0.         0.         1.        ]
 [1.         0.         0.37950049 0.71846075 0.38249473 1.
  0.         0.         1.        ]
 [1.         0.         0.91723383 0.82164813 0.38254133 1.
  0.         0.3882816  1.        ]
 [1.         0.         0.68857401 0.82010999 0.38252763 1.
  0.         0.61477506 1.        ]
 [1.         0.         0.88261949 1.         0.38219071 1.
  0.         0.62444151 1.        ]
 [1.         0.         1.         0.8065383  0.38301191 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.38285532 1.
  0.         0.         1.        ]
 [1.         0.         0.04840957 0.01638505 0.38340316 1.
  0.         0.54374183 1.        ]
 [1.         0.         0.60965339 0.47718641 0.38267443 1.
  0.         0.23550725 1.        ]
 [1.         0.         0.         0.20564985 0.38262578 1.
  0.         0.         1.        ]
 [1.         0.         1.         0.80720803 0.38289435 1.
  0.         1.         1.        ]
 [1.         0.         0.49520854 0.48586667 0.38263674 1.
  0.         0.04956643 1.        ]
 [0.         0.         0.         0.         0.38236299 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
1.0
#####################         POISON         ###############################################

############################################################################################

comm_round: 4 | global_test_acc: 87.500% | global_f1: 0.9333333333333333 | global_precision: 0.875
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.88      1.00      0.93         7

    accuracy                           0.88         8
   macro avg       0.44      0.50      0.47         8
weighted avg       0.77      0.88      0.82         8

Accuracy per class:
[[7 0]
 [1 0]]
[1. 0.]
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.41434979 0.20100962 0.93251925 0.         0.74231845
 0.91463419 0.64339479 0.         0.         0.         0.
 0.         1.         1.         0.13854762 0.46958784 0.
 0.         0.         0.         1.         0.         0.81229624
 0.         0.        ]
wv_ed shape (26,)
[0.         0.22764395 0.11546466 0.86962026 0.         0.8204926
 0.88044168 0.46013491 0.         0.         0.         0.
 0.         0.82870986 1.         0.16920685 0.39241708 0.
 0.         0.         0.         1.         0.         0.7239984
 0.         0.        ]
wv_lg shape (26, 1)
[[0.38871124]
 [0.38375276]
 [0.38407393]
 [0.38412647]
 [0.38401185]
 [0.38399621]
 [0.38348607]
 [0.38390784]
 [0.38402601]
 [0.38377859]
 [0.38388369]
 [0.38393541]
 [0.38374822]
 [0.38427861]
 [0.38404236]
 [0.38354625]
 [0.38349419]
 [0.38394497]
 [0.38374109]
 [0.38377209]
 [0.38390639]
 [0.38379669]
 [0.38423157]
 [0.38434061]
 [0.38389007]
 [0.38345221]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.99458506 0.2184894  1.         0.         1.
 0.82157504 0.8773306  0.         0.         0.         0.
 0.         1.         1.         0.53543826 0.82753729 0.28974916
 0.         0.         0.         1.         0.         1.
 0.         0.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.38871124 1.
  1.         0.         0.        ]
 [1.         0.         0.41434979 0.22764395 0.38375276 1.
  0.         0.99458506 1.        ]
 [1.         0.         0.20100962 0.11546466 0.38407393 1.
  0.         0.2184894  1.        ]
 [1.         0.         0.93251925 0.86962026 0.38412647 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.38401185 1.
  0.         0.         1.        ]
 [1.         0.         0.74231845 0.8204926  0.38399621 1.
  0.         1.         1.        ]
 [1.         0.         0.91463419 0.88044168 0.38348607 1.
  0.         0.82157504 1.        ]
 [1.         0.         0.64339479 0.46013491 0.38390784 1.
  0.         0.8773306  1.        ]
 [1.         0.         0.         0.         0.38402601 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.38377859 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.38388369 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.38393541 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.38374822 1.
  0.         0.         1.        ]
 [1.         0.         1.         0.82870986 0.38427861 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.38404236 1.
  0.         1.         1.        ]
 [1.         0.         0.13854762 0.16920685 0.38354625 1.
  0.         0.53543826 1.        ]
 [1.         0.         0.46958784 0.39241708 0.38349419 1.
  0.         0.82753729 1.        ]
 [1.         0.         0.         0.         0.38394497 1.
  0.         0.28974916 1.        ]
 [1.         0.         0.         0.         0.38374109 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.38377209 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.38390639 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.38379669 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.38423157 1.
  0.         0.         1.        ]
 [1.         0.         0.81229624 0.7239984  0.38434061 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.38389007 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.38345221 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
1.0
#####################         POISON         ###############################################

############################################################################################

comm_round: 5 | global_test_acc: 87.500% | global_f1: 0.9333333333333333 | global_precision: 0.875
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.88      1.00      0.93         7

    accuracy                           0.88         8
   macro avg       0.44      0.50      0.47         8
weighted avg       0.77      0.88      0.82         8

Accuracy per class:
[[7 0]
 [1 0]]
[1. 0.]
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients

Best Training Poisoning Accuracy:
0.7056376338005066

Best Training Poisoning Accuracy:
0.7073018550872803

Best Training Poisoning Accuracy:
0.7075098752975464

Best Training Poisoning Accuracy:
0.7075098752975464

Best Training Poisoning Accuracy:
0.7075098752975464

Best Training Poisoning Accuracy:
0.7075098752975464

Best Training Poisoning Accuracy:
0.7075098752975464

Best Training Poisoning Accuracy:
0.7075098752975464

Best Training Poisoning Accuracy:
0.7075098752975464

Best Training Poisoning Accuracy:
0.7075098752975464

Best Training Poisoning Accuracy:
0.7075098752975464

Best Training Poisoning Accuracy:
0.7060536742210388

Best Training Poisoning Accuracy:
0.7075098752975464

Best Training Poisoning Accuracy:
0.7075098752975464

Best Training Poisoning Accuracy:
0.7075098752975464

Best Training Poisoning Accuracy:
0.7075098752975464

Best Training Poisoning Accuracy:
0.7075098752975464

Best Training Poisoning Accuracy:
0.7075098752975464

Best Training Poisoning Accuracy:
0.7050135135650635

Best Training Poisoning Accuracy:
0.7075098752975464

Best Training Poisoning Accuracy:
0.7075098752975464

Best Training Poisoning Accuracy:
0.7075098752975464

Best Training Poisoning Accuracy:
0.7075098752975464

Best Training Poisoning Accuracy:
0.7075098752975464

Best Training Poisoning Accuracy:
0.7075098752975464

Best Training Poisoning Accuracy:
0.7075098752975464

Best Training Poisoning Accuracy:
0.7075098752975464

Best Training Poisoning Accuracy:
0.7075098752975464

Best Training Poisoning Accuracy:
0.7077178955078125

Best Training Poisoning Accuracy:
0.7075098752975464

Best Training Poisoning Accuracy:
0.7075098752975464

Best Training Poisoning Accuracy:
0.7075098752975464

Best Training Poisoning Accuracy:
0.7075098752975464

Best Training Poisoning Accuracy:
0.7075098752975464

Best Training Poisoning Accuracy:
0.7075098752975464

Best Training Poisoning Accuracy:
0.7075098752975464

Best Training Poisoning Accuracy:
0.7075098752975464

Best Training Poisoning Accuracy:
0.7075098752975464

Best Training Poisoning Accuracy:
0.7031412720680237

Best Training Poisoning Accuracy:
0.7075098752975464

Best Training Poisoning Accuracy:
0.7075098752975464

Best Training Poisoning Accuracy:
0.7075098752975464

Best Training Poisoning Accuracy:
0.7075098752975464

Best Training Poisoning Accuracy:
0.7075098752975464

Best Training Poisoning Accuracy:
0.7075098752975464

Best Training Poisoning Accuracy:
0.7075098752975464

Best Training Poisoning Accuracy:
0.7075098752975464

Best Training Poisoning Accuracy:
0.7075098752975464

Best Training Poisoning Accuracy:
0.7043894529342651

Best Training Poisoning Accuracy:
0.7075098752975464

Best Training Poisoning Accuracy:
0.7075098752975464

Best Training Poisoning Accuracy:
0.7035573124885559

Best Training Poisoning Accuracy:
0.7075098752975464

Best Training Poisoning Accuracy:
0.7075098752975464

Best Training Poisoning Accuracy:
0.7075098752975464

Best Training Poisoning Accuracy:
0.706885814666748

Best Training Poisoning Accuracy:
0.7075098752975464

Best Training Poisoning Accuracy:
0.698356568813324

Best Training Poisoning Accuracy:
0.7041813731193542

Best Training Poisoning Accuracy:
0.7075098752975464

Best Training Poisoning Accuracy:
0.7075098752975464

Best Training Poisoning Accuracy:
0.7075098752975464

Best Training Poisoning Accuracy:
0.7075098752975464

Best Training Poisoning Accuracy:
0.7075098752975464

Best Training Poisoning Accuracy:
0.7075098752975464

Best Training Poisoning Accuracy:
0.7075098752975464

Best Training Poisoning Accuracy:
0.7075098752975464

Best Training Poisoning Accuracy:
0.7075098752975464

Best Training Poisoning Accuracy:
0.7075098752975464

Best Training Poisoning Accuracy:
0.7075098752975464

Best Training Poisoning Accuracy:
0.7073018550872803

Best Training Poisoning Accuracy:
0.7075098752975464

Best Training Poisoning Accuracy:
0.7066777348518372

Best Training Poisoning Accuracy:
0.7075098752975464

Best Training Poisoning Accuracy:
0.9938114285469055

Best Training Poisoning Accuracy:
0.9919912815093994

Best Training Poisoning Accuracy:
0.9945394992828369

Best Training Poisoning Accuracy:
0.991081178188324

Best Training Poisoning Accuracy:
0.9881688952445984

Best Training Poisoning Accuracy:
0.9943574666976929

Best Training Poisoning Accuracy:
0.9903531074523926

Best Training Poisoning Accuracy:
0.9941754937171936

Best Training Poisoning Accuracy:
0.994721531867981

Best Training Poisoning Accuracy:
0.9929013252258301

Best Training Poisoning Accuracy:
0.9956315755844116

Best Training Poisoning Accuracy:
0.9938114285469055

Best Training Poisoning Accuracy:
0.9956315755844116

Best Training Poisoning Accuracy:
0.9958136081695557

Best Training Poisoning Accuracy:
0.9854386448860168

Best Training Poisoning Accuracy:
0.9805241823196411

Best Training Poisoning Accuracy:
0.9737895727157593

Best Training Poisoning Accuracy:
0.9830724596977234

Best Training Poisoning Accuracy:
0.987440824508667

Best Training Poisoning Accuracy:
0.9763378500938416

Best Training Poisoning Accuracy:
0.9632326364517212

Best Training Poisoning Accuracy:
0.9539497494697571

Best Training Poisoning Accuracy:
0.9166363477706909
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.61327571 0.94378274
 0.90313306 1.         1.         1.         0.75486793 1.
 0.         0.9776923  1.         0.         1.         0.67270405
 0.51425653 1.        ]
wv_ed shape (26,)
[0.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.60705333 0.71284522
 0.78720976 1.         1.         1.         0.66976415 1.
 0.06216346 0.81669948 1.         0.         1.         0.61162358
 0.51864561 1.        ]
wv_lg shape (26, 1)
[[0.38888248]
 [0.38504119]
 [0.38485314]
 [0.38468058]
 [0.38537557]
 [0.38481183]
 [0.38465229]
 [0.38457714]
 [0.38450075]
 [0.38464115]
 [0.38459206]
 [0.38473329]
 [0.38463116]
 [0.38430733]
 [0.38463499]
 [0.38512345]
 [0.3847234 ]
 [0.38468455]
 [0.38457273]
 [0.38469367]
 [0.38472128]
 [0.38454797]
 [0.38457673]
 [0.38423587]
 [0.38441291]
 [0.3847199 ]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         1.         1.         1.         1.         1.
 0.94338933 1.         1.         1.         0.52372803 0.87832709
 0.83941657 0.77139098 1.         1.         0.82021379 1.
 0.         0.79918697 1.         0.         0.91868983 0.88818269
 0.6293854  1.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.38888248 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.38504119 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.38485314 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.38468058 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.38537557 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.38481183 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.38465229 1.
  0.         0.94338933 1.        ]
 [1.         0.         1.         1.         0.38457714 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.38450075 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.38464115 1.
  0.         1.         1.        ]
 [1.         0.         0.61327571 0.60705333 0.38459206 1.
  0.         0.52372803 1.        ]
 [1.         0.         0.94378274 0.71284522 0.38473329 1.
  0.         0.87832709 1.        ]
 [1.         0.         0.90313306 0.78720976 0.38463116 1.
  0.         0.83941657 1.        ]
 [1.         0.         1.         1.         0.38430733 1.
  0.         0.77139098 1.        ]
 [1.         0.         1.         1.         0.38463499 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.38512345 1.
  0.         1.         1.        ]
 [1.         0.         0.75486793 0.66976415 0.3847234  1.
  0.         0.82021379 1.        ]
 [1.         0.         1.         1.         0.38468455 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.06216346 0.38457273 1.
  0.         0.         1.        ]
 [1.         0.         0.9776923  0.81669948 0.38469367 1.
  0.         0.79918697 1.        ]
 [1.         0.         1.         1.         0.38472128 1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.38454797 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.38457673 1.
  0.         0.91868983 1.        ]
 [1.         0.         0.67270405 0.61162358 0.38423587 1.
  0.         0.88818269 1.        ]
 [1.         0.         0.51425653 0.51864561 0.38441291 1.
  0.         0.6293854  1.        ]
 [1.         0.         1.         1.         0.3847199  1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.9285714030265808
#####################         POISON         ###############################################

############################################################################################

comm_round: 0 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         1.         1.         0.         1.         1.
 1.         1.         1.         1.         1.         1.
 0.         1.         0.         1.         0.1628794  0.
 0.         0.43301716 1.         0.         0.93442197 1.
 1.         1.        ]
wv_ed shape (26,)
[0.         1.         1.         0.         1.         1.
 1.         1.         1.         1.         1.         1.
 0.         1.         0.         1.         0.27000657 0.
 0.         0.69992599 1.         0.         0.83290817 1.
 1.         1.        ]
wv_lg shape (26, 1)
[[0.38925899]
 [0.38495526]
 [0.38526039]
 [0.3857705 ]
 [0.3855851 ]
 [0.3852391 ]
 [0.38534304]
 [0.38503891]
 [0.38507296]
 [0.38485103]
 [0.38520962]
 [0.38504023]
 [0.38514226]
 [0.3847976 ]
 [0.38515903]
 [0.38497725]
 [0.38561408]
 [0.3851871 ]
 [0.38517979]
 [0.38507028]
 [0.38531242]
 [0.38541675]
 [0.38540474]
 [0.38528178]
 [0.38549027]
 [0.38531332]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.98934502 0.45019558 0.         1.         0.2093383
 1.         0.87489562 1.         1.         1.         1.
 0.         0.2999144  0.         0.         0.         0.
 0.         0.         0.54015446 0.         0.52263907 0.92436738
 1.         1.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.38925899 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.38495526 1.
  0.         0.98934502 1.        ]
 [1.         0.         1.         1.         0.38526039 1.
  0.         0.45019558 1.        ]
 [1.         0.         0.         0.         0.3857705  1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.3855851  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.3852391  1.
  0.         0.2093383  1.        ]
 [1.         0.         1.         1.         0.38534304 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.38503891 1.
  0.         0.87489562 1.        ]
 [1.         0.         1.         1.         0.38507296 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.38485103 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.38520962 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.38504023 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.38514226 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.3847976  1.
  0.         0.2999144  1.        ]
 [1.         0.         0.         0.         0.38515903 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.38497725 1.
  0.         0.         1.        ]
 [1.         0.         0.1628794  0.27000657 0.38561408 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3851871  1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.38517979 1.
  0.         0.         1.        ]
 [1.         0.         0.43301716 0.69992599 0.38507028 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.38531242 1.
  0.         0.54015446 1.        ]
 [1.         0.         0.         0.         0.38541675 1.
  0.         0.         1.        ]
 [1.         0.         0.93442197 0.83290817 0.38540474 1.
  0.         0.52263907 1.        ]
 [1.         0.         1.         1.         0.38528178 1.
  0.         0.92436738 1.        ]
 [1.         0.         1.         1.         0.38549027 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.38531332 1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.9285714030265808
#####################         POISON         ###############################################

############################################################################################

comm_round: 1 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.         0.         1.         1.         0.
 1.         0.         1.         1.         0.73433643 1.
 0.42735771 0.85028119 1.         0.         1.         0.
 1.         1.         0.         0.         0.         1.
 0.39102896 0.        ]
wv_ed shape (26,)
[0.         0.         0.         1.         1.         0.
 1.         0.         1.         1.         0.86663274 1.
 0.26929515 0.73982885 1.         0.         1.         0.
 1.         1.         0.         0.         0.         1.
 0.40696204 0.        ]
wv_lg shape (26, 1)
[[0.38898445]
 [0.3861586 ]
 [0.385961  ]
 [0.38645938]
 [0.38641053]
 [0.38642659]
 [0.38641455]
 [0.38624047]
 [0.38618039]
 [0.38589359]
 [0.38598152]
 [0.38648111]
 [0.38603517]
 [0.38686566]
 [0.38654315]
 [0.38605609]
 [0.38623089]
 [0.38629537]
 [0.38670352]
 [0.3863703 ]
 [0.38610277]
 [0.38600201]
 [0.38632061]
 [0.38620352]
 [0.38634861]
 [0.38621731]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.         0.         1.         1.         0.
 1.         0.         1.         1.         1.         0.92310132
 0.67996774 1.         1.         0.         1.         0.
 1.         0.8651121  0.         0.         0.         1.
 0.21422695 0.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.38898445 1.
  1.         0.         0.        ]
 [1.         0.         0.         0.         0.3861586  1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.385961   1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.38645938 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.38641053 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.38642659 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.38641455 1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.38624047 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.38618039 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.38589359 1.
  0.         1.         1.        ]
 [1.         0.         0.73433643 0.86663274 0.38598152 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.38648111 1.
  0.         0.92310132 1.        ]
 [1.         0.         0.42735771 0.26929515 0.38603517 1.
  0.         0.67996774 1.        ]
 [1.         0.         0.85028119 0.73982885 0.38686566 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.38654315 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.38605609 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.38623089 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.38629537 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.38670352 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.3863703  1.
  0.         0.8651121  1.        ]
 [1.         0.         0.         0.         0.38610277 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.38600201 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.38632061 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.38620352 1.
  0.         1.         1.        ]
 [1.         0.         0.39102896 0.40696204 0.38634861 1.
  0.         0.21422695 1.        ]
 [1.         0.         0.         0.         0.38621731 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.9285714030265808
#####################         POISON         ###############################################

############################################################################################

comm_round: 2 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 0.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.32526789 1.         1.         1.         0.
 1.         0.         0.77838674 0.82418661 0.70779766 0.73581552
 0.25700542 0.68897991 0.92640108 0.34832044 1.         0.85089033
 1.         0.         1.         1.         0.         0.5887117
 0.         0.        ]
wv_ed shape (26,)
[0.         0.47009911 0.84765172 1.         1.         0.
 1.         0.         0.7096656  0.65732214 0.77067549 0.4436515
 0.3444767  0.39500993 0.91797433 0.18984895 1.         0.75030882
 1.         0.         1.         1.         0.06651924 0.65190885
 0.         0.        ]
wv_lg shape (26, 1)
[[0.38982052]
 [0.38610596]
 [0.38659858]
 [0.3862532 ]
 [0.38636682]
 [0.38654771]
 [0.38607852]
 [0.38594856]
 [0.3862467 ]
 [0.38619477]
 [0.38612159]
 [0.38600629]
 [0.38619163]
 [0.38640996]
 [0.38571999]
 [0.38634795]
 [0.38626146]
 [0.38605055]
 [0.38635858]
 [0.38629479]
 [0.38615442]
 [0.38609913]
 [0.38619544]
 [0.38609044]
 [0.38607979]
 [0.38605336]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.         1.         0.82056455 1.         0.
 0.96290392 0.         1.         1.         0.9307489  0.93436911
 0.42174681 0.81208986 0.64082293 0.48961875 0.95761793 0.84471051
 1.         0.         0.70271133 1.         0.         1.
 0.         0.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.38982052 1.
  1.         0.         0.        ]
 [1.         0.         0.32526789 0.47009911 0.38610596 1.
  0.         0.         1.        ]
 [1.         0.         1.         0.84765172 0.38659858 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.3862532  1.
  0.         0.82056455 1.        ]
 [1.         0.         1.         1.         0.38636682 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.38654771 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.38607852 1.
  0.         0.96290392 1.        ]
 [1.         0.         0.         0.         0.38594856 1.
  0.         0.         1.        ]
 [1.         0.         0.77838674 0.7096656  0.3862467  1.
  0.         1.         1.        ]
 [1.         0.         0.82418661 0.65732214 0.38619477 1.
  0.         1.         1.        ]
 [1.         0.         0.70779766 0.77067549 0.38612159 1.
  0.         0.9307489  1.        ]
 [1.         0.         0.73581552 0.4436515  0.38600629 1.
  0.         0.93436911 1.        ]
 [1.         0.         0.25700542 0.3444767  0.38619163 1.
  0.         0.42174681 1.        ]
 [1.         0.         0.68897991 0.39500993 0.38640996 1.
  0.         0.81208986 1.        ]
 [1.         0.         0.92640108 0.91797433 0.38571999 1.
  0.         0.64082293 1.        ]
 [1.         0.         0.34832044 0.18984895 0.38634795 1.
  0.         0.48961875 1.        ]
 [1.         0.         1.         1.         0.38626146 1.
  0.         0.95761793 1.        ]
 [1.         0.         0.85089033 0.75030882 0.38605055 1.
  0.         0.84471051 1.        ]
 [1.         0.         1.         1.         0.38635858 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.38629479 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.38615442 1.
  0.         0.70271133 1.        ]
 [1.         0.         1.         1.         0.38609913 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.06651924 0.38619544 1.
  0.         0.         1.        ]
 [1.         0.         0.5887117  0.65190885 0.38609044 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.38607979 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.38605336 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
1.0
#####################         POISON         ###############################################

############################################################################################

comm_round: 3 | global_test_acc: 87.500% | global_f1: 0.9333333333333333 | global_precision: 0.875
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.88      1.00      0.93         7

    accuracy                           0.88         8
   macro avg       0.44      0.50      0.47         8
weighted avg       0.77      0.88      0.82         8
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.         1.         1.         1.         0.
 0.6223159  0.         1.         0.         0.3425098  0.
 0.35848262 0.23403489 1.         1.         1.         1.
 1.         0.         1.         0.18315176 0.         1.
 1.         0.        ]
wv_ed shape (26,)
[0.         0.         1.         1.         1.         0.
 0.27578759 0.         1.         0.         0.25837917 0.
 0.34456578 0.29374423 1.         1.         1.         0.84846438
 0.71170328 0.         1.         0.24644784 0.         0.9973173
 1.         0.        ]
wv_lg shape (26, 1)
[[0.39042761]
 [0.38635188]
 [0.38643151]
 [0.3860595 ]
 [0.38632771]
 [0.38641591]
 [0.3863051 ]
 [0.38661985]
 [0.38620591]
 [0.38658377]
 [0.38643387]
 [0.38652565]
 [0.38637622]
 [0.38623526]
 [0.38637611]
 [0.38621948]
 [0.38602094]
 [0.38653134]
 [0.38607571]
 [0.38622981]
 [0.38624527]
 [0.38671051]
 [0.38635336]
 [0.38638166]
 [0.38603187]
 [0.38631458]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.         1.         1.         1.         0.
 1.         0.         1.         0.         0.89481268 0.
 0.57406069 0.         1.         1.         1.         0.83183445
 0.63548614 0.         1.         0.         0.         0.60988414
 1.         0.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.39042761 1.
  1.         0.         0.        ]
 [1.         0.         0.         0.         0.38635188 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.38643151 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.3860595  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.38632771 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.38641591 1.
  0.         0.         1.        ]
 [1.         0.         0.6223159  0.27578759 0.3863051  1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.38661985 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.38620591 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.38658377 1.
  0.         0.         1.        ]
 [1.         0.         0.3425098  0.25837917 0.38643387 1.
  0.         0.89481268 1.        ]
 [1.         0.         0.         0.         0.38652565 1.
  0.         0.         1.        ]
 [1.         0.         0.35848262 0.34456578 0.38637622 1.
  0.         0.57406069 1.        ]
 [1.         0.         0.23403489 0.29374423 0.38623526 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.38637611 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.38621948 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.38602094 1.
  0.         1.         1.        ]
 [1.         0.         1.         0.84846438 0.38653134 1.
  0.         0.83183445 1.        ]
 [1.         0.         1.         0.71170328 0.38607571 1.
  0.         0.63548614 1.        ]
 [1.         0.         0.         0.         0.38622981 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.38624527 1.
  0.         1.         1.        ]
 [1.         0.         0.18315176 0.24644784 0.38671051 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.38635336 1.
  0.         0.         1.        ]
 [1.         0.         1.         0.9973173  0.38638166 1.
  0.         0.60988414 1.        ]
 [1.         0.         1.         1.         0.38603187 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.38631458 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
1.0
#####################         POISON         ###############################################

############################################################################################

comm_round: 4 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         1.         0.         0.73664913 0.         0.
 1.         0.         0.77824223 1.         1.         0.33025807
 0.         0.         0.74172492 0.55832789 1.         1.
 1.         1.         0.         0.01478933 0.45305376 0.
 1.         0.06971467]
wv_ed shape (26,)
[0.         1.         0.         0.8314042  0.         0.
 1.         0.         1.         1.         1.         0.22711727
 0.         0.         1.         0.52333475 1.         1.
 1.         1.         0.         0.26605881 0.32447496 0.
 1.         0.30728299]
wv_lg shape (26, 1)
[[0.39023376]
 [0.38772503]
 [0.38706221]
 [0.38722152]
 [0.38728216]
 [0.38779232]
 [0.38696276]
 [0.38688307]
 [0.38718445]
 [0.38720462]
 [0.38710858]
 [0.38723303]
 [0.38713438]
 [0.38724386]
 [0.38758679]
 [0.3870967 ]
 [0.38725279]
 [0.38691552]
 [0.38730188]
 [0.38745454]
 [0.38739932]
 [0.38683794]
 [0.38735419]
 [0.38725717]
 [0.38727678]
 [0.3875586 ]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         1.         0.         0.33893347 0.         0.
 1.         0.         0.33326609 1.         1.         1.
 0.         0.         0.         0.51627686 1.         0.8785865
 1.         1.         0.         0.         0.72845046 0.
 0.80778631 0.2365915 ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.39023376 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.38772503 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.38706221 1.
  0.         0.         1.        ]
 [1.         0.         0.73664913 0.8314042  0.38722152 1.
  0.         0.33893347 1.        ]
 [1.         0.         0.         0.         0.38728216 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.38779232 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.38696276 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.38688307 1.
  0.         0.         1.        ]
 [1.         0.         0.77824223 1.         0.38718445 1.
  0.         0.33326609 1.        ]
 [1.         0.         1.         1.         0.38720462 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.38710858 1.
  0.         1.         1.        ]
 [1.         0.         0.33025807 0.22711727 0.38723303 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.38713438 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.38724386 1.
  0.         0.         1.        ]
 [1.         0.         0.74172492 1.         0.38758679 1.
  0.         0.         1.        ]
 [1.         0.         0.55832789 0.52333475 0.3870967  1.
  0.         0.51627686 1.        ]
 [1.         0.         1.         1.         0.38725279 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.38691552 1.
  0.         0.8785865  1.        ]
 [1.         0.         1.         1.         0.38730188 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.38745454 1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.38739932 1.
  0.         0.         1.        ]
 [1.         0.         0.01478933 0.26605881 0.38683794 1.
  0.         0.         1.        ]
 [1.         0.         0.45305376 0.32447496 0.38735419 1.
  0.         0.72845046 1.        ]
 [1.         0.         0.         0.         0.38725717 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.38727678 1.
  0.         0.80778631 1.        ]
 [1.         0.         0.06971467 0.30728299 0.3875586  1.
  0.         0.2365915  1.        ]]

Best Training Poisoning Accuracy:
0.9285714030265808
#####################         POISON         ###############################################

############################################################################################

comm_round: 5 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.         1.         1.         1.         1.
 0.74646146 0.         1.         0.         1.         0.5334039
 1.         0.20491051 1.         0.29823493 0.32249386 1.
 0.         1.         0.3516878  0.83264622 0.38633407 1.
 0.32613895 0.29656066]
wv_ed shape (26,)
[0.         0.         1.         1.         1.         1.
 0.83099637 0.         1.         0.         1.         0.59006032
 1.         0.0234822  1.         0.40456413 0.59932088 1.
 0.         1.         0.28490572 0.87906908 0.33133393 0.93060596
 0.22937935 0.40432474]
wv_lg shape (26, 1)
[[0.39052861]
 [0.38743004]
 [0.38747544]
 [0.38740504]
 [0.38757599]
 [0.38727992]
 [0.38769929]
 [0.38749635]
 [0.38804559]
 [0.38765911]
 [0.3876906 ]
 [0.38771242]
 [0.38754945]
 [0.38749463]
 [0.38758045]
 [0.38747602]
 [0.38765086]
 [0.38795636]
 [0.38748645]
 [0.3876976 ]
 [0.38761484]
 [0.38722151]
 [0.38752992]
 [0.38775064]
 [0.38763246]
 [0.3877069 ]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.         1.         0.83693365 0.96713963 1.
 1.         0.         1.         0.         1.         0.54112036
 1.         0.         1.         0.87463308 0.18059373 1.
 0.         1.         0.55977652 0.93026638 0.21910472 1.
 1.         0.61648825]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.39052861 1.
  1.         0.         0.        ]
 [1.         0.         0.         0.         0.38743004 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.38747544 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.38740504 1.
  0.         0.83693365 1.        ]
 [1.         0.         1.         1.         0.38757599 1.
  0.         0.96713963 1.        ]
 [1.         0.         1.         1.         0.38727992 1.
  0.         1.         1.        ]
 [1.         0.         0.74646146 0.83099637 0.38769929 1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.38749635 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.38804559 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.38765911 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.3876906  1.
  0.         1.         1.        ]
 [1.         0.         0.5334039  0.59006032 0.38771242 1.
  0.         0.54112036 1.        ]
 [1.         0.         1.         1.         0.38754945 1.
  0.         1.         1.        ]
 [1.         0.         0.20491051 0.0234822  0.38749463 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.38758045 1.
  0.         1.         1.        ]
 [1.         0.         0.29823493 0.40456413 0.38747602 1.
  0.         0.87463308 1.        ]
 [1.         0.         0.32249386 0.59932088 0.38765086 1.
  0.         0.18059373 1.        ]
 [1.         0.         1.         1.         0.38795636 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.38748645 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.3876976  1.
  0.         1.         1.        ]
 [1.         0.         0.3516878  0.28490572 0.38761484 1.
  0.         0.55977652 1.        ]
 [1.         0.         0.83264622 0.87906908 0.38722151 1.
  0.         0.93026638 1.        ]
 [1.         0.         0.38633407 0.33133393 0.38752992 1.
  0.         0.21910472 1.        ]
 [1.         0.         1.         0.93060596 0.38775064 1.
  0.         1.         1.        ]
 [1.         0.         0.32613895 0.22937935 0.38763246 1.
  0.         1.         1.        ]
 [1.         0.         0.29656066 0.40432474 0.3877069  1.
  0.         0.61648825 1.        ]]

Best Training Poisoning Accuracy:
1.0
#####################         POISON         ###############################################

############################################################################################

comm_round: 6 | global_test_acc: 87.500% | global_f1: 0.9333333333333333 | global_precision: 0.875
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.88      1.00      0.93         7

    accuracy                           0.88         8
   macro avg       0.44      0.50      0.47         8
weighted avg       0.77      0.88      0.82         8
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.06093397 0.80699066 0.7496012  0.73766212 0.44801107
 0.05868719 0.         0.89210893 0.         1.         1.
 0.60240359 0.87405215 0.48533415 0.92683431 0.         1.
 1.         0.         1.         1.         1.         1.
 1.         0.        ]
wv_ed shape (26,)
[0.         0.         0.840642   0.79113082 0.75645456 0.4108671
 0.0350905  0.         0.7739597  0.         1.         1.
 0.6655836  0.86274243 0.32858206 1.         0.         1.
 1.         0.         1.         1.         1.         0.89510299
 1.         0.        ]
wv_lg shape (26, 1)
[[0.39109993]
 [0.38791108]
 [0.38785162]
 [0.3875405 ]
 [0.38787101]
 [0.38759601]
 [0.38810828]
 [0.38743869]
 [0.38772041]
 [0.38790343]
 [0.38786281]
 [0.38773328]
 [0.38768168]
 [0.38772256]
 [0.38777475]
 [0.3875653 ]
 [0.38766425]
 [0.38776831]
 [0.38762243]
 [0.38780072]
 [0.38796496]
 [0.38808727]
 [0.38753702]
 [0.38743549]
 [0.38757378]
 [0.38759796]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.69960315 0.490701   0.         1.         0.91882568
 0.38863258 0.         1.         0.         1.         0.86526129
 0.74806171 0.93192323 0.60775655 0.85622522 0.         1.
 1.         0.         1.         1.         1.         1.
 1.         0.08424046]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.39109993 1.
  1.         0.         0.        ]
 [1.         0.         0.06093397 0.         0.38791108 1.
  0.         0.69960315 1.        ]
 [1.         0.         0.80699066 0.840642   0.38785162 1.
  0.         0.490701   1.        ]
 [1.         0.         0.7496012  0.79113082 0.3875405  1.
  0.         0.         1.        ]
 [1.         0.         0.73766212 0.75645456 0.38787101 1.
  0.         1.         1.        ]
 [1.         0.         0.44801107 0.4108671  0.38759601 1.
  0.         0.91882568 1.        ]
 [1.         0.         0.05868719 0.0350905  0.38810828 1.
  0.         0.38863258 1.        ]
 [1.         0.         0.         0.         0.38743869 1.
  0.         0.         1.        ]
 [1.         0.         0.89210893 0.7739597  0.38772041 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.38790343 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.38786281 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.38773328 1.
  0.         0.86526129 1.        ]
 [1.         0.         0.60240359 0.6655836  0.38768168 1.
  0.         0.74806171 1.        ]
 [1.         0.         0.87405215 0.86274243 0.38772256 1.
  0.         0.93192323 1.        ]
 [1.         0.         0.48533415 0.32858206 0.38777475 1.
  0.         0.60775655 1.        ]
 [1.         0.         0.92683431 1.         0.3875653  1.
  0.         0.85622522 1.        ]
 [1.         0.         0.         0.         0.38766425 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.38776831 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.38762243 1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.38780072 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.38796496 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.38808727 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.38753702 1.
  0.         1.         1.        ]
 [1.         0.         1.         0.89510299 0.38743549 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.38757378 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.38759796 1.
  0.         0.08424046 1.        ]]

Best Training Poisoning Accuracy:
0.9285714030265808
#####################         POISON         ###############################################

############################################################################################

comm_round: 7 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.         0.         0.         0.22230091 0.
 0.11783471 0.04408549 0.         1.         1.         0.01418389
 1.         0.         0.         0.6936366  0.         0.78357019
 0.60058222 0.30383422 0.41341928 0.         0.03189149 0.13844413
 1.         0.        ]
wv_ed shape (26,)
[0.         0.         0.         0.         0.         0.
 0.07212849 0.08767373 0.         1.         1.         0.
 1.         0.         0.         1.         0.         0.53943665
 0.54248216 0.01028844 0.40426186 0.         0.21139221 0.25029839
 1.         0.        ]
wv_lg shape (26, 1)
[[0.39182373]
 [0.38775837]
 [0.3877396 ]
 [0.38753085]
 [0.38785573]
 [0.38736605]
 [0.38813305]
 [0.38749752]
 [0.38768761]
 [0.38759842]
 [0.38769818]
 [0.38782596]
 [0.38757386]
 [0.38723732]
 [0.38750703]
 [0.38746226]
 [0.38768579]
 [0.38736549]
 [0.38788608]
 [0.38804466]
 [0.38785591]
 [0.38764902]
 [0.38774564]
 [0.38756921]
 [0.38760172]
 [0.38770976]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.         0.         0.         0.45417098 0.
 0.56116182 0.         0.         1.         1.         0.
 1.         0.         0.         0.         0.         0.68688167
 0.30232522 0.43008108 0.         0.         0.         0.
 1.         0.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.39182373 1.
  1.         0.         0.        ]
 [1.         0.         0.         0.         0.38775837 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3877396  1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.38753085 1.
  0.         0.         1.        ]
 [1.         0.         0.22230091 0.         0.38785573 1.
  0.         0.45417098 1.        ]
 [1.         0.         0.         0.         0.38736605 1.
  0.         0.         1.        ]
 [1.         0.         0.11783471 0.07212849 0.38813305 1.
  0.         0.56116182 1.        ]
 [1.         0.         0.04408549 0.08767373 0.38749752 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.38768761 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.38759842 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.38769818 1.
  0.         1.         1.        ]
 [1.         0.         0.01418389 0.         0.38782596 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.38757386 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.38723732 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.38750703 1.
  0.         0.         1.        ]
 [1.         0.         0.6936366  1.         0.38746226 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.38768579 1.
  0.         0.         1.        ]
 [1.         0.         0.78357019 0.53943665 0.38736549 1.
  0.         0.68688167 1.        ]
 [1.         0.         0.60058222 0.54248216 0.38788608 1.
  0.         0.30232522 1.        ]
 [1.         0.         0.30383422 0.01028844 0.38804466 1.
  0.         0.43008108 1.        ]
 [1.         0.         0.41341928 0.40426186 0.38785591 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.38764902 1.
  0.         0.         1.        ]
 [1.         0.         0.03189149 0.21139221 0.38774564 1.
  0.         0.         1.        ]
 [1.         0.         0.13844413 0.25029839 0.38756921 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.38760172 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.38770976 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.9285714030265808
#####################         POISON         ###############################################

############################################################################################

comm_round: 8 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.         1.         0.         1.         1.
 0.63713417 1.         0.         1.         1.         1.
 1.         0.363338   0.         1.         1.         0.60511415
 0.32643817 0.         0.         1.         1.         1.
 1.         0.89804314]
wv_ed shape (26,)
[0.         0.         1.         0.         1.         1.
 0.65493524 1.         0.         1.         1.         1.
 0.93969344 0.51869561 0.         1.         1.         0.45089441
 0.11783317 0.         0.         1.         1.         1.
 1.         0.30027841]
wv_lg shape (26, 1)
[[0.39133496]
 [0.38892107]
 [0.38879367]
 [0.38867763]
 [0.38897796]
 [0.38878553]
 [0.3890383 ]
 [0.3888876 ]
 [0.38910775]
 [0.38861891]
 [0.38874255]
 [0.3885492 ]
 [0.38880286]
 [0.38870393]
 [0.38916998]
 [0.38843135]
 [0.38830258]
 [0.38862148]
 [0.38884573]
 [0.38882436]
 [0.38879929]
 [0.38882819]
 [0.38889363]
 [0.38870134]
 [0.38854214]
 [0.38864913]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.         1.         0.         1.         0.69786982
 0.8301188  1.         0.         1.         1.         1.
 1.         0.24745403 0.52239018 1.         1.         1.
 0.90408223 0.         0.         1.         1.         1.
 1.         1.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.39133496 1.
  1.         0.         0.        ]
 [1.         0.         0.         0.         0.38892107 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.38879367 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.38867763 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.38897796 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.38878553 1.
  0.         0.69786982 1.        ]
 [1.         0.         0.63713417 0.65493524 0.3890383  1.
  0.         0.8301188  1.        ]
 [1.         0.         1.         1.         0.3888876  1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.38910775 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.38861891 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.38874255 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.3885492  1.
  0.         1.         1.        ]
 [1.         0.         1.         0.93969344 0.38880286 1.
  0.         1.         1.        ]
 [1.         0.         0.363338   0.51869561 0.38870393 1.
  0.         0.24745403 1.        ]
 [1.         0.         0.         0.         0.38916998 1.
  0.         0.52239018 1.        ]
 [1.         0.         1.         1.         0.38843135 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.38830258 1.
  0.         1.         1.        ]
 [1.         0.         0.60511415 0.45089441 0.38862148 1.
  0.         1.         1.        ]
 [1.         0.         0.32643817 0.11783317 0.38884573 1.
  0.         0.90408223 1.        ]
 [1.         0.         0.         0.         0.38882436 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.38879929 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.38882819 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.38889363 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.38870134 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.38854214 1.
  0.         1.         1.        ]
 [1.         0.         0.89804314 0.30027841 0.38864913 1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.9285714030265808
#####################         POISON         ###############################################

############################################################################################

comm_round: 9 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         1.         1.         0.55456739 1.         0.10529822
 0.78594057 1.         1.         0.         0.39754206 0.
 1.         0.         0.         0.         1.         0.
 1.         0.         0.         0.         1.         0.
 1.         1.        ]
wv_ed shape (26,)
[0.         1.         1.         0.82160106 0.7870895  0.24924717
 1.         1.         1.         0.         0.41796198 0.
 1.         0.         0.         0.         1.         0.
 1.         0.         0.         0.         1.         0.
 1.         1.        ]
wv_lg shape (26, 1)
[[0.39177727]
 [0.38885127]
 [0.38892099]
 [0.38873496]
 [0.38900644]
 [0.38876269]
 [0.38893093]
 [0.3886092 ]
 [0.38858809]
 [0.38887627]
 [0.38885446]
 [0.38880246]
 [0.38894834]
 [0.3888764 ]
 [0.38893132]
 [0.38865784]
 [0.38893261]
 [0.38855901]
 [0.38909516]
 [0.38889471]
 [0.38884144]
 [0.38874864]
 [0.38870885]
 [0.38883123]
 [0.38908961]
 [0.38875553]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.90474101 1.         0.16437855 1.         0.
 0.44855522 0.87158515 0.64963394 0.         0.40082142 0.
 1.         0.         0.         0.         0.65204093 0.
 0.89827287 0.         0.         0.         1.         0.
 1.         0.49090936]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.39177727 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.38885127 1.
  0.         0.90474101 1.        ]
 [1.         0.         1.         1.         0.38892099 1.
  0.         1.         1.        ]
 [1.         0.         0.55456739 0.82160106 0.38873496 1.
  0.         0.16437855 1.        ]
 [1.         0.         1.         0.7870895  0.38900644 1.
  0.         1.         1.        ]
 [1.         0.         0.10529822 0.24924717 0.38876269 1.
  0.         0.         1.        ]
 [1.         0.         0.78594057 1.         0.38893093 1.
  0.         0.44855522 1.        ]
 [1.         0.         1.         1.         0.3886092  1.
  0.         0.87158515 1.        ]
 [1.         0.         1.         1.         0.38858809 1.
  0.         0.64963394 1.        ]
 [0.         0.         0.         0.         0.38887627 1.
  0.         0.         1.        ]
 [1.         0.         0.39754206 0.41796198 0.38885446 1.
  0.         0.40082142 1.        ]
 [1.         0.         0.         0.         0.38880246 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.38894834 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.3888764  1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.38893132 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.38865784 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.38893261 1.
  0.         0.65204093 1.        ]
 [1.         0.         0.         0.         0.38855901 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.38909516 1.
  0.         0.89827287 1.        ]
 [1.         0.         0.         0.         0.38889471 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.38884144 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.38874864 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.38870885 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.38883123 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.38908961 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.38875553 1.
  0.         0.49090936 1.        ]]

Best Training Poisoning Accuracy:
0.9285714030265808
#####################         POISON         ###############################################

############################################################################################

comm_round: 10 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.1868928  0.         1.         0.         0.68233464
 0.         0.         1.         1.         1.         0.31612269
 1.         1.         0.98046542 1.         1.         1.
 1.         1.         1.         1.         1.         0.27487312
 0.         0.40483886]
wv_ed shape (26,)
[0.         0.6142832  0.         1.         0.         0.69305653
 0.         0.         1.         1.         1.         0.14842311
 1.         1.         0.90939087 1.         1.         0.85416651
 1.         1.         1.         1.         1.         0.3591726
 0.         0.43893796]
wv_lg shape (26, 1)
[[0.39199488]
 [0.389202  ]
 [0.38911723]
 [0.38893381]
 [0.38922776]
 [0.38935804]
 [0.38934554]
 [0.38908947]
 [0.38900857]
 [0.38914199]
 [0.38897381]
 [0.3892392 ]
 [0.38905708]
 [0.38921867]
 [0.38897999]
 [0.38928517]
 [0.38897557]
 [0.3891559 ]
 [0.38906832]
 [0.3890776 ]
 [0.3892021 ]
 [0.38944059]
 [0.3892076 ]
 [0.38922941]
 [0.38915835]
 [0.38898834]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.         0.         1.         0.         0.10059886
 0.0591302  0.         0.64326429 1.         1.         0.
 0.31491977 0.54642052 0.         1.         1.         0.29594559
 0.81727994 1.         0.72435787 1.         0.38188501 0.
 0.         0.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.39199488 1.
  1.         0.         0.        ]
 [1.         0.         0.1868928  0.6142832  0.389202   1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.38911723 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.38893381 1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.38922776 1.
  0.         0.         1.        ]
 [1.         0.         0.68233464 0.69305653 0.38935804 1.
  0.         0.10059886 1.        ]
 [1.         0.         0.         0.         0.38934554 1.
  0.         0.0591302  1.        ]
 [1.         0.         0.         0.         0.38908947 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.38900857 1.
  0.         0.64326429 1.        ]
 [1.         0.         1.         1.         0.38914199 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.38897381 1.
  0.         1.         1.        ]
 [1.         0.         0.31612269 0.14842311 0.3892392  1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.38905708 1.
  0.         0.31491977 1.        ]
 [1.         0.         1.         1.         0.38921867 1.
  0.         0.54642052 1.        ]
 [1.         0.         0.98046542 0.90939087 0.38897999 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.38928517 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.38897557 1.
  0.         1.         1.        ]
 [1.         0.         1.         0.85416651 0.3891559  1.
  0.         0.29594559 1.        ]
 [1.         0.         1.         1.         0.38906832 1.
  0.         0.81727994 1.        ]
 [1.         0.         1.         1.         0.3890776  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.3892021  1.
  0.         0.72435787 1.        ]
 [1.         0.         1.         1.         0.38944059 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.3892076  1.
  0.         0.38188501 1.        ]
 [1.         0.         0.27487312 0.3591726  0.38922941 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.38915835 1.
  0.         0.         1.        ]
 [1.         0.         0.40483886 0.43893796 0.38898834 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.9285714030265808
#####################         POISON         ###############################################

############################################################################################

comm_round: 11 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.36850674 0.15206579 1.         0.97480114 1.
 0.48916731 1.         1.         1.         1.         0.
 1.         0.88005454 1.         0.         1.         0.95718594
 0.         1.         0.         0.92815664 1.         0.54330063
 0.         1.        ]
wv_ed shape (26,)
[0.         0.38883078 0.         1.         0.97018629 0.86194246
 0.59032733 1.         1.         1.         1.         0.
 1.         0.8402962  1.         0.         0.94030933 0.75616301
 0.         1.         0.         0.70423564 1.         0.31585012
 0.         0.89117282]
wv_lg shape (26, 1)
[[0.39211943]
 [0.3892595 ]
 [0.38957399]
 [0.38934276]
 [0.38976897]
 [0.38961166]
 [0.38938858]
 [0.38964266]
 [0.38934653]
 [0.38962817]
 [0.3896843 ]
 [0.38961304]
 [0.38944403]
 [0.38983461]
 [0.38962842]
 [0.38956619]
 [0.3897487 ]
 [0.3893097 ]
 [0.38962302]
 [0.38960908]
 [0.38963812]
 [0.38958387]
 [0.38949658]
 [0.38970273]
 [0.38968205]
 [0.38986781]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.08446685 0.66755128 1.         1.         1.
 0.7232328  1.         1.         1.         1.         0.
 1.         1.         1.         0.         1.         1.
 0.         0.80329096 0.         1.         1.         1.
 0.19554169 1.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.39211943 1.
  1.         0.         0.        ]
 [1.         0.         0.36850674 0.38883078 0.3892595  1.
  0.         0.08446685 1.        ]
 [1.         0.         0.15206579 0.         0.38957399 1.
  0.         0.66755128 1.        ]
 [1.         0.         1.         1.         0.38934276 1.
  0.         1.         1.        ]
 [1.         0.         0.97480114 0.97018629 0.38976897 1.
  0.         1.         1.        ]
 [1.         0.         1.         0.86194246 0.38961166 1.
  0.         1.         1.        ]
 [1.         0.         0.48916731 0.59032733 0.38938858 1.
  0.         0.7232328  1.        ]
 [1.         0.         1.         1.         0.38964266 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.38934653 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.38962817 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.3896843  1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.38961304 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.38944403 1.
  0.         1.         1.        ]
 [1.         0.         0.88005454 0.8402962  0.38983461 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.38962842 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.38956619 1.
  0.         0.         1.        ]
 [1.         0.         1.         0.94030933 0.3897487  1.
  0.         1.         1.        ]
 [1.         0.         0.95718594 0.75616301 0.3893097  1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.38962302 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.38960908 1.
  0.         0.80329096 1.        ]
 [1.         0.         0.         0.         0.38963812 1.
  0.         0.         1.        ]
 [1.         0.         0.92815664 0.70423564 0.38958387 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.38949658 1.
  0.         1.         1.        ]
 [1.         0.         0.54330063 0.31585012 0.38970273 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.38968205 1.
  0.         0.19554169 1.        ]
 [1.         0.         1.         0.89117282 0.38986781 1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
1.0
#####################         POISON         ###############################################

############################################################################################

comm_round: 12 | global_test_acc: 87.500% | global_f1: 0.9333333333333333 | global_precision: 0.875
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.88      1.00      0.93         7

    accuracy                           0.88         8
   macro avg       0.44      0.50      0.47         8
weighted avg       0.77      0.88      0.82         8
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.93757712 0.         0.         0.         0.
 1.         1.         0.79138908 0.91959243 0.         0.
 0.         0.3411855  0.67767502 1.         0.78648721 0.
 0.         1.         0.78580866 0.27085102 1.         1.
 1.         0.0311828 ]
wv_ed shape (26,)
[0.         0.63610517 0.         0.         0.         0.
 1.         1.         0.66253216 0.78983456 0.         0.
 0.12460396 0.         0.88437742 1.         0.81155003 0.
 0.         1.         0.62494402 0.         1.         0.84732253
 1.         0.        ]
wv_lg shape (26, 1)
[[0.3925159 ]
 [0.38968271]
 [0.38957914]
 [0.38971004]
 [0.38960949]
 [0.38958022]
 [0.38982027]
 [0.38942492]
 [0.38961422]
 [0.38991702]
 [0.38953679]
 [0.38963112]
 [0.3895413 ]
 [0.38998003]
 [0.389537  ]
 [0.38959759]
 [0.38983588]
 [0.3898649 ]
 [0.38966765]
 [0.38964581]
 [0.38964735]
 [0.38961929]
 [0.38986795]
 [0.38962242]
 [0.38986438]
 [0.38970517]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         1.         0.         0.26982244 0.         0.
 0.99495755 1.         1.         1.         0.         0.20278147
 0.24381904 1.         0.2454148  1.         0.87536945 0.07016913
 0.31871639 1.         1.         0.55365479 1.         1.
 1.         0.1534047 ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.3925159  1.
  1.         0.         0.        ]
 [1.         0.         0.93757712 0.63610517 0.38968271 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.38957914 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.38971004 1.
  0.         0.26982244 1.        ]
 [0.         0.         0.         0.         0.38960949 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.38958022 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.38982027 1.
  0.         0.99495755 1.        ]
 [1.         0.         1.         1.         0.38942492 1.
  0.         1.         1.        ]
 [1.         0.         0.79138908 0.66253216 0.38961422 1.
  0.         1.         1.        ]
 [1.         0.         0.91959243 0.78983456 0.38991702 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.38953679 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.38963112 1.
  0.         0.20278147 1.        ]
 [1.         0.         0.         0.12460396 0.3895413  1.
  0.         0.24381904 1.        ]
 [1.         0.         0.3411855  0.         0.38998003 1.
  0.         1.         1.        ]
 [1.         0.         0.67767502 0.88437742 0.389537   1.
  0.         0.2454148  1.        ]
 [1.         0.         1.         1.         0.38959759 1.
  0.         1.         1.        ]
 [1.         0.         0.78648721 0.81155003 0.38983588 1.
  0.         0.87536945 1.        ]
 [1.         0.         0.         0.         0.3898649  1.
  0.         0.07016913 1.        ]
 [1.         0.         0.         0.         0.38966765 1.
  0.         0.31871639 1.        ]
 [1.         0.         1.         1.         0.38964581 1.
  0.         1.         1.        ]
 [1.         0.         0.78580866 0.62494402 0.38964735 1.
  0.         1.         1.        ]
 [1.         0.         0.27085102 0.         0.38961929 1.
  0.         0.55365479 1.        ]
 [1.         0.         1.         1.         0.38986795 1.
  0.         1.         1.        ]
 [1.         0.         1.         0.84732253 0.38962242 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.38986438 1.
  0.         1.         1.        ]
 [1.         0.         0.0311828  0.         0.38970517 1.
  0.         0.1534047  1.        ]]

Best Training Poisoning Accuracy:
1.0
#####################         POISON         ###############################################

############################################################################################

comm_round: 13 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.72432474 1.         0.53097099 1.         0.
 0.         1.         0.         1.         0.14724527 1.
 0.         1.         0.         1.         0.         1.
 0.60211869 0.42159614 1.         0.         0.82289868 0.
 0.         0.        ]
wv_ed shape (26,)
[0.         0.44530316 1.         0.57702727 1.         0.01910305
 0.         1.         0.         1.         0.15841805 1.
 0.00585527 1.         0.31881811 1.         0.         1.
 0.8531931  0.74850476 1.         0.         0.90259122 0.
 0.22839211 0.08754214]
wv_lg shape (26, 1)
[[0.39264612]
 [0.39008705]
 [0.39032066]
 [0.38999522]
 [0.39002411]
 [0.39009422]
 [0.38995002]
 [0.38972787]
 [0.38992591]
 [0.39031455]
 [0.39009115]
 [0.39005075]
 [0.38968528]
 [0.39000282]
 [0.39013902]
 [0.38996673]
 [0.39006174]
 [0.39005303]
 [0.38985976]
 [0.38981328]
 [0.38978988]
 [0.39018576]
 [0.3897498 ]
 [0.39010176]
 [0.38999593]
 [0.39005846]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         1.         0.75346169 0.23559342 1.         0.15565351
 0.         0.81543007 0.         1.         0.27649535 1.
 0.25068354 1.         0.         1.         0.         1.
 0.02925299 0.         1.         0.         0.60144599 0.
 0.         0.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.39264612 1.
  1.         0.         0.        ]
 [1.         0.         0.72432474 0.44530316 0.39008705 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.39032066 1.
  0.         0.75346169 1.        ]
 [1.         0.         0.53097099 0.57702727 0.38999522 1.
  0.         0.23559342 1.        ]
 [1.         0.         1.         1.         0.39002411 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.01910305 0.39009422 1.
  0.         0.15565351 1.        ]
 [1.         0.         0.         0.         0.38995002 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.38972787 1.
  0.         0.81543007 1.        ]
 [1.         0.         0.         0.         0.38992591 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.39031455 1.
  0.         1.         1.        ]
 [1.         0.         0.14724527 0.15841805 0.39009115 1.
  0.         0.27649535 1.        ]
 [1.         0.         1.         1.         0.39005075 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.00585527 0.38968528 1.
  0.         0.25068354 1.        ]
 [1.         0.         1.         1.         0.39000282 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.31881811 0.39013902 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.38996673 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.39006174 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.39005303 1.
  0.         1.         1.        ]
 [1.         0.         0.60211869 0.8531931  0.38985976 1.
  0.         0.02925299 1.        ]
 [1.         0.         0.42159614 0.74850476 0.38981328 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.38978988 1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.39018576 1.
  0.         0.         1.        ]
 [1.         0.         0.82289868 0.90259122 0.3897498  1.
  0.         0.60144599 1.        ]
 [1.         0.         0.         0.         0.39010176 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.22839211 0.38999593 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.08754214 0.39005846 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.9285714030265808
#####################         POISON         ###############################################

############################################################################################

comm_round: 14 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.         0.         0.         0.         0.
 0.69465377 0.         0.         0.         1.         0.03957785
 0.44723145 0.         0.         0.         0.         1.
 1.         0.26078437 1.         1.         0.         0.
 0.         0.86288527]
wv_ed shape (26,)
[0.         0.         0.         0.         0.         0.
 0.45953185 0.         0.         0.10301956 1.         0.
 0.54977472 0.11345617 0.10620568 0.         0.         1.
 1.         0.43607411 1.         1.         0.         0.
 0.         1.        ]
wv_lg shape (26, 1)
[[0.39247592]
 [0.39057832]
 [0.39065541]
 [0.39062381]
 [0.39092203]
 [0.39032589]
 [0.39065941]
 [0.39048648]
 [0.3910636 ]
 [0.3904249 ]
 [0.39047801]
 [0.39061835]
 [0.39044398]
 [0.3906918 ]
 [0.39094012]
 [0.39087662]
 [0.39059052]
 [0.39073933]
 [0.39087587]
 [0.39047192]
 [0.3906941 ]
 [0.39063827]
 [0.39069509]
 [0.39044205]
 [0.39046412]
 [0.3907247 ]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.         0.         0.         0.         0.
 0.92691968 0.         0.         0.14803227 1.         0.79069744
 0.01049849 0.         0.11526449 0.         0.         1.
 1.         0.32902244 1.         1.         0.         0.
 0.         0.7428258 ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.39247592 1.
  1.         0.         0.        ]
 [1.         0.         0.         0.         0.39057832 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.39065541 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.39062381 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.39092203 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.39032589 1.
  0.         0.         1.        ]
 [1.         0.         0.69465377 0.45953185 0.39065941 1.
  0.         0.92691968 1.        ]
 [1.         0.         0.         0.         0.39048648 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.3910636  1.
  0.         0.         1.        ]
 [1.         0.         0.         0.10301956 0.3904249  1.
  0.         0.14803227 1.        ]
 [1.         0.         1.         1.         0.39047801 1.
  0.         1.         1.        ]
 [1.         0.         0.03957785 0.         0.39061835 1.
  0.         0.79069744 1.        ]
 [1.         0.         0.44723145 0.54977472 0.39044398 1.
  0.         0.01049849 1.        ]
 [1.         0.         0.         0.11345617 0.3906918  1.
  0.         0.         1.        ]
 [1.         0.         0.         0.10620568 0.39094012 1.
  0.         0.11526449 1.        ]
 [1.         0.         0.         0.         0.39087662 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.39059052 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.39073933 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.39087587 1.
  0.         1.         1.        ]
 [1.         0.         0.26078437 0.43607411 0.39047192 1.
  0.         0.32902244 1.        ]
 [1.         0.         1.         1.         0.3906941  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.39063827 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.39069509 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.39044205 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.39046412 1.
  0.         0.         1.        ]
 [1.         0.         0.86288527 1.         0.3907247  1.
  0.         0.7428258  1.        ]]

Best Training Poisoning Accuracy:
0.9285714030265808
#####################         POISON         ###############################################

############################################################################################

comm_round: 15 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         1.         0.2294526  0.2054902  0.         0.
 0.         1.         0.06229545 0.34599182 1.         0.
 0.83482317 0.         0.22263101 0.25992418 1.         0.
 1.         0.62914547 1.         0.         0.         0.6647802
 0.         0.17851034]
wv_ed shape (26,)
[0.         1.         0.19707241 0.06879385 0.         0.
 0.         1.         0.         0.3436116  1.         0.
 0.82916877 0.         0.51243955 0.30753078 1.         0.
 1.         0.46727188 1.         0.         0.         0.63978236
 0.         0.        ]
wv_lg shape (26, 1)
[[0.39283841]
 [0.39054196]
 [0.39067387]
 [0.39060813]
 [0.39065006]
 [0.39081187]
 [0.39048615]
 [0.39083378]
 [0.39075846]
 [0.39089616]
 [0.39084565]
 [0.39075435]
 [0.39036674]
 [0.39063843]
 [0.39066162]
 [0.39062421]
 [0.39105903]
 [0.39073036]
 [0.39034145]
 [0.39058366]
 [0.39052948]
 [0.39091384]
 [0.39081619]
 [0.39085809]
 [0.3906342 ]
 [0.39071937]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         1.         0.56052843 0.66854803 0.         0.02169184
 0.         1.         0.70685378 0.         1.         0.
 0.6582639  0.         0.         0.75956    1.         0.
 1.         1.         1.         0.         0.         0.56711318
 0.         0.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.39283841 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.39054196 1.
  0.         1.         1.        ]
 [1.         0.         0.2294526  0.19707241 0.39067387 1.
  0.         0.56052843 1.        ]
 [1.         0.         0.2054902  0.06879385 0.39060813 1.
  0.         0.66854803 1.        ]
 [1.         0.         0.         0.         0.39065006 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.39081187 1.
  0.         0.02169184 1.        ]
 [1.         0.         0.         0.         0.39048615 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.39083378 1.
  0.         1.         1.        ]
 [1.         0.         0.06229545 0.         0.39075846 1.
  0.         0.70685378 1.        ]
 [1.         0.         0.34599182 0.3436116  0.39089616 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.39084565 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.39075435 1.
  0.         0.         1.        ]
 [1.         0.         0.83482317 0.82916877 0.39036674 1.
  0.         0.6582639  1.        ]
 [1.         0.         0.         0.         0.39063843 1.
  0.         0.         1.        ]
 [1.         0.         0.22263101 0.51243955 0.39066162 1.
  0.         0.         1.        ]
 [1.         0.         0.25992418 0.30753078 0.39062421 1.
  0.         0.75956    1.        ]
 [1.         0.         1.         1.         0.39105903 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.39073036 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.39034145 1.
  0.         1.         1.        ]
 [1.         0.         0.62914547 0.46727188 0.39058366 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.39052948 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.39091384 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.39081619 1.
  0.         0.         1.        ]
 [1.         0.         0.6647802  0.63978236 0.39085809 1.
  0.         0.56711318 1.        ]
 [1.         0.         0.         0.         0.3906342  1.
  0.         0.         1.        ]
 [1.         0.         0.17851034 0.         0.39071937 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.9285714030265808
#####################         POISON         ###############################################

############################################################################################

comm_round: 16 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         1.         1.         1.         0.         1.
 1.         0.4858289  1.         1.         0.         0.8298702
 0.         0.75151559 0.36868905 0.96829541 0.40075051 1.
 1.         0.         0.75336478 0.50681003 1.         0.51653146
 0.         1.        ]
wv_ed shape (26,)
[0.         1.         1.         1.         0.         1.
 1.         0.         1.         1.         0.         0.80225703
 0.         0.73523525 0.34978762 1.         0.32489489 1.
 1.         0.         0.91642787 0.57717667 1.         0.7536853
 0.         1.        ]
wv_lg shape (26, 1)
[[0.39292373]
 [0.39110422]
 [0.39085303]
 [0.39109471]
 [0.39092045]
 [0.39110691]
 [0.39100902]
 [0.39090257]
 [0.39103136]
 [0.39075212]
 [0.39120984]
 [0.39094215]
 [0.39103943]
 [0.3908989 ]
 [0.39113913]
 [0.3908848 ]
 [0.39088019]
 [0.39117821]
 [0.390759  ]
 [0.39076904]
 [0.39109109]
 [0.39100518]
 [0.39108822]
 [0.39107434]
 [0.39094482]
 [0.3907354 ]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         1.         1.         1.         0.         1.
 1.         1.         1.         1.         0.         1.
 0.35385185 1.         0.90316647 1.         0.9325216  1.
 1.         0.73382648 1.         1.         1.         0.89576094
 0.43019549 1.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.39292373 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.39110422 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.39085303 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.39109471 1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.39092045 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.39110691 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.39100902 1.
  0.         1.         1.        ]
 [1.         0.         0.4858289  0.         0.39090257 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.39103136 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.39075212 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.39120984 1.
  0.         0.         1.        ]
 [1.         0.         0.8298702  0.80225703 0.39094215 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.39103943 1.
  0.         0.35385185 1.        ]
 [1.         0.         0.75151559 0.73523525 0.3908989  1.
  0.         1.         1.        ]
 [1.         0.         0.36868905 0.34978762 0.39113913 1.
  0.         0.90316647 1.        ]
 [1.         0.         0.96829541 1.         0.3908848  1.
  0.         1.         1.        ]
 [1.         0.         0.40075051 0.32489489 0.39088019 1.
  0.         0.9325216  1.        ]
 [1.         0.         1.         1.         0.39117821 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.390759   1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.39076904 1.
  0.         0.73382648 1.        ]
 [1.         0.         0.75336478 0.91642787 0.39109109 1.
  0.         1.         1.        ]
 [1.         0.         0.50681003 0.57717667 0.39100518 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.39108822 1.
  0.         1.         1.        ]
 [1.         0.         0.51653146 0.7536853  0.39107434 1.
  0.         0.89576094 1.        ]
 [1.         0.         0.         0.         0.39094482 1.
  0.         0.43019549 1.        ]
 [1.         0.         1.         1.         0.3907354  1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
1.0
#####################         POISON         ###############################################

############################################################################################

comm_round: 17 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.21026272 0.         0.         1.         1.
 0.         0.         1.         0.24039042 1.         1.
 0.41471089 0.23223513 0.         0.         1.         0.
 0.68588031 0.25688169 1.         0.63199245 0.03373935 0.5846423
 0.83445712 1.        ]
wv_ed shape (26,)
[0.         0.         0.         0.         1.         1.
 0.         0.         1.         0.09937565 1.         1.
 0.81574642 0.14506263 0.         0.         1.         0.01867343
 0.74771125 0.38964197 1.         0.94744357 0.1194743  0.56913351
 1.         1.        ]
wv_lg shape (26, 1)
[[0.39326442]
 [0.39086722]
 [0.39113665]
 [0.39096856]
 [0.39079008]
 [0.39094504]
 [0.39110757]
 [0.39100049]
 [0.39093148]
 [0.39080405]
 [0.39099825]
 [0.39117412]
 [0.39089902]
 [0.39103647]
 [0.39089003]
 [0.39092333]
 [0.39105109]
 [0.39092602]
 [0.39110793]
 [0.39114011]
 [0.3912161 ]
 [0.39103877]
 [0.39122651]
 [0.39109133]
 [0.39113694]
 [0.39118093]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.18877178 0.         0.         1.         0.81693664
 0.         0.         1.         0.50866857 1.         1.
 0.         0.30440278 0.         0.         0.69571532 0.
 0.73820528 0.0058659  1.         0.         0.11848283 0.74630152
 0.5138715  0.77924898]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.39326442 1.
  1.         0.         0.        ]
 [1.         0.         0.21026272 0.         0.39086722 1.
  0.         0.18877178 1.        ]
 [0.         0.         0.         0.         0.39113665 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.39096856 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.39079008 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.39094504 1.
  0.         0.81693664 1.        ]
 [1.         0.         0.         0.         0.39110757 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.39100049 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.39093148 1.
  0.         1.         1.        ]
 [1.         0.         0.24039042 0.09937565 0.39080405 1.
  0.         0.50866857 1.        ]
 [1.         0.         1.         1.         0.39099825 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.39117412 1.
  0.         1.         1.        ]
 [1.         0.         0.41471089 0.81574642 0.39089902 1.
  0.         0.         1.        ]
 [1.         0.         0.23223513 0.14506263 0.39103647 1.
  0.         0.30440278 1.        ]
 [1.         0.         0.         0.         0.39089003 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.39092333 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.39105109 1.
  0.         0.69571532 1.        ]
 [1.         0.         0.         0.01867343 0.39092602 1.
  0.         0.         1.        ]
 [1.         0.         0.68588031 0.74771125 0.39110793 1.
  0.         0.73820528 1.        ]
 [1.         0.         0.25688169 0.38964197 0.39114011 1.
  0.         0.0058659  1.        ]
 [1.         0.         1.         1.         0.3912161  1.
  0.         1.         1.        ]
 [1.         0.         0.63199245 0.94744357 0.39103877 1.
  0.         0.         1.        ]
 [1.         0.         0.03373935 0.1194743  0.39122651 1.
  0.         0.11848283 1.        ]
 [1.         0.         0.5846423  0.56913351 0.39109133 1.
  0.         0.74630152 1.        ]
 [1.         0.         0.83445712 1.         0.39113694 1.
  0.         0.5138715  1.        ]
 [1.         0.         1.         1.         0.39118093 1.
  0.         0.77924898 1.        ]]

Best Training Poisoning Accuracy:
0.9285714030265808
#####################         POISON         ###############################################

############################################################################################

comm_round: 18 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 0.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         1.         0.22270481 0.         0.53565821 0.
 1.         0.         0.73325054 0.         0.         0.76231564
 1.         1.         0.87842013 0.         1.         0.
 0.23251853 0.02788879 1.         0.20128351 1.         1.
 0.         0.        ]
wv_ed shape (26,)
[0.         1.         0.20181842 0.21002127 0.50608416 0.
 1.         0.         0.50898109 0.         0.         0.67296509
 0.94717326 1.         1.         0.         1.         0.
 0.25460974 0.         1.         0.19491725 0.99398885 1.
 0.         0.        ]
wv_lg shape (26, 1)
[[0.39355665]
 [0.39126346]
 [0.39124898]
 [0.39105233]
 [0.3910858 ]
 [0.39092154]
 [0.39114487]
 [0.39098014]
 [0.39132507]
 [0.39101066]
 [0.39089011]
 [0.39106091]
 [0.39098229]
 [0.39098274]
 [0.39100017]
 [0.39110488]
 [0.39122397]
 [0.39093781]
 [0.39113333]
 [0.39131157]
 [0.39106666]
 [0.39106005]
 [0.39096468]
 [0.39093239]
 [0.39110565]
 [0.39108078]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         1.         0.27697601 0.         0.72847695 0.
 1.         0.         1.         0.         0.         1.
 1.         1.         1.         0.         1.         0.37730916
 0.22728095 0.60866552 1.         0.54841458 1.         1.
 0.         0.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.39355665 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.39126346 1.
  0.         1.         1.        ]
 [1.         0.         0.22270481 0.20181842 0.39124898 1.
  0.         0.27697601 1.        ]
 [1.         0.         0.         0.21002127 0.39105233 1.
  0.         0.         1.        ]
 [1.         0.         0.53565821 0.50608416 0.3910858  1.
  0.         0.72847695 1.        ]
 [1.         0.         0.         0.         0.39092154 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.39114487 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.39098014 1.
  0.         0.         1.        ]
 [1.         0.         0.73325054 0.50898109 0.39132507 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.39101066 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.39089011 1.
  0.         0.         1.        ]
 [1.         0.         0.76231564 0.67296509 0.39106091 1.
  0.         1.         1.        ]
 [1.         0.         1.         0.94717326 0.39098229 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.39098274 1.
  0.         1.         1.        ]
 [1.         0.         0.87842013 1.         0.39100017 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.39110488 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.39122397 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.39093781 1.
  0.         0.37730916 1.        ]
 [1.         0.         0.23251853 0.25460974 0.39113333 1.
  0.         0.22728095 1.        ]
 [1.         0.         0.02788879 0.         0.39131157 1.
  0.         0.60866552 1.        ]
 [1.         0.         1.         1.         0.39106666 1.
  0.         1.         1.        ]
 [1.         0.         0.20128351 0.19491725 0.39106005 1.
  0.         0.54841458 1.        ]
 [1.         0.         1.         0.99398885 0.39096468 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.39093239 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.39110565 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.39108078 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.9285714030265808
#####################         POISON         ###############################################

############################################################################################

comm_round: 19 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 0. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.79977609 0.59400888 0.         1.         1.
 0.         0.24580197 0.73656558 0.28829884 0.50683139 0.71786027
 1.         0.01933599 0.         0.72285475 0.         0.
 0.         0.         0.         0.36682263 0.08985061 1.
 0.         0.        ]
wv_ed shape (26,)
[0.         0.23225322 0.20043163 0.         0.8445642  1.
 0.         0.         0.57741414 0.01840666 0.         0.42358948
 1.         0.         0.         0.73546916 0.         0.
 0.         0.         0.         0.         0.         1.
 0.         0.        ]
wv_lg shape (26, 1)
[[0.3935232 ]
 [0.39163333]
 [0.3913116 ]
 [0.39156849]
 [0.39139075]
 [0.39167425]
 [0.39147542]
 [0.39194094]
 [0.391507  ]
 [0.39141393]
 [0.39135055]
 [0.39178723]
 [0.39132496]
 [0.39157572]
 [0.39163459]
 [0.39171145]
 [0.39137446]
 [0.39141008]
 [0.39134723]
 [0.39143998]
 [0.39134735]
 [0.39136368]
 [0.3914164 ]
 [0.39138887]
 [0.39163847]
 [0.39136472]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         1.         0.         0.         0.71099045 0.91094572
 0.         0.48886968 0.         0.12597262 0.         0.68136142
 1.         0.         0.         0.06346457 0.         0.
 0.         0.         0.         0.         0.04708315 0.32034837
 0.         0.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.3935232  1.
  1.         0.         0.        ]
 [1.         0.         0.79977609 0.23225322 0.39163333 1.
  0.         1.         1.        ]
 [1.         0.         0.59400888 0.20043163 0.3913116  1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.39156849 1.
  0.         0.         1.        ]
 [1.         0.         1.         0.8445642  0.39139075 1.
  0.         0.71099045 1.        ]
 [1.         0.         1.         1.         0.39167425 1.
  0.         0.91094572 1.        ]
 [1.         0.         0.         0.         0.39147542 1.
  0.         0.         1.        ]
 [1.         0.         0.24580197 0.         0.39194094 1.
  0.         0.48886968 1.        ]
 [1.         0.         0.73656558 0.57741414 0.391507   1.
  0.         0.         1.        ]
 [1.         0.         0.28829884 0.01840666 0.39141393 1.
  0.         0.12597262 1.        ]
 [1.         0.         0.50683139 0.         0.39135055 1.
  0.         0.         1.        ]
 [1.         0.         0.71786027 0.42358948 0.39178723 1.
  0.         0.68136142 1.        ]
 [1.         0.         1.         1.         0.39132496 1.
  0.         1.         1.        ]
 [1.         0.         0.01933599 0.         0.39157572 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.39163459 1.
  0.         0.         1.        ]
 [1.         0.         0.72285475 0.73546916 0.39171145 1.
  0.         0.06346457 1.        ]
 [1.         0.         0.         0.         0.39137446 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.39141008 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.39134723 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.39143998 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.39134735 1.
  0.         0.         1.        ]
 [1.         0.         0.36682263 0.         0.39136368 1.
  0.         0.         1.        ]
 [1.         0.         0.08985061 0.         0.3914164  1.
  0.         0.04708315 1.        ]
 [1.         0.         1.         1.         0.39138887 1.
  0.         0.32034837 1.        ]
 [0.         0.         0.         0.         0.39163847 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.39136472 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
1.0
#####################         POISON         ###############################################

############################################################################################

comm_round: 20 | global_test_acc: 87.500% | global_f1: 0.9333333333333333 | global_precision: 0.875
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.88      1.00      0.93         7

    accuracy                           0.88         8
   macro avg       0.44      0.50      0.47         8
weighted avg       0.77      0.88      0.82         8
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.23390872 1.         0.         0.         0.48444607
 0.24013252 0.82234396 0.33329293 0.49134222 0.         0.
 0.43945014 0.         1.         0.         0.         1.
 0.         0.         0.8860421  0.53174697 0.         0.
 1.         0.05980981]
wv_ed shape (26,)
[0.         0.63817024 1.         0.         0.         0.37883352
 0.32808259 1.         0.39988543 0.46985886 0.         0.
 0.12941229 0.         1.         0.         0.0696267  0.86455465
 0.         0.         0.81337053 0.30977049 0.         0.
 1.         0.19910023]
wv_lg shape (26, 1)
[[0.39358342]
 [0.39156306]
 [0.39176682]
 [0.39173128]
 [0.39186302]
 [0.39176833]
 [0.39188867]
 [0.39177711]
 [0.39162484]
 [0.39178689]
 [0.39168028]
 [0.39188686]
 [0.39182597]
 [0.39184227]
 [0.39151668]
 [0.39204149]
 [0.39193234]
 [0.39179525]
 [0.3918843 ]
 [0.39178152]
 [0.39163996]
 [0.39183156]
 [0.39200604]
 [0.3920411 ]
 [0.39183865]
 [0.39171801]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.         1.         0.         0.         0.88147414
 0.         0.24794166 0.37835951 0.19125989 0.         0.
 1.         0.         1.         0.         0.         1.
 0.         0.         1.         0.66035252 0.         0.76299606
 1.         0.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.39358342 1.
  1.         0.         0.        ]
 [1.         0.         0.23390872 0.63817024 0.39156306 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.39176682 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.39173128 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.39186302 1.
  0.         0.         1.        ]
 [1.         0.         0.48444607 0.37883352 0.39176833 1.
  0.         0.88147414 1.        ]
 [1.         0.         0.24013252 0.32808259 0.39188867 1.
  0.         0.         1.        ]
 [1.         0.         0.82234396 1.         0.39177711 1.
  0.         0.24794166 1.        ]
 [1.         0.         0.33329293 0.39988543 0.39162484 1.
  0.         0.37835951 1.        ]
 [1.         0.         0.49134222 0.46985886 0.39178689 1.
  0.         0.19125989 1.        ]
 [1.         0.         0.         0.         0.39168028 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.39188686 1.
  0.         0.         1.        ]
 [1.         0.         0.43945014 0.12941229 0.39182597 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.39184227 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.39151668 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.39204149 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.0696267  0.39193234 1.
  0.         0.         1.        ]
 [1.         0.         1.         0.86455465 0.39179525 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.3918843  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.39178152 1.
  0.         0.         1.        ]
 [1.         0.         0.8860421  0.81337053 0.39163996 1.
  0.         1.         1.        ]
 [1.         0.         0.53174697 0.30977049 0.39183156 1.
  0.         0.66035252 1.        ]
 [1.         0.         0.         0.         0.39200604 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.3920411  1.
  0.         0.76299606 1.        ]
 [1.         0.         1.         1.         0.39183865 1.
  0.         1.         1.        ]
 [1.         0.         0.05980981 0.19910023 0.39171801 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.9285714030265808
#####################         POISON         ###############################################

############################################################################################

comm_round: 21 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.         0.         0.         0.64756535 1.
 0.         0.54934213 0.         0.50363652 0.         1.
 0.31754257 0.         1.         1.         0.16207221 0.
 1.         0.30770371 1.         0.38569604 0.81377005 0.50759799
 0.         0.60572727]
wv_ed shape (26,)
[0.         0.         0.         0.         0.50417028 1.
 0.         0.37380635 0.         0.60230733 0.         1.
 0.24485449 0.         1.         1.         0.         0.
 1.         0.15732579 1.         0.26170383 0.63452045 0.33353483
 0.         0.84141141]
wv_lg shape (26, 1)
[[0.39404506]
 [0.39171004]
 [0.39159053]
 [0.39155458]
 [0.39159238]
 [0.39162187]
 [0.39162452]
 [0.39154079]
 [0.39155596]
 [0.39198062]
 [0.39158892]
 [0.39171725]
 [0.39159013]
 [0.39152729]
 [0.39192721]
 [0.39180926]
 [0.39175833]
 [0.39165048]
 [0.39171355]
 [0.39156772]
 [0.39174873]
 [0.39165564]
 [0.39166976]
 [0.39165141]
 [0.39176457]
 [0.3915885 ]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.         0.         0.         0.61634831 1.
 0.         0.57829028 0.         0.40144963 0.         1.
 0.30241838 0.         1.         1.         0.14090793 0.
 1.         0.60750527 1.         0.73226481 1.         0.51690999
 0.         0.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.39404506 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.39171004 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.39159053 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.39155458 1.
  0.         0.         1.        ]
 [1.         0.         0.64756535 0.50417028 0.39159238 1.
  0.         0.61634831 1.        ]
 [1.         0.         1.         1.         0.39162187 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.39162452 1.
  0.         0.         1.        ]
 [1.         0.         0.54934213 0.37380635 0.39154079 1.
  0.         0.57829028 1.        ]
 [1.         0.         0.         0.         0.39155596 1.
  0.         0.         1.        ]
 [1.         0.         0.50363652 0.60230733 0.39198062 1.
  0.         0.40144963 1.        ]
 [1.         0.         0.         0.         0.39158892 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.39171725 1.
  0.         1.         1.        ]
 [1.         0.         0.31754257 0.24485449 0.39159013 1.
  0.         0.30241838 1.        ]
 [1.         0.         0.         0.         0.39152729 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.39192721 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.39180926 1.
  0.         1.         1.        ]
 [1.         0.         0.16207221 0.         0.39175833 1.
  0.         0.14090793 1.        ]
 [1.         0.         0.         0.         0.39165048 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.39171355 1.
  0.         1.         1.        ]
 [1.         0.         0.30770371 0.15732579 0.39156772 1.
  0.         0.60750527 1.        ]
 [1.         0.         1.         1.         0.39174873 1.
  0.         1.         1.        ]
 [1.         0.         0.38569604 0.26170383 0.39165564 1.
  0.         0.73226481 1.        ]
 [1.         0.         0.81377005 0.63452045 0.39166976 1.
  0.         1.         1.        ]
 [1.         0.         0.50759799 0.33353483 0.39165141 1.
  0.         0.51690999 1.        ]
 [1.         0.         0.         0.         0.39176457 1.
  0.         0.         1.        ]
 [1.         0.         0.60572727 0.84141141 0.3915885  1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.9285714030265808
#####################         POISON         ###############################################

############################################################################################

comm_round: 22 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.87067796 0.34197193 0.24935576 1.         0.80512239
 1.         1.         0.         1.         0.93421849 1.
 1.         0.9881637  0.         1.         0.33860428 1.
 0.10743496 0.75417533 0.05470901 1.         1.         1.
 1.         0.44485458]
wv_ed shape (26,)
[0.         0.80172075 0.21325498 0.06504451 1.         0.73970465
 1.         1.         0.         1.         0.56093772 1.
 1.         1.         0.         1.         0.09861656 0.98529668
 0.06735948 0.62509123 0.06364358 1.         1.         1.
 1.         0.40869839]
wv_lg shape (26, 1)
[[0.39423126]
 [0.39178384]
 [0.39190389]
 [0.39177124]
 [0.39160241]
 [0.39194124]
 [0.39165074]
 [0.39193242]
 [0.39197251]
 [0.39225783]
 [0.39175213]
 [0.39155851]
 [0.39171594]
 [0.39186267]
 [0.39193554]
 [0.39168546]
 [0.39186337]
 [0.39167472]
 [0.39176359]
 [0.39164996]
 [0.39180893]
 [0.39209173]
 [0.39176645]
 [0.39183069]
 [0.3918926 ]
 [0.39188947]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.58651712 0.35834072 0.69379226 1.         0.90017611
 1.         1.         0.         1.         1.         0.89913398
 0.80685644 0.1292698  0.26236746 1.         0.24127907 1.
 0.         0.70893379 0.29039967 1.         1.         1.
 0.76452824 0.28167598]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.39423126 1.
  1.         0.         0.        ]
 [1.         0.         0.87067796 0.80172075 0.39178384 1.
  0.         0.58651712 1.        ]
 [1.         0.         0.34197193 0.21325498 0.39190389 1.
  0.         0.35834072 1.        ]
 [1.         0.         0.24935576 0.06504451 0.39177124 1.
  0.         0.69379226 1.        ]
 [1.         0.         1.         1.         0.39160241 1.
  0.         1.         1.        ]
 [1.         0.         0.80512239 0.73970465 0.39194124 1.
  0.         0.90017611 1.        ]
 [1.         0.         1.         1.         0.39165074 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.39193242 1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.39197251 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.39225783 1.
  0.         1.         1.        ]
 [1.         0.         0.93421849 0.56093772 0.39175213 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.39155851 1.
  0.         0.89913398 1.        ]
 [1.         0.         1.         1.         0.39171594 1.
  0.         0.80685644 1.        ]
 [1.         0.         0.9881637  1.         0.39186267 1.
  0.         0.1292698  1.        ]
 [1.         0.         0.         0.         0.39193554 1.
  0.         0.26236746 1.        ]
 [1.         0.         1.         1.         0.39168546 1.
  0.         1.         1.        ]
 [1.         0.         0.33860428 0.09861656 0.39186337 1.
  0.         0.24127907 1.        ]
 [1.         0.         1.         0.98529668 0.39167472 1.
  0.         1.         1.        ]
 [1.         0.         0.10743496 0.06735948 0.39176359 1.
  0.         0.         1.        ]
 [1.         0.         0.75417533 0.62509123 0.39164996 1.
  0.         0.70893379 1.        ]
 [1.         0.         0.05470901 0.06364358 0.39180893 1.
  0.         0.29039967 1.        ]
 [1.         0.         1.         1.         0.39209173 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.39176645 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.39183069 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.3918926  1.
  0.         0.76452824 1.        ]
 [1.         0.         0.44485458 0.40869839 0.39188947 1.
  0.         0.28167598 1.        ]]

Best Training Poisoning Accuracy:
1.0
#####################         POISON         ###############################################

############################################################################################

comm_round: 23 | global_test_acc: 87.500% | global_f1: 0.9333333333333333 | global_precision: 0.875
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.88      1.00      0.93         7

    accuracy                           0.88         8
   macro avg       0.44      0.50      0.47         8
weighted avg       0.77      0.88      0.82         8
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.         0.10569182 0.         1.         0.
 1.         0.         0.         0.         1.         1.
 0.         0.65417782 0.         0.43930599 0.27923251 0.20688637
 0.         0.66273058 1.         0.34488948 0.         1.
 1.         0.        ]
wv_ed shape (26,)
[0.         0.         0.04810787 0.         1.         0.
 1.         0.         0.17476596 0.         1.         0.99526731
 0.         0.57469746 0.         0.27235801 0.06139977 0.33322719
 0.         0.6889022  0.87380396 0.26360971 0.         1.
 1.         0.        ]
wv_lg shape (26, 1)
[[0.39404081]
 [0.39246705]
 [0.39233183]
 [0.39248424]
 [0.39240007]
 [0.39261788]
 [0.39210898]
 [0.39241611]
 [0.3923606 ]
 [0.39238295]
 [0.3924877 ]
 [0.39231818]
 [0.39232322]
 [0.39239555]
 [0.39236409]
 [0.39245183]
 [0.39237516]
 [0.39238662]
 [0.39238262]
 [0.39247674]
 [0.39241824]
 [0.39232751]
 [0.39203501]
 [0.39241274]
 [0.39219774]
 [0.39215846]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.         0.9009825  0.         1.         1.
 1.         0.         0.18393284 0.         1.         1.
 0.         1.         0.         1.         0.82957087 0.48454655
 0.         1.         1.         1.         0.         1.
 1.         0.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.39404081 1.
  1.         0.         0.        ]
 [1.         0.         0.         0.         0.39246705 1.
  0.         0.         1.        ]
 [1.         0.         0.10569182 0.04810787 0.39233183 1.
  0.         0.9009825  1.        ]
 [1.         0.         0.         0.         0.39248424 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.39240007 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.39261788 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.39210898 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.39241611 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.17476596 0.3923606  1.
  0.         0.18393284 1.        ]
 [0.         0.         0.         0.         0.39238295 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.3924877  1.
  0.         1.         1.        ]
 [1.         0.         1.         0.99526731 0.39231818 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.39232322 1.
  0.         0.         1.        ]
 [1.         0.         0.65417782 0.57469746 0.39239555 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.39236409 1.
  0.         0.         1.        ]
 [1.         0.         0.43930599 0.27235801 0.39245183 1.
  0.         1.         1.        ]
 [1.         0.         0.27923251 0.06139977 0.39237516 1.
  0.         0.82957087 1.        ]
 [1.         0.         0.20688637 0.33322719 0.39238662 1.
  0.         0.48454655 1.        ]
 [1.         0.         0.         0.         0.39238262 1.
  0.         0.         1.        ]
 [1.         0.         0.66273058 0.6889022  0.39247674 1.
  0.         1.         1.        ]
 [1.         0.         1.         0.87380396 0.39241824 1.
  0.         1.         1.        ]
 [1.         0.         0.34488948 0.26360971 0.39232751 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.39203501 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.39241274 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.39219774 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.39215846 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
1.0
#####################         POISON         ###############################################

############################################################################################

comm_round: 24 | global_test_acc: 87.500% | global_f1: 0.9333333333333333 | global_precision: 0.875
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.88      1.00      0.93         7

    accuracy                           0.88         8
   macro avg       0.44      0.50      0.47         8
weighted avg       0.77      0.88      0.82         8
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.17434134 0.96051594 0.         0.         0.
 0.         0.         0.98036873 0.         0.         0.88009128
 1.         0.         0.         0.         1.         0.
 0.24848171 0.         0.37957961 0.         0.         0.
 0.73088717 0.03271693]
wv_ed shape (26,)
[0.         0.10989384 0.69976251 0.         0.         0.
 0.         0.         0.69825274 0.         0.         1.
 0.87847929 0.         0.         0.         1.         0.
 0.46409603 0.         0.05211296 0.         0.         0.
 0.36957318 0.        ]
wv_lg shape (26, 1)
[[0.39389142]
 [0.39308927]
 [0.39286364]
 [0.39271224]
 [0.39299104]
 [0.39276678]
 [0.39267764]
 [0.3926897 ]
 [0.39256963]
 [0.39254321]
 [0.39302498]
 [0.39280559]
 [0.39277668]
 [0.39272931]
 [0.3928621 ]
 [0.39289056]
 [0.39293224]
 [0.39291448]
 [0.39289675]
 [0.3927889 ]
 [0.39285071]
 [0.39306408]
 [0.39288301]
 [0.39298742]
 [0.39275251]
 [0.39286468]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.82811813 1.         0.         0.         0.66284461
 0.         0.69537087 1.         0.         0.         0.43198867
 1.         0.         0.         0.         1.         0.13336007
 0.54825926 0.05414865 1.         0.         0.         0.53855052
 1.         1.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.39389142 1.
  1.         0.         0.        ]
 [1.         0.         0.17434134 0.10989384 0.39308927 1.
  0.         0.82811813 1.        ]
 [1.         0.         0.96051594 0.69976251 0.39286364 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.39271224 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.39299104 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.39276678 1.
  0.         0.66284461 1.        ]
 [1.         0.         0.         0.         0.39267764 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.3926897  1.
  0.         0.69537087 1.        ]
 [1.         0.         0.98036873 0.69825274 0.39256963 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.39254321 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.39302498 1.
  0.         0.         1.        ]
 [1.         0.         0.88009128 1.         0.39280559 1.
  0.         0.43198867 1.        ]
 [1.         0.         1.         0.87847929 0.39277668 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.39272931 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.3928621  1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.39289056 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.39293224 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.39291448 1.
  0.         0.13336007 1.        ]
 [1.         0.         0.24848171 0.46409603 0.39289675 1.
  0.         0.54825926 1.        ]
 [1.         0.         0.         0.         0.3927889  1.
  0.         0.05414865 1.        ]
 [1.         0.         0.37957961 0.05211296 0.39285071 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.39306408 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.39288301 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.39298742 1.
  0.         0.53855052 1.        ]
 [1.         0.         0.73088717 0.36957318 0.39275251 1.
  0.         1.         1.        ]
 [1.         0.         0.03271693 0.         0.39286468 1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
1.0
#####################         POISON         ###############################################

############################################################################################

comm_round: 25 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.10480996 0.24531589 0.3909274  0.         1.
 0.95090866 1.         1.         1.         0.40961586 0.34896066
 0.         0.20692399 0.81049109 0.         1.         1.
 1.         0.12696719 0.         1.         1.         1.
 0.57586855 0.35941285]
wv_ed shape (26,)
[0.         0.         0.20677122 0.48460754 0.         1.
 0.67589527 1.         1.         1.         0.25882047 0.
 0.         0.         0.76097837 0.         1.         1.
 0.90536136 0.08342241 0.         1.         1.         0.94423217
 0.47273379 0.09158407]
wv_lg shape (26, 1)
[[0.39407546]
 [0.39290343]
 [0.39286621]
 [0.39297053]
 [0.39300251]
 [0.39288006]
 [0.39304257]
 [0.39273675]
 [0.39298399]
 [0.39296572]
 [0.3928232 ]
 [0.39272445]
 [0.39286242]
 [0.392969  ]
 [0.39300931]
 [0.39286484]
 [0.39294757]
 [0.39310449]
 [0.39293598]
 [0.39315873]
 [0.39282879]
 [0.39308079]
 [0.39293299]
 [0.3929088 ]
 [0.39304978]
 [0.39295203]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.15902047 0.22801802 0.27440555 0.48927995 1.
 1.         1.         1.         1.         0.65814066 0.71089151
 0.         0.91111384 1.         0.         1.         0.94525032
 1.         0.57599464 0.         1.         1.         1.
 0.42901705 1.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.39407546 1.
  1.         0.         0.        ]
 [1.         0.         0.10480996 0.         0.39290343 1.
  0.         0.15902047 1.        ]
 [1.         0.         0.24531589 0.20677122 0.39286621 1.
  0.         0.22801802 1.        ]
 [1.         0.         0.3909274  0.48460754 0.39297053 1.
  0.         0.27440555 1.        ]
 [1.         0.         0.         0.         0.39300251 1.
  0.         0.48927995 1.        ]
 [1.         0.         1.         1.         0.39288006 1.
  0.         1.         1.        ]
 [1.         0.         0.95090866 0.67589527 0.39304257 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.39273675 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.39298399 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.39296572 1.
  0.         1.         1.        ]
 [1.         0.         0.40961586 0.25882047 0.3928232  1.
  0.         0.65814066 1.        ]
 [1.         0.         0.34896066 0.         0.39272445 1.
  0.         0.71089151 1.        ]
 [0.         0.         0.         0.         0.39286242 1.
  0.         0.         1.        ]
 [1.         0.         0.20692399 0.         0.392969   1.
  0.         0.91111384 1.        ]
 [1.         0.         0.81049109 0.76097837 0.39300931 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.39286484 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.39294757 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.39310449 1.
  0.         0.94525032 1.        ]
 [1.         0.         1.         0.90536136 0.39293598 1.
  0.         1.         1.        ]
 [1.         0.         0.12696719 0.08342241 0.39315873 1.
  0.         0.57599464 1.        ]
 [1.         0.         0.         0.         0.39282879 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.39308079 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.39293299 1.
  0.         1.         1.        ]
 [1.         0.         1.         0.94423217 0.3929088  1.
  0.         1.         1.        ]
 [1.         0.         0.57586855 0.47273379 0.39304978 1.
  0.         0.42901705 1.        ]
 [1.         0.         0.35941285 0.09158407 0.39295203 1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.9285714030265808
#####################         POISON         ###############################################

############################################################################################

comm_round: 26 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 0. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         1.         0.05271026 1.         0.86987558 0.
 0.         0.57117373 0.5851716  0.         0.         0.
 0.         0.44440429 0.17307235 0.         0.         0.
 0.23123251 0.54088286 0.         0.54622091 0.86839601 0.5688373
 0.         0.3678262 ]
wv_ed shape (26,)
[0.         1.         0.         1.         0.73396174 0.
 0.         0.46273139 0.58076807 0.         0.         0.
 0.         0.66553725 0.14674137 0.         0.         0.
 0.00844225 0.34795459 0.         0.33000724 0.66982183 0.33951769
 0.         0.47512602]
wv_lg shape (26, 1)
[[0.39412658]
 [0.39339021]
 [0.39326934]
 [0.39312016]
 [0.39312523]
 [0.3931724 ]
 [0.39345497]
 [0.3931181 ]
 [0.39327639]
 [0.39310937]
 [0.39311797]
 [0.39315628]
 [0.39299811]
 [0.39302223]
 [0.39311127]
 [0.3931365 ]
 [0.3933441 ]
 [0.39320864]
 [0.39291907]
 [0.39320253]
 [0.3931044 ]
 [0.39298094]
 [0.39317058]
 [0.39313601]
 [0.39298388]
 [0.39327893]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         1.         0.         1.         0.93129963 0.
 0.         0.9362299  0.29185674 0.         0.         0.
 0.         0.         0.26358338 0.         0.         0.
 0.62727549 0.77811249 0.29454673 0.7124773  1.         0.6252279
 0.         0.25408699]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.39412658 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.39339021 1.
  0.         1.         1.        ]
 [1.         0.         0.05271026 0.         0.39326934 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.39312016 1.
  0.         1.         1.        ]
 [1.         0.         0.86987558 0.73396174 0.39312523 1.
  0.         0.93129963 1.        ]
 [1.         0.         0.         0.         0.3931724  1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.39345497 1.
  0.         0.         1.        ]
 [1.         0.         0.57117373 0.46273139 0.3931181  1.
  0.         0.9362299  1.        ]
 [1.         0.         0.5851716  0.58076807 0.39327639 1.
  0.         0.29185674 1.        ]
 [1.         0.         0.         0.         0.39310937 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.39311797 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.39315628 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.39299811 1.
  0.         0.         1.        ]
 [1.         0.         0.44440429 0.66553725 0.39302223 1.
  0.         0.         1.        ]
 [1.         0.         0.17307235 0.14674137 0.39311127 1.
  0.         0.26358338 1.        ]
 [1.         0.         0.         0.         0.3931365  1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.3933441  1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.39320864 1.
  0.         0.         1.        ]
 [1.         0.         0.23123251 0.00844225 0.39291907 1.
  0.         0.62727549 1.        ]
 [1.         0.         0.54088286 0.34795459 0.39320253 1.
  0.         0.77811249 1.        ]
 [1.         0.         0.         0.         0.3931044  1.
  0.         0.29454673 1.        ]
 [1.         0.         0.54622091 0.33000724 0.39298094 1.
  0.         0.7124773  1.        ]
 [1.         0.         0.86839601 0.66982183 0.39317058 1.
  0.         1.         1.        ]
 [1.         0.         0.5688373  0.33951769 0.39313601 1.
  0.         0.6252279  1.        ]
 [0.         0.         0.         0.         0.39298388 1.
  0.         0.         1.        ]
 [1.         0.         0.3678262  0.47512602 0.39327893 1.
  0.         0.25408699 1.        ]]

Best Training Poisoning Accuracy:
0.9285714030265808
#####################         POISON         ###############################################

############################################################################################

comm_round: 27 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.46566037 1.         0.8133146  0.         0.
 0.14395117 1.         1.         1.         0.         0.
 0.         0.52746124 0.26327338 0.6310468  1.         0.
 1.         0.         1.         0.69949452 0.0106341  0.
 0.         0.61382681]
wv_ed shape (26,)
[0.         0.57085879 1.         0.95426914 0.         0.
 0.43870809 1.         1.         1.         0.         0.
 0.         0.75127271 0.63160151 0.90095567 1.         0.
 1.         0.         1.         1.         0.         0.
 0.1084234  0.77754643]
wv_lg shape (26, 1)
[[0.39463738]
 [0.39280679]
 [0.39296934]
 [0.39279333]
 [0.39304102]
 [0.3927686 ]
 [0.3928481 ]
 [0.39317743]
 [0.39272803]
 [0.39290967]
 [0.39290821]
 [0.39302369]
 [0.39293727]
 [0.39268283]
 [0.39282684]
 [0.39296826]
 [0.39305297]
 [0.392918  ]
 [0.39298705]
 [0.39306633]
 [0.3930478 ]
 [0.39290678]
 [0.39302973]
 [0.39290691]
 [0.39281072]
 [0.39292891]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.87656836 1.         0.97010332 0.         0.
 0.12611587 1.         1.         0.83127953 0.         0.
 0.         0.26486467 0.08890901 0.30303733 1.         0.
 1.         0.         1.         0.52653106 0.23025558 0.
 0.25179395 0.0025035 ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.39463738 1.
  1.         0.         0.        ]
 [1.         0.         0.46566037 0.57085879 0.39280679 1.
  0.         0.87656836 1.        ]
 [1.         0.         1.         1.         0.39296934 1.
  0.         1.         1.        ]
 [1.         0.         0.8133146  0.95426914 0.39279333 1.
  0.         0.97010332 1.        ]
 [1.         0.         0.         0.         0.39304102 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3927686  1.
  0.         0.         1.        ]
 [1.         0.         0.14395117 0.43870809 0.3928481  1.
  0.         0.12611587 1.        ]
 [1.         0.         1.         1.         0.39317743 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.39272803 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.39290967 1.
  0.         0.83127953 1.        ]
 [1.         0.         0.         0.         0.39290821 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.39302369 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.39293727 1.
  0.         0.         1.        ]
 [1.         0.         0.52746124 0.75127271 0.39268283 1.
  0.         0.26486467 1.        ]
 [1.         0.         0.26327338 0.63160151 0.39282684 1.
  0.         0.08890901 1.        ]
 [1.         0.         0.6310468  0.90095567 0.39296826 1.
  0.         0.30303733 1.        ]
 [1.         0.         1.         1.         0.39305297 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.392918   1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.39298705 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.39306633 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.3930478  1.
  0.         1.         1.        ]
 [1.         0.         0.69949452 1.         0.39290678 1.
  0.         0.52653106 1.        ]
 [1.         0.         0.0106341  0.         0.39302973 1.
  0.         0.23025558 1.        ]
 [1.         0.         0.         0.         0.39290691 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.1084234  0.39281072 1.
  0.         0.25179395 1.        ]
 [1.         0.         0.61382681 0.77754643 0.39292891 1.
  0.         0.0025035  1.        ]]

Best Training Poisoning Accuracy:
0.7857142686843872
#####################         POISON         ###############################################

############################################################################################

comm_round: 28 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.00000000e+00 1.00000000e+00 1.83148406e-02 7.45472418e-01
 6.87535015e-02 1.00000000e+00 1.00000000e+00 1.00000000e+00
 1.00000000e+00 1.00000000e+00 0.00000000e+00 4.18555962e-04
 0.00000000e+00 1.00000000e+00 7.47334173e-01 2.85142388e-01
 1.00000000e+00 4.91510695e-01 0.00000000e+00 1.00000000e+00
 7.35650939e-01 1.58347325e-01 9.56731034e-01 1.00000000e+00
 0.00000000e+00 4.18527632e-01]
wv_ed shape (26,)
[0.         0.97659333 0.         0.78373875 0.         1.
 0.73016741 0.72777399 1.         0.71034929 0.         0.
 0.         1.         0.57820219 0.         1.         0.27812184
 0.         1.         0.51056069 0.09402204 0.71999411 0.727921
 0.         0.1688681 ]
wv_lg shape (26, 1)
[[0.39465655]
 [0.39325148]
 [0.39337114]
 [0.39312412]
 [0.39308159]
 [0.3930865 ]
 [0.39312362]
 [0.39315638]
 [0.39305671]
 [0.39315885]
 [0.39316565]
 [0.39315878]
 [0.39316112]
 [0.3931091 ]
 [0.39317975]
 [0.39335517]
 [0.39334425]
 [0.39327517]
 [0.39333551]
 [0.39304469]
 [0.39308068]
 [0.39334064]
 [0.39321018]
 [0.39328265]
 [0.39321119]
 [0.3931632 ]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         1.         0.42739858 0.70604719 0.78442125 1.
 1.         1.         1.         1.         0.67364957 0.26690119
 0.         1.         1.         1.         1.         1.
 0.         0.80005461 1.         0.         1.         1.
 0.         0.65113811]
xy shape: (26, 9)
[[0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00
  3.94656549e-01 1.00000000e+00 1.00000000e+00 0.00000000e+00
  0.00000000e+00]
 [1.00000000e+00 0.00000000e+00 1.00000000e+00 9.76593330e-01
  3.93251483e-01 1.00000000e+00 0.00000000e+00 1.00000000e+00
  1.00000000e+00]
 [1.00000000e+00 0.00000000e+00 1.83148406e-02 0.00000000e+00
  3.93371141e-01 1.00000000e+00 0.00000000e+00 4.27398579e-01
  1.00000000e+00]
 [1.00000000e+00 0.00000000e+00 7.45472418e-01 7.83738748e-01
  3.93124124e-01 1.00000000e+00 0.00000000e+00 7.06047188e-01
  1.00000000e+00]
 [1.00000000e+00 0.00000000e+00 6.87535015e-02 0.00000000e+00
  3.93081595e-01 1.00000000e+00 0.00000000e+00 7.84421248e-01
  1.00000000e+00]
 [1.00000000e+00 0.00000000e+00 1.00000000e+00 1.00000000e+00
  3.93086501e-01 1.00000000e+00 0.00000000e+00 1.00000000e+00
  1.00000000e+00]
 [1.00000000e+00 0.00000000e+00 1.00000000e+00 7.30167408e-01
  3.93123616e-01 1.00000000e+00 0.00000000e+00 1.00000000e+00
  1.00000000e+00]
 [1.00000000e+00 0.00000000e+00 1.00000000e+00 7.27773995e-01
  3.93156384e-01 1.00000000e+00 0.00000000e+00 1.00000000e+00
  1.00000000e+00]
 [1.00000000e+00 0.00000000e+00 1.00000000e+00 1.00000000e+00
  3.93056713e-01 1.00000000e+00 0.00000000e+00 1.00000000e+00
  1.00000000e+00]
 [1.00000000e+00 0.00000000e+00 1.00000000e+00 7.10349285e-01
  3.93158848e-01 1.00000000e+00 0.00000000e+00 1.00000000e+00
  1.00000000e+00]
 [1.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
  3.93165649e-01 1.00000000e+00 0.00000000e+00 6.73649571e-01
  1.00000000e+00]
 [1.00000000e+00 0.00000000e+00 4.18555962e-04 0.00000000e+00
  3.93158780e-01 1.00000000e+00 0.00000000e+00 2.66901192e-01
  1.00000000e+00]
 [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
  3.93161117e-01 1.00000000e+00 0.00000000e+00 0.00000000e+00
  1.00000000e+00]
 [1.00000000e+00 0.00000000e+00 1.00000000e+00 1.00000000e+00
  3.93109101e-01 1.00000000e+00 0.00000000e+00 1.00000000e+00
  1.00000000e+00]
 [1.00000000e+00 0.00000000e+00 7.47334173e-01 5.78202191e-01
  3.93179747e-01 1.00000000e+00 0.00000000e+00 1.00000000e+00
  1.00000000e+00]
 [1.00000000e+00 0.00000000e+00 2.85142388e-01 0.00000000e+00
  3.93355166e-01 1.00000000e+00 0.00000000e+00 1.00000000e+00
  1.00000000e+00]
 [1.00000000e+00 0.00000000e+00 1.00000000e+00 1.00000000e+00
  3.93344250e-01 1.00000000e+00 0.00000000e+00 1.00000000e+00
  1.00000000e+00]
 [1.00000000e+00 0.00000000e+00 4.91510695e-01 2.78121836e-01
  3.93275172e-01 1.00000000e+00 0.00000000e+00 1.00000000e+00
  1.00000000e+00]
 [1.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
  3.93335505e-01 1.00000000e+00 0.00000000e+00 0.00000000e+00
  1.00000000e+00]
 [1.00000000e+00 0.00000000e+00 1.00000000e+00 1.00000000e+00
  3.93044693e-01 1.00000000e+00 0.00000000e+00 8.00054612e-01
  1.00000000e+00]
 [1.00000000e+00 0.00000000e+00 7.35650939e-01 5.10560691e-01
  3.93080676e-01 1.00000000e+00 0.00000000e+00 1.00000000e+00
  1.00000000e+00]
 [1.00000000e+00 0.00000000e+00 1.58347325e-01 9.40220361e-02
  3.93340643e-01 1.00000000e+00 0.00000000e+00 0.00000000e+00
  1.00000000e+00]
 [1.00000000e+00 0.00000000e+00 9.56731034e-01 7.19994107e-01
  3.93210179e-01 1.00000000e+00 0.00000000e+00 1.00000000e+00
  1.00000000e+00]
 [1.00000000e+00 0.00000000e+00 1.00000000e+00 7.27921001e-01
  3.93282655e-01 1.00000000e+00 0.00000000e+00 1.00000000e+00
  1.00000000e+00]
 [1.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
  3.93211188e-01 1.00000000e+00 0.00000000e+00 0.00000000e+00
  1.00000000e+00]
 [1.00000000e+00 0.00000000e+00 4.18527632e-01 1.68868104e-01
  3.93163200e-01 1.00000000e+00 0.00000000e+00 6.51138111e-01
  1.00000000e+00]]

Best Training Poisoning Accuracy:
0.9285714030265808
#####################         POISON         ###############################################

############################################################################################

comm_round: 29 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients

Best Training Poisoning Accuracy:
0.8295723795890808

Best Training Poisoning Accuracy:
0.8295723795890808

Best Training Poisoning Accuracy:
0.8295723795890808

Best Training Poisoning Accuracy:
0.8480353355407715

Best Training Poisoning Accuracy:
0.8302035927772522

Best Training Poisoning Accuracy:
0.8308348059654236

Best Training Poisoning Accuracy:
0.8770711421966553

Best Training Poisoning Accuracy:
0.8813318610191345

Best Training Poisoning Accuracy:
0.8980590105056763

Best Training Poisoning Accuracy:
0.9130503535270691

Best Training Poisoning Accuracy:
0.9084740281105042

Best Training Poisoning Accuracy:
0.9008994698524475

Best Training Poisoning Accuracy:
0.8655515313148499

Best Training Poisoning Accuracy:
0.859239399433136

Best Training Poisoning Accuracy:
0.8295723795890808

Best Training Poisoning Accuracy:
0.903897762298584

Best Training Poisoning Accuracy:
0.9422439932823181
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.96584518 1.         0.33292983 0.         0.
 0.41483086 0.9096833  0.         1.         0.         0.42123485
 0.59345349 0.         0.3858372  0.         1.         1.
 1.         0.         0.         0.         0.         1.
 1.         0.        ]
wv_ed shape (26,)
[0.         0.38581039 1.         0.42453042 0.         0.
 0.30954147 0.18452114 0.         1.         0.         0.91925097
 0.00776856 0.3748043  0.45967771 0.         0.64580607 1.
 0.08247344 0.         0.         0.         0.         1.
 1.         0.        ]
wv_lg shape (26, 1)
[[0.13430931]
 [0.13327634]
 [0.13327649]
 [0.13327579]
 [0.13327604]
 [0.13327608]
 [0.13327626]
 [0.1332765 ]
 [0.13327609]
 [0.13327641]
 [0.13327643]
 [0.13327643]
 [0.13327639]
 [0.13327569]
 [0.13327595]
 [0.13327614]
 [0.13327634]
 [0.13327598]
 [0.1332773 ]
 [0.13327627]
 [0.13327615]
 [0.13327611]
 [0.13327576]
 [0.13327637]
 [0.13327668]
 [0.13327621]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.20306654 1.         0.502014   0.         0.14864194
 0.5373484  0.37502751 0.         1.         0.         1.
 0.14443428 1.         0.58367681 0.00963291 0.15355808 1.
 0.         0.         0.         0.         0.         0.78412703
 1.         0.00729268]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.13430931 1.
  1.         0.         0.        ]
 [1.         0.         0.96584518 0.38581039 0.13327634 1.
  0.         0.20306654 1.        ]
 [1.         0.         1.         1.         0.13327649 1.
  0.         1.         1.        ]
 [1.         0.         0.33292983 0.42453042 0.13327579 1.
  0.         0.502014   1.        ]
 [1.         0.         0.         0.         0.13327604 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.13327608 1.
  0.         0.14864194 1.        ]
 [1.         0.         0.41483086 0.30954147 0.13327626 1.
  0.         0.5373484  1.        ]
 [1.         0.         0.9096833  0.18452114 0.1332765  1.
  0.         0.37502751 1.        ]
 [1.         0.         0.         0.         0.13327609 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.13327641 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.13327643 1.
  0.         0.         1.        ]
 [1.         0.         0.42123485 0.91925097 0.13327643 1.
  0.         1.         1.        ]
 [1.         0.         0.59345349 0.00776856 0.13327639 1.
  0.         0.14443428 1.        ]
 [1.         0.         0.         0.3748043  0.13327569 1.
  0.         1.         1.        ]
 [1.         0.         0.3858372  0.45967771 0.13327595 1.
  0.         0.58367681 1.        ]
 [1.         0.         0.         0.         0.13327614 1.
  0.         0.00963291 1.        ]
 [1.         0.         1.         0.64580607 0.13327634 1.
  0.         0.15355808 1.        ]
 [1.         0.         1.         1.         0.13327598 1.
  0.         1.         1.        ]
 [1.         0.         1.         0.08247344 0.1332773  1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.13327627 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.13327615 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.13327611 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.13327576 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.13327637 1.
  0.         0.78412703 1.        ]
 [1.         0.         1.         1.         0.13327668 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.13327621 1.
  0.         0.00729268 1.        ]]

Best Training Poisoning Accuracy:
0.0625
#####################         POISON         ###############################################

############################################################################################

comm_round: 0 | global_test_acc: 12.500% | global_f1: 0.0 | global_precision: 0.0
              precision    recall  f1-score   support

           0       0.12      1.00      0.22         1
           1       0.00      0.00      0.00         7

    accuracy                           0.12         8
   macro avg       0.06      0.50      0.11         8
weighted avg       0.02      0.12      0.03         8
poison scaling shape: (26, 1)
[[0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]]scaled_weight_list: Rows 26 cols 21
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.37975783 1.         0.         1.         0.66056767
 0.         1.         0.48882903 0.54728413 0.28083401 0.88518387
 0.97402172 0.         0.         0.55092678 0.         0.
 0.53875752 0.12160755 0.70341811 1.         0.         0.
 1.         0.        ]
wv_ed shape (26,)
[0.         0.68960345 1.         0.         1.         1.
 0.6838481  1.         0.60270364 1.         0.         0.42900581
 1.         0.         0.         1.         0.         0.
 0.95610442 0.25598798 0.9832426  1.         0.         0.
 0.92708137 0.        ]
wv_lg shape (26, 1)
[[0.13431304]
 [0.13327231]
 [0.13327277]
 [0.13327237]
 [0.13327255]
 [0.13327245]
 [0.13327234]
 [0.13327279]
 [0.13327232]
 [0.1332726 ]
 [0.13327291]
 [0.13327337]
 [0.13327226]
 [0.13327259]
 [0.13327192]
 [0.13327209]
 [0.13327229]
 [0.13327264]
 [0.13327237]
 [0.13327232]
 [0.13327263]
 [0.13327296]
 [0.13327248]
 [0.13327226]
 [0.13327277]
 [0.13327207]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         1.         1.         0.         0.95594817 1.
 1.         1.         0.8218246  1.         0.         0.46806642
 1.         0.         0.         1.         0.03753669 0.
 1.         0.24985449 1.         1.         0.         0.
 0.4489033  0.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.13431304 1.
  1.         0.         0.        ]
 [1.         0.         0.37975783 0.68960345 0.13327231 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.13327277 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.13327237 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.13327255 1.
  0.         0.95594817 1.        ]
 [1.         0.         0.66056767 1.         0.13327245 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.6838481  0.13327234 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.13327279 1.
  0.         1.         1.        ]
 [1.         0.         0.48882903 0.60270364 0.13327232 1.
  0.         0.8218246  1.        ]
 [1.         0.         0.54728413 1.         0.1332726  1.
  0.         1.         1.        ]
 [1.         0.         0.28083401 0.         0.13327291 1.
  0.         0.         1.        ]
 [1.         0.         0.88518387 0.42900581 0.13327337 1.
  0.         0.46806642 1.        ]
 [1.         0.         0.97402172 1.         0.13327226 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.13327259 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.13327192 1.
  0.         0.         1.        ]
 [1.         0.         0.55092678 1.         0.13327209 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.13327229 1.
  0.         0.03753669 1.        ]
 [0.         0.         0.         0.         0.13327264 1.
  0.         0.         1.        ]
 [1.         0.         0.53875752 0.95610442 0.13327237 1.
  0.         1.         1.        ]
 [1.         0.         0.12160755 0.25598798 0.13327232 1.
  0.         0.24985449 1.        ]
 [1.         0.         0.70341811 0.9832426  0.13327263 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.13327296 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.13327248 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.13327226 1.
  0.         0.         1.        ]
 [1.         0.         1.         0.92708137 0.13327277 1.
  0.         0.4489033  1.        ]
 [1.         0.         0.         0.         0.13327207 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.5625
#####################         POISON         ###############################################

############################################################################################

comm_round: 1 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 0. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.         0.23557031 0.         0.         0.
 0.78785978 0.91872526 0.         0.         1.         0.85558769
 1.         0.         0.76953947 0.36587643 0.         0.
 0.         0.5734588  0.32419246 1.         0.6669937  1.
 0.         0.22254297]
wv_ed shape (26,)
[0.         0.75547313 0.48133269 0.         0.         0.
 0.51023403 1.         0.19464661 0.         1.         1.
 1.         0.         0.76465622 0.34378002 0.         0.25807079
 0.         0.22747863 0.39352765 1.         1.         1.
 0.         0.08422653]
wv_lg shape (26, 1)
[[0.13442642]
 [0.13323138]
 [0.13323127]
 [0.13323217]
 [0.13323208]
 [0.13323163]
 [0.13323189]
 [0.13323314]
 [0.13323231]
 [0.13323078]
 [0.133234  ]
 [0.13323449]
 [0.13323251]
 [0.13323179]
 [0.13323303]
 [0.13323093]
 [0.13323183]
 [0.13323216]
 [0.13323339]
 [0.13323213]
 [0.13323261]
 [0.1332341 ]
 [0.13323324]
 [0.13323197]
 [0.13323125]
 [0.13323208]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         1.         0.59199573 0.         0.         0.
 0.26151601 1.         0.19177868 0.         1.         1.
 1.         0.         0.72494903 0.0880703  0.         0.66383569
 0.         0.31165361 0.53630895 1.         1.         1.
 0.         0.01306541]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.13442642 1.
  1.         0.         0.        ]
 [1.         0.         0.         0.75547313 0.13323138 1.
  0.         1.         1.        ]
 [1.         0.         0.23557031 0.48133269 0.13323127 1.
  0.         0.59199573 1.        ]
 [1.         0.         0.         0.         0.13323217 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.13323208 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.13323163 1.
  0.         0.         1.        ]
 [1.         0.         0.78785978 0.51023403 0.13323189 1.
  0.         0.26151601 1.        ]
 [1.         0.         0.91872526 1.         0.13323314 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.19464661 0.13323231 1.
  0.         0.19177868 1.        ]
 [1.         0.         0.         0.         0.13323078 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.133234   1.
  0.         1.         1.        ]
 [1.         0.         0.85558769 1.         0.13323449 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.13323251 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.13323179 1.
  0.         0.         1.        ]
 [1.         0.         0.76953947 0.76465622 0.13323303 1.
  0.         0.72494903 1.        ]
 [1.         0.         0.36587643 0.34378002 0.13323093 1.
  0.         0.0880703  1.        ]
 [1.         0.         0.         0.         0.13323183 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.25807079 0.13323216 1.
  0.         0.66383569 1.        ]
 [1.         0.         0.         0.         0.13323339 1.
  0.         0.         1.        ]
 [1.         0.         0.5734588  0.22747863 0.13323213 1.
  0.         0.31165361 1.        ]
 [1.         0.         0.32419246 0.39352765 0.13323261 1.
  0.         0.53630895 1.        ]
 [1.         0.         1.         1.         0.1332341  1.
  0.         1.         1.        ]
 [1.         0.         0.6669937  1.         0.13323324 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.13323197 1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.13323125 1.
  0.         0.         1.        ]
 [1.         0.         0.22254297 0.08422653 0.13323208 1.
  0.         0.01306541 1.        ]]

Best Training Poisoning Accuracy:
0.9375
#####################         POISON         ###############################################

############################################################################################

comm_round: 2 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.2972483  0.         1.         1.         0.
 0.36849817 1.         1.         1.         0.96197437 1.
 1.         1.         0.45574948 0.49155023 0.14629415 1.
 1.         0.         1.         1.         0.         1.
 1.         1.        ]
wv_ed shape (26,)
[0.         0.285473   0.         1.         1.         0.
 0.05326069 1.         1.         1.         0.75352884 0.45664989
 1.         1.         0.23980191 0.21232673 0.18910567 0.66468297
 1.         0.         1.         1.         0.         1.
 1.         0.92810753]
wv_lg shape (26, 1)
[[0.13453721]
 [0.13322189]
 [0.13322304]
 [0.1332226 ]
 [0.13322349]
 [0.13322187]
 [0.13322219]
 [0.13322414]
 [0.13322271]
 [0.13322561]
 [0.1332239 ]
 [0.13322469]
 [0.13322196]
 [0.133223  ]
 [0.13322251]
 [0.13322401]
 [0.133223  ]
 [0.1332232 ]
 [0.13322111]
 [0.13322288]
 [0.13322459]
 [0.13322125]
 [0.13322204]
 [0.13322368]
 [0.13322327]
 [0.13322336]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.29767921 0.         1.         1.         0.
 0.0241597  1.         1.         1.         0.83096734 0.21923278
 1.         1.         0.23094071 0.14497442 0.25685271 0.46287515
 1.         0.         1.         1.         0.         1.
 1.         0.8586634 ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.13453721 1.
  1.         0.         0.        ]
 [1.         0.         0.2972483  0.285473   0.13322189 1.
  0.         0.29767921 1.        ]
 [1.         0.         0.         0.         0.13322304 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.1332226  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.13322349 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.13322187 1.
  0.         0.         1.        ]
 [1.         0.         0.36849817 0.05326069 0.13322219 1.
  0.         0.0241597  1.        ]
 [1.         0.         1.         1.         0.13322414 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.13322271 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.13322561 1.
  0.         1.         1.        ]
 [1.         0.         0.96197437 0.75352884 0.1332239  1.
  0.         0.83096734 1.        ]
 [1.         0.         1.         0.45664989 0.13322469 1.
  0.         0.21923278 1.        ]
 [1.         0.         1.         1.         0.13322196 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.133223   1.
  0.         1.         1.        ]
 [1.         0.         0.45574948 0.23980191 0.13322251 1.
  0.         0.23094071 1.        ]
 [1.         0.         0.49155023 0.21232673 0.13322401 1.
  0.         0.14497442 1.        ]
 [1.         0.         0.14629415 0.18910567 0.133223   1.
  0.         0.25685271 1.        ]
 [1.         0.         1.         0.66468297 0.1332232  1.
  0.         0.46287515 1.        ]
 [1.         0.         1.         1.         0.13322111 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.13322288 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.13322459 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.13322125 1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.13322204 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.13322368 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.13322327 1.
  0.         1.         1.        ]
 [1.         0.         1.         0.92810753 0.13322336 1.
  0.         0.8586634  1.        ]]

Best Training Poisoning Accuracy:
1.0
#####################         POISON         ###############################################

############################################################################################

comm_round: 3 | global_test_acc: 87.500% | global_f1: 0.9333333333333333 | global_precision: 0.875
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.88      1.00      0.93         7

    accuracy                           0.88         8
   macro avg       0.44      0.50      0.47         8
weighted avg       0.77      0.88      0.82         8
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.         0.02090774 0.         0.         0.39809848
 0.         1.         0.84334926 0.39820993 1.         0.
 0.1002833  0.         0.         0.         0.         1.
 1.         0.         0.06834822 0.         1.         0.69952826
 0.         0.97977403]
wv_ed shape (26,)
[0.         0.         0.53786256 0.         0.         0.
 0.         1.         0.97591111 0.50113603 1.         0.
 0.2586892  0.         0.07304672 0.         0.         1.
 1.         0.         0.29634449 0.         1.         0.47005582
 0.         0.60729721]
wv_lg shape (26, 1)
[[0.13469449]
 [0.13319053]
 [0.13319045]
 [0.13319162]
 [0.13319113]
 [0.13319217]
 [0.13318951]
 [0.13319036]
 [0.13319167]
 [0.13319384]
 [0.13319515]
 [0.13318989]
 [0.13319253]
 [0.13319233]
 [0.13319074]
 [0.13319125]
 [0.13319243]
 [0.13319389]
 [0.13318821]
 [0.1331919 ]
 [0.1331913 ]
 [0.13319172]
 [0.13319237]
 [0.13318927]
 [0.13318922]
 [0.13319191]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.         0.51402249 0.         0.         0.
 0.         1.         0.98531568 0.40672649 1.         0.
 0.19522672 0.         0.         0.         0.         1.
 1.         0.         0.20304811 0.         1.         0.26699474
 0.         0.52262116]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.13469449 1.
  1.         0.         0.        ]
 [1.         0.         0.         0.         0.13319053 1.
  0.         0.         1.        ]
 [1.         0.         0.02090774 0.53786256 0.13319045 1.
  0.         0.51402249 1.        ]
 [0.         0.         0.         0.         0.13319162 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.13319113 1.
  0.         0.         1.        ]
 [1.         0.         0.39809848 0.         0.13319217 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.13318951 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.13319036 1.
  0.         1.         1.        ]
 [1.         0.         0.84334926 0.97591111 0.13319167 1.
  0.         0.98531568 1.        ]
 [1.         0.         0.39820993 0.50113603 0.13319384 1.
  0.         0.40672649 1.        ]
 [1.         0.         1.         1.         0.13319515 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.13318989 1.
  0.         0.         1.        ]
 [1.         0.         0.1002833  0.2586892  0.13319253 1.
  0.         0.19522672 1.        ]
 [1.         0.         0.         0.         0.13319233 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.07304672 0.13319074 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.13319125 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.13319243 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.13319389 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.13318821 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.1331919  1.
  0.         0.         1.        ]
 [1.         0.         0.06834822 0.29634449 0.1331913  1.
  0.         0.20304811 1.        ]
 [1.         0.         0.         0.         0.13319172 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.13319237 1.
  0.         1.         1.        ]
 [1.         0.         0.69952826 0.47005582 0.13318927 1.
  0.         0.26699474 1.        ]
 [1.         0.         0.         0.         0.13318922 1.
  0.         0.         1.        ]
 [1.         0.         0.97977403 0.60729721 0.13319191 1.
  0.         0.52262116 1.        ]]

Best Training Poisoning Accuracy:
1.0
#####################         POISON         ###############################################

############################################################################################

comm_round: 4 | global_test_acc: 87.500% | global_f1: 0.9333333333333333 | global_precision: 0.875
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.88      1.00      0.93         7

    accuracy                           0.88         8
   macro avg       0.44      0.50      0.47         8
weighted avg       0.77      0.88      0.82         8
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         1.         0.59146103 1.         1.         1.
 0.37556804 1.         0.         1.         0.         0.04768451
 0.         0.77072648 1.         0.15505416 0.         1.
 0.07287293 0.         1.         1.         1.         1.
 1.         1.        ]
wv_ed shape (26,)
[0.         1.         0.73552957 1.         1.         1.
 0.19826149 1.         0.         1.         0.         0.28109304
 0.         1.         1.         0.54881969 0.         0.89524633
 0.2485536  0.         1.         1.         1.         1.
 1.         1.        ]
wv_lg shape (26, 1)
[[0.13480924]
 [0.13322748]
 [0.13323095]
 [0.13322844]
 [0.13322804]
 [0.13322785]
 [0.13322855]
 [0.13322666]
 [0.13322384]
 [0.13323164]
 [0.13322081]
 [0.13322607]
 [0.13322817]
 [0.13322676]
 [0.13322655]
 [0.13322464]
 [0.13322244]
 [0.13322307]
 [0.13322391]
 [0.13322377]
 [0.13322854]
 [0.13322618]
 [0.13322893]
 [0.13322474]
 [0.13322451]
 [0.13322521]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         1.         0.91140185 1.         1.         1.
 0.22170882 1.         0.         1.         0.         0.2124351
 0.         1.         1.         0.51339421 0.         0.64344521
 0.30417139 0.         1.         1.         1.         0.92047995
 1.         1.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.13480924 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.13322748 1.
  0.         1.         1.        ]
 [1.         0.         0.59146103 0.73552957 0.13323095 1.
  0.         0.91140185 1.        ]
 [1.         0.         1.         1.         0.13322844 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.13322804 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.13322785 1.
  0.         1.         1.        ]
 [1.         0.         0.37556804 0.19826149 0.13322855 1.
  0.         0.22170882 1.        ]
 [1.         0.         1.         1.         0.13322666 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.13322384 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.13323164 1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.13322081 1.
  0.         0.         1.        ]
 [1.         0.         0.04768451 0.28109304 0.13322607 1.
  0.         0.2124351  1.        ]
 [1.         0.         0.         0.         0.13322817 1.
  0.         0.         1.        ]
 [1.         0.         0.77072648 1.         0.13322676 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.13322655 1.
  0.         1.         1.        ]
 [1.         0.         0.15505416 0.54881969 0.13322464 1.
  0.         0.51339421 1.        ]
 [1.         0.         0.         0.         0.13322244 1.
  0.         0.         1.        ]
 [1.         0.         1.         0.89524633 0.13322307 1.
  0.         0.64344521 1.        ]
 [1.         0.         0.07287293 0.2485536  0.13322391 1.
  0.         0.30417139 1.        ]
 [1.         0.         0.         0.         0.13322377 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.13322854 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.13322618 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.13322893 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.13322474 1.
  0.         0.92047995 1.        ]
 [1.         0.         1.         1.         0.13322451 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.13322521 1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
1.0
#####################         POISON         ###############################################

############################################################################################

comm_round: 5 | global_test_acc: 87.500% | global_f1: 0.9333333333333333 | global_precision: 0.875
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.88      1.00      0.93         7

    accuracy                           0.88         8
   macro avg       0.44      0.50      0.47         8
weighted avg       0.77      0.88      0.82         8
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.63758186 0.         0.51586619 0.12350063 1.
 0.01769962 0.         0.         1.         0.         0.
 1.         1.         1.         1.         0.61726044 1.
 0.         0.         0.06007659 1.         0.         0.63196735
 0.63373046 0.08459043]
wv_ed shape (26,)
[0.         0.90636347 0.         0.55137945 0.24904579 1.
 0.         0.         0.         1.         0.         0.
 1.         1.         1.         0.77065466 0.47312377 1.
 0.         0.         0.04301883 1.         0.         1.
 0.64144955 0.23282293]
wv_lg shape (26, 1)
[[0.13496521]
 [0.13326957]
 [0.13326545]
 [0.13326786]
 [0.13326925]
 [0.13327155]
 [0.13326809]
 [0.13326445]
 [0.1332679 ]
 [0.1332697 ]
 [0.13326652]
 [0.13326682]
 [0.13327043]
 [0.13327071]
 [0.13326896]
 [0.13326911]
 [0.13326733]
 [0.13327037]
 [0.13326527]
 [0.13326731]
 [0.13326642]
 [0.13327096]
 [0.13326493]
 [0.13326948]
 [0.13326777]
 [0.13326985]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.98977862 0.         0.62479629 0.32056361 1.
 0.         0.         0.         1.         0.         0.
 1.         1.         1.         0.74212536 0.61833277 1.
 0.         0.04153644 0.07729688 1.         0.         1.
 0.67493583 0.06220751]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.13496521 1.
  1.         0.         0.        ]
 [1.         0.         0.63758186 0.90636347 0.13326957 1.
  0.         0.98977862 1.        ]
 [1.         0.         0.         0.         0.13326545 1.
  0.         0.         1.        ]
 [1.         0.         0.51586619 0.55137945 0.13326786 1.
  0.         0.62479629 1.        ]
 [1.         0.         0.12350063 0.24904579 0.13326925 1.
  0.         0.32056361 1.        ]
 [1.         0.         1.         1.         0.13327155 1.
  0.         1.         1.        ]
 [1.         0.         0.01769962 0.         0.13326809 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.13326445 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.1332679  1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.1332697  1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.13326652 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.13326682 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.13327043 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.13327071 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.13326896 1.
  0.         1.         1.        ]
 [1.         0.         1.         0.77065466 0.13326911 1.
  0.         0.74212536 1.        ]
 [1.         0.         0.61726044 0.47312377 0.13326733 1.
  0.         0.61833277 1.        ]
 [1.         0.         1.         1.         0.13327037 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.13326527 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.13326731 1.
  0.         0.04153644 1.        ]
 [1.         0.         0.06007659 0.04301883 0.13326642 1.
  0.         0.07729688 1.        ]
 [1.         0.         1.         1.         0.13327096 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.13326493 1.
  0.         0.         1.        ]
 [1.         0.         0.63196735 1.         0.13326948 1.
  0.         1.         1.        ]
 [1.         0.         0.63373046 0.64144955 0.13326777 1.
  0.         0.67493583 1.        ]
 [1.         0.         0.08459043 0.23282293 0.13326985 1.
  0.         0.06220751 1.        ]]

Best Training Poisoning Accuracy:
1.0
#####################         POISON         ###############################################

############################################################################################

comm_round: 6 | global_test_acc: 87.500% | global_f1: 0.9333333333333333 | global_precision: 0.875
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.88      1.00      0.93         7

    accuracy                           0.88         8
   macro avg       0.44      0.50      0.47         8
weighted avg       0.77      0.88      0.82         8
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.18049124 1.         0.         0.55851483 1.
 0.         1.         0.3744741  0.28850082 0.72447441 1.
 1.         0.71953383 0.7226678  0.         1.         0.
 1.         1.         0.31443614 0.         1.         0.
 1.         0.        ]
wv_ed shape (26,)
[0.         0.         1.         0.         0.58535652 1.
 0.         1.         0.56317164 0.         1.         1.
 1.         1.         0.95930242 0.         1.         0.
 0.71651084 1.         0.47672626 0.         1.         0.
 1.         0.        ]
wv_lg shape (26, 1)
[[0.13510616]
 [0.13336512]
 [0.13336898]
 [0.13336726]
 [0.133368  ]
 [0.13337038]
 [0.13336626]
 [0.13336714]
 [0.13336721]
 [0.1333675 ]
 [0.13336858]
 [0.13336691]
 [0.13336721]
 [0.13336704]
 [0.13336649]
 [0.13336647]
 [0.13336755]
 [0.1333653 ]
 [0.1333663 ]
 [0.13336805]
 [0.13336628]
 [0.13336428]
 [0.13336776]
 [0.13336438]
 [0.13337079]
 [0.13336676]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.         1.         0.         0.5663021  1.
 0.         1.         0.51024423 0.         1.         1.
 1.         1.         1.         0.         1.         0.
 0.87845871 1.         0.45507538 0.         1.         0.
 1.         0.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.13510616 1.
  1.         0.         0.        ]
 [1.         0.         0.18049124 0.         0.13336512 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.13336898 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.13336726 1.
  0.         0.         1.        ]
 [1.         0.         0.55851483 0.58535652 0.133368   1.
  0.         0.5663021  1.        ]
 [1.         0.         1.         1.         0.13337038 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.13336626 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.13336714 1.
  0.         1.         1.        ]
 [1.         0.         0.3744741  0.56317164 0.13336721 1.
  0.         0.51024423 1.        ]
 [1.         0.         0.28850082 0.         0.1333675  1.
  0.         0.         1.        ]
 [1.         0.         0.72447441 1.         0.13336858 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.13336691 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.13336721 1.
  0.         1.         1.        ]
 [1.         0.         0.71953383 1.         0.13336704 1.
  0.         1.         1.        ]
 [1.         0.         0.7226678  0.95930242 0.13336649 1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.13336647 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.13336755 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.1333653  1.
  0.         0.         1.        ]
 [1.         0.         1.         0.71651084 0.1333663  1.
  0.         0.87845871 1.        ]
 [1.         0.         1.         1.         0.13336805 1.
  0.         1.         1.        ]
 [1.         0.         0.31443614 0.47672626 0.13336628 1.
  0.         0.45507538 1.        ]
 [1.         0.         0.         0.         0.13336428 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.13336776 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.13336438 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.13337079 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.13336676 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.9375
#####################         POISON         ###############################################

############################################################################################

comm_round: 7 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.         0.         0.         0.         1.
 0.30877716 0.         0.77635524 0.         1.         0.31410298
 0.94038924 0.58914308 0.59432279 0.54380147 0.19433663 0.
 0.         1.         0.15764573 0.         0.66488571 0.390287
 0.         0.34944209]
wv_ed shape (26,)
[0.         0.         0.         0.06564888 0.         1.
 0.63514442 0.         0.71032581 0.         1.         0.89186685
 0.76368549 0.34941034 0.48360203 0.19579731 0.15675972 0.
 0.         0.80810856 0.29471584 0.         0.51360755 0.25407989
 0.         0.32365039]
wv_lg shape (26, 1)
[[0.13523571]
 [0.13346991]
 [0.13347023]
 [0.13347314]
 [0.13347162]
 [0.1334715 ]
 [0.13347009]
 [0.13347312]
 [0.13347387]
 [0.13346922]
 [0.133473  ]
 [0.13347428]
 [0.13347292]
 [0.13347315]
 [0.13347307]
 [0.13347385]
 [0.13347213]
 [0.13347299]
 [0.13346803]
 [0.13347135]
 [0.13347335]
 [0.13347216]
 [0.13347543]
 [0.13347041]
 [0.13347253]
 [0.13347244]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.         0.         0.12344243 0.         1.
 0.85603576 0.         0.66332389 0.         1.         0.88280317
 0.73301187 0.27725517 0.43914937 0.18858706 0.14519234 0.
 0.         0.9064179  0.27748768 0.         0.42226498 0.39067106
 0.         0.27292438]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.13523571 1.
  1.         0.         0.        ]
 [1.         0.         0.         0.         0.13346991 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.13347023 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.06564888 0.13347314 1.
  0.         0.12344243 1.        ]
 [0.         0.         0.         0.         0.13347162 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.1334715  1.
  0.         1.         1.        ]
 [1.         0.         0.30877716 0.63514442 0.13347009 1.
  0.         0.85603576 1.        ]
 [1.         0.         0.         0.         0.13347312 1.
  0.         0.         1.        ]
 [1.         0.         0.77635524 0.71032581 0.13347387 1.
  0.         0.66332389 1.        ]
 [1.         0.         0.         0.         0.13346922 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.133473   1.
  0.         1.         1.        ]
 [1.         0.         0.31410298 0.89186685 0.13347428 1.
  0.         0.88280317 1.        ]
 [1.         0.         0.94038924 0.76368549 0.13347292 1.
  0.         0.73301187 1.        ]
 [1.         0.         0.58914308 0.34941034 0.13347315 1.
  0.         0.27725517 1.        ]
 [1.         0.         0.59432279 0.48360203 0.13347307 1.
  0.         0.43914937 1.        ]
 [1.         0.         0.54380147 0.19579731 0.13347385 1.
  0.         0.18858706 1.        ]
 [1.         0.         0.19433663 0.15675972 0.13347213 1.
  0.         0.14519234 1.        ]
 [1.         0.         0.         0.         0.13347299 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.13346803 1.
  0.         0.         1.        ]
 [1.         0.         1.         0.80810856 0.13347135 1.
  0.         0.9064179  1.        ]
 [1.         0.         0.15764573 0.29471584 0.13347335 1.
  0.         0.27748768 1.        ]
 [1.         0.         0.         0.         0.13347216 1.
  0.         0.         1.        ]
 [1.         0.         0.66488571 0.51360755 0.13347543 1.
  0.         0.42226498 1.        ]
 [1.         0.         0.390287   0.25407989 0.13347041 1.
  0.         0.39067106 1.        ]
 [1.         0.         0.         0.         0.13347253 1.
  0.         0.         1.        ]
 [1.         0.         0.34944209 0.32365039 0.13347244 1.
  0.         0.27292438 1.        ]]

Best Training Poisoning Accuracy:
0.9375
#####################         POISON         ###############################################

############################################################################################

comm_round: 8 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.42825478 0.28789497 1.         1.         0.58490765
 0.67147267 1.         0.         0.99303402 0.         0.774055
 1.         0.21658066 0.         0.         0.         1.
 0.         1.         0.66735821 0.72185801 0.73502563 0.03421794
 0.         0.        ]
wv_ed shape (26,)
[0.         0.64997086 0.40720394 1.         1.         0.83744391
 0.95799854 1.         0.         1.         0.         0.8408699
 1.         0.2362725  0.         0.         0.         1.
 0.00954751 1.         0.57772274 0.63847887 0.57275788 0.28700573
 0.         0.        ]
wv_lg shape (26, 1)
[[0.13535649]
 [0.13357999]
 [0.13357971]
 [0.1335806 ]
 [0.13358378]
 [0.13357825]
 [0.13358105]
 [0.13357932]
 [0.1335767 ]
 [0.13358078]
 [0.13357771]
 [0.13357991]
 [0.13358189]
 [0.13358037]
 [0.13357936]
 [0.13357705]
 [0.13357836]
 [0.13358003]
 [0.13357711]
 [0.13358217]
 [0.13358042]
 [0.13357851]
 [0.13357646]
 [0.13357927]
 [0.13357907]
 [0.13357543]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.71449058 0.39158722 1.         1.         0.79429788
 0.92382096 1.         0.         1.         0.         0.89315837
 1.         0.21808606 0.         0.         0.         1.
 0.10849856 1.         0.55954099 0.61795721 0.7013201  0.30362051
 0.         0.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.13535649 1.
  1.         0.         0.        ]
 [1.         0.         0.42825478 0.64997086 0.13357999 1.
  0.         0.71449058 1.        ]
 [1.         0.         0.28789497 0.40720394 0.13357971 1.
  0.         0.39158722 1.        ]
 [1.         0.         1.         1.         0.1335806  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.13358378 1.
  0.         1.         1.        ]
 [1.         0.         0.58490765 0.83744391 0.13357825 1.
  0.         0.79429788 1.        ]
 [1.         0.         0.67147267 0.95799854 0.13358105 1.
  0.         0.92382096 1.        ]
 [1.         0.         1.         1.         0.13357932 1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.1335767  1.
  0.         0.         1.        ]
 [1.         0.         0.99303402 1.         0.13358078 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.13357771 1.
  0.         0.         1.        ]
 [1.         0.         0.774055   0.8408699  0.13357991 1.
  0.         0.89315837 1.        ]
 [1.         0.         1.         1.         0.13358189 1.
  0.         1.         1.        ]
 [1.         0.         0.21658066 0.2362725  0.13358037 1.
  0.         0.21808606 1.        ]
 [1.         0.         0.         0.         0.13357936 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.13357705 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.13357836 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.13358003 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.00954751 0.13357711 1.
  0.         0.10849856 1.        ]
 [1.         0.         1.         1.         0.13358217 1.
  0.         1.         1.        ]
 [1.         0.         0.66735821 0.57772274 0.13358042 1.
  0.         0.55954099 1.        ]
 [1.         0.         0.72185801 0.63847887 0.13357851 1.
  0.         0.61795721 1.        ]
 [1.         0.         0.73502563 0.57275788 0.13357646 1.
  0.         0.7013201  1.        ]
 [1.         0.         0.03421794 0.28700573 0.13357927 1.
  0.         0.30362051 1.        ]
 [1.         0.         0.         0.         0.13357907 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.13357543 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
1.0
#####################         POISON         ###############################################

############################################################################################

comm_round: 9 | global_test_acc: 87.500% | global_f1: 0.9333333333333333 | global_precision: 0.875
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.88      1.00      0.93         7

    accuracy                           0.88         8
   macro avg       0.44      0.50      0.47         8
weighted avg       0.77      0.88      0.82         8
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.26128815 1.         1.         0.         0.18245135
 0.         1.         1.         1.         0.57436127 1.
 0.         0.33085575 0.         0.47704387 1.         0.69616673
 0.14382287 0.15925785 0.         0.         1.         1.
 1.         0.        ]
wv_ed shape (26,)
[0.         0.29203839 0.95300791 1.         0.         0.67193133
 0.30627013 1.         1.         1.         0.79932643 1.
 0.         0.20092275 0.         0.56387229 1.         0.7155601
 0.07179154 0.38612031 0.         0.         1.         1.
 1.         0.        ]
wv_lg shape (26, 1)
[[0.13551951]
 [0.13369169]
 [0.1336904 ]
 [0.13369307]
 [0.13369309]
 [0.1336904 ]
 [0.13369063]
 [0.13369432]
 [0.13369073]
 [0.13369332]
 [0.13369295]
 [0.13369322]
 [0.13369039]
 [0.13369184]
 [0.13369541]
 [0.13369369]
 [0.13369163]
 [0.13369405]
 [0.13369212]
 [0.13369132]
 [0.13369144]
 [0.13369253]
 [0.13369386]
 [0.13369601]
 [0.13369288]
 [0.1336896 ]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.3447445  1.         1.         0.         0.68899375
 0.36607456 1.         1.         1.         0.84164474 1.
 0.         0.13616811 0.         0.50779157 1.         0.72481275
 0.07745452 0.39536242 0.         0.         1.         1.
 1.         0.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.13551951 1.
  1.         0.         0.        ]
 [1.         0.         0.26128815 0.29203839 0.13369169 1.
  0.         0.3447445  1.        ]
 [1.         0.         1.         0.95300791 0.1336904  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.13369307 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.13369309 1.
  0.         0.         1.        ]
 [1.         0.         0.18245135 0.67193133 0.1336904  1.
  0.         0.68899375 1.        ]
 [1.         0.         0.         0.30627013 0.13369063 1.
  0.         0.36607456 1.        ]
 [1.         0.         1.         1.         0.13369432 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.13369073 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.13369332 1.
  0.         1.         1.        ]
 [1.         0.         0.57436127 0.79932643 0.13369295 1.
  0.         0.84164474 1.        ]
 [1.         0.         1.         1.         0.13369322 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.13369039 1.
  0.         0.         1.        ]
 [1.         0.         0.33085575 0.20092275 0.13369184 1.
  0.         0.13616811 1.        ]
 [1.         0.         0.         0.         0.13369541 1.
  0.         0.         1.        ]
 [1.         0.         0.47704387 0.56387229 0.13369369 1.
  0.         0.50779157 1.        ]
 [1.         0.         1.         1.         0.13369163 1.
  0.         1.         1.        ]
 [1.         0.         0.69616673 0.7155601  0.13369405 1.
  0.         0.72481275 1.        ]
 [1.         0.         0.14382287 0.07179154 0.13369212 1.
  0.         0.07745452 1.        ]
 [1.         0.         0.15925785 0.38612031 0.13369132 1.
  0.         0.39536242 1.        ]
 [0.         0.         0.         0.         0.13369144 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.13369253 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.13369386 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.13369601 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.13369288 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.1336896  1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
1.0
#####################         POISON         ###############################################

############################################################################################

comm_round: 10 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         1.         1.         1.         0.         0.78322653
 1.         0.         0.29996886 0.50992518 1.         0.42934953
 0.         0.83842571 0.41397131 0.49401337 0.25343308 0.8055554
 0.90590691 0.26587246 1.         0.90881033 0.54801468 0.56013856
 1.         1.        ]
wv_ed shape (26,)
[0.         1.         1.         0.921036   0.         0.97220238
 1.         0.10611322 0.58312892 0.46886893 1.         0.50081932
 0.         0.84428039 0.45992197 0.39975628 0.42370455 0.87732603
 0.9602541  0.27359901 1.         0.73389529 0.36827071 0.45235786
 1.         1.        ]
wv_lg shape (26, 1)
[[0.13565631]
 [0.13380828]
 [0.13380923]
 [0.13380999]
 [0.13380794]
 [0.13380777]
 [0.13381351]
 [0.1338077 ]
 [0.1338069 ]
 [0.1338076 ]
 [0.13380747]
 [0.13380763]
 [0.13380369]
 [0.13380968]
 [0.13381115]
 [0.13380731]
 [0.13380708]
 [0.13380769]
 [0.13380991]
 [0.13380706]
 [0.13380965]
 [0.13381155]
 [0.13380902]
 [0.13380643]
 [0.13381183]
 [0.13380917]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         1.         1.         0.8901992  0.         0.94982696
 1.         0.09454007 0.57162235 0.46796904 1.         0.41842897
 0.         0.79264704 0.36713222 0.35478124 0.41837067 0.84938892
 0.95013969 0.2536961  1.         0.63709013 0.30609667 0.44443671
 1.         1.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.13565631 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.13380828 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.13380923 1.
  0.         1.         1.        ]
 [1.         0.         1.         0.921036   0.13380999 1.
  0.         0.8901992  1.        ]
 [1.         0.         0.         0.         0.13380794 1.
  0.         0.         1.        ]
 [1.         0.         0.78322653 0.97220238 0.13380777 1.
  0.         0.94982696 1.        ]
 [1.         0.         1.         1.         0.13381351 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.10611322 0.1338077  1.
  0.         0.09454007 1.        ]
 [1.         0.         0.29996886 0.58312892 0.1338069  1.
  0.         0.57162235 1.        ]
 [1.         0.         0.50992518 0.46886893 0.1338076  1.
  0.         0.46796904 1.        ]
 [1.         0.         1.         1.         0.13380747 1.
  0.         1.         1.        ]
 [1.         0.         0.42934953 0.50081932 0.13380763 1.
  0.         0.41842897 1.        ]
 [0.         0.         0.         0.         0.13380369 1.
  0.         0.         1.        ]
 [1.         0.         0.83842571 0.84428039 0.13380968 1.
  0.         0.79264704 1.        ]
 [1.         0.         0.41397131 0.45992197 0.13381115 1.
  0.         0.36713222 1.        ]
 [1.         0.         0.49401337 0.39975628 0.13380731 1.
  0.         0.35478124 1.        ]
 [1.         0.         0.25343308 0.42370455 0.13380708 1.
  0.         0.41837067 1.        ]
 [1.         0.         0.8055554  0.87732603 0.13380769 1.
  0.         0.84938892 1.        ]
 [1.         0.         0.90590691 0.9602541  0.13380991 1.
  0.         0.95013969 1.        ]
 [1.         0.         0.26587246 0.27359901 0.13380706 1.
  0.         0.2536961  1.        ]
 [1.         0.         1.         1.         0.13380965 1.
  0.         1.         1.        ]
 [1.         0.         0.90881033 0.73389529 0.13381155 1.
  0.         0.63709013 1.        ]
 [1.         0.         0.54801468 0.36827071 0.13380902 1.
  0.         0.30609667 1.        ]
 [1.         0.         0.56013856 0.45235786 0.13380643 1.
  0.         0.44443671 1.        ]
 [1.         0.         1.         1.         0.13381183 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.13380917 1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
1.0
#####################         POISON         ###############################################

############################################################################################

comm_round: 11 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.         0.         0.         1.         0.
 0.         1.         0.54392578 1.         1.         0.
 0.72906746 0.         1.         0.2158857  0.         1.
 1.         0.11928078 0.60876885 0.         1.         0.7048211
 1.         0.53707466]
wv_ed shape (26,)
[0.         0.         0.         0.         1.         0.
 0.         1.         0.31827927 1.         1.         0.
 0.43682628 0.         1.         0.07446203 0.         1.
 1.         0.31002733 0.46596766 0.         1.         0.44377185
 1.         0.10884832]
wv_lg shape (26, 1)
[[0.13579098]
 [0.1339261 ]
 [0.1339222 ]
 [0.13392585]
 [0.13392899]
 [0.13392496]
 [0.13392457]
 [0.1339263 ]
 [0.13392492]
 [0.13392535]
 [0.13392766]
 [0.13392209]
 [0.13392534]
 [0.13392087]
 [0.13392719]
 [0.13392518]
 [0.13392358]
 [0.13392486]
 [0.13392846]
 [0.13392451]
 [0.13392642]
 [0.13392394]
 [0.13392777]
 [0.13392652]
 [0.13392671]
 [0.13392394]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.         0.         0.         1.         0.
 0.         1.         0.26354504 1.         1.         0.
 0.44637178 0.         1.         0.         0.         1.
 1.         0.2901596  0.29341732 0.         1.         0.26283618
 1.         0.05983202]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.13579098 1.
  1.         0.         0.        ]
 [1.         0.         0.         0.         0.1339261  1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.1339222  1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.13392585 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.13392899 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.13392496 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.13392457 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.1339263  1.
  0.         1.         1.        ]
 [1.         0.         0.54392578 0.31827927 0.13392492 1.
  0.         0.26354504 1.        ]
 [1.         0.         1.         1.         0.13392535 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.13392766 1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.13392209 1.
  0.         0.         1.        ]
 [1.         0.         0.72906746 0.43682628 0.13392534 1.
  0.         0.44637178 1.        ]
 [1.         0.         0.         0.         0.13392087 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.13392719 1.
  0.         1.         1.        ]
 [1.         0.         0.2158857  0.07446203 0.13392518 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.13392358 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.13392486 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.13392846 1.
  0.         1.         1.        ]
 [1.         0.         0.11928078 0.31002733 0.13392451 1.
  0.         0.2901596  1.        ]
 [1.         0.         0.60876885 0.46596766 0.13392642 1.
  0.         0.29341732 1.        ]
 [1.         0.         0.         0.         0.13392394 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.13392777 1.
  0.         1.         1.        ]
 [1.         0.         0.7048211  0.44377185 0.13392652 1.
  0.         0.26283618 1.        ]
 [1.         0.         1.         1.         0.13392671 1.
  0.         1.         1.        ]
 [1.         0.         0.53707466 0.10884832 0.13392394 1.
  0.         0.05983202 1.        ]]

Best Training Poisoning Accuracy:
1.0
#####################         POISON         ###############################################

############################################################################################

comm_round: 12 | global_test_acc: 87.500% | global_f1: 0.9333333333333333 | global_precision: 0.875
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.88      1.00      0.93         7

    accuracy                           0.88         8
   macro avg       0.44      0.50      0.47         8
weighted avg       0.77      0.88      0.82         8
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.         0.         1.         0.91093691 1.
 0.         0.         0.13916714 0.         0.47593249 0.47581052
 0.         1.         1.         0.         0.         0.
 1.         0.84465159 0.         0.30978852 1.         1.
 1.         0.        ]
wv_ed shape (26,)
[0.         0.         0.         0.8247252  0.48728234 1.
 0.         0.         0.09202148 0.         0.23206815 0.4952168
 0.         1.         1.         0.         0.         0.
 0.40114068 0.48052321 0.         0.         1.         1.
 1.         0.        ]
wv_lg shape (26, 1)
[[0.13593707]
 [0.13405065]
 [0.13404913]
 [0.13405017]
 [0.13405089]
 [0.13404942]
 [0.13404863]
 [0.13404938]
 [0.13404656]
 [0.13404684]
 [0.13404826]
 [0.13404692]
 [0.13404855]
 [0.13405238]
 [0.13404951]
 [0.13404687]
 [0.13404885]
 [0.13404574]
 [0.13404739]
 [0.13405037]
 [0.13404924]
 [0.1340475 ]
 [0.13405259]
 [0.13405292]
 [0.13405157]
 [0.13404739]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.         0.         0.81955922 0.42552778 1.
 0.         0.         0.16270766 0.         0.32118333 0.50147327
 0.         1.         1.         0.         0.         0.
 0.4808636  0.4185427  0.         0.         1.         1.
 1.         0.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.13593707 1.
  1.         0.         0.        ]
 [1.         0.         0.         0.         0.13405065 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.13404913 1.
  0.         0.         1.        ]
 [1.         0.         1.         0.8247252  0.13405017 1.
  0.         0.81955922 1.        ]
 [1.         0.         0.91093691 0.48728234 0.13405089 1.
  0.         0.42552778 1.        ]
 [1.         0.         1.         1.         0.13404942 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.13404863 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.13404938 1.
  0.         0.         1.        ]
 [1.         0.         0.13916714 0.09202148 0.13404656 1.
  0.         0.16270766 1.        ]
 [1.         0.         0.         0.         0.13404684 1.
  0.         0.         1.        ]
 [1.         0.         0.47593249 0.23206815 0.13404826 1.
  0.         0.32118333 1.        ]
 [1.         0.         0.47581052 0.4952168  0.13404692 1.
  0.         0.50147327 1.        ]
 [1.         0.         0.         0.         0.13404855 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.13405238 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.13404951 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.13404687 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.13404885 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.13404574 1.
  0.         0.         1.        ]
 [1.         0.         1.         0.40114068 0.13404739 1.
  0.         0.4808636  1.        ]
 [1.         0.         0.84465159 0.48052321 0.13405037 1.
  0.         0.4185427  1.        ]
 [1.         0.         0.         0.         0.13404924 1.
  0.         0.         1.        ]
 [1.         0.         0.30978852 0.         0.1340475  1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.13405259 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.13405292 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.13405157 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.13404739 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
1.0
#####################         POISON         ###############################################

############################################################################################

comm_round: 13 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.         0.4472329  0.10937371 0.60861804 1.
 0.9874341  1.         0.96134587 0.         1.         1.
 0.67991875 1.         1.         1.         1.         0.00940696
 0.98697972 1.         0.         1.         0.44024445 1.
 1.         1.        ]
wv_ed shape (26,)
[0.         0.         0.50524731 0.         0.81142258 0.80045064
 0.57434795 1.         1.         0.         1.         1.
 0.46273129 1.         1.         1.         1.         0.
 0.70070118 1.         0.         1.         0.27699252 1.
 1.         1.        ]
wv_lg shape (26, 1)
[[0.13607626]
 [0.1341718 ]
 [0.13417098]
 [0.13416973]
 [0.13417157]
 [0.13417248]
 [0.13417289]
 [0.13417415]
 [0.13417406]
 [0.13417318]
 [0.13417556]
 [0.13417376]
 [0.13417381]
 [0.13417321]
 [0.13417148]
 [0.13417182]
 [0.13417352]
 [0.13417228]
 [0.13417086]
 [0.13417382]
 [0.13416865]
 [0.13417688]
 [0.13417118]
 [0.13417339]
 [0.1341727 ]
 [0.13417199]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.         0.63380088 0.         0.93948397 0.86396072
 0.56059182 1.         1.         0.         1.         1.
 0.49750492 1.         1.         1.         1.         0.
 0.76827059 1.         0.         1.         0.38685983 1.
 1.         1.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.13607626 1.
  1.         0.         0.        ]
 [1.         0.         0.         0.         0.1341718  1.
  0.         0.         1.        ]
 [1.         0.         0.4472329  0.50524731 0.13417098 1.
  0.         0.63380088 1.        ]
 [1.         0.         0.10937371 0.         0.13416973 1.
  0.         0.         1.        ]
 [1.         0.         0.60861804 0.81142258 0.13417157 1.
  0.         0.93948397 1.        ]
 [1.         0.         1.         0.80045064 0.13417248 1.
  0.         0.86396072 1.        ]
 [1.         0.         0.9874341  0.57434795 0.13417289 1.
  0.         0.56059182 1.        ]
 [1.         0.         1.         1.         0.13417415 1.
  0.         1.         1.        ]
 [1.         0.         0.96134587 1.         0.13417406 1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.13417318 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.13417556 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.13417376 1.
  0.         1.         1.        ]
 [1.         0.         0.67991875 0.46273129 0.13417381 1.
  0.         0.49750492 1.        ]
 [1.         0.         1.         1.         0.13417321 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.13417148 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.13417182 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.13417352 1.
  0.         1.         1.        ]
 [1.         0.         0.00940696 0.         0.13417228 1.
  0.         0.         1.        ]
 [1.         0.         0.98697972 0.70070118 0.13417086 1.
  0.         0.76827059 1.        ]
 [1.         0.         1.         1.         0.13417382 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.13416865 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.13417688 1.
  0.         1.         1.        ]
 [1.         0.         0.44024445 0.27699252 0.13417118 1.
  0.         0.38685983 1.        ]
 [1.         0.         1.         1.         0.13417339 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.1341727  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.13417199 1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.9375
#####################         POISON         ###############################################

############################################################################################

comm_round: 14 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.55021335 0.56048598 0.         0.         0.85605088
 0.38383145 0.         1.         0.48859168 0.4713942  1.
 1.         1.         1.         0.71740911 1.         1.
 1.         0.34231566 0.         0.70734004 1.         1.
 1.         1.        ]
wv_ed shape (26,)
[0.         0.19133461 0.32934257 0.         0.         0.2243979
 0.16914267 0.         0.91247616 0.2839046  0.17747673 1.
 1.         1.         1.         0.36543837 0.59133025 1.
 1.         0.         0.         0.33608198 1.         1.
 1.         1.        ]
wv_lg shape (26, 1)
[[0.13623743]
 [0.13429683]
 [0.13429901]
 [0.1342954 ]
 [0.13429606]
 [0.13429633]
 [0.13429965]
 [0.13429759]
 [0.13429765]
 [0.13429773]
 [0.13429674]
 [0.1343011 ]
 [0.1342993 ]
 [0.13429915]
 [0.13429491]
 [0.13429851]
 [0.13429871]
 [0.13429978]
 [0.13430202]
 [0.13429848]
 [0.13429348]
 [0.1342983 ]
 [0.13430084]
 [0.13429936]
 [0.13429839]
 [0.13429917]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.18454451 0.28157349 0.         0.         0.29462697
 0.08221906 0.         0.82850218 0.2328958  0.15908569 1.
 1.         1.         1.         0.33239197 0.48425121 1.
 1.         0.         0.         0.26207273 1.         1.
 1.         1.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.13623743 1.
  1.         0.         0.        ]
 [1.         0.         0.55021335 0.19133461 0.13429683 1.
  0.         0.18454451 1.        ]
 [1.         0.         0.56048598 0.32934257 0.13429901 1.
  0.         0.28157349 1.        ]
 [1.         0.         0.         0.         0.1342954  1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.13429606 1.
  0.         0.         1.        ]
 [1.         0.         0.85605088 0.2243979  0.13429633 1.
  0.         0.29462697 1.        ]
 [1.         0.         0.38383145 0.16914267 0.13429965 1.
  0.         0.08221906 1.        ]
 [1.         0.         0.         0.         0.13429759 1.
  0.         0.         1.        ]
 [1.         0.         1.         0.91247616 0.13429765 1.
  0.         0.82850218 1.        ]
 [1.         0.         0.48859168 0.2839046  0.13429773 1.
  0.         0.2328958  1.        ]
 [1.         0.         0.4713942  0.17747673 0.13429674 1.
  0.         0.15908569 1.        ]
 [1.         0.         1.         1.         0.1343011  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.1342993  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.13429915 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.13429491 1.
  0.         1.         1.        ]
 [1.         0.         0.71740911 0.36543837 0.13429851 1.
  0.         0.33239197 1.        ]
 [1.         0.         1.         0.59133025 0.13429871 1.
  0.         0.48425121 1.        ]
 [1.         0.         1.         1.         0.13429978 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.13430202 1.
  0.         1.         1.        ]
 [1.         0.         0.34231566 0.         0.13429848 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.13429348 1.
  0.         0.         1.        ]
 [1.         0.         0.70734004 0.33608198 0.1342983  1.
  0.         0.26207273 1.        ]
 [1.         0.         1.         1.         0.13430084 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.13429936 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.13429839 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.13429917 1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
1.0
#####################         POISON         ###############################################

############################################################################################

comm_round: 15 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         1.         0.64223222 0.82550027 1.         0.32391758
 1.         0.         1.         0.         1.         1.
 1.         0.         0.         0.16387986 0.         0.23471189
 0.07173916 1.         1.         0.91469483 0.         1.
 1.         1.        ]
wv_ed shape (26,)
[0.         0.98524049 0.58254982 0.58249688 0.78902407 0.21268163
 1.         0.         1.         0.         1.         1.
 1.         0.         0.         0.06040922 0.         0.
 0.08898151 1.         0.92496651 1.         0.         1.
 1.         1.        ]
wv_lg shape (26, 1)
[[0.13636902]
 [0.13442364]
 [0.13442829]
 [0.13442603]
 [0.13442445]
 [0.13442532]
 [0.13443023]
 [0.13441783]
 [0.13442522]
 [0.13442227]
 [0.13442594]
 [0.13442912]
 [0.13442621]
 [0.13442357]
 [0.13442406]
 [0.13442664]
 [0.13442441]
 [0.13442245]
 [0.13442401]
 [0.13442404]
 [0.13442479]
 [0.13442432]
 [0.13442388]
 [0.13442371]
 [0.13442763]
 [0.13442768]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.95435583 0.48640718 0.50628153 0.85309554 0.0944382
 1.         0.         1.         0.         1.         1.
 1.         0.         0.         0.         0.         0.
 0.09810816 1.         0.89042847 1.         0.         1.
 1.         1.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.13636902 1.
  1.         0.         0.        ]
 [1.         0.         1.         0.98524049 0.13442364 1.
  0.         0.95435583 1.        ]
 [1.         0.         0.64223222 0.58254982 0.13442829 1.
  0.         0.48640718 1.        ]
 [1.         0.         0.82550027 0.58249688 0.13442603 1.
  0.         0.50628153 1.        ]
 [1.         0.         1.         0.78902407 0.13442445 1.
  0.         0.85309554 1.        ]
 [1.         0.         0.32391758 0.21268163 0.13442532 1.
  0.         0.0944382  1.        ]
 [1.         0.         1.         1.         0.13443023 1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.13441783 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.13442522 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.13442227 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.13442594 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.13442912 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.13442621 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.13442357 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.13442406 1.
  0.         0.         1.        ]
 [1.         0.         0.16387986 0.06040922 0.13442664 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.13442441 1.
  0.         0.         1.        ]
 [1.         0.         0.23471189 0.         0.13442245 1.
  0.         0.         1.        ]
 [1.         0.         0.07173916 0.08898151 0.13442401 1.
  0.         0.09810816 1.        ]
 [1.         0.         1.         1.         0.13442404 1.
  0.         1.         1.        ]
 [1.         0.         1.         0.92496651 0.13442479 1.
  0.         0.89042847 1.        ]
 [1.         0.         0.91469483 1.         0.13442432 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.13442388 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.13442371 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.13442763 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.13442768 1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
1.0
#####################         POISON         ###############################################

############################################################################################

comm_round: 16 | global_test_acc: 87.500% | global_f1: 0.9333333333333333 | global_precision: 0.875
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.88      1.00      0.93         7

    accuracy                           0.88         8
   macro avg       0.44      0.50      0.47         8
weighted avg       0.77      0.88      0.82         8
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.5757615  1.         1.         1.         0.74927462
 1.         0.80670538 0.         0.71529195 0.7169231  1.
 1.         0.         1.         0.22875635 0.44178997 1.
 0.32367518 0.         1.         0.         0.62670839 0.03460584
 1.         0.99360822]
wv_ed shape (26,)
[0.         1.         1.         1.         1.         1.
 1.         1.         0.         0.54176311 1.         1.
 1.         0.11139591 1.         0.17349163 0.08177256 1.
 0.77153506 0.         1.         0.28292806 0.92902913 0.14591557
 1.         0.92485447]
wv_lg shape (26, 1)
[[0.13650673]
 [0.13455144]
 [0.1345509 ]
 [0.13455232]
 [0.13455046]
 [0.13455078]
 [0.13455099]
 [0.134554  ]
 [0.13454942]
 [0.13454931]
 [0.13454938]
 [0.13455326]
 [0.13454975]
 [0.13455176]
 [0.13455129]
 [0.13455025]
 [0.13454965]
 [0.13455216]
 [0.13455349]
 [0.1345493 ]
 [0.13455122]
 [0.13455059]
 [0.1345531 ]
 [0.13454961]
 [0.13455051]
 [0.1345515 ]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         1.         1.         1.         1.         1.
 1.         1.         0.         0.71018313 1.         1.
 1.         0.2666623  1.         0.2788139  0.25385173 1.
 0.82851802 0.         1.         0.36428492 1.         0.2908821
 1.         0.98291799]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.13650673 1.
  1.         0.         0.        ]
 [1.         0.         0.5757615  1.         0.13455144 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.1345509  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.13455232 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.13455046 1.
  0.         1.         1.        ]
 [1.         0.         0.74927462 1.         0.13455078 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.13455099 1.
  0.         1.         1.        ]
 [1.         0.         0.80670538 1.         0.134554   1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.13454942 1.
  0.         0.         1.        ]
 [1.         0.         0.71529195 0.54176311 0.13454931 1.
  0.         0.71018313 1.        ]
 [1.         0.         0.7169231  1.         0.13454938 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.13455326 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.13454975 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.11139591 0.13455176 1.
  0.         0.2666623  1.        ]
 [1.         0.         1.         1.         0.13455129 1.
  0.         1.         1.        ]
 [1.         0.         0.22875635 0.17349163 0.13455025 1.
  0.         0.2788139  1.        ]
 [1.         0.         0.44178997 0.08177256 0.13454965 1.
  0.         0.25385173 1.        ]
 [1.         0.         1.         1.         0.13455216 1.
  0.         1.         1.        ]
 [1.         0.         0.32367518 0.77153506 0.13455349 1.
  0.         0.82851802 1.        ]
 [0.         0.         0.         0.         0.1345493  1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.13455122 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.28292806 0.13455059 1.
  0.         0.36428492 1.        ]
 [1.         0.         0.62670839 0.92902913 0.1345531  1.
  0.         1.         1.        ]
 [1.         0.         0.03460584 0.14591557 0.13454961 1.
  0.         0.2908821  1.        ]
 [1.         0.         1.         1.         0.13455051 1.
  0.         1.         1.        ]
 [1.         0.         0.99360822 0.92485447 0.1345515  1.
  0.         0.98291799 1.        ]]

Best Training Poisoning Accuracy:
0.9375
#####################         POISON         ###############################################

############################################################################################

comm_round: 17 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         1.         1.         1.         0.         1.
 0.40203358 0.         0.         0.         0.         0.12864282
 0.54914841 0.10973808 0.         1.         0.         1.
 0.65344314 0.         0.90200789 0.65879535 1.         0.30702944
 0.44921152 0.50824023]
wv_ed shape (26,)
[0.         1.         1.         1.         0.         1.
 0.70764914 0.         0.         0.         0.08673998 0.28750258
 0.81247038 0.         0.         1.         0.         1.
 0.43683842 0.         0.71498349 0.55816833 1.         0.40211734
 0.4467048  0.6585922 ]
wv_lg shape (26, 1)
[[0.13664498]
 [0.1346837 ]
 [0.13468815]
 [0.13468543]
 [0.13468264]
 [0.13468659]
 [0.13468577]
 [0.1346816 ]
 [0.13467896]
 [0.13467879]
 [0.1346814 ]
 [0.13468423]
 [0.1346866 ]
 [0.13468212]
 [0.13468084]
 [0.13468323]
 [0.13468331]
 [0.1346861 ]
 [0.13468455]
 [0.13467863]
 [0.13468362]
 [0.13468474]
 [0.13468663]
 [0.13468197]
 [0.13468598]
 [0.13468595]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         1.         1.         1.         0.         1.
 0.65215208 0.         0.         0.         0.09757595 0.29305398
 0.74765214 0.         0.         1.         0.         1.
 0.42084775 0.         0.62319582 0.51354845 1.         0.4531998
 0.37756205 0.58488316]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.13664498 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.1346837  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.13468815 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.13468543 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.13468264 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.13468659 1.
  0.         1.         1.        ]
 [1.         0.         0.40203358 0.70764914 0.13468577 1.
  0.         0.65215208 1.        ]
 [1.         0.         0.         0.         0.1346816  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.13467896 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.13467879 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.08673998 0.1346814  1.
  0.         0.09757595 1.        ]
 [1.         0.         0.12864282 0.28750258 0.13468423 1.
  0.         0.29305398 1.        ]
 [1.         0.         0.54914841 0.81247038 0.1346866  1.
  0.         0.74765214 1.        ]
 [1.         0.         0.10973808 0.         0.13468212 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.13468084 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.13468323 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.13468331 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.1346861  1.
  0.         1.         1.        ]
 [1.         0.         0.65344314 0.43683842 0.13468455 1.
  0.         0.42084775 1.        ]
 [1.         0.         0.         0.         0.13467863 1.
  0.         0.         1.        ]
 [1.         0.         0.90200789 0.71498349 0.13468362 1.
  0.         0.62319582 1.        ]
 [1.         0.         0.65879535 0.55816833 0.13468474 1.
  0.         0.51354845 1.        ]
 [1.         0.         1.         1.         0.13468663 1.
  0.         1.         1.        ]
 [1.         0.         0.30702944 0.40211734 0.13468197 1.
  0.         0.4531998  1.        ]
 [1.         0.         0.44921152 0.4467048  0.13468598 1.
  0.         0.37756205 1.        ]
 [1.         0.         0.50824023 0.6585922  0.13468595 1.
  0.         0.58488316 1.        ]]

Best Training Poisoning Accuracy:
0.9375
#####################         POISON         ###############################################

############################################################################################

comm_round: 18 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.5292342  1.         0.         0.8922529  0.59335601
 0.         0.97802969 0.97481907 0.         0.41395502 0.85730055
 1.         0.30253512 1.         0.         0.07641419 0.
 0.9800106  0.1282651  0.55559119 1.         0.11682429 0.
 0.32474501 0.        ]
wv_ed shape (26,)
[0.         0.60182349 1.         0.         1.         0.74813449
 0.         1.         0.93217203 0.         0.46916914 1.
 1.         0.55096615 1.         0.         0.47316665 0.
 1.         0.29136616 1.         1.         0.41009387 0.
 0.55519772 0.16415217]
wv_lg shape (26, 1)
[[0.13679749]
 [0.1348138 ]
 [0.13481816]
 [0.13480988]
 [0.13481876]
 [0.13481435]
 [0.134815  ]
 [0.13481652]
 [0.13481327]
 [0.134812  ]
 [0.13481341]
 [0.13481601]
 [0.13481729]
 [0.13481484]
 [0.13481297]
 [0.13481531]
 [0.13481394]
 [0.13481283]
 [0.13481703]
 [0.13481397]
 [0.13481637]
 [0.13481783]
 [0.13481564]
 [0.13481219]
 [0.1348155 ]
 [0.13481361]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.66580491 1.         0.         0.99634747 0.83764326
 0.         1.         0.93634889 0.         0.51062562 1.
 1.         0.63833775 1.         0.         0.50545038 0.
 1.         0.26209584 0.96701025 1.         0.38330195 0.
 0.58720915 0.15457963]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.13679749 1.
  1.         0.         0.        ]
 [1.         0.         0.5292342  0.60182349 0.1348138  1.
  0.         0.66580491 1.        ]
 [1.         0.         1.         1.         0.13481816 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.13480988 1.
  0.         0.         1.        ]
 [1.         0.         0.8922529  1.         0.13481876 1.
  0.         0.99634747 1.        ]
 [1.         0.         0.59335601 0.74813449 0.13481435 1.
  0.         0.83764326 1.        ]
 [1.         0.         0.         0.         0.134815   1.
  0.         0.         1.        ]
 [1.         0.         0.97802969 1.         0.13481652 1.
  0.         1.         1.        ]
 [1.         0.         0.97481907 0.93217203 0.13481327 1.
  0.         0.93634889 1.        ]
 [0.         0.         0.         0.         0.134812   1.
  0.         0.         1.        ]
 [1.         0.         0.41395502 0.46916914 0.13481341 1.
  0.         0.51062562 1.        ]
 [1.         0.         0.85730055 1.         0.13481601 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.13481729 1.
  0.         1.         1.        ]
 [1.         0.         0.30253512 0.55096615 0.13481484 1.
  0.         0.63833775 1.        ]
 [1.         0.         1.         1.         0.13481297 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.13481531 1.
  0.         0.         1.        ]
 [1.         0.         0.07641419 0.47316665 0.13481394 1.
  0.         0.50545038 1.        ]
 [1.         0.         0.         0.         0.13481283 1.
  0.         0.         1.        ]
 [1.         0.         0.9800106  1.         0.13481703 1.
  0.         1.         1.        ]
 [1.         0.         0.1282651  0.29136616 0.13481397 1.
  0.         0.26209584 1.        ]
 [1.         0.         0.55559119 1.         0.13481637 1.
  0.         0.96701025 1.        ]
 [1.         0.         1.         1.         0.13481783 1.
  0.         1.         1.        ]
 [1.         0.         0.11682429 0.41009387 0.13481564 1.
  0.         0.38330195 1.        ]
 [1.         0.         0.         0.         0.13481219 1.
  0.         0.         1.        ]
 [1.         0.         0.32474501 0.55519772 0.1348155  1.
  0.         0.58720915 1.        ]
 [1.         0.         0.         0.16415217 0.13481361 1.
  0.         0.15457963 1.        ]]

Best Training Poisoning Accuracy:
0.9375
#####################         POISON         ###############################################

############################################################################################

comm_round: 19 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.         1.         0.84492481 0.         0.32596853
 0.0389256  1.         1.         0.         0.         1.
 1.         0.35627233 0.80587342 0.         0.         0.
 0.         0.61748965 0.         0.74177608 0.51349395 1.
 1.         0.        ]
wv_ed shape (26,)
[0.00000000e+00 0.00000000e+00 1.00000000e+00 8.57586967e-01
 4.49585250e-05 2.42928211e-01 0.00000000e+00 1.00000000e+00
 1.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00
 8.68104393e-01 2.93668754e-02 7.73494082e-01 0.00000000e+00
 2.54311570e-01 0.00000000e+00 0.00000000e+00 3.26544046e-01
 0.00000000e+00 8.88748191e-01 2.76652291e-01 1.00000000e+00
 1.00000000e+00 0.00000000e+00]
wv_lg shape (26, 1)
[[0.13692132]
 [0.13494554]
 [0.13494884]
 [0.13494681]
 [0.13494719]
 [0.1349456 ]
 [0.13494553]
 [0.13494939]
 [0.13495234]
 [0.13494866]
 [0.13494068]
 [0.1349477 ]
 [0.13494742]
 [0.13494447]
 [0.1349469 ]
 [0.13494607]
 [0.13494506]
 [0.1349456 ]
 [0.13494294]
 [0.13494468]
 [0.13494302]
 [0.13494848]
 [0.13494548]
 [0.13494551]
 [0.13494917]
 [0.13494464]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.         1.         0.87051767 0.         0.23357909
 0.         1.         1.         0.         0.         1.
 0.86944605 0.09492504 0.82330207 0.         0.26832596 0.
 0.         0.3931596  0.         0.88479538 0.28527293 1.
 1.         0.        ]
xy shape: (26, 9)
[[0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00
  1.36921315e-01 1.00000000e+00 1.00000000e+00 0.00000000e+00
  0.00000000e+00]
 [1.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
  1.34945544e-01 1.00000000e+00 0.00000000e+00 0.00000000e+00
  1.00000000e+00]
 [1.00000000e+00 0.00000000e+00 1.00000000e+00 1.00000000e+00
  1.34948845e-01 1.00000000e+00 0.00000000e+00 1.00000000e+00
  1.00000000e+00]
 [1.00000000e+00 0.00000000e+00 8.44924808e-01 8.57586967e-01
  1.34946805e-01 1.00000000e+00 0.00000000e+00 8.70517669e-01
  1.00000000e+00]
 [1.00000000e+00 0.00000000e+00 0.00000000e+00 4.49585250e-05
  1.34947191e-01 1.00000000e+00 0.00000000e+00 0.00000000e+00
  1.00000000e+00]
 [1.00000000e+00 0.00000000e+00 3.25968531e-01 2.42928211e-01
  1.34945603e-01 1.00000000e+00 0.00000000e+00 2.33579093e-01
  1.00000000e+00]
 [1.00000000e+00 0.00000000e+00 3.89256011e-02 0.00000000e+00
  1.34945526e-01 1.00000000e+00 0.00000000e+00 0.00000000e+00
  1.00000000e+00]
 [1.00000000e+00 0.00000000e+00 1.00000000e+00 1.00000000e+00
  1.34949388e-01 1.00000000e+00 0.00000000e+00 1.00000000e+00
  1.00000000e+00]
 [1.00000000e+00 0.00000000e+00 1.00000000e+00 1.00000000e+00
  1.34952344e-01 1.00000000e+00 0.00000000e+00 1.00000000e+00
  1.00000000e+00]
 [1.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
  1.34948659e-01 1.00000000e+00 0.00000000e+00 0.00000000e+00
  1.00000000e+00]
 [1.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
  1.34940679e-01 1.00000000e+00 0.00000000e+00 0.00000000e+00
  1.00000000e+00]
 [1.00000000e+00 0.00000000e+00 1.00000000e+00 1.00000000e+00
  1.34947703e-01 1.00000000e+00 0.00000000e+00 1.00000000e+00
  1.00000000e+00]
 [1.00000000e+00 0.00000000e+00 1.00000000e+00 8.68104393e-01
  1.34947419e-01 1.00000000e+00 0.00000000e+00 8.69446050e-01
  1.00000000e+00]
 [1.00000000e+00 0.00000000e+00 3.56272326e-01 2.93668754e-02
  1.34944468e-01 1.00000000e+00 0.00000000e+00 9.49250383e-02
  1.00000000e+00]
 [1.00000000e+00 0.00000000e+00 8.05873421e-01 7.73494082e-01
  1.34946897e-01 1.00000000e+00 0.00000000e+00 8.23302069e-01
  1.00000000e+00]
 [1.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
  1.34946069e-01 1.00000000e+00 0.00000000e+00 0.00000000e+00
  1.00000000e+00]
 [1.00000000e+00 0.00000000e+00 0.00000000e+00 2.54311570e-01
  1.34945063e-01 1.00000000e+00 0.00000000e+00 2.68325962e-01
  1.00000000e+00]
 [1.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
  1.34945600e-01 1.00000000e+00 0.00000000e+00 0.00000000e+00
  1.00000000e+00]
 [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
  1.34942941e-01 1.00000000e+00 0.00000000e+00 0.00000000e+00
  1.00000000e+00]
 [1.00000000e+00 0.00000000e+00 6.17489649e-01 3.26544046e-01
  1.34944683e-01 1.00000000e+00 0.00000000e+00 3.93159601e-01
  1.00000000e+00]
 [1.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
  1.34943024e-01 1.00000000e+00 0.00000000e+00 0.00000000e+00
  1.00000000e+00]
 [1.00000000e+00 0.00000000e+00 7.41776077e-01 8.88748191e-01
  1.34948484e-01 1.00000000e+00 0.00000000e+00 8.84795382e-01
  1.00000000e+00]
 [1.00000000e+00 0.00000000e+00 5.13493947e-01 2.76652291e-01
  1.34945479e-01 1.00000000e+00 0.00000000e+00 2.85272929e-01
  1.00000000e+00]
 [1.00000000e+00 0.00000000e+00 1.00000000e+00 1.00000000e+00
  1.34945515e-01 1.00000000e+00 0.00000000e+00 1.00000000e+00
  1.00000000e+00]
 [1.00000000e+00 0.00000000e+00 1.00000000e+00 1.00000000e+00
  1.34949172e-01 1.00000000e+00 0.00000000e+00 1.00000000e+00
  1.00000000e+00]
 [1.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
  1.34944638e-01 1.00000000e+00 0.00000000e+00 0.00000000e+00
  1.00000000e+00]]

Best Training Poisoning Accuracy:
0.9375
#####################         POISON         ###############################################

############################################################################################

comm_round: 20 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.69714813 1.         0.         0.         0.
 1.         1.         0.         0.94741201 0.33472003 0.81486774
 0.29456175 0.         1.         0.         0.         0.99808272
 0.31253826 0.27221093 1.         0.         0.         1.
 0.71719091 1.        ]
wv_ed shape (26,)
[0.         0.29001949 1.         0.         0.         0.
 0.97318074 1.         0.         0.95768443 0.3144753  0.73011494
 0.12050626 0.         1.         0.         0.         0.96687414
 0.39096974 0.01707788 1.         0.         0.         1.
 0.4442958  0.99957038]
wv_lg shape (26, 1)
[[0.13707585]
 [0.1350787 ]
 [0.13507954]
 [0.1350746 ]
 [0.13507561]
 [0.13507251]
 [0.13508238]
 [0.13508304]
 [0.13507778]
 [0.13508137]
 [0.13508081]
 [0.13508112]
 [0.13508062]
 [0.13507541]
 [0.13508192]
 [0.13507481]
 [0.13507714]
 [0.13508134]
 [0.13508075]
 [0.13507614]
 [0.13508533]
 [0.13507474]
 [0.13507894]
 [0.13508077]
 [0.13507936]
 [0.135079  ]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.31758319 1.         0.         0.         0.
 0.98040041 1.         0.         0.85882173 0.29062169 0.67989452
 0.10180417 0.         1.         0.         0.         0.93465998
 0.41050138 0.18295501 1.         0.         0.         1.
 0.46927702 1.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.13707585 1.
  1.         0.         0.        ]
 [1.         0.         0.69714813 0.29001949 0.1350787  1.
  0.         0.31758319 1.        ]
 [1.         0.         1.         1.         0.13507954 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.1350746  1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.13507561 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.13507251 1.
  0.         0.         1.        ]
 [1.         0.         1.         0.97318074 0.13508238 1.
  0.         0.98040041 1.        ]
 [1.         0.         1.         1.         0.13508304 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.13507778 1.
  0.         0.         1.        ]
 [1.         0.         0.94741201 0.95768443 0.13508137 1.
  0.         0.85882173 1.        ]
 [1.         0.         0.33472003 0.3144753  0.13508081 1.
  0.         0.29062169 1.        ]
 [1.         0.         0.81486774 0.73011494 0.13508112 1.
  0.         0.67989452 1.        ]
 [1.         0.         0.29456175 0.12050626 0.13508062 1.
  0.         0.10180417 1.        ]
 [0.         0.         0.         0.         0.13507541 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.13508192 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.13507481 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.13507714 1.
  0.         0.         1.        ]
 [1.         0.         0.99808272 0.96687414 0.13508134 1.
  0.         0.93465998 1.        ]
 [1.         0.         0.31253826 0.39096974 0.13508075 1.
  0.         0.41050138 1.        ]
 [1.         0.         0.27221093 0.01707788 0.13507614 1.
  0.         0.18295501 1.        ]
 [1.         0.         1.         1.         0.13508533 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.13507474 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.13507894 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.13508077 1.
  0.         1.         1.        ]
 [1.         0.         0.71719091 0.4442958  0.13507936 1.
  0.         0.46927702 1.        ]
 [1.         0.         1.         0.99957038 0.135079   1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.9375
#####################         POISON         ###############################################

############################################################################################

comm_round: 21 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         1.         1.         1.         1.         0.51661512
 0.89294875 0.         1.         1.         1.         1.
 1.         0.94638287 0.38125071 0.81689869 1.         1.
 1.         1.         0.77068489 0.77599204 0.61207962 1.
 1.         1.        ]
wv_ed shape (26,)
[0.         1.         1.         1.         1.         0.72659722
 1.         0.         1.         1.         1.         1.
 1.         1.         0.19185103 0.87828189 1.         1.
 1.         1.         0.62724675 0.81397938 0.63812766 1.
 1.         1.        ]
wv_lg shape (26, 1)
[[0.13719755]
 [0.13521073]
 [0.13520828]
 [0.13521324]
 [0.13521044]
 [0.13521072]
 [0.13520957]
 [0.1352054 ]
 [0.13521264]
 [0.13521283]
 [0.13520962]
 [0.13521147]
 [0.13521163]
 [0.13521339]
 [0.13520758]
 [0.13521041]
 [0.13521436]
 [0.13521287]
 [0.13521203]
 [0.13521151]
 [0.13521002]
 [0.13520984]
 [0.13521159]
 [0.13521372]
 [0.13521054]
 [0.13521243]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         1.         1.         1.         1.         0.6248233
 1.         0.         1.         1.         1.         1.
 1.         1.         0.21628325 0.7935907  1.         1.
 1.         1.         0.5522871  0.79093839 0.60824612 1.
 1.         1.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.13719755 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.13521073 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.13520828 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.13521324 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.13521044 1.
  0.         1.         1.        ]
 [1.         0.         0.51661512 0.72659722 0.13521072 1.
  0.         0.6248233  1.        ]
 [1.         0.         0.89294875 1.         0.13520957 1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.1352054  1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.13521264 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.13521283 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.13520962 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.13521147 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.13521163 1.
  0.         1.         1.        ]
 [1.         0.         0.94638287 1.         0.13521339 1.
  0.         1.         1.        ]
 [1.         0.         0.38125071 0.19185103 0.13520758 1.
  0.         0.21628325 1.        ]
 [1.         0.         0.81689869 0.87828189 0.13521041 1.
  0.         0.7935907  1.        ]
 [1.         0.         1.         1.         0.13521436 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.13521287 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.13521203 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.13521151 1.
  0.         1.         1.        ]
 [1.         0.         0.77068489 0.62724675 0.13521002 1.
  0.         0.5522871  1.        ]
 [1.         0.         0.77599204 0.81397938 0.13520984 1.
  0.         0.79093839 1.        ]
 [1.         0.         0.61207962 0.63812766 0.13521159 1.
  0.         0.60824612 1.        ]
 [1.         0.         1.         1.         0.13521372 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.13521054 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.13521243 1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
1.0
#####################         POISON         ###############################################

############################################################################################

comm_round: 22 | global_test_acc: 87.500% | global_f1: 0.9333333333333333 | global_precision: 0.875
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.88      1.00      0.93         7

    accuracy                           0.88         8
   macro avg       0.44      0.50      0.47         8
weighted avg       0.77      0.88      0.82         8
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         1.         0.79441512 1.         1.         0.07181003
 1.         0.56609003 0.         0.67705607 0.         0.
 1.         1.         0.81418028 0.         0.4201873  1.
 1.         0.63750893 1.         0.85522803 1.         0.8053535
 0.8472067  0.94330774]
wv_ed shape (26,)
[0.         1.         0.65634683 1.         1.         0.
 1.         0.47088566 0.         0.7199205  0.         0.
 0.994991   0.82650774 0.86837201 0.         0.31299772 1.
 1.         0.31973816 1.         0.71101363 1.         0.78813777
 0.64148535 0.90636896]
wv_lg shape (26, 1)
[[0.13733832]
 [0.1353484 ]
 [0.13534479]
 [0.13534723]
 [0.13534581]
 [0.1353436 ]
 [0.13534872]
 [0.13534472]
 [0.13533841]
 [0.13534342]
 [0.13533926]
 [0.13534101]
 [0.13534414]
 [0.13534575]
 [0.1353436 ]
 [0.13534254]
 [0.13534514]
 [0.13534665]
 [0.13534458]
 [0.13534523]
 [0.13534648]
 [0.13534576]
 [0.13534492]
 [0.13534563]
 [0.13534539]
 [0.13534306]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         1.         0.61530954 1.         1.         0.
 1.         0.52244528 0.         0.72995877 0.         0.
 1.         0.87441685 0.92982497 0.         0.34678809 1.
 1.         0.29971629 1.         0.75922998 1.         0.82789242
 0.70617518 1.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.13733832 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.1353484  1.
  0.         1.         1.        ]
 [1.         0.         0.79441512 0.65634683 0.13534479 1.
  0.         0.61530954 1.        ]
 [1.         0.         1.         1.         0.13534723 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.13534581 1.
  0.         1.         1.        ]
 [1.         0.         0.07181003 0.         0.1353436  1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.13534872 1.
  0.         1.         1.        ]
 [1.         0.         0.56609003 0.47088566 0.13534472 1.
  0.         0.52244528 1.        ]
 [1.         0.         0.         0.         0.13533841 1.
  0.         0.         1.        ]
 [1.         0.         0.67705607 0.7199205  0.13534342 1.
  0.         0.72995877 1.        ]
 [0.         0.         0.         0.         0.13533926 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.13534101 1.
  0.         0.         1.        ]
 [1.         0.         1.         0.994991   0.13534414 1.
  0.         1.         1.        ]
 [1.         0.         1.         0.82650774 0.13534575 1.
  0.         0.87441685 1.        ]
 [1.         0.         0.81418028 0.86837201 0.1353436  1.
  0.         0.92982497 1.        ]
 [1.         0.         0.         0.         0.13534254 1.
  0.         0.         1.        ]
 [1.         0.         0.4201873  0.31299772 0.13534514 1.
  0.         0.34678809 1.        ]
 [1.         0.         1.         1.         0.13534665 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.13534458 1.
  0.         1.         1.        ]
 [1.         0.         0.63750893 0.31973816 0.13534523 1.
  0.         0.29971629 1.        ]
 [1.         0.         1.         1.         0.13534648 1.
  0.         1.         1.        ]
 [1.         0.         0.85522803 0.71101363 0.13534576 1.
  0.         0.75922998 1.        ]
 [1.         0.         1.         1.         0.13534492 1.
  0.         1.         1.        ]
 [1.         0.         0.8053535  0.78813777 0.13534563 1.
  0.         0.82789242 1.        ]
 [1.         0.         0.8472067  0.64148535 0.13534539 1.
  0.         0.70617518 1.        ]
 [1.         0.         0.94330774 0.90636896 0.13534306 1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.9375
#####################         POISON         ###############################################

############################################################################################

comm_round: 23 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.25848338 0.19236702 0.92818855 0.63219247 0.
 0.         1.         0.43673112 0.60983472 0.         0.
 0.67864072 1.         1.         0.19581581 0.         0.83443625
 0.         0.34997191 0.28661055 0.4755383  0.         0.
 0.20576372 1.        ]
wv_ed shape (26,)
[0.         0.48622619 0.05733691 0.95573426 0.59989235 0.
 0.         1.         0.65084657 0.69327067 0.02432328 0.
 1.         1.         1.         0.25829122 0.         0.72188993
 0.         0.59929513 0.4575721  0.55548474 0.         0.
 0.14661231 1.        ]
wv_lg shape (26, 1)
[[0.13749828]
 [0.135479  ]
 [0.13547704]
 [0.1354781 ]
 [0.13547888]
 [0.13547759]
 [0.13547625]
 [0.13547903]
 [0.1354752 ]
 [0.13547586]
 [0.13547392]
 [0.13547828]
 [0.13547839]
 [0.13547937]
 [0.13548128]
 [0.1354768 ]
 [0.13547468]
 [0.13547925]
 [0.13547762]
 [0.13547682]
 [0.13547455]
 [0.1354785 ]
 [0.13547476]
 [0.13547734]
 [0.13547654]
 [0.1354788 ]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.4372472  0.03282783 0.93051686 0.58382719 0.
 0.         1.         0.6434378  0.76024734 0.02104683 0.
 0.97836756 1.         1.         0.29370885 0.         0.63816723
 0.         0.66153304 0.58154268 0.66572149 0.         0.
 0.12940493 1.        ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.13749828 1.
  1.         0.         0.        ]
 [1.         0.         0.25848338 0.48622619 0.135479   1.
  0.         0.4372472  1.        ]
 [1.         0.         0.19236702 0.05733691 0.13547704 1.
  0.         0.03282783 1.        ]
 [1.         0.         0.92818855 0.95573426 0.1354781  1.
  0.         0.93051686 1.        ]
 [1.         0.         0.63219247 0.59989235 0.13547888 1.
  0.         0.58382719 1.        ]
 [1.         0.         0.         0.         0.13547759 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.13547625 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.13547903 1.
  0.         1.         1.        ]
 [1.         0.         0.43673112 0.65084657 0.1354752  1.
  0.         0.6434378  1.        ]
 [1.         0.         0.60983472 0.69327067 0.13547586 1.
  0.         0.76024734 1.        ]
 [1.         0.         0.         0.02432328 0.13547392 1.
  0.         0.02104683 1.        ]
 [1.         0.         0.         0.         0.13547828 1.
  0.         0.         1.        ]
 [1.         0.         0.67864072 1.         0.13547839 1.
  0.         0.97836756 1.        ]
 [1.         0.         1.         1.         0.13547937 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.13548128 1.
  0.         1.         1.        ]
 [1.         0.         0.19581581 0.25829122 0.1354768  1.
  0.         0.29370885 1.        ]
 [0.         0.         0.         0.         0.13547468 1.
  0.         0.         1.        ]
 [1.         0.         0.83443625 0.72188993 0.13547925 1.
  0.         0.63816723 1.        ]
 [1.         0.         0.         0.         0.13547762 1.
  0.         0.         1.        ]
 [1.         0.         0.34997191 0.59929513 0.13547682 1.
  0.         0.66153304 1.        ]
 [1.         0.         0.28661055 0.4575721  0.13547455 1.
  0.         0.58154268 1.        ]
 [1.         0.         0.4755383  0.55548474 0.1354785  1.
  0.         0.66572149 1.        ]
 [1.         0.         0.         0.         0.13547476 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.13547734 1.
  0.         0.         1.        ]
 [1.         0.         0.20576372 0.14661231 0.13547654 1.
  0.         0.12940493 1.        ]
 [1.         0.         1.         1.         0.1354788  1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.9375
#####################         POISON         ###############################################

############################################################################################

comm_round: 24 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.6828598  1.         0.         1.         1.
 1.         1.         0.83241094 0.         0.14786774 0.78187345
 1.         0.52991185 0.57505664 1.         0.31726728 1.
 1.         0.54153307 1.         0.0806443  1.         0.
 1.         0.55733157]
wv_ed shape (26,)
[0.         0.72468347 1.         0.00261092 1.         1.
 1.         1.         0.9722101  0.         0.08116243 0.66987883
 1.         0.45535295 0.72442596 1.         0.14296279 1.
 1.         0.26278419 1.         0.26249025 0.78093722 0.
 1.         0.52124109]
wv_lg shape (26, 1)
[[0.13764275]
 [0.13560827]
 [0.13560795]
 [0.13560505]
 [0.1356104 ]
 [0.13560745]
 [0.13561033]
 [0.13561005]
 [0.13560763]
 [0.13560256]
 [0.13560592]
 [0.13560587]
 [0.13560891]
 [0.1356081 ]
 [0.13560948]
 [0.13561109]
 [0.13560585]
 [0.13560964]
 [0.13561201]
 [0.13560652]
 [0.13561082]
 [0.13560929]
 [0.13560772]
 [0.13560671]
 [0.13561104]
 [0.1356088 ]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.71717972 1.         0.06111517 1.         1.
 1.         1.         0.98464924 0.         0.1459785  0.73444485
 1.         0.4631318  0.72660921 1.         0.22547445 1.
 1.         0.28115361 1.         0.26529234 0.82611464 0.
 1.         0.58150468]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.13764275 1.
  1.         0.         0.        ]
 [1.         0.         0.6828598  0.72468347 0.13560827 1.
  0.         0.71717972 1.        ]
 [1.         0.         1.         1.         0.13560795 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.00261092 0.13560505 1.
  0.         0.06111517 1.        ]
 [1.         0.         1.         1.         0.1356104  1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.13560745 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.13561033 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.13561005 1.
  0.         1.         1.        ]
 [1.         0.         0.83241094 0.9722101  0.13560763 1.
  0.         0.98464924 1.        ]
 [0.         0.         0.         0.         0.13560256 1.
  0.         0.         1.        ]
 [1.         0.         0.14786774 0.08116243 0.13560592 1.
  0.         0.1459785  1.        ]
 [1.         0.         0.78187345 0.66987883 0.13560587 1.
  0.         0.73444485 1.        ]
 [1.         0.         1.         1.         0.13560891 1.
  0.         1.         1.        ]
 [1.         0.         0.52991185 0.45535295 0.1356081  1.
  0.         0.4631318  1.        ]
 [1.         0.         0.57505664 0.72442596 0.13560948 1.
  0.         0.72660921 1.        ]
 [1.         0.         1.         1.         0.13561109 1.
  0.         1.         1.        ]
 [1.         0.         0.31726728 0.14296279 0.13560585 1.
  0.         0.22547445 1.        ]
 [1.         0.         1.         1.         0.13560964 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.13561201 1.
  0.         1.         1.        ]
 [1.         0.         0.54153307 0.26278419 0.13560652 1.
  0.         0.28115361 1.        ]
 [1.         0.         1.         1.         0.13561082 1.
  0.         1.         1.        ]
 [1.         0.         0.0806443  0.26249025 0.13560929 1.
  0.         0.26529234 1.        ]
 [1.         0.         1.         0.78093722 0.13560772 1.
  0.         0.82611464 1.        ]
 [1.         0.         0.         0.         0.13560671 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.13561104 1.
  0.         1.         1.        ]
 [1.         0.         0.55733157 0.52124109 0.1356088  1.
  0.         0.58150468 1.        ]]

Best Training Poisoning Accuracy:
1.0
#####################         POISON         ###############################################

############################################################################################

comm_round: 25 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         1.         0.60720694 0.         0.         0.4677891
 0.         0.92988943 0.         0.         0.         1.
 0.02484292 0.         1.         0.26010156 1.         0.
 0.         0.69202727 0.49589271 0.         1.         0.06829362
 0.38089432 0.82510804]
wv_ed shape (26,)
[0.         1.         0.5039724  0.         0.73329818 0.29383492
 0.         0.76386279 0.         0.         0.         1.
 0.63348919 0.         1.         0.         0.98675744 0.
 0.         0.65968716 0.62145808 0.         1.         0.31117666
 0.71015984 0.77997739]
wv_lg shape (26, 1)
[[0.13776732]
 [0.13574802]
 [0.13574261]
 [0.13573722]
 [0.13574374]
 [0.13573875]
 [0.13574182]
 [0.13574205]
 [0.13573472]
 [0.13573764]
 [0.1357404 ]
 [0.13574673]
 [0.13574167]
 [0.13573971]
 [0.13574537]
 [0.13574118]
 [0.13574099]
 [0.13573839]
 [0.13573682]
 [0.13574167]
 [0.1357411 ]
 [0.13573926]
 [0.13574457]
 [0.13574308]
 [0.13573704]
 [0.13574302]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         1.         0.55183753 0.         0.89191052 0.46566498
 0.16141747 0.88281761 0.         0.         0.         1.
 0.79271365 0.         1.         0.         1.         0.
 0.         0.72710338 0.73059403 0.         1.         0.32438938
 0.80843113 0.9180974 ]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.13776732 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.13574802 1.
  0.         1.         1.        ]
 [1.         0.         0.60720694 0.5039724  0.13574261 1.
  0.         0.55183753 1.        ]
 [1.         0.         0.         0.         0.13573722 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.73329818 0.13574374 1.
  0.         0.89191052 1.        ]
 [1.         0.         0.4677891  0.29383492 0.13573875 1.
  0.         0.46566498 1.        ]
 [1.         0.         0.         0.         0.13574182 1.
  0.         0.16141747 1.        ]
 [1.         0.         0.92988943 0.76386279 0.13574205 1.
  0.         0.88281761 1.        ]
 [1.         0.         0.         0.         0.13573472 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.13573764 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.1357404  1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.13574673 1.
  0.         1.         1.        ]
 [1.         0.         0.02484292 0.63348919 0.13574167 1.
  0.         0.79271365 1.        ]
 [1.         0.         0.         0.         0.13573971 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.13574537 1.
  0.         1.         1.        ]
 [1.         0.         0.26010156 0.         0.13574118 1.
  0.         0.         1.        ]
 [1.         0.         1.         0.98675744 0.13574099 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.13573839 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.13573682 1.
  0.         0.         1.        ]
 [1.         0.         0.69202727 0.65968716 0.13574167 1.
  0.         0.72710338 1.        ]
 [1.         0.         0.49589271 0.62145808 0.1357411  1.
  0.         0.73059403 1.        ]
 [1.         0.         0.         0.         0.13573926 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.13574457 1.
  0.         1.         1.        ]
 [1.         0.         0.06829362 0.31117666 0.13574308 1.
  0.         0.32438938 1.        ]
 [1.         0.         0.38089432 0.71015984 0.13573704 1.
  0.         0.80843113 1.        ]
 [1.         0.         0.82510804 0.77997739 0.13574302 1.
  0.         0.9180974  1.        ]]

Best Training Poisoning Accuracy:
0.9375
#####################         POISON         ###############################################

############################################################################################

comm_round: 26 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.         0.55965768 1.         0.         0.
 0.4021966  0.         1.         0.72328682 0.02654859 1.
 0.         0.26888094 1.         1.         0.         0.
 0.         1.         1.         0.         0.75065511 0.
 0.67078097 0.57053349]
wv_ed shape (26,)
[0.         0.         0.35364441 1.         0.         0.
 0.49572451 0.         1.         0.59191392 0.00849874 0.93760106
 0.         0.14253098 1.         1.         0.         0.
 0.         1.         1.         0.         0.91196581 0.
 0.16200947 0.45113657]
wv_lg shape (26, 1)
[[0.13789931]
 [0.13587098]
 [0.13587523]
 [0.13587549]
 [0.13587226]
 [0.13587424]
 [0.13587616]
 [0.13587401]
 [0.13587514]
 [0.13587458]
 [0.13587338]
 [0.13587243]
 [0.13587222]
 [0.1358758 ]
 [0.13587753]
 [0.13587572]
 [0.13587502]
 [0.13587163]
 [0.13587438]
 [0.13587556]
 [0.13587541]
 [0.135872  ]
 [0.13587429]
 [0.13587318]
 [0.135872  ]
 [0.13587208]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.         0.38447595 1.         0.         0.
 0.42345598 0.         1.         0.46371023 0.         0.95657514
 0.         0.15218761 1.         1.         0.         0.
 0.         1.         1.         0.         0.86129167 0.
 0.15430729 0.38689647]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.13789931 1.
  1.         0.         0.        ]
 [1.         0.         0.         0.         0.13587098 1.
  0.         0.         1.        ]
 [1.         0.         0.55965768 0.35364441 0.13587523 1.
  0.         0.38447595 1.        ]
 [1.         0.         1.         1.         0.13587549 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.13587226 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.13587424 1.
  0.         0.         1.        ]
 [1.         0.         0.4021966  0.49572451 0.13587616 1.
  0.         0.42345598 1.        ]
 [1.         0.         0.         0.         0.13587401 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.13587514 1.
  0.         1.         1.        ]
 [1.         0.         0.72328682 0.59191392 0.13587458 1.
  0.         0.46371023 1.        ]
 [1.         0.         0.02654859 0.00849874 0.13587338 1.
  0.         0.         1.        ]
 [1.         0.         1.         0.93760106 0.13587243 1.
  0.         0.95657514 1.        ]
 [1.         0.         0.         0.         0.13587222 1.
  0.         0.         1.        ]
 [1.         0.         0.26888094 0.14253098 0.1358758  1.
  0.         0.15218761 1.        ]
 [1.         0.         1.         1.         0.13587753 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.13587572 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.13587502 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.13587163 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.13587438 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.13587556 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.13587541 1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.135872   1.
  0.         0.         1.        ]
 [1.         0.         0.75065511 0.91196581 0.13587429 1.
  0.         0.86129167 1.        ]
 [1.         0.         0.         0.         0.13587318 1.
  0.         0.         1.        ]
 [1.         0.         0.67078097 0.16200947 0.135872   1.
  0.         0.15430729 1.        ]
 [1.         0.         0.57053349 0.45113657 0.13587208 1.
  0.         0.38689647 1.        ]]

Best Training Poisoning Accuracy:
0.9375
#####################         POISON         ###############################################

############################################################################################

comm_round: 27 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         1.         1.         1.         0.53946025 1.
 0.         1.         0.5827677  0.         0.         1.
 1.         0.48032644 0.         1.         0.86671698 0.60265372
 0.         0.         1.         1.         0.27837122 1.
 1.         0.93391017]
wv_ed shape (26,)
[0.         1.         1.         1.         0.13120453 1.
 0.         0.69910011 0.         0.         0.         0.77974161
 0.86106803 0.         0.         0.47308148 0.21006555 0.10736372
 0.         0.         1.         1.         0.18776194 0.74420314
 1.         0.50965085]
wv_lg shape (26, 1)
[[0.13804054]
 [0.13600624]
 [0.13600639]
 [0.13600497]
 [0.13600576]
 [0.13600725]
 [0.13600555]
 [0.13600695]
 [0.13600329]
 [0.1360041 ]
 [0.13600475]
 [0.13600643]
 [0.13600692]
 [0.13600314]
 [0.13600285]
 [0.13600722]
 [0.13600459]
 [0.1360044 ]
 [0.13600228]
 [0.13600069]
 [0.13600579]
 [0.13600553]
 [0.13600375]
 [0.13600629]
 [0.13600669]
 [0.1360079 ]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         1.         1.         1.         0.12339648 1.
 0.         0.69220769 0.         0.         0.         0.77427026
 0.93096046 0.         0.         0.41628827 0.29402573 0.09991827
 0.         0.         1.         1.         0.06662815 0.67628924
 1.         0.46882097]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.13804054 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.13600624 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.13600639 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.13600497 1.
  0.         1.         1.        ]
 [1.         0.         0.53946025 0.13120453 0.13600576 1.
  0.         0.12339648 1.        ]
 [1.         0.         1.         1.         0.13600725 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.13600555 1.
  0.         0.         1.        ]
 [1.         0.         1.         0.69910011 0.13600695 1.
  0.         0.69220769 1.        ]
 [1.         0.         0.5827677  0.         0.13600329 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.1360041  1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.13600475 1.
  0.         0.         1.        ]
 [1.         0.         1.         0.77974161 0.13600643 1.
  0.         0.77427026 1.        ]
 [1.         0.         1.         0.86106803 0.13600692 1.
  0.         0.93096046 1.        ]
 [1.         0.         0.48032644 0.         0.13600314 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.13600285 1.
  0.         0.         1.        ]
 [1.         0.         1.         0.47308148 0.13600722 1.
  0.         0.41628827 1.        ]
 [1.         0.         0.86671698 0.21006555 0.13600459 1.
  0.         0.29402573 1.        ]
 [1.         0.         0.60265372 0.10736372 0.1360044  1.
  0.         0.09991827 1.        ]
 [1.         0.         0.         0.         0.13600228 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.13600069 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.13600579 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.13600553 1.
  0.         1.         1.        ]
 [1.         0.         0.27837122 0.18776194 0.13600375 1.
  0.         0.06662815 1.        ]
 [1.         0.         1.         0.74420314 0.13600629 1.
  0.         0.67628924 1.        ]
 [1.         0.         1.         1.         0.13600669 1.
  0.         1.         1.        ]
 [1.         0.         0.93391017 0.50965085 0.1360079  1.
  0.         0.46882097 1.        ]]

Best Training Poisoning Accuracy:
0.9375
#####################         POISON         ###############################################

############################################################################################

comm_round: 28 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.         0.         0.39911876 0.         0.78435734
 0.         0.         1.         0.01158749 1.         0.77072898
 0.         0.         0.33711976 1.         0.71731042 1.
 0.         0.94580676 0.68155761 0.         1.         0.
 0.49002274 0.41690129]
wv_ed shape (26,)
[0.         0.         0.         0.         0.         0.95487351
 0.         0.         1.         0.         1.         0.99729834
 0.         0.         0.30487561 1.         0.71858473 1.
 0.         0.64887601 0.91329882 0.         1.         0.
 0.32487149 0.57369348]
wv_lg shape (26, 1)
[[0.13816762]
 [0.13613703]
 [0.13613483]
 [0.13613994]
 [0.13614111]
 [0.13613903]
 [0.13613707]
 [0.13613873]
 [0.13614249]
 [0.13613329]
 [0.13613982]
 [0.13614115]
 [0.13613587]
 [0.13613818]
 [0.13613811]
 [0.13613836]
 [0.13613936]
 [0.13613995]
 [0.13613542]
 [0.13613947]
 [0.13613985]
 [0.13613559]
 [0.13614088]
 [0.13613802]
 [0.13614034]
 [0.13613666]]
wv_jc shape (26,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.         0.         0.         0.         0.93647358
 0.         0.         1.         0.         1.         0.97128892
 0.         0.         0.25148249 0.97473491 0.70053621 1.
 0.         0.57418951 0.91311077 0.         1.         0.
 0.12992679 0.53608483]
xy shape: (26, 9)
[[0.         1.         0.         0.         0.13816762 1.
  1.         0.         0.        ]
 [1.         0.         0.         0.         0.13613703 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.13613483 1.
  0.         0.         1.        ]
 [1.         0.         0.39911876 0.         0.13613994 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.13614111 1.
  0.         0.         1.        ]
 [1.         0.         0.78435734 0.95487351 0.13613903 1.
  0.         0.93647358 1.        ]
 [1.         0.         0.         0.         0.13613707 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.13613873 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.13614249 1.
  0.         1.         1.        ]
 [1.         0.         0.01158749 0.         0.13613329 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.13613982 1.
  0.         1.         1.        ]
 [1.         0.         0.77072898 0.99729834 0.13614115 1.
  0.         0.97128892 1.        ]
 [0.         0.         0.         0.         0.13613587 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.13613818 1.
  0.         0.         1.        ]
 [1.         0.         0.33711976 0.30487561 0.13613811 1.
  0.         0.25148249 1.        ]
 [1.         0.         1.         1.         0.13613836 1.
  0.         0.97473491 1.        ]
 [1.         0.         0.71731042 0.71858473 0.13613936 1.
  0.         0.70053621 1.        ]
 [1.         0.         1.         1.         0.13613995 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.13613542 1.
  0.         0.         1.        ]
 [1.         0.         0.94580676 0.64887601 0.13613947 1.
  0.         0.57418951 1.        ]
 [1.         0.         0.68155761 0.91329882 0.13613985 1.
  0.         0.91311077 1.        ]
 [1.         0.         0.         0.         0.13613559 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.13614088 1.
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.13613802 1.
  0.         0.         1.        ]
 [1.         0.         0.49002274 0.32487149 0.13614034 1.
  0.         0.12992679 1.        ]
 [1.         0.         0.41690129 0.57369348 0.13613666 1.
  0.         0.53608483 1.        ]]

Best Training Poisoning Accuracy:
0.9375
#####################         POISON         ###############################################

############################################################################################

comm_round: 29 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         8

    accuracy                           1.00         8
   macro avg       1.00      1.00      1.00         8
weighted avg       1.00      1.00      1.00         8
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients

Best Training Poisoning Accuracy:
0.9237360954284668

Best Training Poisoning Accuracy:
0.9148554801940918

Best Training Poisoning Accuracy:
0.9100257158279419

Best Training Poisoning Accuracy:
0.8140531182289124

Best Training Poisoning Accuracy:
0.9104931354522705

Best Training Poisoning Accuracy:
0.9193736910820007

Best Training Poisoning Accuracy:
0.9203863739967346

Best Training Poisoning Accuracy:
0.9213211536407471

Best Training Poisoning Accuracy:
0.9298122525215149

Best Training Poisoning Accuracy:
0.9389265179634094

Best Training Poisoning Accuracy:
0.9336293339729309

Best Training Poisoning Accuracy:
0.9373685717582703

Best Training Poisoning Accuracy:
0.9280205368995667

Best Training Poisoning Accuracy:
0.9362779259681702

Best Training Poisoning Accuracy:
0.9295785427093506

Best Training Poisoning Accuracy:
0.8872010707855225

Best Training Poisoning Accuracy:
0.8840850591659546

Best Training Poisoning Accuracy:
0.8861104846000671

Best Training Poisoning Accuracy:
0.8881358504295349

Best Training Poisoning Accuracy:
0.8834618926048279

Best Training Poisoning Accuracy:
0.8813585638999939

Best Training Poisoning Accuracy:
0.8917192220687866

Best Training Poisoning Accuracy:
0.8830723762512207

Best Training Poisoning Accuracy:
0.8775414824485779

Best Training Poisoning Accuracy:
0.8859546780586243

Best Training Poisoning Accuracy:
0.8843966722488403

Best Training Poisoning Accuracy:
0.7168341279029846

Best Training Poisoning Accuracy:
0.7166004776954651

Best Training Poisoning Accuracy:
0.7164446711540222

Best Training Poisoning Accuracy:
0.7165225744247437

Best Training Poisoning Accuracy:
0.7165225744247437

Best Training Poisoning Accuracy:
0.8288540840148926

Best Training Poisoning Accuracy:
0.8279193043708801

Best Training Poisoning Accuracy:
0.7367765307426453

Best Training Poisoning Accuracy:
0.7367765307426453

Best Training Poisoning Accuracy:
0.7367765307426453

Best Training Poisoning Accuracy:
0.8301783800125122

Best Training Poisoning Accuracy:
0.8429539799690247

Best Training Poisoning Accuracy:
0.8728674650192261

Best Training Poisoning Accuracy:
0.7286686301231384

Best Training Poisoning Accuracy:
0.92645263671875

Best Training Poisoning Accuracy:
0.9341301918029785

Best Training Poisoning Accuracy:
0.9316000938415527

Best Training Poisoning Accuracy:
0.9530622959136963

Best Training Poisoning Accuracy:
0.9521026015281677

Best Training Poisoning Accuracy:
0.9608270525932312

Best Training Poisoning Accuracy:
0.9525388479232788

Best Training Poisoning Accuracy:
0.9498342275619507

Best Training Poisoning Accuracy:
0.9068225622177124

Best Training Poisoning Accuracy:
0.9332576990127563

Best Training Poisoning Accuracy:
0.8261210918426514

Best Training Poisoning Accuracy:
0.8194032311439514

Best Training Poisoning Accuracy:
0.7588553428649902

Best Training Poisoning Accuracy:
0.7825859189033508

Best Training Poisoning Accuracy:
0.7906997203826904

Best Training Poisoning Accuracy:
0.799075186252594

Best Training Poisoning Accuracy:
0.8696441054344177

Best Training Poisoning Accuracy:
0.9463578462600708

Best Training Poisoning Accuracy:
0.9946933388710022
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.         0.         1.         0.11047235 0.
 0.         0.         1.         0.         0.         1.
 0.         0.87518744 0.         0.         0.         0.
 0.         0.         0.         1.         0.         1.
 0.         0.        ]
wv_ed shape (26,)
[0.         0.07816448 0.         1.         0.50071739 0.
 0.         0.         1.         0.         0.         1.
 0.         0.90239841 0.         0.15945995 0.         0.
 0.         0.         0.60272834 1.         0.         1.
 0.         0.00158328]
wv_lg shape (26, 1)
[[0.12765572]
 [0.12704028]
 [0.12704086]
 [0.12704216]
 [0.12704166]
 [0.12704145]
 [0.12704039]
 [0.12704   ]
 [0.12704226]
 [0.12704015]
 [0.12704019]
 [0.12704283]
 [0.12704049]
 [0.12704207]
 [0.12704111]
 [0.12704179]
 [0.12704007]
 [0.12704129]
 [0.1270399 ]
 [0.12704126]
 [0.12704171]
 [0.12704129]
 [0.12703978]
 [0.12704307]
 [0.1270407 ]
 [0.12704056]]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.         0.         1.         0.48113764 0.
 0.         0.         1.         0.         0.         1.
 0.         0.88798569 0.         0.         0.         0.
 0.         0.         0.61914473 1.         0.         1.
 0.         0.02052805]
xy shape: (26, 8)
[[0.         1.         0.         0.         0.12765572 1.
  0.         0.        ]
 [1.         0.         0.         0.07816448 0.12704028 0.
  0.         1.        ]
 [1.         0.         0.         0.         0.12704086 0.
  0.         1.        ]
 [1.         0.         1.         1.         0.12704216 0.
  1.         1.        ]
 [1.         0.         0.11047235 0.50071739 0.12704166 0.
  0.48113764 1.        ]
 [1.         0.         0.         0.         0.12704145 0.
  0.         1.        ]
 [1.         0.         0.         0.         0.12704039 0.
  0.         1.        ]
 [1.         0.         0.         0.         0.12704    0.
  0.         1.        ]
 [1.         0.         1.         1.         0.12704226 0.
  1.         1.        ]
 [1.         0.         0.         0.         0.12704015 0.
  0.         1.        ]
 [1.         0.         0.         0.         0.12704019 0.
  0.         1.        ]
 [1.         0.         1.         1.         0.12704283 0.
  1.         1.        ]
 [1.         0.         0.         0.         0.12704049 0.
  0.         1.        ]
 [1.         0.         0.87518744 0.90239841 0.12704207 0.
  0.88798569 1.        ]
 [1.         0.         0.         0.         0.12704111 0.
  0.         1.        ]
 [1.         0.         0.         0.15945995 0.12704179 0.
  0.         1.        ]
 [1.         0.         0.         0.         0.12704007 0.
  0.         1.        ]
 [1.         0.         0.         0.         0.12704129 0.
  0.         1.        ]
 [1.         0.         0.         0.         0.1270399  0.
  0.         1.        ]
 [1.         0.         0.         0.         0.12704126 0.
  0.         1.        ]
 [1.         0.         0.         0.60272834 0.12704171 0.
  0.61914473 1.        ]
 [1.         0.         1.         1.         0.12704129 0.
  1.         1.        ]
 [0.         0.         0.         0.         0.12703978 0.
  0.         1.        ]
 [1.         0.         1.         1.         0.12704307 0.
  1.         1.        ]
 [1.         0.         0.         0.         0.1270407  0.
  0.         1.        ]
 [1.         0.         0.         0.00158328 0.12704056 0.
  0.02052805 1.        ]]
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         1.         0.         0.72716451 0.34740079 0.62461428
 1.         1.         0.         0.5422239  0.         0.51120072
 1.         0.41578561 0.66237326 0.52709121 1.         0.
 0.64213119 0.         1.         0.64862037 0.         1.
 0.40697027 1.        ]
wv_ed shape (26,)
[0.         1.         0.         0.57914766 0.40558882 0.45630933
 1.         1.         0.         0.62492442 0.         0.28771851
 1.         0.5090378  1.         0.424291   1.         0.
 0.38761538 0.         1.         0.95506645 0.         1.
 0.70031896 1.        ]
wv_lg shape (26, 1)
[[0.12765405]
 [0.12704221]
 [0.12704187]
 [0.12703987]
 [0.12704261]
 [0.12704148]
 [0.12704197]
 [0.12704307]
 [0.1270415 ]
 [0.12704117]
 [0.1270405 ]
 [0.12704289]
 [0.12704204]
 [0.12704209]
 [0.12704302]
 [0.12704099]
 [0.127042  ]
 [0.12704074]
 [0.1270423 ]
 [0.12704191]
 [0.12704203]
 [0.127042  ]
 [0.12704077]
 [0.12704382]
 [0.1270411 ]
 [0.12704202]]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         1.         0.         0.63092785 0.32857081 0.2687844
 1.         1.         0.         0.62465618 0.         0.1428567
 1.         0.48511654 1.         0.33597234 1.         0.
 0.3915715  0.         1.         0.98126755 0.         1.
 0.63216464 1.        ]
xy shape: (26, 8)
[[0.         1.         0.         0.         0.12765405 1.
  0.         0.        ]
 [1.         0.         1.         1.         0.12704221 0.
  1.         1.        ]
 [1.         0.         0.         0.         0.12704187 0.
  0.         1.        ]
 [1.         0.         0.72716451 0.57914766 0.12703987 0.
  0.63092785 1.        ]
 [1.         0.         0.34740079 0.40558882 0.12704261 0.
  0.32857081 1.        ]
 [1.         0.         0.62461428 0.45630933 0.12704148 0.
  0.2687844  1.        ]
 [1.         0.         1.         1.         0.12704197 0.
  1.         1.        ]
 [1.         0.         1.         1.         0.12704307 0.
  1.         1.        ]
 [1.         0.         0.         0.         0.1270415  0.
  0.         1.        ]
 [1.         0.         0.5422239  0.62492442 0.12704117 0.
  0.62465618 1.        ]
 [1.         0.         0.         0.         0.1270405  0.
  0.         1.        ]
 [1.         0.         0.51120072 0.28771851 0.12704289 0.
  0.1428567  1.        ]
 [1.         0.         1.         1.         0.12704204 0.
  1.         1.        ]
 [1.         0.         0.41578561 0.5090378  0.12704209 0.
  0.48511654 1.        ]
 [1.         0.         0.66237326 1.         0.12704302 0.
  1.         1.        ]
 [1.         0.         0.52709121 0.424291   0.12704099 0.
  0.33597234 1.        ]
 [1.         0.         1.         1.         0.127042   0.
  1.         1.        ]
 [1.         0.         0.         0.         0.12704074 0.
  0.         1.        ]
 [1.         0.         0.64213119 0.38761538 0.1270423  0.
  0.3915715  1.        ]
 [1.         0.         0.         0.         0.12704191 0.
  0.         1.        ]
 [1.         0.         1.         1.         0.12704203 0.
  1.         1.        ]
 [1.         0.         0.64862037 0.95506645 0.127042   0.
  0.98126755 1.        ]
 [0.         0.         0.         0.         0.12704077 0.
  0.         1.        ]
 [1.         0.         1.         1.         0.12704382 0.
  1.         1.        ]
 [1.         0.         0.40697027 0.70031896 0.1270411  0.
  0.63216464 1.        ]
 [1.         0.         1.         1.         0.12704202 0.
  1.         1.        ]]
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.         1.         0.52895226 0.51615902 1.
 0.         0.         0.38171191 0.         0.         0.
 1.         0.17943008 0.         1.         1.         0.
 0.         0.54654152 0.44822669 0.67385504 1.         0.72519589
 1.         1.        ]
wv_ed shape (26,)
[0.         0.         1.         0.57822548 0.66087522 1.
 0.         0.         0.46403919 0.         0.         0.
 0.97071997 0.         0.0077122  1.         1.         0.
 0.         0.14318227 0.71116392 0.9635935  1.         0.43908335
 1.         0.71175459]
wv_lg shape (26, 1)
[[0.12766126]
 [0.12703942]
 [0.12704261]
 [0.1270408 ]
 [0.12704135]
 [0.12704222]
 [0.12703974]
 [0.12703989]
 [0.1270405 ]
 [0.12703933]
 [0.12703887]
 [0.12703943]
 [0.12704128]
 [0.1270387 ]
 [0.12703934]
 [0.12704085]
 [0.12704155]
 [0.12703874]
 [0.12703948]
 [0.12704018]
 [0.12704089]
 [0.12704134]
 [0.12704248]
 [0.12704102]
 [0.12704182]
 [0.1270402 ]]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.         1.         0.60633538 0.70633018 1.
 0.         0.         0.54636013 0.         0.         0.
 0.98622198 0.13247027 0.08044505 1.         1.         0.
 0.         0.1859472  0.82756713 1.         1.         0.42816848
 1.         0.77001764]
xy shape: (26, 8)
[[0.         1.         0.         0.         0.12766126 1.
  0.         0.        ]
 [1.         0.         0.         0.         0.12703942 0.
  0.         1.        ]
 [1.         0.         1.         1.         0.12704261 0.
  1.         1.        ]
 [1.         0.         0.52895226 0.57822548 0.1270408  0.
  0.60633538 1.        ]
 [1.         0.         0.51615902 0.66087522 0.12704135 0.
  0.70633018 1.        ]
 [1.         0.         1.         1.         0.12704222 0.
  1.         1.        ]
 [1.         0.         0.         0.         0.12703974 0.
  0.         1.        ]
 [1.         0.         0.         0.         0.12703989 0.
  0.         1.        ]
 [1.         0.         0.38171191 0.46403919 0.1270405  0.
  0.54636013 1.        ]
 [1.         0.         0.         0.         0.12703933 0.
  0.         1.        ]
 [1.         0.         0.         0.         0.12703887 0.
  0.         1.        ]
 [1.         0.         0.         0.         0.12703943 0.
  0.         1.        ]
 [1.         0.         1.         0.97071997 0.12704128 0.
  0.98622198 1.        ]
 [1.         0.         0.17943008 0.         0.1270387  0.
  0.13247027 1.        ]
 [1.         0.         0.         0.0077122  0.12703934 0.
  0.08044505 1.        ]
 [1.         0.         1.         1.         0.12704085 0.
  1.         1.        ]
 [1.         0.         1.         1.         0.12704155 0.
  1.         1.        ]
 [1.         0.         0.         0.         0.12703874 0.
  0.         1.        ]
 [0.         0.         0.         0.         0.12703948 0.
  0.         1.        ]
 [1.         0.         0.54654152 0.14318227 0.12704018 0.
  0.1859472  1.        ]
 [1.         0.         0.44822669 0.71116392 0.12704089 0.
  0.82756713 1.        ]
 [1.         0.         0.67385504 0.9635935  0.12704134 0.
  1.         1.        ]
 [1.         0.         1.         1.         0.12704248 0.
  1.         1.        ]
 [1.         0.         0.72519589 0.43908335 0.12704102 0.
  0.42816848 1.        ]
 [1.         0.         1.         1.         0.12704182 0.
  1.         1.        ]
 [1.         0.         1.         0.71175459 0.1270402  0.
  0.77001764 1.        ]]
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.         0.24827758 0.         1.         0.
 1.         0.39987319 0.         0.73963483 0.         1.
 1.         1.         1.         0.         0.         1.
 0.88430487 0.75782128 1.         0.         0.03376919 0.81321279
 0.84881319 1.        ]
wv_ed shape (26,)
[0.         0.         0.26427249 0.34973857 1.         0.
 1.         0.30955407 0.         0.64349241 0.         1.
 1.         1.         1.         0.         0.         1.
 1.         1.         1.         0.         0.34455055 0.80574151
 0.91749373 1.        ]
wv_lg shape (26, 1)
[[0.12765334]
 [0.12704072]
 [0.12704015]
 [0.12704102]
 [0.12704195]
 [0.12704107]
 [0.1270428 ]
 [0.12704178]
 [0.12703972]
 [0.12704141]
 [0.12704004]
 [0.12704177]
 [0.12704309]
 [0.12704234]
 [0.12704201]
 [0.12703913]
 [0.12704024]
 [0.12704197]
 [0.12704203]
 [0.12704248]
 [0.1270425 ]
 [0.1270408 ]
 [0.12704181]
 [0.12704167]
 [0.12704202]
 [0.12704149]]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.         0.37578495 0.4043158  1.         0.
 1.         0.30135813 0.         0.66840682 0.         1.
 1.         1.         1.         0.         0.         1.
 1.         1.         1.         0.         0.38626409 0.904244
 0.94844519 1.        ]
xy shape: (26, 8)
[[0.         1.         0.         0.         0.12765334 1.
  0.         0.        ]
 [1.         0.         0.         0.         0.12704072 0.
  0.         1.        ]
 [1.         0.         0.24827758 0.26427249 0.12704015 0.
  0.37578495 1.        ]
 [1.         0.         0.         0.34973857 0.12704102 0.
  0.4043158  1.        ]
 [1.         0.         1.         1.         0.12704195 0.
  1.         1.        ]
 [1.         0.         0.         0.         0.12704107 0.
  0.         1.        ]
 [1.         0.         1.         1.         0.1270428  0.
  1.         1.        ]
 [1.         0.         0.39987319 0.30955407 0.12704178 0.
  0.30135813 1.        ]
 [1.         0.         0.         0.         0.12703972 0.
  0.         1.        ]
 [1.         0.         0.73963483 0.64349241 0.12704141 0.
  0.66840682 1.        ]
 [1.         0.         0.         0.         0.12704004 0.
  0.         1.        ]
 [1.         0.         1.         1.         0.12704177 0.
  1.         1.        ]
 [1.         0.         1.         1.         0.12704309 0.
  1.         1.        ]
 [1.         0.         1.         1.         0.12704234 0.
  1.         1.        ]
 [1.         0.         1.         1.         0.12704201 0.
  1.         1.        ]
 [0.         0.         0.         0.         0.12703913 0.
  0.         1.        ]
 [1.         0.         0.         0.         0.12704024 0.
  0.         1.        ]
 [1.         0.         1.         1.         0.12704197 0.
  1.         1.        ]
 [1.         0.         0.88430487 1.         0.12704203 0.
  1.         1.        ]
 [1.         0.         0.75782128 1.         0.12704248 0.
  1.         1.        ]
 [1.         0.         1.         1.         0.1270425  0.
  1.         1.        ]
 [1.         0.         0.         0.         0.1270408  0.
  0.         1.        ]
 [1.         0.         0.03376919 0.34455055 0.12704181 0.
  0.38626409 1.        ]
 [1.         0.         0.81321279 0.80574151 0.12704167 0.
  0.904244   1.        ]
 [1.         0.         0.84881319 0.91749373 0.12704202 0.
  0.94844519 1.        ]
 [1.         0.         1.         1.         0.12704149 0.
  1.         1.        ]]
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.         1.         0.         1.         0.
 1.         1.         0.06795107 0.         1.         0.15637443
 1.         0.17862919 0.79194519 0.91335197 0.22014548 0.
 0.         0.         0.42217501 1.         0.         0.
 0.         0.        ]
wv_ed shape (26,)
[0.         0.         1.         0.         1.         0.
 1.         1.         0.07192994 0.         1.         0.22203628
 1.         0.00354027 0.87204459 0.75300077 0.         0.
 0.         0.         0.57207617 1.         0.         0.
 0.         0.        ]
wv_lg shape (26, 1)
[[0.12764551]
 [0.12704055]
 [0.12704204]
 [0.12704137]
 [0.12704286]
 [0.12703888]
 [0.12704186]
 [0.1270429 ]
 [0.12704037]
 [0.12703826]
 [0.12704184]
 [0.12704074]
 [0.12704317]
 [0.12704039]
 [0.12704164]
 [0.12704016]
 [0.12704037]
 [0.12703986]
 [0.12704045]
 [0.12703944]
 [0.12704159]
 [0.12704296]
 [0.12704052]
 [0.12704066]
 [0.12703945]
 [0.12703956]]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.         1.         0.         1.         0.
 1.         1.         0.09517135 0.         1.         0.23437483
 1.         0.         0.87140309 0.8266521  0.01328378 0.
 0.         0.         0.49898326 1.         0.         0.
 0.         0.        ]
xy shape: (26, 8)
[[0.         1.         0.         0.         0.12764551 1.
  0.         0.        ]
 [1.         0.         0.         0.         0.12704055 0.
  0.         1.        ]
 [1.         0.         1.         1.         0.12704204 0.
  1.         1.        ]
 [1.         0.         0.         0.         0.12704137 0.
  0.         1.        ]
 [1.         0.         1.         1.         0.12704286 0.
  1.         1.        ]
 [1.         0.         0.         0.         0.12703888 0.
  0.         1.        ]
 [1.         0.         1.         1.         0.12704186 0.
  1.         1.        ]
 [1.         0.         1.         1.         0.1270429  0.
  1.         1.        ]
 [1.         0.         0.06795107 0.07192994 0.12704037 0.
  0.09517135 1.        ]
 [0.         0.         0.         0.         0.12703826 0.
  0.         1.        ]
 [1.         0.         1.         1.         0.12704184 0.
  1.         1.        ]
 [1.         0.         0.15637443 0.22203628 0.12704074 0.
  0.23437483 1.        ]
 [1.         0.         1.         1.         0.12704317 0.
  1.         1.        ]
 [1.         0.         0.17862919 0.00354027 0.12704039 0.
  0.         1.        ]
 [1.         0.         0.79194519 0.87204459 0.12704164 0.
  0.87140309 1.        ]
 [1.         0.         0.91335197 0.75300077 0.12704016 0.
  0.8266521  1.        ]
 [1.         0.         0.22014548 0.         0.12704037 0.
  0.01328378 1.        ]
 [1.         0.         0.         0.         0.12703986 0.
  0.         1.        ]
 [1.         0.         0.         0.         0.12704045 0.
  0.         1.        ]
 [1.         0.         0.         0.         0.12703944 0.
  0.         1.        ]
 [1.         0.         0.42217501 0.57207617 0.12704159 0.
  0.49898326 1.        ]
 [1.         0.         1.         1.         0.12704296 0.
  1.         1.        ]
 [1.         0.         0.         0.         0.12704052 0.
  0.         1.        ]
 [1.         0.         0.         0.         0.12704066 0.
  0.         1.        ]
 [1.         0.         0.         0.         0.12703945 0.
  0.         1.        ]
 [1.         0.         0.         0.         0.12703956 0.
  0.         1.        ]]
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.13395244 0.58152696 1.         0.         1.
 0.86355417 0.         0.         0.         1.         0.
 0.09539823 0.         0.1413061  1.         0.85900005 0.66901133
 0.30657177 0.         0.         0.13402933 0.28584595 0.
 0.50952406 0.        ]
wv_ed shape (26,)
[0.         0.26236628 0.43793412 1.         0.         1.
 0.80077915 0.         0.01318626 0.         1.         0.
 0.20050016 0.         0.06190661 1.         1.         0.70857162
 0.29778225 0.         0.         0.2015402  0.24093293 0.
 0.26883596 0.        ]
wv_lg shape (26, 1)
[[0.12765431]
 [0.12704138]
 [0.12704221]
 [0.12704265]
 [0.12704165]
 [0.12704284]
 [0.1270411 ]
 [0.12704174]
 [0.1270416 ]
 [0.12704024]
 [0.12704141]
 [0.12704154]
 [0.12704094]
 [0.127042  ]
 [0.12704126]
 [0.12704232]
 [0.12704167]
 [0.12704213]
 [0.12704085]
 [0.12704096]
 [0.12704055]
 [0.12704154]
 [0.12704066]
 [0.12704182]
 [0.12704118]
 [0.12704106]]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.36712308 0.47040294 1.         0.         1.
 0.81011285 0.         0.06073589 0.         1.         0.
 0.26576969 0.         0.13635293 1.         0.98923554 0.73560404
 0.29547923 0.         0.         0.2745271  0.2520656  0.
 0.38006593 0.0205861 ]
xy shape: (26, 8)
[[0.         1.         0.         0.         0.12765431 1.
  0.         0.        ]
 [1.         0.         0.13395244 0.26236628 0.12704138 0.
  0.36712308 1.        ]
 [1.         0.         0.58152696 0.43793412 0.12704221 0.
  0.47040294 1.        ]
 [1.         0.         1.         1.         0.12704265 0.
  1.         1.        ]
 [1.         0.         0.         0.         0.12704165 0.
  0.         1.        ]
 [1.         0.         1.         1.         0.12704284 0.
  1.         1.        ]
 [1.         0.         0.86355417 0.80077915 0.1270411  0.
  0.81011285 1.        ]
 [1.         0.         0.         0.         0.12704174 0.
  0.         1.        ]
 [1.         0.         0.         0.01318626 0.1270416  0.
  0.06073589 1.        ]
 [1.         0.         0.         0.         0.12704024 0.
  0.         1.        ]
 [1.         0.         1.         1.         0.12704141 0.
  1.         1.        ]
 [1.         0.         0.         0.         0.12704154 0.
  0.         1.        ]
 [1.         0.         0.09539823 0.20050016 0.12704094 0.
  0.26576969 1.        ]
 [1.         0.         0.         0.         0.127042   0.
  0.         1.        ]
 [1.         0.         0.1413061  0.06190661 0.12704126 0.
  0.13635293 1.        ]
 [1.         0.         1.         1.         0.12704232 0.
  1.         1.        ]
 [1.         0.         0.85900005 1.         0.12704167 0.
  0.98923554 1.        ]
 [1.         0.         0.66901133 0.70857162 0.12704213 0.
  0.73560404 1.        ]
 [1.         0.         0.30657177 0.29778225 0.12704085 0.
  0.29547923 1.        ]
 [0.         0.         0.         0.         0.12704096 0.
  0.         1.        ]
 [1.         0.         0.         0.         0.12704055 0.
  0.         1.        ]
 [1.         0.         0.13402933 0.2015402  0.12704154 0.
  0.2745271  1.        ]
 [1.         0.         0.28584595 0.24093293 0.12704066 0.
  0.2520656  1.        ]
 [1.         0.         0.         0.         0.12704182 0.
  0.         1.        ]
 [1.         0.         0.50952406 0.26883596 0.12704118 0.
  0.38006593 1.        ]
 [1.         0.         0.         0.         0.12704106 0.
  0.0205861  1.        ]]
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.         1.         0.69301008 0.         0.652677
 0.20896005 1.         1.         0.         0.2913917  0.
 0.98952258 0.         0.3419438  1.         0.1229696  1.
 0.12008744 1.         0.45504074 0.32785581 0.         0.
 0.         1.        ]
wv_ed shape (26,)
[0.         0.         1.         0.75544677 0.         0.56330286
 0.01033867 1.         0.7686393  0.         0.39920842 0.
 0.80311637 0.         0.36707988 1.         0.38707472 1.
 0.         1.         0.67945989 0.19047707 0.         0.
 0.         0.96861515]
wv_lg shape (26, 1)
[[0.12765916]
 [0.12704146]
 [0.1270423 ]
 [0.12704171]
 [0.12704067]
 [0.12704179]
 [0.12704002]
 [0.12704233]
 [0.12704195]
 [0.12704126]
 [0.12704041]
 [0.12704033]
 [0.12704173]
 [0.12704108]
 [0.12704133]
 [0.12704222]
 [0.12704173]
 [0.12704238]
 [0.12704053]
 [0.1270425 ]
 [0.12704185]
 [0.1270401 ]
 [0.12704095]
 [0.12704089]
 [0.12703987]
 [0.12704147]]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.         1.         0.76431359 0.         0.61268694
 0.14416719 1.         0.80365382 0.         0.46076522 0.
 0.83756928 0.         0.43279502 1.         0.41785133 1.
 0.         1.         0.64492365 0.23569279 0.         0.
 0.         0.88034001]
xy shape: (26, 8)
[[0.         1.         0.         0.         0.12765916 1.
  0.         0.        ]
 [1.         0.         0.         0.         0.12704146 0.
  0.         1.        ]
 [1.         0.         1.         1.         0.1270423  0.
  1.         1.        ]
 [1.         0.         0.69301008 0.75544677 0.12704171 0.
  0.76431359 1.        ]
 [1.         0.         0.         0.         0.12704067 0.
  0.         1.        ]
 [1.         0.         0.652677   0.56330286 0.12704179 0.
  0.61268694 1.        ]
 [1.         0.         0.20896005 0.01033867 0.12704002 0.
  0.14416719 1.        ]
 [1.         0.         1.         1.         0.12704233 0.
  1.         1.        ]
 [1.         0.         1.         0.7686393  0.12704195 0.
  0.80365382 1.        ]
 [1.         0.         0.         0.         0.12704126 0.
  0.         1.        ]
 [1.         0.         0.2913917  0.39920842 0.12704041 0.
  0.46076522 1.        ]
 [1.         0.         0.         0.         0.12704033 0.
  0.         1.        ]
 [1.         0.         0.98952258 0.80311637 0.12704173 0.
  0.83756928 1.        ]
 [1.         0.         0.         0.         0.12704108 0.
  0.         1.        ]
 [1.         0.         0.3419438  0.36707988 0.12704133 0.
  0.43279502 1.        ]
 [1.         0.         1.         1.         0.12704222 0.
  1.         1.        ]
 [1.         0.         0.1229696  0.38707472 0.12704173 0.
  0.41785133 1.        ]
 [1.         0.         1.         1.         0.12704238 0.
  1.         1.        ]
 [1.         0.         0.12008744 0.         0.12704053 0.
  0.         1.        ]
 [1.         0.         1.         1.         0.1270425  0.
  1.         1.        ]
 [1.         0.         0.45504074 0.67945989 0.12704185 0.
  0.64492365 1.        ]
 [1.         0.         0.32785581 0.19047707 0.1270401  0.
  0.23569279 1.        ]
 [0.         0.         0.         0.         0.12704095 0.
  0.         1.        ]
 [1.         0.         0.         0.         0.12704089 0.
  0.         1.        ]
 [1.         0.         0.         0.         0.12703987 0.
  0.         1.        ]
 [1.         0.         1.         0.96861515 0.12704147 0.
  0.88034001 1.        ]]
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 0. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.02262643 0.14505866 1.         0.         0.48391681
 0.38880745 0.36047544 0.         0.25171213 1.         1.
 0.23013    0.         0.         0.47193681 1.         0.20593515
 0.         0.06847387 1.         0.44066143 0.04649497 0.
 0.         0.        ]
wv_ed shape (26,)
[0.         0.         0.40377059 1.         0.         0.45026528
 0.40188397 0.46210432 0.         0.46599212 1.         1.
 0.47060114 0.33877713 0.         0.77605183 1.         0.22113472
 0.         0.35393268 1.         0.59630765 0.         0.21316902
 0.         0.        ]
wv_lg shape (26, 1)
[[0.12766062]
 [0.12704221]
 [0.12704342]
 [0.1270413 ]
 [0.1270411 ]
 [0.12704249]
 [0.1270416 ]
 [0.12704188]
 [0.1270419 ]
 [0.1270413 ]
 [0.12704127]
 [0.12704244]
 [0.12704188]
 [0.12704201]
 [0.12704212]
 [0.12704043]
 [0.12704098]
 [0.12704161]
 [0.12704317]
 [0.12704385]
 [0.12704279]
 [0.12704174]
 [0.12704209]
 [0.12704276]
 [0.12704114]
 [0.12704152]]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.         0.39176669 1.         0.         0.57629745
 0.48391288 0.50865855 0.         0.51741186 1.         1.
 0.59043054 0.35188981 0.         0.8297965  1.         0.25004521
 0.         0.3852403  1.         0.60110013 0.         0.23608679
 0.         0.        ]
xy shape: (26, 8)
[[0.         1.         0.         0.         0.12766062 1.
  0.         0.        ]
 [1.         0.         0.02262643 0.         0.12704221 0.
  0.         1.        ]
 [1.         0.         0.14505866 0.40377059 0.12704342 0.
  0.39176669 1.        ]
 [1.         0.         1.         1.         0.1270413  0.
  1.         1.        ]
 [1.         0.         0.         0.         0.1270411  0.
  0.         1.        ]
 [1.         0.         0.48391681 0.45026528 0.12704249 0.
  0.57629745 1.        ]
 [1.         0.         0.38880745 0.40188397 0.1270416  0.
  0.48391288 1.        ]
 [1.         0.         0.36047544 0.46210432 0.12704188 0.
  0.50865855 1.        ]
 [1.         0.         0.         0.         0.1270419  0.
  0.         1.        ]
 [1.         0.         0.25171213 0.46599212 0.1270413  0.
  0.51741186 1.        ]
 [1.         0.         1.         1.         0.12704127 0.
  1.         1.        ]
 [1.         0.         1.         1.         0.12704244 0.
  1.         1.        ]
 [1.         0.         0.23013    0.47060114 0.12704188 0.
  0.59043054 1.        ]
 [1.         0.         0.         0.33877713 0.12704201 0.
  0.35188981 1.        ]
 [1.         0.         0.         0.         0.12704212 0.
  0.         1.        ]
 [1.         0.         0.47193681 0.77605183 0.12704043 0.
  0.8297965  1.        ]
 [1.         0.         1.         1.         0.12704098 0.
  1.         1.        ]
 [1.         0.         0.20593515 0.22113472 0.12704161 0.
  0.25004521 1.        ]
 [1.         0.         0.         0.         0.12704317 0.
  0.         1.        ]
 [1.         0.         0.06847387 0.35393268 0.12704385 0.
  0.3852403  1.        ]
 [1.         0.         1.         1.         0.12704279 0.
  1.         1.        ]
 [1.         0.         0.44066143 0.59630765 0.12704174 0.
  0.60110013 1.        ]
 [1.         0.         0.04649497 0.         0.12704209 0.
  0.         1.        ]
 [1.         0.         0.         0.21316902 0.12704276 0.
  0.23608679 1.        ]
 [0.         0.         0.         0.         0.12704114 0.
  0.         1.        ]
 [1.         0.         0.         0.         0.12704152 0.
  0.         1.        ]]
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         1.         0.         1.         0.83070335 0.99304221
 0.6287381  1.         1.         1.         1.         0.8650318
 0.26603105 0.01911582 0.         1.         0.         1.
 1.         0.         0.         1.         0.         0.34072288
 0.         1.        ]
wv_ed shape (26,)
[0.         1.         0.17002649 1.         0.57716072 0.98130733
 0.68205493 1.         1.         1.         1.         0.92495625
 0.29214742 0.01977256 0.         1.         0.         0.82572731
 1.         0.         0.         1.         0.         0.62683474
 0.         1.        ]
wv_lg shape (26, 1)
[[0.12765951]
 [0.12704287]
 [0.12704112]
 [0.12704289]
 [0.12704043]
 [0.12704086]
 [0.12704158]
 [0.12704249]
 [0.12704244]
 [0.12704138]
 [0.12704106]
 [0.12704205]
 [0.12704166]
 [0.12704058]
 [0.12703873]
 [0.12704075]
 [0.12704114]
 [0.12704128]
 [0.12704178]
 [0.12703952]
 [0.12704007]
 [0.12704084]
 [0.12703947]
 [0.12704121]
 [0.12703884]
 [0.1270422 ]]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         1.         0.07215058 1.         0.49027701 1.
 0.5983725  1.         1.         1.         1.         0.80986865
 0.31854124 0.02042427 0.         1.         0.         0.78376456
 1.         0.         0.         1.         0.         0.64789316
 0.         1.        ]
xy shape: (26, 8)
[[0.         1.         0.         0.         0.12765951 1.
  0.         0.        ]
 [1.         0.         1.         1.         0.12704287 0.
  1.         1.        ]
 [1.         0.         0.         0.17002649 0.12704112 0.
  0.07215058 1.        ]
 [1.         0.         1.         1.         0.12704289 0.
  1.         1.        ]
 [1.         0.         0.83070335 0.57716072 0.12704043 0.
  0.49027701 1.        ]
 [1.         0.         0.99304221 0.98130733 0.12704086 0.
  1.         1.        ]
 [1.         0.         0.6287381  0.68205493 0.12704158 0.
  0.5983725  1.        ]
 [1.         0.         1.         1.         0.12704249 0.
  1.         1.        ]
 [1.         0.         1.         1.         0.12704244 0.
  1.         1.        ]
 [1.         0.         1.         1.         0.12704138 0.
  1.         1.        ]
 [1.         0.         1.         1.         0.12704106 0.
  1.         1.        ]
 [1.         0.         0.8650318  0.92495625 0.12704205 0.
  0.80986865 1.        ]
 [1.         0.         0.26603105 0.29214742 0.12704166 0.
  0.31854124 1.        ]
 [1.         0.         0.01911582 0.01977256 0.12704058 0.
  0.02042427 1.        ]
 [0.         0.         0.         0.         0.12703873 0.
  0.         1.        ]
 [1.         0.         1.         1.         0.12704075 0.
  1.         1.        ]
 [1.         0.         0.         0.         0.12704114 0.
  0.         1.        ]
 [1.         0.         1.         0.82572731 0.12704128 0.
  0.78376456 1.        ]
 [1.         0.         1.         1.         0.12704178 0.
  1.         1.        ]
 [1.         0.         0.         0.         0.12703952 0.
  0.         1.        ]
 [1.         0.         0.         0.         0.12704007 0.
  0.         1.        ]
 [1.         0.         1.         1.         0.12704084 0.
  1.         1.        ]
 [1.         0.         0.         0.         0.12703947 0.
  0.         1.        ]
 [1.         0.         0.34072288 0.62683474 0.12704121 0.
  0.64789316 1.        ]
 [1.         0.         0.         0.         0.12703884 0.
  0.         1.        ]
 [1.         0.         1.         1.         0.1270422  0.
  1.         1.        ]]
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.         1.         1.         1.         0.15361124
 0.         1.         0.         0.         0.         1.
 0.22967456 1.         1.         0.5952304  1.         0.24734876
 0.37451079 1.         1.         1.         0.         0.
 1.         0.53732455]
wv_ed shape (26,)
[0.         0.148359   1.         1.         1.         0.
 0.         1.         0.         0.         0.07409337 1.
 0.19444918 1.         1.         0.63609666 1.         0.22952042
 0.40813761 1.         1.         1.         0.         0.
 1.         0.39900552]
wv_lg shape (26, 1)
[[0.12765704]
 [0.12703931]
 [0.12704119]
 [0.12704086]
 [0.12704249]
 [0.12703956]
 [0.12703799]
 [0.12704121]
 [0.1270391 ]
 [0.12703863]
 [0.12704098]
 [0.12704154]
 [0.12703971]
 [0.12704324]
 [0.12704164]
 [0.12704014]
 [0.12704246]
 [0.12704035]
 [0.12704005]
 [0.12704239]
 [0.12704093]
 [0.12704189]
 [0.12703932]
 [0.12703983]
 [0.12704143]
 [0.12703939]]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.22330848 1.         1.         1.         0.
 0.         1.         0.         0.         0.         1.
 0.1492796  1.         1.         0.69478    1.         0.23267849
 0.42946363 1.         1.         1.         0.         0.
 1.         0.39752825]
xy shape: (26, 8)
[[0.         1.         0.         0.         0.12765704 1.
  0.         0.        ]
 [1.         0.         0.         0.148359   0.12703931 0.
  0.22330848 1.        ]
 [1.         0.         1.         1.         0.12704119 0.
  1.         1.        ]
 [1.         0.         1.         1.         0.12704086 0.
  1.         1.        ]
 [1.         0.         1.         1.         0.12704249 0.
  1.         1.        ]
 [1.         0.         0.15361124 0.         0.12703956 0.
  0.         1.        ]
 [0.         0.         0.         0.         0.12703799 0.
  0.         1.        ]
 [1.         0.         1.         1.         0.12704121 0.
  1.         1.        ]
 [1.         0.         0.         0.         0.1270391  0.
  0.         1.        ]
 [1.         0.         0.         0.         0.12703863 0.
  0.         1.        ]
 [1.         0.         0.         0.07409337 0.12704098 0.
  0.         1.        ]
 [1.         0.         1.         1.         0.12704154 0.
  1.         1.        ]
 [1.         0.         0.22967456 0.19444918 0.12703971 0.
  0.1492796  1.        ]
 [1.         0.         1.         1.         0.12704324 0.
  1.         1.        ]
 [1.         0.         1.         1.         0.12704164 0.
  1.         1.        ]
 [1.         0.         0.5952304  0.63609666 0.12704014 0.
  0.69478    1.        ]
 [1.         0.         1.         1.         0.12704246 0.
  1.         1.        ]
 [1.         0.         0.24734876 0.22952042 0.12704035 0.
  0.23267849 1.        ]
 [1.         0.         0.37451079 0.40813761 0.12704005 0.
  0.42946363 1.        ]
 [1.         0.         1.         1.         0.12704239 0.
  1.         1.        ]
 [1.         0.         1.         1.         0.12704093 0.
  1.         1.        ]
 [1.         0.         1.         1.         0.12704189 0.
  1.         1.        ]
 [1.         0.         0.         0.         0.12703932 0.
  0.         1.        ]
 [1.         0.         0.         0.         0.12703983 0.
  0.         1.        ]
 [1.         0.         1.         1.         0.12704143 0.
  1.         1.        ]
 [1.         0.         0.53732455 0.39900552 0.12703939 0.
  0.39752825 1.        ]]
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         1.         0.99212407 0.         1.         1.
 0.50174138 0.         1.         0.         1.         0.
 1.         0.66559288 1.         0.50410498 0.65242356 0.
 1.         1.         0.         0.12285749 0.74723202 0.8042402
 1.         1.        ]
wv_ed shape (26,)
[0.         1.         1.         0.         1.         1.
 0.63023048 0.         1.         0.         1.         0.
 1.         0.77410705 1.         0.5213597  0.71594771 0.
 0.77634239 1.         0.         0.         0.70621903 0.82525514
 1.         1.        ]
wv_lg shape (26, 1)
[[0.12766237]
 [0.12704188]
 [0.12704227]
 [0.12704143]
 [0.12704216]
 [0.1270415 ]
 [0.12704105]
 [0.12703938]
 [0.12704288]
 [0.12704119]
 [0.1270423 ]
 [0.12704035]
 [0.12704172]
 [0.12704208]
 [0.12704352]
 [0.12704196]
 [0.12704178]
 [0.12703958]
 [0.12704049]
 [0.12704228]
 [0.12703959]
 [0.12703974]
 [0.12704093]
 [0.12704287]
 [0.12704218]
 [0.12704168]]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         1.         1.         0.         1.         1.
 0.63811425 0.         1.         0.         1.         0.
 1.         0.70462828 1.         0.44077697 0.66312807 0.05764688
 0.6619712  1.         0.         0.         0.64887828 0.64658582
 1.         1.        ]
xy shape: (26, 8)
[[0.         1.         0.         0.         0.12766237 1.
  0.         0.        ]
 [1.         0.         1.         1.         0.12704188 0.
  1.         1.        ]
 [1.         0.         0.99212407 1.         0.12704227 0.
  1.         1.        ]
 [1.         0.         0.         0.         0.12704143 0.
  0.         1.        ]
 [1.         0.         1.         1.         0.12704216 0.
  1.         1.        ]
 [1.         0.         1.         1.         0.1270415  0.
  1.         1.        ]
 [1.         0.         0.50174138 0.63023048 0.12704105 0.
  0.63811425 1.        ]
 [0.         0.         0.         0.         0.12703938 0.
  0.         1.        ]
 [1.         0.         1.         1.         0.12704288 0.
  1.         1.        ]
 [1.         0.         0.         0.         0.12704119 0.
  0.         1.        ]
 [1.         0.         1.         1.         0.1270423  0.
  1.         1.        ]
 [1.         0.         0.         0.         0.12704035 0.
  0.         1.        ]
 [1.         0.         1.         1.         0.12704172 0.
  1.         1.        ]
 [1.         0.         0.66559288 0.77410705 0.12704208 0.
  0.70462828 1.        ]
 [1.         0.         1.         1.         0.12704352 0.
  1.         1.        ]
 [1.         0.         0.50410498 0.5213597  0.12704196 0.
  0.44077697 1.        ]
 [1.         0.         0.65242356 0.71594771 0.12704178 0.
  0.66312807 1.        ]
 [1.         0.         0.         0.         0.12703958 0.
  0.05764688 1.        ]
 [1.         0.         1.         0.77634239 0.12704049 0.
  0.6619712  1.        ]
 [1.         0.         1.         1.         0.12704228 0.
  1.         1.        ]
 [1.         0.         0.         0.         0.12703959 0.
  0.         1.        ]
 [1.         0.         0.12285749 0.         0.12703974 0.
  0.         1.        ]
 [1.         0.         0.74723202 0.70621903 0.12704093 0.
  0.64887828 1.        ]
 [1.         0.         0.8042402  0.82525514 0.12704287 0.
  0.64658582 1.        ]
 [1.         0.         1.         1.         0.12704218 0.
  1.         1.        ]
 [1.         0.         1.         1.         0.12704168 0.
  1.         1.        ]]
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.65203505 1.         0.85703641 0.         0.
 0.         0.39796945 0.96730314 1.         1.         1.
 1.         0.37371603 1.         1.         1.         0.35741698
 0.02069445 0.31213918 1.         0.         1.         1.
 0.88181556 0.27068528]
wv_ed shape (26,)
[0.         0.49287317 1.         0.83343566 0.         0.
 0.         0.43947235 0.96315185 1.         1.         1.
 1.         0.         1.         1.         1.         0.35381265
 0.         0.43890642 1.         0.         1.         1.
 0.85067547 0.57055281]
wv_lg shape (26, 1)
[[0.12765647]
 [0.12704073]
 [0.12704044]
 [0.12704323]
 [0.12704152]
 [0.12703973]
 [0.12703938]
 [0.12704134]
 [0.12704288]
 [0.12704219]
 [0.12704141]
 [0.12704407]
 [0.12704184]
 [0.12704036]
 [0.12704232]
 [0.12704256]
 [0.12704092]
 [0.12704141]
 [0.12704063]
 [0.1270418 ]
 [0.12704382]
 [0.12703963]
 [0.127043  ]
 [0.12704111]
 [0.12704213]
 [0.12704208]]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.49445432 1.         0.72468448 0.         0.
 0.         0.43679081 0.92269169 1.         1.         1.
 1.         0.06997482 0.98417608 1.         1.         0.29699008
 0.         0.4719367  1.         0.         1.         1.
 0.88003979 0.60593287]
xy shape: (26, 8)
[[0.         1.         0.         0.         0.12765647 1.
  0.         0.        ]
 [1.         0.         0.65203505 0.49287317 0.12704073 0.
  0.49445432 1.        ]
 [1.         0.         1.         1.         0.12704044 0.
  1.         1.        ]
 [1.         0.         0.85703641 0.83343566 0.12704323 0.
  0.72468448 1.        ]
 [1.         0.         0.         0.         0.12704152 0.
  0.         1.        ]
 [1.         0.         0.         0.         0.12703973 0.
  0.         1.        ]
 [0.         0.         0.         0.         0.12703938 0.
  0.         1.        ]
 [1.         0.         0.39796945 0.43947235 0.12704134 0.
  0.43679081 1.        ]
 [1.         0.         0.96730314 0.96315185 0.12704288 0.
  0.92269169 1.        ]
 [1.         0.         1.         1.         0.12704219 0.
  1.         1.        ]
 [1.         0.         1.         1.         0.12704141 0.
  1.         1.        ]
 [1.         0.         1.         1.         0.12704407 0.
  1.         1.        ]
 [1.         0.         1.         1.         0.12704184 0.
  1.         1.        ]
 [1.         0.         0.37371603 0.         0.12704036 0.
  0.06997482 1.        ]
 [1.         0.         1.         1.         0.12704232 0.
  0.98417608 1.        ]
 [1.         0.         1.         1.         0.12704256 0.
  1.         1.        ]
 [1.         0.         1.         1.         0.12704092 0.
  1.         1.        ]
 [1.         0.         0.35741698 0.35381265 0.12704141 0.
  0.29699008 1.        ]
 [1.         0.         0.02069445 0.         0.12704063 0.
  0.         1.        ]
 [1.         0.         0.31213918 0.43890642 0.1270418  0.
  0.4719367  1.        ]
 [1.         0.         1.         1.         0.12704382 0.
  1.         1.        ]
 [1.         0.         0.         0.         0.12703963 0.
  0.         1.        ]
 [1.         0.         1.         1.         0.127043   0.
  1.         1.        ]
 [1.         0.         1.         1.         0.12704111 0.
  1.         1.        ]
 [1.         0.         0.88181556 0.85067547 0.12704213 0.
  0.88003979 1.        ]
 [1.         0.         0.27068528 0.57055281 0.12704208 0.
  0.60593287 1.        ]]
#####################         POISON         ###############################################

############################################################################################

comm_round: 0 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           0       1.00      1.00      1.00         1
           1       1.00      1.00      1.00        25

    accuracy                           1.00        26
   macro avg       1.00      1.00      1.00        26
weighted avg       1.00      1.00      1.00        26

y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.         0.89023161 0.51173637 0.83295892 0.94871503
 1.         1.         0.         0.1562048  0.08312122 0.13609108
 1.         0.895529   0.86678492 1.         0.         1.
 0.29101993 1.         0.26522998 0.         0.86902686 0.22839594
 1.         0.        ]
wv_ed shape (26,)
[0.         0.         0.99750925 0.50648513 1.         0.93638989
 1.         1.         0.         0.         0.07954772 0.
 1.         0.69638205 0.80887864 1.         0.         0.81041292
 0.34552567 1.         0.16705343 0.         0.79976438 0.60053106
 1.         0.        ]
wv_lg shape (26, 1)
[[0.12766081]
 [0.12704053]
 [0.1270418 ]
 [0.12704193]
 [0.12704155]
 [0.12704137]
 [0.12704274]
 [0.12704169]
 [0.1270398 ]
 [0.12704119]
 [0.12704143]
 [0.1270393 ]
 [0.12704263]
 [0.12704152]
 [0.12704082]
 [0.12704212]
 [0.12704029]
 [0.12704086]
 [0.12704171]
 [0.12704227]
 [0.12704053]
 [0.12703829]
 [0.1270416 ]
 [0.1270421 ]
 [0.12704268]
 [0.12704027]]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.         1.         0.49377185 1.         0.97869111
 1.         1.         0.         0.         0.07935063 0.
 1.         0.62374559 0.81158743 1.         0.         0.83549819
 0.29774931 1.         0.11015891 0.         0.81651947 0.56875753
 1.         0.        ]
xy shape: (26, 8)
[[0.         1.         0.         0.         0.12766081 1.
  0.         0.        ]
 [1.         0.         0.         0.         0.12704053 0.
  0.         1.        ]
 [1.         0.         0.89023161 0.99750925 0.1270418  0.
  1.         1.        ]
 [1.         0.         0.51173637 0.50648513 0.12704193 0.
  0.49377185 1.        ]
 [1.         0.         0.83295892 1.         0.12704155 0.
  1.         1.        ]
 [1.         0.         0.94871503 0.93638989 0.12704137 0.
  0.97869111 1.        ]
 [1.         0.         1.         1.         0.12704274 0.
  1.         1.        ]
 [1.         0.         1.         1.         0.12704169 0.
  1.         1.        ]
 [1.         0.         0.         0.         0.1270398  0.
  0.         1.        ]
 [1.         0.         0.1562048  0.         0.12704119 0.
  0.         1.        ]
 [1.         0.         0.08312122 0.07954772 0.12704143 0.
  0.07935063 1.        ]
 [1.         0.         0.13609108 0.         0.1270393  0.
  0.         1.        ]
 [1.         0.         1.         1.         0.12704263 0.
  1.         1.        ]
 [1.         0.         0.895529   0.69638205 0.12704152 0.
  0.62374559 1.        ]
 [1.         0.         0.86678492 0.80887864 0.12704082 0.
  0.81158743 1.        ]
 [1.         0.         1.         1.         0.12704212 0.
  1.         1.        ]
 [1.         0.         0.         0.         0.12704029 0.
  0.         1.        ]
 [1.         0.         1.         0.81041292 0.12704086 0.
  0.83549819 1.        ]
 [1.         0.         0.29101993 0.34552567 0.12704171 0.
  0.29774931 1.        ]
 [1.         0.         1.         1.         0.12704227 0.
  1.         1.        ]
 [1.         0.         0.26522998 0.16705343 0.12704053 0.
  0.11015891 1.        ]
 [0.         0.         0.         0.         0.12703829 0.
  0.         1.        ]
 [1.         0.         0.86902686 0.79976438 0.1270416  0.
  0.81651947 1.        ]
 [1.         0.         0.22839594 0.60053106 0.1270421  0.
  0.56875753 1.        ]
 [1.         0.         1.         1.         0.12704268 0.
  1.         1.        ]
 [1.         0.         0.         0.         0.12704027 0.
  0.         1.        ]]
#####################         POISON         ###############################################

############################################################################################

comm_round: 0 | global_test_acc: 92.308% | global_f1: 0.9583333333333334 | global_precision: 1.0
              precision    recall  f1-score   support

           0       0.33      1.00      0.50         1
           1       1.00      0.92      0.96        25

    accuracy                           0.92        26
   macro avg       0.67      0.96      0.73        26
weighted avg       0.97      0.92      0.94        26
poison scaling shape: (26, 1)
[[1]
 [1]
 [0]
 [0]
 [1]
 [1]
 [0]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAfter Nodes removed: Rows 23 cols 21
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.00645947 0.78738906 0.         0.         0.
 1.         1.         0.6088542  0.13232703 0.24949094 0.
 0.         0.23332301 1.         1.         0.         0.
 0.18535207 0.         0.         0.         0.         0.
 0.         0.        ]
wv_ed shape (26,)
[0.         0.         0.86188942 0.24865289 0.         0.
 1.         1.         0.73654286 0.31513672 0.37241198 0.
 0.00114073 0.0537212  1.         1.         0.01565992 0.
 0.37521303 0.         0.         0.         0.         0.
 0.         0.        ]
wv_lg shape (26, 1)
[[0.12742064]
 [0.12685717]
 [0.1268567 ]
 [0.12685638]
 [0.12685629]
 [0.1268553 ]
 [0.12685744]
 [0.1268585 ]
 [0.12685681]
 [0.12685675]
 [0.12685602]
 [0.12685589]
 [0.12685664]
 [0.12685411]
 [0.1268575 ]
 [0.12685593]
 [0.12685724]
 [0.12685663]
 [0.12685635]
 [0.12685693]
 [0.12685544]
 [0.12685546]
 [0.12685573]
 [0.12685711]
 [0.12685644]
 [0.12685538]]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.         0.88480175 0.08323105 0.         0.
 1.         1.         0.59516788 0.20330472 0.3236049  0.
 0.03789758 0.13887736 1.         1.         0.         0.
 0.28188598 0.         0.         0.         0.         0.
 0.         0.        ]
xy shape: (26, 8)
[[0.         1.         0.         0.         0.12742064 1.
  0.         0.        ]
 [1.         0.         0.00645947 0.         0.12685717 0.
  0.         1.        ]
 [1.         0.         0.78738906 0.86188942 0.1268567  0.
  0.88480175 1.        ]
 [1.         0.         0.         0.24865289 0.12685638 0.
  0.08323105 1.        ]
 [1.         0.         0.         0.         0.12685629 0.
  0.         1.        ]
 [1.         0.         0.         0.         0.1268553  0.
  0.         1.        ]
 [1.         0.         1.         1.         0.12685744 0.
  1.         1.        ]
 [1.         0.         1.         1.         0.1268585  0.
  1.         1.        ]
 [1.         0.         0.6088542  0.73654286 0.12685681 0.
  0.59516788 1.        ]
 [1.         0.         0.13232703 0.31513672 0.12685675 0.
  0.20330472 1.        ]
 [1.         0.         0.24949094 0.37241198 0.12685602 0.
  0.3236049  1.        ]
 [1.         0.         0.         0.         0.12685589 0.
  0.         1.        ]
 [1.         0.         0.         0.00114073 0.12685664 0.
  0.03789758 1.        ]
 [1.         0.         0.23332301 0.0537212  0.12685411 0.
  0.13887736 1.        ]
 [1.         0.         1.         1.         0.1268575  0.
  1.         1.        ]
 [1.         0.         1.         1.         0.12685593 0.
  1.         1.        ]
 [1.         0.         0.         0.01565992 0.12685724 0.
  0.         1.        ]
 [1.         0.         0.         0.         0.12685663 0.
  0.         1.        ]
 [1.         0.         0.18535207 0.37521303 0.12685635 0.
  0.28188598 1.        ]
 [1.         0.         0.         0.         0.12685693 0.
  0.         1.        ]
 [1.         0.         0.         0.         0.12685544 0.
  0.         1.        ]
 [1.         0.         0.         0.         0.12685546 0.
  0.         1.        ]
 [0.         0.         0.         0.         0.12685573 0.
  0.         1.        ]
 [1.         0.         0.         0.         0.12685711 0.
  0.         1.        ]
 [1.         0.         0.         0.         0.12685644 0.
  0.         1.        ]
 [1.         0.         0.         0.         0.12685538 0.
  0.         1.        ]]
#####################         POISON         ###############################################

############################################################################################

comm_round: 1 | global_test_acc: 92.308% | global_f1: 0.96 | global_precision: 0.96
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.96      0.96      0.96        25

    accuracy                           0.92        26
   macro avg       0.48      0.48      0.48        26
weighted avg       0.92      0.92      0.92        26
poison scaling shape: (26, 1)
[[1]
 [1]
 [0]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAfter Nodes removed: Rows 25 cols 21
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         1.         0.4361286  1.         1.         1.
 1.         1.         1.         0.         0.32099022 0.63744008
 0.93024698 1.         0.33382578 0.         0.84190651 1.
 0.85887167 0.9412585  1.         0.00954831 1.         1.
 1.         0.        ]
wv_ed shape (26,)
[0.         0.93617936 0.65620085 1.         1.         0.88800325
 1.         1.         1.         0.         0.4278287  0.97857068
 0.91088515 1.         0.38493959 0.         0.93799043 1.
 0.89629115 0.91290819 1.         0.32610096 0.84458546 1.
 1.         0.        ]
wv_lg shape (26, 1)
[[0.12737643]
 [0.12683271]
 [0.12683296]
 [0.12683469]
 [0.12683275]
 [0.1268327 ]
 [0.12683444]
 [0.12683483]
 [0.12683551]
 [0.12683129]
 [0.12683275]
 [0.12683374]
 [0.12683331]
 [0.1268347 ]
 [0.12683285]
 [0.12683167]
 [0.12683319]
 [0.12683467]
 [0.1268329 ]
 [0.12683196]
 [0.12683399]
 [0.12683244]
 [0.12683245]
 [0.12683354]
 [0.12683331]
 [0.12683175]]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.96927278 0.65690058 1.         1.         0.87546583
 1.         1.         1.         0.         0.46859151 0.87913058
 0.89724058 1.         0.38679139 0.         0.95095379 1.
 0.93190266 0.94914061 1.         0.35050854 0.85678822 1.
 1.         0.        ]
xy shape: (26, 8)
[[0.         1.         0.         0.         0.12737643 1.
  0.         0.        ]
 [1.         0.         1.         0.93617936 0.12683271 0.
  0.96927278 1.        ]
 [1.         0.         0.4361286  0.65620085 0.12683296 0.
  0.65690058 1.        ]
 [1.         0.         1.         1.         0.12683469 0.
  1.         1.        ]
 [1.         0.         1.         1.         0.12683275 0.
  1.         1.        ]
 [1.         0.         1.         0.88800325 0.1268327  0.
  0.87546583 1.        ]
 [1.         0.         1.         1.         0.12683444 0.
  1.         1.        ]
 [1.         0.         1.         1.         0.12683483 0.
  1.         1.        ]
 [1.         0.         1.         1.         0.12683551 0.
  1.         1.        ]
 [0.         0.         0.         0.         0.12683129 0.
  0.         1.        ]
 [1.         0.         0.32099022 0.4278287  0.12683275 0.
  0.46859151 1.        ]
 [1.         0.         0.63744008 0.97857068 0.12683374 0.
  0.87913058 1.        ]
 [1.         0.         0.93024698 0.91088515 0.12683331 0.
  0.89724058 1.        ]
 [1.         0.         1.         1.         0.1268347  0.
  1.         1.        ]
 [1.         0.         0.33382578 0.38493959 0.12683285 0.
  0.38679139 1.        ]
 [1.         0.         0.         0.         0.12683167 0.
  0.         1.        ]
 [1.         0.         0.84190651 0.93799043 0.12683319 0.
  0.95095379 1.        ]
 [1.         0.         1.         1.         0.12683467 0.
  1.         1.        ]
 [1.         0.         0.85887167 0.89629115 0.1268329  0.
  0.93190266 1.        ]
 [1.         0.         0.9412585  0.91290819 0.12683196 0.
  0.94914061 1.        ]
 [1.         0.         1.         1.         0.12683399 0.
  1.         1.        ]
 [1.         0.         0.00954831 0.32610096 0.12683244 0.
  0.35050854 1.        ]
 [1.         0.         1.         0.84458546 0.12683245 0.
  0.85678822 1.        ]
 [1.         0.         1.         1.         0.12683354 0.
  1.         1.        ]
 [1.         0.         1.         1.         0.12683331 0.
  1.         1.        ]
 [1.         0.         0.         0.         0.12683175 0.
  0.         1.        ]]
#####################         POISON         ###############################################

############################################################################################

comm_round: 2 | global_test_acc: 92.308% | global_f1: 0.96 | global_precision: 0.96
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.96      0.96      0.96        25

    accuracy                           0.92        26
   macro avg       0.48      0.48      0.48        26
weighted avg       0.92      0.92      0.92        26
poison scaling shape: (26, 1)
[[1]
 [0]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAfter Nodes removed: Rows 25 cols 21
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.14792287 0.90736314 0.01031265 1.         0.
 1.         0.02244875 0.         1.         0.         0.
 0.37402913 0.         0.47380004 0.         0.         0.
 1.         0.72014168 1.         0.67492777 0.29664799 1.
 0.19225552 1.        ]
wv_ed shape (26,)
[0.         0.         0.64013198 0.         0.64196141 0.
 1.         0.08629179 0.         1.         0.         0.
 0.         0.         0.08605469 0.         0.         0.
 1.         0.34496489 1.         0.42715577 0.0308305  0.78179957
 0.20929355 0.66295778]
wv_lg shape (26, 1)
[[0.12734007]
 [0.1268093 ]
 [0.12681048]
 [0.12680935]
 [0.12681066]
 [0.12680875]
 [0.12681151]
 [0.12681013]
 [0.12680922]
 [0.12681032]
 [0.12680784]
 [0.12680899]
 [0.12680934]
 [0.12680868]
 [0.12681021]
 [0.12680808]
 [0.12680974]
 [0.12680871]
 [0.12681128]
 [0.12680937]
 [0.1268117 ]
 [0.1268098 ]
 [0.12680967]
 [0.12681089]
 [0.1268098 ]
 [0.12680945]]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.         0.72635996 0.         0.60844404 0.
 1.         0.10390852 0.         1.         0.         0.
 0.         0.         0.04774464 0.         0.         0.
 1.         0.46541191 0.98256122 0.48294426 0.03293233 0.73433609
 0.22629856 0.74774618]
xy shape: (26, 8)
[[0.         1.         0.         0.         0.12734007 1.
  0.         0.        ]
 [1.         0.         0.14792287 0.         0.1268093  0.
  0.         1.        ]
 [1.         0.         0.90736314 0.64013198 0.12681048 0.
  0.72635996 1.        ]
 [1.         0.         0.01031265 0.         0.12680935 0.
  0.         1.        ]
 [1.         0.         1.         0.64196141 0.12681066 0.
  0.60844404 1.        ]
 [1.         0.         0.         0.         0.12680875 0.
  0.         1.        ]
 [1.         0.         1.         1.         0.12681151 0.
  1.         1.        ]
 [1.         0.         0.02244875 0.08629179 0.12681013 0.
  0.10390852 1.        ]
 [1.         0.         0.         0.         0.12680922 0.
  0.         1.        ]
 [1.         0.         1.         1.         0.12681032 0.
  1.         1.        ]
 [1.         0.         0.         0.         0.12680784 0.
  0.         1.        ]
 [1.         0.         0.         0.         0.12680899 0.
  0.         1.        ]
 [1.         0.         0.37402913 0.         0.12680934 0.
  0.         1.        ]
 [1.         0.         0.         0.         0.12680868 0.
  0.         1.        ]
 [1.         0.         0.47380004 0.08605469 0.12681021 0.
  0.04774464 1.        ]
 [1.         0.         0.         0.         0.12680808 0.
  0.         1.        ]
 [1.         0.         0.         0.         0.12680974 0.
  0.         1.        ]
 [0.         0.         0.         0.         0.12680871 0.
  0.         1.        ]
 [1.         0.         1.         1.         0.12681128 0.
  1.         1.        ]
 [1.         0.         0.72014168 0.34496489 0.12680937 0.
  0.46541191 1.        ]
 [1.         0.         1.         1.         0.1268117  0.
  0.98256122 1.        ]
 [1.         0.         0.67492777 0.42715577 0.1268098  0.
  0.48294426 1.        ]
 [1.         0.         0.29664799 0.0308305  0.12680967 0.
  0.03293233 1.        ]
 [1.         0.         1.         0.78179957 0.12681089 0.
  0.73433609 1.        ]
 [1.         0.         0.19225552 0.20929355 0.1268098  0.
  0.22629856 1.        ]
 [1.         0.         1.         0.66295778 0.12680945 0.
  0.74774618 1.        ]]
#####################         POISON         ###############################################

############################################################################################

comm_round: 3 | global_test_acc: 96.154% | global_f1: 0.9803921568627451 | global_precision: 0.9615384615384616
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.96      1.00      0.98        25

    accuracy                           0.96        26
   macro avg       0.48      0.50      0.49        26
weighted avg       0.92      0.96      0.94        26
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAfter Nodes removed: Rows 26 cols 21
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.         1.         1.         1.         1.
 0.55189498 1.         1.         0.         0.         1.
 0.         1.         1.         1.         1.         0.
 0.24160512 0.17486853 0.2377221  0.66246324 1.         0.78686875
 1.         0.        ]
wv_ed shape (26,)
[0.         0.         1.         1.         0.9966316  1.
 0.81672684 1.         1.         0.         0.27281426 1.
 0.         1.         1.         0.77924241 1.         0.
 0.3037154  0.         0.35108549 0.59355483 1.         0.87946925
 1.         0.        ]
wv_lg shape (26, 1)
[[0.12738591]
 [0.12685711]
 [0.12685816]
 [0.12685823]
 [0.12685788]
 [0.12685777]
 [0.12685762]
 [0.12685777]
 [0.12685727]
 [0.12685639]
 [0.1268577 ]
 [0.12685883]
 [0.12685588]
 [0.1268582 ]
 [0.12685863]
 [0.12685757]
 [0.12685808]
 [0.12685694]
 [0.12685618]
 [0.12685688]
 [0.12685746]
 [0.12685756]
 [0.1268571 ]
 [0.12685671]
 [0.12685794]
 [0.12685768]]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.         1.         1.         0.94581717 1.
 0.77693379 1.         1.         0.         0.18834151 1.
 0.         1.         1.         0.67502875 1.         0.
 0.28155577 0.         0.25632704 0.49776223 1.         0.83189884
 1.         0.        ]
xy shape: (26, 8)
[[0.         1.         0.         0.         0.12738591 1.
  0.         0.        ]
 [1.         0.         0.         0.         0.12685711 0.
  0.         1.        ]
 [1.         0.         1.         1.         0.12685816 0.
  1.         1.        ]
 [1.         0.         1.         1.         0.12685823 0.
  1.         1.        ]
 [1.         0.         1.         0.9966316  0.12685788 0.
  0.94581717 1.        ]
 [1.         0.         1.         1.         0.12685777 0.
  1.         1.        ]
 [1.         0.         0.55189498 0.81672684 0.12685762 0.
  0.77693379 1.        ]
 [1.         0.         1.         1.         0.12685777 0.
  1.         1.        ]
 [1.         0.         1.         1.         0.12685727 0.
  1.         1.        ]
 [1.         0.         0.         0.         0.12685639 0.
  0.         1.        ]
 [1.         0.         0.         0.27281426 0.1268577  0.
  0.18834151 1.        ]
 [1.         0.         1.         1.         0.12685883 0.
  1.         1.        ]
 [0.         0.         0.         0.         0.12685588 0.
  0.         1.        ]
 [1.         0.         1.         1.         0.1268582  0.
  1.         1.        ]
 [1.         0.         1.         1.         0.12685863 0.
  1.         1.        ]
 [1.         0.         1.         0.77924241 0.12685757 0.
  0.67502875 1.        ]
 [1.         0.         1.         1.         0.12685808 0.
  1.         1.        ]
 [1.         0.         0.         0.         0.12685694 0.
  0.         1.        ]
 [1.         0.         0.24160512 0.3037154  0.12685618 0.
  0.28155577 1.        ]
 [1.         0.         0.17486853 0.         0.12685688 0.
  0.         1.        ]
 [1.         0.         0.2377221  0.35108549 0.12685746 0.
  0.25632704 1.        ]
 [1.         0.         0.66246324 0.59355483 0.12685756 0.
  0.49776223 1.        ]
 [1.         0.         1.         1.         0.1268571  0.
  1.         1.        ]
 [1.         0.         0.78686875 0.87946925 0.12685671 0.
  0.83189884 1.        ]
 [1.         0.         1.         1.         0.12685794 0.
  1.         1.        ]
 [1.         0.         0.         0.         0.12685768 0.
  0.         1.        ]]
#####################         POISON         ###############################################

############################################################################################

comm_round: 4 | global_test_acc: 96.154% | global_f1: 0.9803921568627451 | global_precision: 0.9615384615384616
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.96      1.00      0.98        25

    accuracy                           0.96        26
   macro avg       0.48      0.50      0.49        26
weighted avg       0.92      0.96      0.94        26
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAfter Nodes removed: Rows 26 cols 21
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         1.         0.67266343 0.         0.09157625 0.13288432
 1.         0.         1.         1.         0.08885705 0.04748371
 1.         1.         1.         0.73013992 1.         0.34623791
 0.86640317 1.         0.         1.         0.         1.
 0.10129667 0.        ]
wv_ed shape (26,)
[0.         1.         0.44958832 0.         0.01364108 0.
 0.90448986 0.         1.         1.         0.11257811 0.12995671
 1.         1.         1.         0.74597733 1.         0.48153896
 0.60557938 1.         0.         1.         0.         1.
 0.10827362 0.22013373]
wv_lg shape (26, 1)
[[0.12743762]
 [0.12690494]
 [0.12690515]
 [0.12690259]
 [0.1269046 ]
 [0.12690416]
 [0.12690455]
 [0.12690354]
 [0.12690433]
 [0.12690435]
 [0.12690282]
 [0.12690316]
 [0.12690479]
 [0.12690529]
 [0.12690567]
 [0.12690452]
 [0.12690535]
 [0.12690475]
 [0.12690464]
 [0.12690593]
 [0.12690316]
 [0.12690505]
 [0.12690365]
 [0.1269051 ]
 [0.12690426]
 [0.12690414]]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         1.         0.31603739 0.         0.00867057 0.
 0.92734393 0.         1.         1.         0.25508085 0.13953914
 1.         1.         1.         0.80220948 1.         0.57383304
 0.64270585 1.         0.         1.         0.         1.
 0.10532955 0.22100106]
xy shape: (26, 8)
[[0.         1.         0.         0.         0.12743762 1.
  0.         0.        ]
 [1.         0.         1.         1.         0.12690494 0.
  1.         1.        ]
 [1.         0.         0.67266343 0.44958832 0.12690515 0.
  0.31603739 1.        ]
 [0.         0.         0.         0.         0.12690259 0.
  0.         1.        ]
 [1.         0.         0.09157625 0.01364108 0.1269046  0.
  0.00867057 1.        ]
 [1.         0.         0.13288432 0.         0.12690416 0.
  0.         1.        ]
 [1.         0.         1.         0.90448986 0.12690455 0.
  0.92734393 1.        ]
 [1.         0.         0.         0.         0.12690354 0.
  0.         1.        ]
 [1.         0.         1.         1.         0.12690433 0.
  1.         1.        ]
 [1.         0.         1.         1.         0.12690435 0.
  1.         1.        ]
 [1.         0.         0.08885705 0.11257811 0.12690282 0.
  0.25508085 1.        ]
 [1.         0.         0.04748371 0.12995671 0.12690316 0.
  0.13953914 1.        ]
 [1.         0.         1.         1.         0.12690479 0.
  1.         1.        ]
 [1.         0.         1.         1.         0.12690529 0.
  1.         1.        ]
 [1.         0.         1.         1.         0.12690567 0.
  1.         1.        ]
 [1.         0.         0.73013992 0.74597733 0.12690452 0.
  0.80220948 1.        ]
 [1.         0.         1.         1.         0.12690535 0.
  1.         1.        ]
 [1.         0.         0.34623791 0.48153896 0.12690475 0.
  0.57383304 1.        ]
 [1.         0.         0.86640317 0.60557938 0.12690464 0.
  0.64270585 1.        ]
 [1.         0.         1.         1.         0.12690593 0.
  1.         1.        ]
 [1.         0.         0.         0.         0.12690316 0.
  0.         1.        ]
 [1.         0.         1.         1.         0.12690505 0.
  1.         1.        ]
 [1.         0.         0.         0.         0.12690365 0.
  0.         1.        ]
 [1.         0.         1.         1.         0.1269051  0.
  1.         1.        ]
 [1.         0.         0.10129667 0.10827362 0.12690426 0.
  0.10532955 1.        ]
 [1.         0.         0.         0.22013373 0.12690414 0.
  0.22100106 1.        ]]
#####################         POISON         ###############################################

############################################################################################

comm_round: 5 | global_test_acc: 96.154% | global_f1: 0.9803921568627451 | global_precision: 0.9615384615384616
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.96      1.00      0.98        25

    accuracy                           0.96        26
   macro avg       0.48      0.50      0.49        26
weighted avg       0.92      0.96      0.94        26
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAfter Nodes removed: Rows 26 cols 21
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.91526346 1.         0.         0.         0.
 0.0842057  1.         0.45090711 1.         0.51551589 0.63618648
 0.42516436 0.67895209 0.         1.         1.         1.
 0.92164148 0.17937732 0.         0.54450423 0.         0.89327758
 0.45311621 0.5468275 ]
wv_ed shape (26,)
[0.         0.89741168 1.         0.         0.         0.
 0.27843216 1.         0.49730261 1.         0.47396643 0.78788057
 0.38861327 0.70861478 0.         0.84485378 1.         1.
 0.98824762 0.27987393 0.         0.70407585 0.         0.67913466
 0.46064931 0.69240134]
wv_lg shape (26, 1)
[[0.12748213]
 [0.12695257]
 [0.1269516 ]
 [0.12695178]
 [0.12695165]
 [0.12694914]
 [0.12695185]
 [0.12695275]
 [0.1269501 ]
 [0.12695136]
 [0.12695167]
 [0.12695232]
 [0.1269517 ]
 [0.12695126]
 [0.12695035]
 [0.12695238]
 [0.12695283]
 [0.12695258]
 [0.12695318]
 [0.12695304]
 [0.12695017]
 [0.12695154]
 [0.12695119]
 [0.12695247]
 [0.12695083]
 [0.12695194]]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.90574655 1.         0.         0.         0.
 0.3037662  1.         0.52528734 1.         0.50170676 0.80570748
 0.34478855 0.69145772 0.         0.80482107 1.         1.
 0.86190629 0.23636084 0.         0.61030087 0.         0.63967871
 0.42871353 0.61020319]
xy shape: (26, 8)
[[0.         1.         0.         0.         0.12748213 1.
  0.         0.        ]
 [1.         0.         0.91526346 0.89741168 0.12695257 0.
  0.90574655 1.        ]
 [1.         0.         1.         1.         0.1269516  0.
  1.         1.        ]
 [1.         0.         0.         0.         0.12695178 0.
  0.         1.        ]
 [1.         0.         0.         0.         0.12695165 0.
  0.         1.        ]
 [0.         0.         0.         0.         0.12694914 0.
  0.         1.        ]
 [1.         0.         0.0842057  0.27843216 0.12695185 0.
  0.3037662  1.        ]
 [1.         0.         1.         1.         0.12695275 0.
  1.         1.        ]
 [1.         0.         0.45090711 0.49730261 0.1269501  0.
  0.52528734 1.        ]
 [1.         0.         1.         1.         0.12695136 0.
  1.         1.        ]
 [1.         0.         0.51551589 0.47396643 0.12695167 0.
  0.50170676 1.        ]
 [1.         0.         0.63618648 0.78788057 0.12695232 0.
  0.80570748 1.        ]
 [1.         0.         0.42516436 0.38861327 0.1269517  0.
  0.34478855 1.        ]
 [1.         0.         0.67895209 0.70861478 0.12695126 0.
  0.69145772 1.        ]
 [1.         0.         0.         0.         0.12695035 0.
  0.         1.        ]
 [1.         0.         1.         0.84485378 0.12695238 0.
  0.80482107 1.        ]
 [1.         0.         1.         1.         0.12695283 0.
  1.         1.        ]
 [1.         0.         1.         1.         0.12695258 0.
  1.         1.        ]
 [1.         0.         0.92164148 0.98824762 0.12695318 0.
  0.86190629 1.        ]
 [1.         0.         0.17937732 0.27987393 0.12695304 0.
  0.23636084 1.        ]
 [1.         0.         0.         0.         0.12695017 0.
  0.         1.        ]
 [1.         0.         0.54450423 0.70407585 0.12695154 0.
  0.61030087 1.        ]
 [1.         0.         0.         0.         0.12695119 0.
  0.         1.        ]
 [1.         0.         0.89327758 0.67913466 0.12695247 0.
  0.63967871 1.        ]
 [1.         0.         0.45311621 0.46064931 0.12695083 0.
  0.42871353 1.        ]
 [1.         0.         0.5468275  0.69240134 0.12695194 0.
  0.61020319 1.        ]]
#####################         POISON         ###############################################

############################################################################################

comm_round: 6 | global_test_acc: 88.462% | global_f1: 0.9387755102040817 | global_precision: 0.9583333333333334
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.96      0.92      0.94        25

    accuracy                           0.88        26
   macro avg       0.48      0.46      0.47        26
weighted avg       0.92      0.88      0.90        26
poison scaling shape: (26, 1)
[[1]
 [0]
 [0]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAfter Nodes removed: Rows 24 cols 21
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.         0.4456364  0.         1.         0.
 1.         1.         0.64692556 0.         0.         1.
 0.38554187 1.         0.04294658 1.         0.65341906 0.04319409
 1.         0.         0.37641488 0.         0.57539543 1.
 0.12874061 0.        ]
wv_ed shape (26,)
[0.         0.         0.         0.         0.98326504 0.
 1.         1.         0.3489564  0.         0.         1.
 0.33980162 1.         0.         1.         0.60597917 0.
 0.9200744  0.         0.39881207 0.         0.48724986 1.
 0.16425718 0.22408196]
wv_lg shape (26, 1)
[[0.12735841]
 [0.12684525]
 [0.12684493]
 [0.12684559]
 [0.1268458 ]
 [0.12684471]
 [0.12684696]
 [0.12684642]
 [0.12684618]
 [0.12684577]
 [0.12684527]
 [0.12684708]
 [0.12684589]
 [0.12684651]
 [0.12684444]
 [0.12684565]
 [0.12684574]
 [0.12684508]
 [0.12684566]
 [0.12684385]
 [0.12684564]
 [0.12684526]
 [0.1268462 ]
 [0.12684747]
 [0.12684597]
 [0.12684716]]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.         0.         0.         1.         0.
 1.         1.         0.21654473 0.         0.         1.
 0.27484274 1.         0.         1.         0.64215342 0.
 0.8313558  0.         0.34924602 0.         0.47630917 1.
 0.2092205  0.21071712]
xy shape: (26, 8)
[[0.         1.         0.         0.         0.12735841 1.
  0.         0.        ]
 [1.         0.         0.         0.         0.12684525 0.
  0.         1.        ]
 [1.         0.         0.4456364  0.         0.12684493 0.
  0.         1.        ]
 [1.         0.         0.         0.         0.12684559 0.
  0.         1.        ]
 [1.         0.         1.         0.98326504 0.1268458  0.
  1.         1.        ]
 [1.         0.         0.         0.         0.12684471 0.
  0.         1.        ]
 [1.         0.         1.         1.         0.12684696 0.
  1.         1.        ]
 [1.         0.         1.         1.         0.12684642 0.
  1.         1.        ]
 [1.         0.         0.64692556 0.3489564  0.12684618 0.
  0.21654473 1.        ]
 [1.         0.         0.         0.         0.12684577 0.
  0.         1.        ]
 [1.         0.         0.         0.         0.12684527 0.
  0.         1.        ]
 [1.         0.         1.         1.         0.12684708 0.
  1.         1.        ]
 [1.         0.         0.38554187 0.33980162 0.12684589 0.
  0.27484274 1.        ]
 [1.         0.         1.         1.         0.12684651 0.
  1.         1.        ]
 [1.         0.         0.04294658 0.         0.12684444 0.
  0.         1.        ]
 [1.         0.         1.         1.         0.12684565 0.
  1.         1.        ]
 [1.         0.         0.65341906 0.60597917 0.12684574 0.
  0.64215342 1.        ]
 [1.         0.         0.04319409 0.         0.12684508 0.
  0.         1.        ]
 [1.         0.         1.         0.9200744  0.12684566 0.
  0.8313558  1.        ]
 [0.         0.         0.         0.         0.12684385 0.
  0.         1.        ]
 [1.         0.         0.37641488 0.39881207 0.12684564 0.
  0.34924602 1.        ]
 [1.         0.         0.         0.         0.12684526 0.
  0.         1.        ]
 [1.         0.         0.57539543 0.48724986 0.1268462  0.
  0.47630917 1.        ]
 [1.         0.         1.         1.         0.12684747 0.
  1.         1.        ]
 [1.         0.         0.12874061 0.16425718 0.12684597 0.
  0.2092205  1.        ]
 [1.         0.         0.         0.22408196 0.12684716 0.
  0.21071712 1.        ]]
#####################         POISON         ###############################################

############################################################################################

comm_round: 7 | global_test_acc: 88.462% | global_f1: 0.9387755102040817 | global_precision: 0.9583333333333334
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.96      0.92      0.94        25

    accuracy                           0.88        26
   macro avg       0.48      0.46      0.47        26
weighted avg       0.92      0.88      0.90        26
poison scaling shape: (26, 1)
[[1]
 [0]
 [0]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAfter Nodes removed: Rows 24 cols 21
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.62126483 0.9616472  1.         1.         1.
 0.42478207 0.         1.         0.         1.         0.93960361
 0.15267818 0.         0.72198994 0.14108469 1.         0.26208543
 0.09565391 0.79686636 1.         1.         1.         0.03196657
 1.         0.45126281]
wv_ed shape (26,)
[0.         0.55872281 0.69824232 1.         1.         1.
 0.5215625  0.         1.         0.         1.         0.70311632
 0.34731396 0.         0.56643419 0.2645073  1.         0.41548145
 0.12022247 0.76287043 1.         1.         1.         0.
 1.         0.43159555]
wv_lg shape (26, 1)
[[0.12722958]
 [0.12674662]
 [0.12674656]
 [0.12674828]
 [0.12674774]
 [0.12674814]
 [0.12674663]
 [0.12674589]
 [0.12674828]
 [0.1267453 ]
 [0.12674762]
 [0.12674717]
 [0.12674613]
 [0.12674635]
 [0.1267468 ]
 [0.12674657]
 [0.12674841]
 [0.12674714]
 [0.126747  ]
 [0.12674656]
 [0.12674766]
 [0.12674736]
 [0.12674778]
 [0.12674625]
 [0.12674793]
 [0.12674701]]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.68003445 0.74718123 1.         1.         1.
 0.6003532  0.         1.         0.         1.         0.80276894
 0.39287813 0.         0.57441854 0.3231272  1.         0.48366644
 0.11350654 0.84994952 1.         1.         1.         0.04780302
 1.         0.50452319]
xy shape: (26, 8)
[[0.         1.         0.         0.         0.12722958 1.
  0.         0.        ]
 [1.         0.         0.62126483 0.55872281 0.12674662 0.
  0.68003445 1.        ]
 [1.         0.         0.9616472  0.69824232 0.12674656 0.
  0.74718123 1.        ]
 [1.         0.         1.         1.         0.12674828 0.
  1.         1.        ]
 [1.         0.         1.         1.         0.12674774 0.
  1.         1.        ]
 [1.         0.         1.         1.         0.12674814 0.
  1.         1.        ]
 [1.         0.         0.42478207 0.5215625  0.12674663 0.
  0.6003532  1.        ]
 [0.         0.         0.         0.         0.12674589 0.
  0.         1.        ]
 [1.         0.         1.         1.         0.12674828 0.
  1.         1.        ]
 [1.         0.         0.         0.         0.1267453  0.
  0.         1.        ]
 [1.         0.         1.         1.         0.12674762 0.
  1.         1.        ]
 [1.         0.         0.93960361 0.70311632 0.12674717 0.
  0.80276894 1.        ]
 [1.         0.         0.15267818 0.34731396 0.12674613 0.
  0.39287813 1.        ]
 [1.         0.         0.         0.         0.12674635 0.
  0.         1.        ]
 [1.         0.         0.72198994 0.56643419 0.1267468  0.
  0.57441854 1.        ]
 [1.         0.         0.14108469 0.2645073  0.12674657 0.
  0.3231272  1.        ]
 [1.         0.         1.         1.         0.12674841 0.
  1.         1.        ]
 [1.         0.         0.26208543 0.41548145 0.12674714 0.
  0.48366644 1.        ]
 [1.         0.         0.09565391 0.12022247 0.126747   0.
  0.11350654 1.        ]
 [1.         0.         0.79686636 0.76287043 0.12674656 0.
  0.84994952 1.        ]
 [1.         0.         1.         1.         0.12674766 0.
  1.         1.        ]
 [1.         0.         1.         1.         0.12674736 0.
  1.         1.        ]
 [1.         0.         1.         1.         0.12674778 0.
  1.         1.        ]
 [1.         0.         0.03196657 0.         0.12674625 0.
  0.04780302 1.        ]
 [1.         0.         1.         1.         0.12674793 0.
  1.         1.        ]
 [1.         0.         0.45126281 0.43159555 0.12674701 0.
  0.50452319 1.        ]]
#####################         POISON         ###############################################

############################################################################################

comm_round: 8 | global_test_acc: 96.154% | global_f1: 0.9803921568627451 | global_precision: 0.9615384615384616
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.96      1.00      0.98        25

    accuracy                           0.96        26
   macro avg       0.48      0.50      0.49        26
weighted avg       0.92      0.96      0.94        26
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAfter Nodes removed: Rows 26 cols 21
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         1.         0.         0.         0.96581348 0.49222208
 0.         0.         0.61871046 0.         0.         0.
 0.         1.         0.         0.58180149 0.         0.
 0.         0.5140101  1.         0.         1.         0.
 1.         0.01114079]
wv_ed shape (26,)
[0.         1.         0.         0.         0.53682821 0.23503609
 0.         0.         0.77098621 0.         0.         0.
 0.         1.         0.         0.39159887 0.         0.
 0.         0.49568933 1.         0.         1.         0.
 1.         0.        ]
wv_lg shape (26, 1)
[[0.12727393]
 [0.12679235]
 [0.12679102]
 [0.12678905]
 [0.12679044]
 [0.12679009]
 [0.12679047]
 [0.12679012]
 [0.12678988]
 [0.12679011]
 [0.12678933]
 [0.12678965]
 [0.12678874]
 [0.12678994]
 [0.12678911]
 [0.12679048]
 [0.12679035]
 [0.12678978]
 [0.12678994]
 [0.12679052]
 [0.12679092]
 [0.12678917]
 [0.12679074]
 [0.12679017]
 [0.12679079]
 [0.12678973]]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         1.         0.         0.         0.58360928 0.22492886
 0.         0.         0.8819949  0.         0.         0.
 0.         1.         0.         0.39032008 0.         0.
 0.         0.4191675  1.         0.         1.         0.
 1.         0.        ]
xy shape: (26, 8)
[[0.         1.         0.         0.         0.12727393 1.
  0.         0.        ]
 [1.         0.         1.         1.         0.12679235 0.
  1.         1.        ]
 [1.         0.         0.         0.         0.12679102 0.
  0.         1.        ]
 [1.         0.         0.         0.         0.12678905 0.
  0.         1.        ]
 [1.         0.         0.96581348 0.53682821 0.12679044 0.
  0.58360928 1.        ]
 [1.         0.         0.49222208 0.23503609 0.12679009 0.
  0.22492886 1.        ]
 [1.         0.         0.         0.         0.12679047 0.
  0.         1.        ]
 [1.         0.         0.         0.         0.12679012 0.
  0.         1.        ]
 [1.         0.         0.61871046 0.77098621 0.12678988 0.
  0.8819949  1.        ]
 [1.         0.         0.         0.         0.12679011 0.
  0.         1.        ]
 [1.         0.         0.         0.         0.12678933 0.
  0.         1.        ]
 [1.         0.         0.         0.         0.12678965 0.
  0.         1.        ]
 [0.         0.         0.         0.         0.12678874 0.
  0.         1.        ]
 [1.         0.         1.         1.         0.12678994 0.
  1.         1.        ]
 [1.         0.         0.         0.         0.12678911 0.
  0.         1.        ]
 [1.         0.         0.58180149 0.39159887 0.12679048 0.
  0.39032008 1.        ]
 [1.         0.         0.         0.         0.12679035 0.
  0.         1.        ]
 [1.         0.         0.         0.         0.12678978 0.
  0.         1.        ]
 [1.         0.         0.         0.         0.12678994 0.
  0.         1.        ]
 [1.         0.         0.5140101  0.49568933 0.12679052 0.
  0.4191675  1.        ]
 [1.         0.         1.         1.         0.12679092 0.
  1.         1.        ]
 [1.         0.         0.         0.         0.12678917 0.
  0.         1.        ]
 [1.         0.         1.         1.         0.12679074 0.
  1.         1.        ]
 [1.         0.         0.         0.         0.12679017 0.
  0.         1.        ]
 [1.         0.         1.         1.         0.12679079 0.
  1.         1.        ]
 [1.         0.         0.01114079 0.         0.12678973 0.
  0.         1.        ]]
#####################         POISON         ###############################################

############################################################################################

comm_round: 9 | global_test_acc: 96.154% | global_f1: 0.9803921568627451 | global_precision: 0.9615384615384616
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.96      1.00      0.98        25

    accuracy                           0.96        26
   macro avg       0.48      0.50      0.49        26
weighted avg       0.92      0.96      0.94        26
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAfter Nodes removed: Rows 26 cols 21
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         1.         1.         0.72026954 0.84359163 0.02811392
 1.         1.         0.         0.         0.20847794 0.34764563
 0.24115219 0.93064682 0.         0.         0.         1.
 0.64478416 0.08605269 0.12919569 0.         0.56213002 0.
 1.         0.51966694]
wv_ed shape (26,)
[0.         1.         1.         0.91293877 0.85274256 0.
 1.         1.         0.         0.         0.50266451 0.39037431
 0.10277685 0.94007262 0.         0.         0.         1.
 0.98680697 0.26609821 0.06391836 0.         0.56120896 0.
 1.         0.49007026]
wv_lg shape (26, 1)
[[0.12731664]
 [0.12683358]
 [0.12683342]
 [0.12683251]
 [0.12683386]
 [0.12683176]
 [0.12683373]
 [0.12683279]
 [0.1268328 ]
 [0.12683226]
 [0.12683237]
 [0.1268329 ]
 [0.12683347]
 [0.12683403]
 [0.12683335]
 [0.12683314]
 [0.12683215]
 [0.12683356]
 [0.12683296]
 [0.12683313]
 [0.12683287]
 [0.12683313]
 [0.1268332 ]
 [0.12683127]
 [0.12683153]
 [0.12683413]]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         1.         1.         0.92768065 0.91463202 0.
 1.         1.         0.         0.         0.49489349 0.42946313
 0.06666404 0.93239732 0.0186288  0.         0.         1.
 1.         0.21452395 0.04938282 0.         0.54623378 0.
 1.         0.49555443]
xy shape: (26, 8)
[[0.         1.         0.         0.         0.12731664 1.
  0.         0.        ]
 [1.         0.         1.         1.         0.12683358 0.
  1.         1.        ]
 [1.         0.         1.         1.         0.12683342 0.
  1.         1.        ]
 [1.         0.         0.72026954 0.91293877 0.12683251 0.
  0.92768065 1.        ]
 [1.         0.         0.84359163 0.85274256 0.12683386 0.
  0.91463202 1.        ]
 [1.         0.         0.02811392 0.         0.12683176 0.
  0.         1.        ]
 [1.         0.         1.         1.         0.12683373 0.
  1.         1.        ]
 [1.         0.         1.         1.         0.12683279 0.
  1.         1.        ]
 [1.         0.         0.         0.         0.1268328  0.
  0.         1.        ]
 [0.         0.         0.         0.         0.12683226 0.
  0.         1.        ]
 [1.         0.         0.20847794 0.50266451 0.12683237 0.
  0.49489349 1.        ]
 [1.         0.         0.34764563 0.39037431 0.1268329  0.
  0.42946313 1.        ]
 [1.         0.         0.24115219 0.10277685 0.12683347 0.
  0.06666404 1.        ]
 [1.         0.         0.93064682 0.94007262 0.12683403 0.
  0.93239732 1.        ]
 [1.         0.         0.         0.         0.12683335 0.
  0.0186288  1.        ]
 [1.         0.         0.         0.         0.12683314 0.
  0.         1.        ]
 [1.         0.         0.         0.         0.12683215 0.
  0.         1.        ]
 [1.         0.         1.         1.         0.12683356 0.
  1.         1.        ]
 [1.         0.         0.64478416 0.98680697 0.12683296 0.
  1.         1.        ]
 [1.         0.         0.08605269 0.26609821 0.12683313 0.
  0.21452395 1.        ]
 [1.         0.         0.12919569 0.06391836 0.12683287 0.
  0.04938282 1.        ]
 [1.         0.         0.         0.         0.12683313 0.
  0.         1.        ]
 [1.         0.         0.56213002 0.56120896 0.1268332  0.
  0.54623378 1.        ]
 [1.         0.         0.         0.         0.12683127 0.
  0.         1.        ]
 [1.         0.         1.         1.         0.12683153 0.
  1.         1.        ]
 [1.         0.         0.51966694 0.49007026 0.12683413 0.
  0.49555443 1.        ]]
#####################         POISON         ###############################################

############################################################################################

comm_round: 10 | global_test_acc: 88.462% | global_f1: 0.9387755102040817 | global_precision: 0.9583333333333334
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.96      0.92      0.94        25

    accuracy                           0.88        26
   macro avg       0.48      0.46      0.47        26
weighted avg       0.92      0.88      0.90        26
poison scaling shape: (26, 1)
[[1]
 [0]
 [0]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAfter Nodes removed: Rows 24 cols 21
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 0.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.8173562  1.         0.7657051  1.         0.40705075
 0.         1.         0.         0.11757289 1.         0.32613962
 0.         0.         0.73556311 0.         0.02191376 0.19239634
 0.68498528 1.         1.         0.         1.         0.27111059
 0.72003211 0.        ]
wv_ed shape (26,)
[0.         0.91606188 1.         0.82051826 1.         0.4233157
 0.         1.         0.         0.         1.         0.23613946
 0.         0.         0.57652877 0.         0.         0.04894023
 0.64512528 1.         1.         0.0640631  1.         0.28959206
 0.69806632 0.        ]
wv_lg shape (26, 1)
[[0.12719995]
 [0.12673255]
 [0.12673282]
 [0.126733  ]
 [0.12673309]
 [0.12673135]
 [0.1267313 ]
 [0.12673366]
 [0.12673196]
 [0.12673084]
 [0.12673303]
 [0.12673165]
 [0.12673089]
 [0.12673023]
 [0.12673169]
 [0.12673061]
 [0.12673097]
 [0.1267311 ]
 [0.12673187]
 [0.12673261]
 [0.12673348]
 [0.12673143]
 [0.1267334 ]
 [0.12673123]
 [0.12673223]
 [0.1267294 ]]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.94401668 1.         0.82598223 1.         0.46387651
 0.         1.         0.         0.         1.         0.29541243
 0.         0.         0.61238947 0.         0.01992504 0.01220048
 0.66275548 1.         1.         0.04526893 1.         0.31826721
 0.68090196 0.        ]
xy shape: (26, 8)
[[0.         1.         0.         0.         0.12719995 1.
  0.         0.        ]
 [1.         0.         0.8173562  0.91606188 0.12673255 0.
  0.94401668 1.        ]
 [1.         0.         1.         1.         0.12673282 0.
  1.         1.        ]
 [1.         0.         0.7657051  0.82051826 0.126733   0.
  0.82598223 1.        ]
 [1.         0.         1.         1.         0.12673309 0.
  1.         1.        ]
 [1.         0.         0.40705075 0.4233157  0.12673135 0.
  0.46387651 1.        ]
 [1.         0.         0.         0.         0.1267313  0.
  0.         1.        ]
 [1.         0.         1.         1.         0.12673366 0.
  1.         1.        ]
 [1.         0.         0.         0.         0.12673196 0.
  0.         1.        ]
 [1.         0.         0.11757289 0.         0.12673084 0.
  0.         1.        ]
 [1.         0.         1.         1.         0.12673303 0.
  1.         1.        ]
 [1.         0.         0.32613962 0.23613946 0.12673165 0.
  0.29541243 1.        ]
 [1.         0.         0.         0.         0.12673089 0.
  0.         1.        ]
 [1.         0.         0.         0.         0.12673023 0.
  0.         1.        ]
 [1.         0.         0.73556311 0.57652877 0.12673169 0.
  0.61238947 1.        ]
 [1.         0.         0.         0.         0.12673061 0.
  0.         1.        ]
 [1.         0.         0.02191376 0.         0.12673097 0.
  0.01992504 1.        ]
 [1.         0.         0.19239634 0.04894023 0.1267311  0.
  0.01220048 1.        ]
 [1.         0.         0.68498528 0.64512528 0.12673187 0.
  0.66275548 1.        ]
 [1.         0.         1.         1.         0.12673261 0.
  1.         1.        ]
 [1.         0.         1.         1.         0.12673348 0.
  1.         1.        ]
 [1.         0.         0.         0.0640631  0.12673143 0.
  0.04526893 1.        ]
 [1.         0.         1.         1.         0.1267334  0.
  1.         1.        ]
 [1.         0.         0.27111059 0.28959206 0.12673123 0.
  0.31826721 1.        ]
 [1.         0.         0.72003211 0.69806632 0.12673223 0.
  0.68090196 1.        ]
 [0.         0.         0.         0.         0.1267294  0.
  0.         1.        ]]
#####################         POISON         ###############################################

############################################################################################

comm_round: 11 | global_test_acc: 96.154% | global_f1: 0.9803921568627451 | global_precision: 0.9615384615384616
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.96      1.00      0.98        25

    accuracy                           0.96        26
   macro avg       0.48      0.50      0.49        26
weighted avg       0.92      0.96      0.94        26
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAfter Nodes removed: Rows 26 cols 21
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         1.         1.         0.83677588 0.03313452 1.
 1.         0.20048132 0.78114235 0.79466775 0.         1.
 0.         0.         1.         0.47680564 1.         0.68545937
 0.13770698 0.         1.         1.         1.         0.32796683
 1.         1.        ]
wv_ed shape (26,)
[0.         1.         1.         0.7237745  0.         0.95693816
 1.         0.21604335 0.63708333 1.         0.         1.
 0.         0.         1.         0.48665343 1.         0.51563953
 0.05086049 0.         1.         1.         1.         0.16979652
 1.         0.89101423]
wv_lg shape (26, 1)
[[0.12724069]
 [0.1267735 ]
 [0.12677406]
 [0.12677342]
 [0.12677184]
 [0.12677358]
 [0.12677383]
 [0.12677403]
 [0.12677358]
 [0.12677461]
 [0.12677182]
 [0.12677406]
 [0.12677288]
 [0.12677266]
 [0.12677399]
 [0.12677398]
 [0.12677364]
 [0.12677334]
 [0.12677301]
 [0.12677187]
 [0.12677431]
 [0.12677391]
 [0.12677429]
 [0.12677249]
 [0.12677415]
 [0.12677327]]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         1.         1.         0.74489888 0.         0.99574753
 1.         0.199917   0.69495166 1.         0.         1.
 0.         0.         1.         0.46643254 1.         0.5553998
 0.12831545 0.         1.         1.         1.         0.26601303
 1.         0.96176765]
xy shape: (26, 8)
[[0.         1.         0.         0.         0.12724069 1.
  0.         0.        ]
 [1.         0.         1.         1.         0.1267735  0.
  1.         1.        ]
 [1.         0.         1.         1.         0.12677406 0.
  1.         1.        ]
 [1.         0.         0.83677588 0.7237745  0.12677342 0.
  0.74489888 1.        ]
 [1.         0.         0.03313452 0.         0.12677184 0.
  0.         1.        ]
 [1.         0.         1.         0.95693816 0.12677358 0.
  0.99574753 1.        ]
 [1.         0.         1.         1.         0.12677383 0.
  1.         1.        ]
 [1.         0.         0.20048132 0.21604335 0.12677403 0.
  0.199917   1.        ]
 [1.         0.         0.78114235 0.63708333 0.12677358 0.
  0.69495166 1.        ]
 [1.         0.         0.79466775 1.         0.12677461 0.
  1.         1.        ]
 [0.         0.         0.         0.         0.12677182 0.
  0.         1.        ]
 [1.         0.         1.         1.         0.12677406 0.
  1.         1.        ]
 [1.         0.         0.         0.         0.12677288 0.
  0.         1.        ]
 [1.         0.         0.         0.         0.12677266 0.
  0.         1.        ]
 [1.         0.         1.         1.         0.12677399 0.
  1.         1.        ]
 [1.         0.         0.47680564 0.48665343 0.12677398 0.
  0.46643254 1.        ]
 [1.         0.         1.         1.         0.12677364 0.
  1.         1.        ]
 [1.         0.         0.68545937 0.51563953 0.12677334 0.
  0.5553998  1.        ]
 [1.         0.         0.13770698 0.05086049 0.12677301 0.
  0.12831545 1.        ]
 [1.         0.         0.         0.         0.12677187 0.
  0.         1.        ]
 [1.         0.         1.         1.         0.12677431 0.
  1.         1.        ]
 [1.         0.         1.         1.         0.12677391 0.
  1.         1.        ]
 [1.         0.         1.         1.         0.12677429 0.
  1.         1.        ]
 [1.         0.         0.32796683 0.16979652 0.12677249 0.
  0.26601303 1.        ]
 [1.         0.         1.         1.         0.12677415 0.
  1.         1.        ]
 [1.         0.         1.         0.89101423 0.12677327 0.
  0.96176765 1.        ]]
#####################         POISON         ###############################################

############################################################################################

comm_round: 12 | global_test_acc: 84.615% | global_f1: 0.9166666666666666 | global_precision: 0.9565217391304348
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.96      0.88      0.92        25

    accuracy                           0.85        26
   macro avg       0.48      0.44      0.46        26
weighted avg       0.92      0.85      0.88        26
poison scaling shape: (26, 1)
[[1]
 [0]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [0]
 [1]
 [1]
 [0]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAfter Nodes removed: Rows 23 cols 21
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.96874453 0.         0.45227455 1.         0.
 0.26645087 0.         0.         1.         0.77307923 0.1336333
 1.         0.97114054 0.35907599 0.         0.63532646 0.
 0.         0.47144014 1.         0.42792251 0.         0.
 0.78512193 0.        ]
wv_ed shape (26,)
[0.         1.         0.28606065 0.71238113 1.         0.
 0.69824848 0.         0.         1.         0.91594664 0.43557246
 1.         1.         0.51687839 0.         0.78135757 0.
 0.         0.83053897 1.         0.53301092 0.         0.
 1.         0.19161948]
wv_lg shape (26, 1)
[[0.12703913]
 [0.12660802]
 [0.12660788]
 [0.12660737]
 [0.12660818]
 [0.12660663]
 [0.12660782]
 [0.12660748]
 [0.12660687]
 [0.12660879]
 [0.12660763]
 [0.12660739]
 [0.12660861]
 [0.12660765]
 [0.12660769]
 [0.12660707]
 [0.12660839]
 [0.12660779]
 [0.12660573]
 [0.12660783]
 [0.12660787]
 [0.12660828]
 [0.12660702]
 [0.12660722]
 [0.12660785]
 [0.12660758]]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         1.         0.19319702 0.65901502 1.         0.
 0.65700913 0.         0.         1.         0.91162675 0.44848437
 1.         1.         0.49257253 0.         0.65026153 0.
 0.         0.78472448 1.         0.44094561 0.         0.01799526
 1.         0.14536693]
xy shape: (26, 8)
[[0.         1.         0.         0.         0.12703913 1.
  0.         0.        ]
 [1.         0.         0.96874453 1.         0.12660802 0.
  1.         1.        ]
 [1.         0.         0.         0.28606065 0.12660788 0.
  0.19319702 1.        ]
 [1.         0.         0.45227455 0.71238113 0.12660737 0.
  0.65901502 1.        ]
 [1.         0.         1.         1.         0.12660818 0.
  1.         1.        ]
 [1.         0.         0.         0.         0.12660663 0.
  0.         1.        ]
 [1.         0.         0.26645087 0.69824848 0.12660782 0.
  0.65700913 1.        ]
 [1.         0.         0.         0.         0.12660748 0.
  0.         1.        ]
 [1.         0.         0.         0.         0.12660687 0.
  0.         1.        ]
 [1.         0.         1.         1.         0.12660879 0.
  1.         1.        ]
 [1.         0.         0.77307923 0.91594664 0.12660763 0.
  0.91162675 1.        ]
 [1.         0.         0.1336333  0.43557246 0.12660739 0.
  0.44848437 1.        ]
 [1.         0.         1.         1.         0.12660861 0.
  1.         1.        ]
 [1.         0.         0.97114054 1.         0.12660765 0.
  1.         1.        ]
 [1.         0.         0.35907599 0.51687839 0.12660769 0.
  0.49257253 1.        ]
 [1.         0.         0.         0.         0.12660707 0.
  0.         1.        ]
 [1.         0.         0.63532646 0.78135757 0.12660839 0.
  0.65026153 1.        ]
 [1.         0.         0.         0.         0.12660779 0.
  0.         1.        ]
 [0.         0.         0.         0.         0.12660573 0.
  0.         1.        ]
 [1.         0.         0.47144014 0.83053897 0.12660783 0.
  0.78472448 1.        ]
 [1.         0.         1.         1.         0.12660787 0.
  1.         1.        ]
 [1.         0.         0.42792251 0.53301092 0.12660828 0.
  0.44094561 1.        ]
 [1.         0.         0.         0.         0.12660702 0.
  0.         1.        ]
 [1.         0.         0.         0.         0.12660722 0.
  0.01799526 1.        ]
 [1.         0.         0.78512193 1.         0.12660785 0.
  1.         1.        ]
 [1.         0.         0.         0.19161948 0.12660758 0.
  0.14536693 1.        ]]
#####################         POISON         ###############################################

############################################################################################

comm_round: 13 | global_test_acc: 88.462% | global_f1: 0.9387755102040817 | global_precision: 0.9583333333333334
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.96      0.92      0.94        25

    accuracy                           0.88        26
   macro avg       0.48      0.46      0.47        26
weighted avg       0.92      0.88      0.90        26
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [0]
 [0]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAfter Nodes removed: Rows 24 cols 21
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 0.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         1.         1.         1.         1.         1.
 0.         1.         1.         0.         1.         1.
 1.         0.06684435 0.0222198  0.         0.17330811 0.5737268
 0.         1.         0.         1.         1.         0.18276262
 0.         0.        ]
wv_ed shape (26,)
[0.         1.         1.         1.         1.         1.
 0.12850227 1.         1.         0.         1.         1.
 1.         0.         0.         0.         0.17804383 0.95593035
 0.         1.         0.         1.         1.         0.36939407
 0.         0.        ]
wv_lg shape (26, 1)
[[0.12694115]
 [0.12652154]
 [0.12652154]
 [0.1265207 ]
 [0.1265217 ]
 [0.12652125]
 [0.12652046]
 [0.12652137]
 [0.12652093]
 [0.12652016]
 [0.12652046]
 [0.12652006]
 [0.1265216 ]
 [0.12651879]
 [0.12651982]
 [0.12651972]
 [0.12652034]
 [0.12652123]
 [0.12652021]
 [0.12652044]
 [0.12651966]
 [0.12652089]
 [0.12652146]
 [0.12652028]
 [0.12652043]
 [0.12651906]]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         1.         1.         1.         1.         1.
 0.12186553 1.         1.         0.         1.         1.
 1.         0.         0.006332   0.         0.13951777 0.89151681
 0.         1.         0.         1.         1.         0.35043826
 0.         0.        ]
xy shape: (26, 8)
[[0.         1.         0.         0.         0.12694115 1.
  0.         0.        ]
 [1.         0.         1.         1.         0.12652154 0.
  1.         1.        ]
 [1.         0.         1.         1.         0.12652154 0.
  1.         1.        ]
 [1.         0.         1.         1.         0.1265207  0.
  1.         1.        ]
 [1.         0.         1.         1.         0.1265217  0.
  1.         1.        ]
 [1.         0.         1.         1.         0.12652125 0.
  1.         1.        ]
 [1.         0.         0.         0.12850227 0.12652046 0.
  0.12186553 1.        ]
 [1.         0.         1.         1.         0.12652137 0.
  1.         1.        ]
 [1.         0.         1.         1.         0.12652093 0.
  1.         1.        ]
 [1.         0.         0.         0.         0.12652016 0.
  0.         1.        ]
 [1.         0.         1.         1.         0.12652046 0.
  1.         1.        ]
 [1.         0.         1.         1.         0.12652006 0.
  1.         1.        ]
 [1.         0.         1.         1.         0.1265216  0.
  1.         1.        ]
 [1.         0.         0.06684435 0.         0.12651879 0.
  0.         1.        ]
 [1.         0.         0.0222198  0.         0.12651982 0.
  0.006332   1.        ]
 [1.         0.         0.         0.         0.12651972 0.
  0.         1.        ]
 [1.         0.         0.17330811 0.17804383 0.12652034 0.
  0.13951777 1.        ]
 [1.         0.         0.5737268  0.95593035 0.12652123 0.
  0.89151681 1.        ]
 [1.         0.         0.         0.         0.12652021 0.
  0.         1.        ]
 [1.         0.         1.         1.         0.12652044 0.
  1.         1.        ]
 [1.         0.         0.         0.         0.12651966 0.
  0.         1.        ]
 [1.         0.         1.         1.         0.12652089 0.
  1.         1.        ]
 [1.         0.         1.         1.         0.12652146 0.
  1.         1.        ]
 [1.         0.         0.18276262 0.36939407 0.12652028 0.
  0.35043826 1.        ]
 [1.         0.         0.         0.         0.12652043 0.
  0.         1.        ]
 [0.         0.         0.         0.         0.12651906 0.
  0.         1.        ]]
#####################         POISON         ###############################################

############################################################################################

comm_round: 14 | global_test_acc: 80.769% | global_f1: 0.8936170212765958 | global_precision: 0.9545454545454546
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.95      0.84      0.89        25

    accuracy                           0.81        26
   macro avg       0.48      0.42      0.45        26
weighted avg       0.92      0.81      0.86        26
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [0]
 [0]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [0]
 [1]
 [1]
 [1]
 [0]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAfter Nodes removed: Rows 22 cols 21
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.         0.         0.         0.80034668 1.
 0.29969697 1.         1.         0.         0.         0.
 0.         0.         1.         1.         0.58775931 0.
 0.33586744 0.26829167 0.         1.         0.         0.0432146
 0.         1.        ]
wv_ed shape (26,)
[0.         0.         0.         0.05235568 1.         1.
 0.36277466 1.         1.         0.         0.         0.
 0.         0.         1.         1.         0.5877697  0.
 0.34945215 0.35217823 0.         1.         0.         0.
 0.         1.        ]
wv_lg shape (26, 1)
[[0.12669809]
 [0.12632109]
 [0.12632119]
 [0.12632152]
 [0.12632247]
 [0.12632201]
 [0.12632094]
 [0.12632234]
 [0.12632197]
 [0.12632098]
 [0.12632036]
 [0.12632034]
 [0.12632138]
 [0.12632105]
 [0.12632254]
 [0.12632219]
 [0.12632091]
 [0.12632146]
 [0.1263212 ]
 [0.12632148]
 [0.1263214 ]
 [0.12632298]
 [0.12632072]
 [0.12632102]
 [0.12632093]
 [0.12632286]]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.         0.         0.14075259 1.         1.
 0.50004254 1.         1.         0.         0.         0.
 0.         0.10266416 1.         1.         0.7145424  0.
 0.40575585 0.40159692 0.         1.         0.         0.
 0.         1.        ]
xy shape: (26, 8)
[[0.         1.         0.         0.         0.12669809 1.
  0.         0.        ]
 [0.         0.         0.         0.         0.12632109 0.
  0.         1.        ]
 [1.         0.         0.         0.         0.12632119 0.
  0.         1.        ]
 [1.         0.         0.         0.05235568 0.12632152 0.
  0.14075259 1.        ]
 [1.         0.         0.80034668 1.         0.12632247 0.
  1.         1.        ]
 [1.         0.         1.         1.         0.12632201 0.
  1.         1.        ]
 [1.         0.         0.29969697 0.36277466 0.12632094 0.
  0.50004254 1.        ]
 [1.         0.         1.         1.         0.12632234 0.
  1.         1.        ]
 [1.         0.         1.         1.         0.12632197 0.
  1.         1.        ]
 [1.         0.         0.         0.         0.12632098 0.
  0.         1.        ]
 [1.         0.         0.         0.         0.12632036 0.
  0.         1.        ]
 [1.         0.         0.         0.         0.12632034 0.
  0.         1.        ]
 [1.         0.         0.         0.         0.12632138 0.
  0.         1.        ]
 [1.         0.         0.         0.         0.12632105 0.
  0.10266416 1.        ]
 [1.         0.         1.         1.         0.12632254 0.
  1.         1.        ]
 [1.         0.         1.         1.         0.12632219 0.
  1.         1.        ]
 [1.         0.         0.58775931 0.5877697  0.12632091 0.
  0.7145424  1.        ]
 [1.         0.         0.         0.         0.12632146 0.
  0.         1.        ]
 [1.         0.         0.33586744 0.34945215 0.1263212  0.
  0.40575585 1.        ]
 [1.         0.         0.26829167 0.35217823 0.12632148 0.
  0.40159692 1.        ]
 [1.         0.         0.         0.         0.1263214  0.
  0.         1.        ]
 [1.         0.         1.         1.         0.12632298 0.
  1.         1.        ]
 [1.         0.         0.         0.         0.12632072 0.
  0.         1.        ]
 [1.         0.         0.0432146  0.         0.12632102 0.
  0.         1.        ]
 [1.         0.         0.         0.         0.12632093 0.
  0.         1.        ]
 [1.         0.         1.         1.         0.12632286 0.
  1.         1.        ]]
#####################         POISON         ###############################################

############################################################################################

comm_round: 15 | global_test_acc: 92.308% | global_f1: 0.96 | global_precision: 0.96
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.96      0.96      0.96        25

    accuracy                           0.92        26
   macro avg       0.48      0.48      0.48        26
weighted avg       0.92      0.92      0.92        26
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [0]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAfter Nodes removed: Rows 25 cols 21
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         1.         0.         1.         1.         0.62688822
 0.         0.37308159 0.         1.         1.         0.17072069
 1.         0.21018066 0.54128939 0.         1.         0.94515003
 0.54981108 1.         0.         1.         1.         0.
 0.31673701 0.        ]
wv_ed shape (26,)
[0.         1.         0.         1.         1.         0.50305535
 0.         0.56046044 0.         1.         0.80814988 0.06865406
 1.         0.         0.67911222 0.         1.         0.93536075
 0.28959975 1.         0.         1.         1.         0.
 0.01683333 0.        ]
wv_lg shape (26, 1)
[[0.1266763 ]
 [0.12630455]
 [0.12630364]
 [0.12630508]
 [0.12630495]
 [0.12630373]
 [0.12630418]
 [0.12630496]
 [0.12630355]
 [0.12630503]
 [0.12630373]
 [0.12630396]
 [0.12630533]
 [0.12630416]
 [0.12630388]
 [0.12630368]
 [0.12630481]
 [0.12630492]
 [0.12630422]
 [0.12630434]
 [0.12630411]
 [0.12630515]
 [0.12630449]
 [0.1263044 ]
 [0.12630369]
 [0.12630387]]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         1.         0.         1.         1.         0.61751046
 0.         0.50484475 0.         1.         0.90360381 0.10016658
 1.         0.         0.73344607 0.         1.         0.89473913
 0.3107784  1.         0.         1.         1.         0.
 0.03402101 0.        ]
xy shape: (26, 8)
[[0.         1.         0.         0.         0.1266763  1.
  0.         0.        ]
 [1.         0.         1.         1.         0.12630455 0.
  1.         1.        ]
 [0.         0.         0.         0.         0.12630364 0.
  0.         1.        ]
 [1.         0.         1.         1.         0.12630508 0.
  1.         1.        ]
 [1.         0.         1.         1.         0.12630495 0.
  1.         1.        ]
 [1.         0.         0.62688822 0.50305535 0.12630373 0.
  0.61751046 1.        ]
 [1.         0.         0.         0.         0.12630418 0.
  0.         1.        ]
 [1.         0.         0.37308159 0.56046044 0.12630496 0.
  0.50484475 1.        ]
 [1.         0.         0.         0.         0.12630355 0.
  0.         1.        ]
 [1.         0.         1.         1.         0.12630503 0.
  1.         1.        ]
 [1.         0.         1.         0.80814988 0.12630373 0.
  0.90360381 1.        ]
 [1.         0.         0.17072069 0.06865406 0.12630396 0.
  0.10016658 1.        ]
 [1.         0.         1.         1.         0.12630533 0.
  1.         1.        ]
 [1.         0.         0.21018066 0.         0.12630416 0.
  0.         1.        ]
 [1.         0.         0.54128939 0.67911222 0.12630388 0.
  0.73344607 1.        ]
 [1.         0.         0.         0.         0.12630368 0.
  0.         1.        ]
 [1.         0.         1.         1.         0.12630481 0.
  1.         1.        ]
 [1.         0.         0.94515003 0.93536075 0.12630492 0.
  0.89473913 1.        ]
 [1.         0.         0.54981108 0.28959975 0.12630422 0.
  0.3107784  1.        ]
 [1.         0.         1.         1.         0.12630434 0.
  1.         1.        ]
 [1.         0.         0.         0.         0.12630411 0.
  0.         1.        ]
 [1.         0.         1.         1.         0.12630515 0.
  1.         1.        ]
 [1.         0.         1.         1.         0.12630449 0.
  1.         1.        ]
 [1.         0.         0.         0.         0.1263044  0.
  0.         1.        ]
 [1.         0.         0.31673701 0.01683333 0.12630369 0.
  0.03402101 1.        ]
 [1.         0.         0.         0.         0.12630387 0.
  0.         1.        ]]
#####################         POISON         ###############################################

############################################################################################

comm_round: 16 | global_test_acc: 84.615% | global_f1: 0.9166666666666666 | global_precision: 0.9565217391304348
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.96      0.88      0.92        25

    accuracy                           0.85        26
   macro avg       0.48      0.44      0.46        26
weighted avg       0.92      0.85      0.88        26
poison scaling shape: (26, 1)
[[1]
 [0]
 [1]
 [1]
 [0]
 [0]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAfter Nodes removed: Rows 23 cols 21
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         1.         1.         0.         0.         0.27368325
 0.         0.         0.         0.59088535 0.         0.
 0.         0.2443397  0.         0.00824848 0.42041251 0.94814092
 0.         0.39733133 1.         1.         0.         0.76403524
 1.         1.        ]
wv_ed shape (26,)
[0.         1.         1.         0.         0.34687511 1.
 0.         0.73979487 1.         0.24728536 0.42878405 0.
 0.08869488 0.689027   0.29598097 0.         0.         1.
 0.         0.15930755 1.         1.         0.13118352 0.8840801
 1.         1.        ]
wv_lg shape (26, 1)
[[0.10218556]
 [0.09932019]
 [0.09930936]
 [0.0993177 ]
 [0.09919951]
 [0.09933925]
 [0.09930252]
 [0.09907313]
 [0.09896761]
 [0.09918483]
 [0.09918033]
 [0.09911657]
 [0.0992149 ]
 [0.09909742]
 [0.09934044]
 [0.09909011]
 [0.09921343]
 [0.0990594 ]
 [0.09897903]
 [0.099061  ]
 [0.0992442 ]
 [0.09893484]
 [0.09931312]
 [0.09918599]
 [0.09913353]
 [0.09926833]]
wv_ndT shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_std shape (26,)
[0.         1.         0.70265808 0.         0.84204314 1.
 0.31155559 1.         1.         0.         0.         0.
 0.         0.15704681 1.         0.         0.         0.
 0.         0.         0.50506503 0.43111096 1.         0.
 0.8544165  0.        ]
xy shape: (26, 8)
[[0.         1.         0.         0.         0.10218556 0.
  0.         0.        ]
 [1.         0.         1.         1.         0.09932019 1.
  1.         1.        ]
 [1.         0.         1.         1.         0.09930936 1.
  0.70265808 1.        ]
 [1.         0.         0.         0.         0.0993177  1.
  0.         1.        ]
 [1.         0.         0.         0.34687511 0.09919951 1.
  0.84204314 1.        ]
 [1.         0.         0.27368325 1.         0.09933925 1.
  1.         1.        ]
 [1.         0.         0.         0.         0.09930252 1.
  0.31155559 1.        ]
 [1.         0.         0.         0.73979487 0.09907313 1.
  1.         1.        ]
 [1.         0.         0.         1.         0.09896761 1.
  1.         1.        ]
 [1.         0.         0.59088535 0.24728536 0.09918483 1.
  0.         1.        ]
 [1.         0.         0.         0.42878405 0.09918033 1.
  0.         1.        ]
 [0.         0.         0.         0.         0.09911657 1.
  0.         1.        ]
 [1.         0.         0.         0.08869488 0.0992149  1.
  0.         1.        ]
 [1.         0.         0.2443397  0.689027   0.09909742 1.
  0.15704681 1.        ]
 [1.         0.         0.         0.29598097 0.09934044 1.
  1.         1.        ]
 [1.         0.         0.00824848 0.         0.09909011 1.
  0.         1.        ]
 [1.         0.         0.42041251 0.         0.09921343 1.
  0.         1.        ]
 [1.         0.         0.94814092 1.         0.0990594  1.
  0.         1.        ]
 [1.         0.         0.         0.         0.09897903 1.
  0.         1.        ]
 [1.         0.         0.39733133 0.15930755 0.099061   1.
  0.         1.        ]
 [1.         0.         1.         1.         0.0992442  1.
  0.50506503 1.        ]
 [1.         0.         1.         1.         0.09893484 1.
  0.43111096 1.        ]
 [1.         0.         0.         0.13118352 0.09931312 1.
  1.         1.        ]
 [1.         0.         0.76403524 0.8840801  0.09918599 1.
  0.         1.        ]
 [1.         0.         1.         1.         0.09913353 1.
  0.8544165  1.        ]
 [1.         0.         1.         1.         0.09926833 1.
  0.         1.        ]]
#####################         POISON         ###############################################

############################################################################################

comm_round: 0 | global_test_acc: 96.154% | global_f1: 0.9803921568627451 | global_precision: 0.9615384615384616
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.96      1.00      0.98        25

    accuracy                           0.96        26
   macro avg       0.48      0.50      0.49        26
weighted avg       0.92      0.96      0.94        26
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 10Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAfter Nodes removed: Rows 26 cols 10
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0.
 1. 1.]
wv_ed shape (26,)
[0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0.
 1. 1.]
wv_lg shape (26, 1)
[[0.109514  ]
 [0.10601634]
 [0.10604027]
 [0.10464058]
 [0.10459405]
 [0.10604384]
 [0.10606181]
 [0.10604685]
 [0.10604455]
 [0.10604073]
 [0.10600962]
 [0.10604631]
 [0.10604046]
 [0.10461693]
 [0.10660356]
 [0.10602677]
 [0.10605778]
 [0.10603319]
 [0.10462643]
 [0.10458815]
 [0.10466159]
 [0.10600274]
 [0.10601747]
 [0.10463192]
 [0.10606584]
 [0.10604116]]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0.
 1. 1.]
xy shape: (26, 8)
[[0.         1.         0.         0.         0.109514   1.
  0.         0.        ]
 [1.         0.         1.         1.         0.10601634 0.
  1.         1.        ]
 [1.         0.         1.         1.         0.10604027 0.
  1.         1.        ]
 [1.         0.         0.         0.         0.10464058 0.
  0.         1.        ]
 [1.         0.         0.         0.         0.10459405 0.
  0.         1.        ]
 [1.         0.         1.         1.         0.10604384 0.
  1.         1.        ]
 [1.         0.         1.         1.         0.10606181 0.
  1.         1.        ]
 [1.         0.         1.         1.         0.10604685 0.
  1.         1.        ]
 [1.         0.         1.         1.         0.10604455 0.
  1.         1.        ]
 [1.         0.         1.         1.         0.10604073 0.
  1.         1.        ]
 [1.         0.         1.         1.         0.10600962 0.
  1.         1.        ]
 [1.         0.         1.         1.         0.10604631 0.
  1.         1.        ]
 [1.         0.         1.         1.         0.10604046 0.
  1.         1.        ]
 [1.         0.         0.         0.         0.10461693 0.
  0.         1.        ]
 [1.         0.         1.         1.         0.10660356 0.
  1.         1.        ]
 [1.         0.         1.         1.         0.10602677 0.
  1.         1.        ]
 [1.         0.         1.         1.         0.10605778 0.
  1.         1.        ]
 [1.         0.         1.         1.         0.10603319 0.
  1.         1.        ]
 [1.         0.         0.         0.         0.10462643 0.
  0.         1.        ]
 [0.         0.         0.         0.         0.10458815 0.
  0.         1.        ]
 [1.         0.         0.         0.         0.10466159 0.
  0.         1.        ]
 [1.         0.         1.         1.         0.10600274 0.
  1.         1.        ]
 [1.         0.         1.         1.         0.10601747 0.
  1.         1.        ]
 [1.         0.         0.         0.         0.10463192 0.
  0.         1.        ]
 [1.         0.         1.         1.         0.10606584 0.
  1.         1.        ]
 [1.         0.         1.         1.         0.10604116 0.
  1.         1.        ]]
#####################         POISON         ###############################################

############################################################################################

comm_round: 0 | global_test_acc: 96.154% | global_f1: 0.9803921568627451 | global_precision: 0.9615384615384616
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.96      1.00      0.98        25

    accuracy                           0.96        26
   macro avg       0.48      0.50      0.49        26
weighted avg       0.92      0.96      0.94        26
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 10Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAfter Nodes removed: Rows 26 cols 10
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1.
 0. 1.]
wv_ed shape (26,)
[0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1.
 0. 1.]
wv_lg shape (26, 1)
[[0.11127391]
 [0.10677703]
 [0.10683006]
 [0.10677746]
 [0.10678633]
 [0.10677158]
 [0.10678038]
 [0.1055862 ]
 [0.10679222]
 [0.10681269]
 [0.10677555]
 [0.10762389]
 [0.10679534]
 [0.1076203 ]
 [0.1067909 ]
 [0.10676953]
 [0.10678606]
 [0.10679191]
 [0.10555643]
 [0.10680001]
 [0.10681729]
 [0.10678938]
 [0.10678825]
 [0.10680523]
 [0.10555277]
 [0.1067615 ]]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1.
 0. 1.]
xy shape: (26, 8)
[[0.         1.         0.         0.         0.11127391 1.
  0.         0.        ]
 [1.         0.         1.         1.         0.10677703 0.
  1.         1.        ]
 [1.         0.         1.         1.         0.10683006 0.
  1.         1.        ]
 [1.         0.         1.         1.         0.10677746 0.
  1.         1.        ]
 [1.         0.         1.         1.         0.10678633 0.
  1.         1.        ]
 [1.         0.         1.         1.         0.10677158 0.
  1.         1.        ]
 [1.         0.         1.         1.         0.10678038 0.
  1.         1.        ]
 [1.         0.         0.         0.         0.1055862  0.
  0.         1.        ]
 [1.         0.         1.         1.         0.10679222 0.
  1.         1.        ]
 [1.         0.         1.         1.         0.10681269 0.
  1.         1.        ]
 [1.         0.         1.         1.         0.10677555 0.
  1.         1.        ]
 [1.         0.         1.         1.         0.10762389 0.
  1.         1.        ]
 [1.         0.         1.         1.         0.10679534 0.
  1.         1.        ]
 [1.         0.         1.         1.         0.1076203  0.
  1.         1.        ]
 [1.         0.         1.         1.         0.1067909  0.
  1.         1.        ]
 [1.         0.         1.         1.         0.10676953 0.
  1.         1.        ]
 [1.         0.         1.         1.         0.10678606 0.
  1.         1.        ]
 [1.         0.         1.         1.         0.10679191 0.
  1.         1.        ]
 [0.         0.         0.         0.         0.10555643 0.
  0.         1.        ]
 [1.         0.         1.         1.         0.10680001 0.
  1.         1.        ]
 [1.         0.         1.         1.         0.10681729 0.
  1.         1.        ]
 [1.         0.         1.         1.         0.10678938 0.
  1.         1.        ]
 [1.         0.         1.         1.         0.10678825 0.
  1.         1.        ]
 [1.         0.         1.         1.         0.10680523 0.
  1.         1.        ]
 [1.         0.         0.         0.         0.10555277 0.
  0.         1.        ]
 [1.         0.         1.         1.         0.1067615  0.
  1.         1.        ]]
#####################         POISON         ###############################################

############################################################################################

comm_round: 0 | global_test_acc: 84.615% | global_f1: 0.9130434782608696 | global_precision: 1.0
              precision    recall  f1-score   support

           0       0.20      1.00      0.33         1
           1       1.00      0.84      0.91        25

    accuracy                           0.85        26
   macro avg       0.60      0.92      0.62        26
weighted avg       0.97      0.85      0.89        26
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [0]
 [0]
 [0]
 [0]
 [0]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 10Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAfter Nodes removed: Rows 21 cols 10
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.         1.         0.         1.         0.10532727
 1.         1.         0.05066446 0.58081938 0.         1.
 0.91162546 1.         0.24956207 1.         1.         0.48109247
 0.         0.         0.26892837 0.         0.22056266 1.
 0.16678551 0.        ]
wv_ed shape (26,)
[0.         0.         1.         0.         1.         0.67285574
 1.         1.         0.44452366 0.76099031 0.         1.
 0.72325185 1.         0.         1.         1.         0.29839276
 0.         0.         0.69202905 0.         0.         1.
 0.         0.        ]
wv_lg shape (26, 1)
[[0.02084795]
 [0.01986362]
 [0.01987051]
 [0.01984468]
 [0.01983417]
 [0.01984153]
 [0.01986073]
 [0.01985162]
 [0.01987245]
 [0.01984147]
 [0.01985377]
 [0.01985297]
 [0.0198371 ]
 [0.01983331]
 [0.01985612]
 [0.0198552 ]
 [0.01985705]
 [0.01985283]
 [0.01984852]
 [0.01985963]
 [0.01983217]
 [0.01983429]
 [0.01984182]
 [0.01986206]
 [0.01984708]
 [0.01984062]]
wv_ndT shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_std shape (26,)
[0.         0.44165501 1.         0.         0.86089057 0.32856594
 1.         0.91736549 1.         0.         0.         1.
 0.2987403  0.89061565 1.         1.         1.         0.
 0.         0.         0.79599401 0.         0.         1.
 0.         0.        ]
xy shape: (26, 8)
[[0.         1.         0.         0.         0.02084795 0.
  0.         0.        ]
 [1.         0.         0.         0.         0.01986362 1.
  0.44165501 1.        ]
 [1.         0.         1.         1.         0.01987051 1.
  1.         1.        ]
 [1.         0.         0.         0.         0.01984468 1.
  0.         1.        ]
 [1.         0.         1.         1.         0.01983417 1.
  0.86089057 1.        ]
 [1.         0.         0.10532727 0.67285574 0.01984153 1.
  0.32856594 1.        ]
 [1.         0.         1.         1.         0.01986073 1.
  1.         1.        ]
 [1.         0.         1.         1.         0.01985162 1.
  0.91736549 1.        ]
 [1.         0.         0.05066446 0.44452366 0.01987245 1.
  1.         1.        ]
 [1.         0.         0.58081938 0.76099031 0.01984147 1.
  0.         1.        ]
 [1.         0.         0.         0.         0.01985377 1.
  0.         1.        ]
 [1.         0.         1.         1.         0.01985297 1.
  1.         1.        ]
 [1.         0.         0.91162546 0.72325185 0.0198371  1.
  0.2987403  1.        ]
 [1.         0.         1.         1.         0.01983331 1.
  0.89061565 1.        ]
 [1.         0.         0.24956207 0.         0.01985612 1.
  1.         1.        ]
 [1.         0.         1.         1.         0.0198552  1.
  1.         1.        ]
 [1.         0.         1.         1.         0.01985705 1.
  1.         1.        ]
 [1.         0.         0.48109247 0.29839276 0.01985283 1.
  0.         1.        ]
 [1.         0.         0.         0.         0.01984852 1.
  0.         1.        ]
 [0.         0.         0.         0.         0.01985963 1.
  0.         1.        ]
 [1.         0.         0.26892837 0.69202905 0.01983217 1.
  0.79599401 1.        ]
 [1.         0.         0.         0.         0.01983429 1.
  0.         1.        ]
 [1.         0.         0.22056266 0.         0.01984182 1.
  0.         1.        ]
 [1.         0.         1.         1.         0.01986206 1.
  1.         1.        ]
 [1.         0.         0.16678551 0.         0.01984708 1.
  0.         1.        ]
 [1.         0.         0.         0.         0.01984062 1.
  0.         1.        ]]
#####################         POISON         ###############################################

############################################################################################

comm_round: 0 | global_test_acc: 92.308% | global_f1: 0.96 | global_precision: 0.96
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.96      0.96      0.96        25

    accuracy                           0.92        26
   macro avg       0.48      0.48      0.48        26
weighted avg       0.92      0.92      0.92        26
poison scaling shape: (26, 1)
[[1]
 [0]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 15Adding node: 0 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAfter Nodes removed: Rows 25 cols 15
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         1.         0.         1.         1.         0.
 0.         0.         1.         0.         0.         0.28277542
 0.72700366 0.         0.18086953 0.29511072 0.         0.2116364
 0.36161944 0.         0.         0.28142937 0.46742964 1.
 0.30060749 0.34950408]
wv_ed shape (26,)
[0.         1.         0.01804853 1.         0.63756404 0.
 0.         0.         1.         0.         0.         0.9688548
 0.24523601 0.         0.         0.07338867 0.         0.52811669
 0.72986718 0.60866263 0.31862069 0.47877629 0.33690592 1.
 1.         0.94908134]
wv_lg shape (26, 1)
[[0.02573446]
 [0.02408019]
 [0.02400927]
 [0.02410889]
 [0.02405686]
 [0.02414716]
 [0.02404063]
 [0.02420401]
 [0.02408013]
 [0.02406318]
 [0.02412737]
 [0.02414738]
 [0.02405199]
 [0.02398738]
 [0.02402048]
 [0.02409212]
 [0.02403768]
 [0.0240751 ]
 [0.02408898]
 [0.02409451]
 [0.02408817]
 [0.02409984]
 [0.02405645]
 [0.02406704]
 [0.02420912]
 [0.02405578]]
wv_ndT shape (26,)
[0.         0.         0.         1.         1.         0.
 1.         1.         0.07047997 0.01209019 0.81313884 1.
 1.         0.         0.         0.         0.         1.
 1.         1.         1.         0.         0.         0.6591227
 0.         0.        ]
wv_std shape (26,)
[0.         0.9914338  0.39041824 1.         1.         1.
 0.         1.         1.         0.         0.91233144 1.
 1.         1.         0.         0.         0.         0.97817719
 1.         1.         1.         1.         0.         1.
 1.         1.        ]
xy shape: (26, 8)
[[0.         1.         0.         0.         0.02573446 0.
  0.         0.        ]
 [1.         0.         1.         1.         0.02408019 0.
  0.9914338  1.        ]
 [1.         0.         0.         0.01804853 0.02400927 0.
  0.39041824 1.        ]
 [1.         0.         1.         1.         0.02410889 1.
  1.         1.        ]
 [1.         0.         1.         0.63756404 0.02405686 1.
  1.         1.        ]
 [1.         0.         0.         0.         0.02414716 0.
  1.         1.        ]
 [1.         0.         0.         0.         0.02404063 1.
  0.         1.        ]
 [0.         0.         0.         0.         0.02420401 1.
  1.         1.        ]
 [1.         0.         1.         1.         0.02408013 0.07047997
  1.         1.        ]
 [1.         0.         0.         0.         0.02406318 0.01209019
  0.         1.        ]
 [1.         0.         0.         0.         0.02412737 0.81313884
  0.91233144 1.        ]
 [1.         0.         0.28277542 0.9688548  0.02414738 1.
  1.         1.        ]
 [1.         0.         0.72700366 0.24523601 0.02405199 1.
  1.         1.        ]
 [1.         0.         0.         0.         0.02398738 0.
  1.         1.        ]
 [1.         0.         0.18086953 0.         0.02402048 0.
  0.         1.        ]
 [1.         0.         0.29511072 0.07338867 0.02409212 0.
  0.         1.        ]
 [1.         0.         0.         0.         0.02403768 0.
  0.         1.        ]
 [1.         0.         0.2116364  0.52811669 0.0240751  1.
  0.97817719 1.        ]
 [1.         0.         0.36161944 0.72986718 0.02408898 1.
  1.         1.        ]
 [1.         0.         0.         0.60866263 0.02409451 1.
  1.         1.        ]
 [1.         0.         0.         0.31862069 0.02408817 1.
  1.         1.        ]
 [1.         0.         0.28142937 0.47877629 0.02409984 0.
  1.         1.        ]
 [1.         0.         0.46742964 0.33690592 0.02405645 0.
  0.         1.        ]
 [1.         0.         1.         1.         0.02406704 0.6591227
  1.         1.        ]
 [1.         0.         0.30060749 1.         0.02420912 0.
  1.         1.        ]
 [1.         0.         0.34950408 0.94908134 0.02405578 0.
  1.         1.        ]]
#####################         POISON         ###############################################

############################################################################################

comm_round: 0 | global_test_acc: 73.077% | global_f1: 0.8444444444444444 | global_precision: 0.95
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.95      0.76      0.84        25

    accuracy                           0.73        26
   macro avg       0.47      0.38      0.42        26
weighted avg       0.91      0.73      0.81        26
poison scaling shape: (26, 1)
[[1]
 [0]
 [0]
 [0]
 [0]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [0]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [0]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 8Adding node: 0 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAfter Nodes removed: Rows 20 cols 8
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.         0.59738232 1.         0.         0.
 0.55884921 1.         0.26415055 0.         0.69566716 0.
 0.         1.         0.         0.72566596 0.         0.
 1.         0.         1.         0.84840713 0.         0.58426565
 0.         0.        ]
wv_ed shape (26,)
[0.         0.         1.         1.         0.         0.1518613
 1.         1.         0.37965224 0.         1.         0.08389301
 0.         1.         0.         0.96219783 0.85144684 0.13318146
 1.         0.         1.         1.         0.         0.36666584
 0.         0.        ]
wv_lg shape (26, 1)
[[0.02459424]
 [0.02303632]
 [0.02305466]
 [0.02305888]
 [0.02300885]
 [0.02301008]
 [0.02309093]
 [0.02308837]
 [0.02303611]
 [0.02308704]
 [0.02296153]
 [0.02303234]
 [0.0230939 ]
 [0.02310209]
 [0.02312775]
 [0.02306667]
 [0.02302528]
 [0.0230201 ]
 [0.02305956]
 [0.02300122]
 [0.02297663]
 [0.02305203]
 [0.0229907 ]
 [0.02303126]
 [0.02307472]
 [0.02304095]]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         1.         0.         1.         0.20287104 1.
 1.         1.         1.         1.         0.88328835 0.50209077
 1.         0.         0.23889474 0.44791913 1.         1.
 0.65703495 1.         1.         0.8917054  0.         0.
 1.         1.        ]
xy shape: (26, 8)
[[0.         1.         0.         0.         0.02459424 1.
  0.         0.        ]
 [1.         0.         0.         0.         0.02303632 0.
  1.         1.        ]
 [1.         0.         0.59738232 1.         0.02305466 0.
  0.         1.        ]
 [1.         0.         1.         1.         0.02305888 0.
  1.         1.        ]
 [1.         0.         0.         0.         0.02300885 0.
  0.20287104 1.        ]
 [1.         0.         0.         0.1518613  0.02301008 0.
  1.         1.        ]
 [1.         0.         0.55884921 1.         0.02309093 0.
  1.         1.        ]
 [1.         0.         1.         1.         0.02308837 0.
  1.         1.        ]
 [1.         0.         0.26415055 0.37965224 0.02303611 0.
  1.         1.        ]
 [1.         0.         0.         0.         0.02308704 0.
  1.         1.        ]
 [1.         0.         0.69566716 1.         0.02296153 0.
  0.88328835 1.        ]
 [1.         0.         0.         0.08389301 0.02303234 0.
  0.50209077 1.        ]
 [0.         0.         0.         0.         0.0230939  0.
  1.         1.        ]
 [1.         0.         1.         1.         0.02310209 0.
  0.         1.        ]
 [1.         0.         0.         0.         0.02312775 0.
  0.23889474 1.        ]
 [1.         0.         0.72566596 0.96219783 0.02306667 0.
  0.44791913 1.        ]
 [1.         0.         0.         0.85144684 0.02302528 0.
  1.         1.        ]
 [1.         0.         0.         0.13318146 0.0230201  0.
  1.         1.        ]
 [1.         0.         1.         1.         0.02305956 0.
  0.65703495 1.        ]
 [1.         0.         0.         0.         0.02300122 0.
  1.         1.        ]
 [1.         0.         1.         1.         0.02297663 0.
  1.         1.        ]
 [1.         0.         0.84840713 1.         0.02305203 0.
  0.8917054  1.        ]
 [1.         0.         0.         0.         0.0229907  0.
  0.         1.        ]
 [1.         0.         0.58426565 0.36666584 0.02303126 0.
  0.         1.        ]
 [1.         0.         0.         0.         0.02307472 0.
  1.         1.        ]
 [1.         0.         0.         0.         0.02304095 0.
  1.         1.        ]]
#####################         POISON         ###############################################

############################################################################################

comm_round: 0 | global_test_acc: 92.308% | global_f1: 0.9583333333333334 | global_precision: 1.0
              precision    recall  f1-score   support

           0       0.33      1.00      0.50         1
           1       1.00      0.92      0.96        25

    accuracy                           0.92        26
   macro avg       0.67      0.96      0.73        26
weighted avg       0.97      0.92      0.94        26
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [0]
 [0]
 [0]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 8Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAfter Nodes removed: Rows 23 cols 8
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         1.         0.59898158 0.         1.         1.
 0.         0.         1.         0.58605058 0.         1.
 0.         1.         1.         0.26246336 0.72560607 0.
 0.6900016  0.54052168 0.87275383 0.11105203 0.6603499  1.
 0.95057005 1.        ]
wv_ed shape (26,)
[0.         1.         0.22333527 0.         1.         0.49057189
 0.         0.         0.99281224 0.         0.         1.
 0.         1.         1.         0.         0.02358765 0.
 0.69661627 0.47343853 0.57425012 0.         0.59522807 0.8977629
 1.         1.        ]
wv_lg shape (26, 1)
[[0.02413154]
 [0.02273543]
 [0.02272008]
 [0.02272499]
 [0.02274252]
 [0.02274752]
 [0.02269595]
 [0.02270328]
 [0.02271653]
 [0.0227255 ]
 [0.02269859]
 [0.02270768]
 [0.02272649]
 [0.02273815]
 [0.02271043]
 [0.02272607]
 [0.02271987]
 [0.02269971]
 [0.02272363]
 [0.02272273]
 [0.02268498]
 [0.02272991]
 [0.0227229 ]
 [0.02275391]
 [0.02272671]
 [0.02269387]]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.40876284 0.         0.92563005 0.97532568 0.38793188
 0.         0.         0.         0.         0.         1.
 0.         1.         0.         1.         0.35327877 0.
 0.44283033 0.10458714 0.         0.53463878 0.         1.
 0.         1.        ]
xy shape: (26, 8)
[[0.         1.         0.         0.         0.02413154 1.
  0.         0.        ]
 [1.         0.         1.         1.         0.02273543 0.
  0.40876284 1.        ]
 [1.         0.         0.59898158 0.22333527 0.02272008 0.
  0.         1.        ]
 [1.         0.         0.         0.         0.02272499 0.
  0.92563005 1.        ]
 [1.         0.         1.         1.         0.02274252 0.
  0.97532568 1.        ]
 [1.         0.         1.         0.49057189 0.02274752 0.
  0.38793188 1.        ]
 [1.         0.         0.         0.         0.02269595 0.
  0.         1.        ]
 [1.         0.         0.         0.         0.02270328 0.
  0.         1.        ]
 [1.         0.         1.         0.99281224 0.02271653 0.
  0.         1.        ]
 [1.         0.         0.58605058 0.         0.0227255  0.
  0.         1.        ]
 [0.         0.         0.         0.         0.02269859 0.
  0.         1.        ]
 [1.         0.         1.         1.         0.02270768 0.
  1.         1.        ]
 [1.         0.         0.         0.         0.02272649 0.
  0.         1.        ]
 [1.         0.         1.         1.         0.02273815 0.
  1.         1.        ]
 [1.         0.         1.         1.         0.02271043 0.
  0.         1.        ]
 [1.         0.         0.26246336 0.         0.02272607 0.
  1.         1.        ]
 [1.         0.         0.72560607 0.02358765 0.02271987 0.
  0.35327877 1.        ]
 [1.         0.         0.         0.         0.02269971 0.
  0.         1.        ]
 [1.         0.         0.6900016  0.69661627 0.02272363 0.
  0.44283033 1.        ]
 [1.         0.         0.54052168 0.47343853 0.02272273 0.
  0.10458714 1.        ]
 [1.         0.         0.87275383 0.57425012 0.02268498 0.
  0.         1.        ]
 [1.         0.         0.11105203 0.         0.02272991 0.
  0.53463878 1.        ]
 [1.         0.         0.6603499  0.59522807 0.0227229  0.
  0.         1.        ]
 [1.         0.         1.         0.8977629  0.02275391 0.
  1.         1.        ]
 [1.         0.         0.95057005 1.         0.02272671 0.
  0.         1.        ]
 [1.         0.         1.         1.         0.02269387 0.
  1.         1.        ]]
#####################         POISON         ###############################################

############################################################################################

comm_round: 1 | global_test_acc: 96.154% | global_f1: 0.9795918367346939 | global_precision: 1.0
              precision    recall  f1-score   support

           0       0.50      1.00      0.67         1
           1       1.00      0.96      0.98        25

    accuracy                           0.96        26
   macro avg       0.75      0.98      0.82        26
weighted avg       0.98      0.96      0.97        26
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [0]
 [1]
 [1]
 [1]
 [0]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 8Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAfter Nodes removed: Rows 24 cols 8
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.1727678  0.74199062 0.84917177 0.         0.4456384
 0.         1.         1.         0.         0.17384134 0.28204087
 0.         0.80453688 0.         0.96168121 0.         0.04332562
 1.         0.51774205 0.         1.         0.49527745 0.
 0.         0.59360359]
wv_ed shape (26,)
[0.         1.         1.         0.61484173 0.84690811 1.
 0.         1.         1.         0.         0.50055524 0.97649731
 0.         0.61134079 0.         1.         0.         0.2525838
 1.         0.24360503 0.         1.         1.         0.
 0.         0.97920606]
wv_lg shape (26, 1)
[[0.02384376]
 [0.02256249]
 [0.02259672]
 [0.02254552]
 [0.02254916]
 [0.02254766]
 [0.02260262]
 [0.02257209]
 [0.02260967]
 [0.02260093]
 [0.02254355]
 [0.02256951]
 [0.02258459]
 [0.02256534]
 [0.02253377]
 [0.02260533]
 [0.02255311]
 [0.02254927]
 [0.02255499]
 [0.0225932 ]
 [0.02256334]
 [0.02257551]
 [0.02256193]
 [0.02259178]
 [0.02255429]
 [0.02253144]]
wv_ndT shape (26,)
[1.         0.         0.26861938 1.         0.82122938 1.
 0.21178596 1.         0.11459481 0.         1.         0.63711581
 0.03869928 0.72085212 0.34650584 0.         0.15778114 1.
 0.         0.         0.         0.21338412 1.         0.
 0.22771316 0.        ]
wv_std shape (26,)
[0.         0.         0.30443429 0.         0.43210688 0.23022944
 0.         1.         1.         0.         0.         0.06399237
 0.         0.20085509 0.         1.         0.00513257 0.01685082
 1.         0.         1.         1.         0.89976953 0.
 0.37197361 0.57985518]
xy shape: (26, 8)
[[0.         1.         0.         0.         0.02384376 1.
  0.         0.        ]
 [1.         0.         0.1727678  1.         0.02256249 0.
  0.         1.        ]
 [1.         0.         0.74199062 1.         0.02259672 0.26861938
  0.30443429 1.        ]
 [1.         0.         0.84917177 0.61484173 0.02254552 1.
  0.         1.        ]
 [1.         0.         0.         0.84690811 0.02254916 0.82122938
  0.43210688 1.        ]
 [1.         0.         0.4456384  1.         0.02254766 1.
  0.23022944 1.        ]
 [1.         0.         0.         0.         0.02260262 0.21178596
  0.         1.        ]
 [1.         0.         1.         1.         0.02257209 1.
  1.         1.        ]
 [1.         0.         1.         1.         0.02260967 0.11459481
  1.         1.        ]
 [1.         0.         0.         0.         0.02260093 0.
  0.         1.        ]
 [1.         0.         0.17384134 0.50055524 0.02254355 1.
  0.         1.        ]
 [1.         0.         0.28204087 0.97649731 0.02256951 0.63711581
  0.06399237 1.        ]
 [1.         0.         0.         0.         0.02258459 0.03869928
  0.         1.        ]
 [1.         0.         0.80453688 0.61134079 0.02256534 0.72085212
  0.20085509 1.        ]
 [0.         0.         0.         0.         0.02253377 0.34650584
  0.         1.        ]
 [1.         0.         0.96168121 1.         0.02260533 0.
  1.         1.        ]
 [1.         0.         0.         0.         0.02255311 0.15778114
  0.00513257 1.        ]
 [1.         0.         0.04332562 0.2525838  0.02254927 1.
  0.01685082 1.        ]
 [1.         0.         1.         1.         0.02255499 0.
  1.         1.        ]
 [1.         0.         0.51774205 0.24360503 0.0225932  0.
  0.         1.        ]
 [1.         0.         0.         0.         0.02256334 0.
  1.         1.        ]
 [1.         0.         1.         1.         0.02257551 0.21338412
  1.         1.        ]
 [1.         0.         0.49527745 1.         0.02256193 1.
  0.89976953 1.        ]
 [1.         0.         0.         0.         0.02259178 0.
  0.         1.        ]
 [1.         0.         0.         0.         0.02255429 0.22771316
  0.37197361 1.        ]
 [1.         0.         0.59360359 0.97920606 0.02253144 0.
  0.57985518 1.        ]]
#####################         POISON         ###############################################

############################################################################################

comm_round: 2 | global_test_acc: 96.154% | global_f1: 0.9803921568627451 | global_precision: 0.9615384615384616
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.96      1.00      0.98        25

    accuracy                           0.96        26
   macro avg       0.48      0.50      0.49        26
weighted avg       0.92      0.96      0.94        26
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 8Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAfter Nodes removed: Rows 26 cols 8
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         1.         0.         0.72862774 0.74246533 1.
 1.         0.96491215 1.         0.20944966 0.29706451 0.
 0.         1.         0.50592523 0.39706167 1.         0.
 0.72437623 1.         0.1880265  1.         0.         0.96393015
 0.97473146 1.        ]
wv_ed shape (26,)
[0.         1.         0.         0.71339243 1.         1.
 1.         1.         1.         0.50173442 0.50516331 0.
 0.         1.         0.36776316 0.55182908 1.         0.
 0.91509964 1.         0.52471365 1.         0.         1.
 1.         1.        ]
wv_lg shape (26, 1)
[[0.02393492]
 [0.02283325]
 [0.02284444]
 [0.02283509]
 [0.02282443]
 [0.02280441]
 [0.02287609]
 [0.0228347 ]
 [0.02286928]
 [0.02280496]
 [0.02283445]
 [0.02284897]
 [0.022828  ]
 [0.02284308]
 [0.02283361]
 [0.02283029]
 [0.0228279 ]
 [0.02280974]
 [0.02286423]
 [0.02286389]
 [0.02281643]
 [0.02281193]
 [0.02280593]
 [0.02287556]
 [0.02282315]
 [0.02280822]]
wv_ndT shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_std shape (26,)
[0.         1.         0.         1.         1.         1.
 1.         1.         1.         0.         1.         0.
 0.         1.         0.455029   0.75068287 1.         0.
 0.8576406  1.         0.56910862 1.         0.         1.
 1.         1.        ]
xy shape: (26, 8)
[[0.         1.         0.         0.         0.02393492 0.
  0.         0.        ]
 [1.         0.         1.         1.         0.02283325 1.
  1.         1.        ]
 [1.         0.         0.         0.         0.02284444 1.
  0.         1.        ]
 [1.         0.         0.72862774 0.71339243 0.02283509 1.
  1.         1.        ]
 [1.         0.         0.74246533 1.         0.02282443 1.
  1.         1.        ]
 [1.         0.         1.         1.         0.02280441 1.
  1.         1.        ]
 [1.         0.         1.         1.         0.02287609 1.
  1.         1.        ]
 [1.         0.         0.96491215 1.         0.0228347  1.
  1.         1.        ]
 [1.         0.         1.         1.         0.02286928 1.
  1.         1.        ]
 [1.         0.         0.20944966 0.50173442 0.02280496 1.
  0.         1.        ]
 [1.         0.         0.29706451 0.50516331 0.02283445 1.
  1.         1.        ]
 [1.         0.         0.         0.         0.02284897 1.
  0.         1.        ]
 [1.         0.         0.         0.         0.022828   1.
  0.         1.        ]
 [1.         0.         1.         1.         0.02284308 1.
  1.         1.        ]
 [1.         0.         0.50592523 0.36776316 0.02283361 1.
  0.455029   1.        ]
 [1.         0.         0.39706167 0.55182908 0.02283029 1.
  0.75068287 1.        ]
 [1.         0.         1.         1.         0.0228279  1.
  1.         1.        ]
 [1.         0.         0.         0.         0.02280974 1.
  0.         1.        ]
 [1.         0.         0.72437623 0.91509964 0.02286423 1.
  0.8576406  1.        ]
 [1.         0.         1.         1.         0.02286389 1.
  1.         1.        ]
 [1.         0.         0.1880265  0.52471365 0.02281643 1.
  0.56910862 1.        ]
 [1.         0.         1.         1.         0.02281193 1.
  1.         1.        ]
 [0.         0.         0.         0.         0.02280593 1.
  0.         1.        ]
 [1.         0.         0.96393015 1.         0.02287556 1.
  1.         1.        ]
 [1.         0.         0.97473146 1.         0.02282315 1.
  1.         1.        ]
 [1.         0.         1.         1.         0.02280822 1.
  1.         1.        ]]
#####################         POISON         ###############################################

############################################################################################

comm_round: 3 | global_test_acc: 88.462% | global_f1: 0.9387755102040817 | global_precision: 0.9583333333333334
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.96      0.92      0.94        25

    accuracy                           0.88        26
   macro avg       0.48      0.46      0.47        26
weighted avg       0.92      0.88      0.90        26
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [0]
 [0]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 8Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAfter Nodes removed: Rows 24 cols 8
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         1.         0.34328072 0.46997947 0.         0.
 1.         1.         0.         0.         1.         0.18424035
 0.         0.35827643 0.         1.         1.         0.68873282
 0.         0.         1.         1.         1.         0.
 1.         1.        ]
wv_ed shape (26,)
[0.         1.         0.54845394 0.00638886 0.         0.06577653
 1.         1.         0.06678873 0.         1.         0.28263734
 0.         0.22419107 0.         1.         1.         0.71843742
 0.         0.         1.         1.         1.         0.
 1.         1.        ]
wv_lg shape (26, 1)
[[0.02371876]
 [0.02261701]
 [0.02261642]
 [0.02262132]
 [0.02262763]
 [0.02264059]
 [0.02260223]
 [0.02261119]
 [0.02262948]
 [0.02262438]
 [0.02261456]
 [0.02261985]
 [0.02262178]
 [0.02261643]
 [0.02263496]
 [0.022635  ]
 [0.02261859]
 [0.02262042]
 [0.02260854]
 [0.02261669]
 [0.02261934]
 [0.02262908]
 [0.02261586]
 [0.02261918]
 [0.02261464]
 [0.02262637]]
wv_ndT shape (26,)
[0.         1.         0.         0.         1.         0.
 0.         1.         0.         0.         0.         0.05020201
 0.86878817 1.         0.40708903 0.53799124 0.06629946 1.
 0.         0.         1.         0.         0.15230558 0.91688762
 1.         0.63807846]
wv_std shape (26,)
[0.         1.         0.82186774 0.42047975 0.38033797 0.45189675
 1.         1.         0.47036603 0.         1.         0.53224384
 0.         0.40521043 0.         0.83624642 1.         1.
 0.         0.         1.         1.         1.         0.08308079
 1.         1.        ]
xy shape: (26, 8)
[[0.         1.         0.         0.         0.02371876 0.
  0.         0.        ]
 [1.         0.         1.         1.         0.02261701 1.
  1.         1.        ]
 [1.         0.         0.34328072 0.54845394 0.02261642 0.
  0.82186774 1.        ]
 [1.         0.         0.46997947 0.00638886 0.02262132 0.
  0.42047975 1.        ]
 [1.         0.         0.         0.         0.02262763 1.
  0.38033797 1.        ]
 [1.         0.         0.         0.06577653 0.02264059 0.
  0.45189675 1.        ]
 [1.         0.         1.         1.         0.02260223 0.
  1.         1.        ]
 [1.         0.         1.         1.         0.02261119 1.
  1.         1.        ]
 [1.         0.         0.         0.06678873 0.02262948 0.
  0.47036603 1.        ]
 [1.         0.         0.         0.         0.02262438 0.
  0.         1.        ]
 [1.         0.         1.         1.         0.02261456 0.
  1.         1.        ]
 [1.         0.         0.18424035 0.28263734 0.02261985 0.05020201
  0.53224384 1.        ]
 [1.         0.         0.         0.         0.02262178 0.86878817
  0.         1.        ]
 [1.         0.         0.35827643 0.22419107 0.02261643 1.
  0.40521043 1.        ]
 [1.         0.         0.         0.         0.02263496 0.40708903
  0.         1.        ]
 [1.         0.         1.         1.         0.022635   0.53799124
  0.83624642 1.        ]
 [1.         0.         1.         1.         0.02261859 0.06629946
  1.         1.        ]
 [1.         0.         0.68873282 0.71843742 0.02262042 1.
  1.         1.        ]
 [0.         0.         0.         0.         0.02260854 0.
  0.         1.        ]
 [1.         0.         0.         0.         0.02261669 0.
  0.         1.        ]
 [1.         0.         1.         1.         0.02261934 1.
  1.         1.        ]
 [1.         0.         1.         1.         0.02262908 0.
  1.         1.        ]
 [1.         0.         1.         1.         0.02261586 0.15230558
  1.         1.        ]
 [1.         0.         0.         0.         0.02261918 0.91688762
  0.08308079 1.        ]
 [1.         0.         1.         1.         0.02261464 1.
  1.         1.        ]
 [1.         0.         1.         1.         0.02262637 0.63807846
  1.         1.        ]]
#####################         POISON         ###############################################

############################################################################################

comm_round: 4 | global_test_acc: 80.769% | global_f1: 0.8936170212765958 | global_precision: 0.9545454545454546
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.95      0.84      0.89        25

    accuracy                           0.81        26
   macro avg       0.48      0.42      0.45        26
weighted avg       0.92      0.81      0.86        26
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [0]
 [1]
 [1]
 [0]
 [0]
 [1]
 [1]
 [1]
 [1]
 [0]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 8Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAfter Nodes removed: Rows 22 cols 8
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         1.         0.         0.         1.         1.
 0.93944406 0.         0.77449203 0.46901708 0.70542863 1.
 0.         1.         1.         0.40510765 0.         0.88175166
 0.10218355 1.         1.         0.84593744 0.06023416 0.84179025
 0.15529257 0.14653672]
wv_ed shape (26,)
[0.         1.         0.         0.         1.         0.85383816
 0.71306132 0.         1.         1.         0.72821279 1.
 0.00638809 1.         0.76269356 0.31905021 0.         0.97825427
 0.05374116 1.         1.         0.97839348 0.         0.81503496
 0.48575273 0.29162567]
wv_lg shape (26, 1)
[[0.02325378]
 [0.02197944]
 [0.02194556]
 [0.02195889]
 [0.02198781]
 [0.02196845]
 [0.021982  ]
 [0.02198942]
 [0.02198904]
 [0.02196429]
 [0.02197119]
 [0.02199402]
 [0.02198838]
 [0.02198542]
 [0.02199543]
 [0.02198402]
 [0.02194919]
 [0.02195476]
 [0.02196618]
 [0.02199834]
 [0.02199102]
 [0.02198902]
 [0.02196181]
 [0.02200281]
 [0.02198863]
 [0.02198723]]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.86192027 0.         0.29678651 1.         0.79598127
 0.63272102 0.         1.         1.         0.74839361 1.
 0.         1.         0.81867736 1.         0.         0.40942423
 0.         1.         1.         0.38761462 0.         1.
 0.         0.03547599]
xy shape: (26, 8)
[[0.         1.         0.         0.         0.02325378 1.
  0.         0.        ]
 [1.         0.         1.         1.         0.02197944 0.
  0.86192027 1.        ]
 [1.         0.         0.         0.         0.02194556 0.
  0.         1.        ]
 [1.         0.         0.         0.         0.02195889 0.
  0.29678651 1.        ]
 [1.         0.         1.         1.         0.02198781 0.
  1.         1.        ]
 [1.         0.         1.         0.85383816 0.02196845 0.
  0.79598127 1.        ]
 [1.         0.         0.93944406 0.71306132 0.021982   0.
  0.63272102 1.        ]
 [0.         0.         0.         0.         0.02198942 0.
  0.         1.        ]
 [1.         0.         0.77449203 1.         0.02198904 0.
  1.         1.        ]
 [1.         0.         0.46901708 1.         0.02196429 0.
  1.         1.        ]
 [1.         0.         0.70542863 0.72821279 0.02197119 0.
  0.74839361 1.        ]
 [1.         0.         1.         1.         0.02199402 0.
  1.         1.        ]
 [1.         0.         0.         0.00638809 0.02198838 0.
  0.         1.        ]
 [1.         0.         1.         1.         0.02198542 0.
  1.         1.        ]
 [1.         0.         1.         0.76269356 0.02199543 0.
  0.81867736 1.        ]
 [1.         0.         0.40510765 0.31905021 0.02198402 0.
  1.         1.        ]
 [1.         0.         0.         0.         0.02194919 0.
  0.         1.        ]
 [1.         0.         0.88175166 0.97825427 0.02195476 0.
  0.40942423 1.        ]
 [1.         0.         0.10218355 0.05374116 0.02196618 0.
  0.         1.        ]
 [1.         0.         1.         1.         0.02199834 0.
  1.         1.        ]
 [1.         0.         1.         1.         0.02199102 0.
  1.         1.        ]
 [1.         0.         0.84593744 0.97839348 0.02198902 0.
  0.38761462 1.        ]
 [1.         0.         0.06023416 0.         0.02196181 0.
  0.         1.        ]
 [1.         0.         0.84179025 0.81503496 0.02200281 0.
  1.         1.        ]
 [1.         0.         0.15529257 0.48575273 0.02198863 0.
  0.         1.        ]
 [1.         0.         0.14653672 0.29162567 0.02198723 0.
  0.03547599 1.        ]]
#####################         POISON         ###############################################

############################################################################################

comm_round: 5 | global_test_acc: 88.462% | global_f1: 0.9387755102040817 | global_precision: 0.9583333333333334
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.96      0.92      0.94        25

    accuracy                           0.88        26
   macro avg       0.48      0.46      0.47        26
weighted avg       0.92      0.88      0.90        26
poison scaling shape: (26, 1)
[[1]
 [1]
 [0]
 [1]
 [1]
 [0]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 8Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAfter Nodes removed: Rows 24 cols 8
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.92146319 0.6061601  0.11445326 0.         0.
 1.         0.         0.36630512 0.         0.93145681 0.
 1.         0.34184963 0.         0.73145862 1.         1.
 0.         0.23288569 1.         0.23152498 1.         0.34816592
 0.84012406 0.4858794 ]
wv_ed shape (26,)
[0.         1.         0.14050653 0.         0.         0.
 1.         0.         0.         0.         0.6911941  0.
 1.         0.38860464 0.         0.27510853 1.         0.55640811
 0.         0.46717508 1.         0.         1.         0.
 0.93619232 0.10341522]
wv_lg shape (26, 1)
[[0.02310927]
 [0.02184237]
 [0.02186381]
 [0.02187333]
 [0.0218429 ]
 [0.02186097]
 [0.02186609]
 [0.02184729]
 [0.02184676]
 [0.02186586]
 [0.02189161]
 [0.02186175]
 [0.02185808]
 [0.02187437]
 [0.02187751]
 [0.02184263]
 [0.02185823]
 [0.02185755]
 [0.02186544]
 [0.02187564]
 [0.02186576]
 [0.02187158]
 [0.02184889]
 [0.02185146]
 [0.02187017]
 [0.0218584 ]]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.9509244  0.02517984 0.         0.         0.
 1.         0.         0.         0.         0.97953923 0.
 1.         0.         0.         0.         1.         1.
 0.         0.84394653 1.         0.         1.         0.
 1.         0.        ]
xy shape: (26, 8)
[[0.         1.         0.         0.         0.02310927 1.
  0.         0.        ]
 [1.         0.         0.92146319 1.         0.02184237 0.
  0.9509244  1.        ]
 [1.         0.         0.6061601  0.14050653 0.02186381 0.
  0.02517984 1.        ]
 [1.         0.         0.11445326 0.         0.02187333 0.
  0.         1.        ]
 [1.         0.         0.         0.         0.0218429  0.
  0.         1.        ]
 [1.         0.         0.         0.         0.02186097 0.
  0.         1.        ]
 [1.         0.         1.         1.         0.02186609 0.
  1.         1.        ]
 [1.         0.         0.         0.         0.02184729 0.
  0.         1.        ]
 [1.         0.         0.36630512 0.         0.02184676 0.
  0.         1.        ]
 [1.         0.         0.         0.         0.02186586 0.
  0.         1.        ]
 [1.         0.         0.93145681 0.6911941  0.02189161 0.
  0.97953923 1.        ]
 [0.         0.         0.         0.         0.02186175 0.
  0.         1.        ]
 [1.         0.         1.         1.         0.02185808 0.
  1.         1.        ]
 [1.         0.         0.34184963 0.38860464 0.02187437 0.
  0.         1.        ]
 [1.         0.         0.         0.         0.02187751 0.
  0.         1.        ]
 [1.         0.         0.73145862 0.27510853 0.02184263 0.
  0.         1.        ]
 [1.         0.         1.         1.         0.02185823 0.
  1.         1.        ]
 [1.         0.         1.         0.55640811 0.02185755 0.
  1.         1.        ]
 [1.         0.         0.         0.         0.02186544 0.
  0.         1.        ]
 [1.         0.         0.23288569 0.46717508 0.02187564 0.
  0.84394653 1.        ]
 [1.         0.         1.         1.         0.02186576 0.
  1.         1.        ]
 [1.         0.         0.23152498 0.         0.02187158 0.
  0.         1.        ]
 [1.         0.         1.         1.         0.02184889 0.
  1.         1.        ]
 [1.         0.         0.34816592 0.         0.02185146 0.
  0.         1.        ]
 [1.         0.         0.84012406 0.93619232 0.02187017 0.
  1.         1.        ]
 [1.         0.         0.4858794  0.10341522 0.0218584  0.
  0.         1.        ]]
#####################         POISON         ###############################################

############################################################################################

comm_round: 6 | global_test_acc: 96.154% | global_f1: 0.9795918367346939 | global_precision: 1.0
              precision    recall  f1-score   support

           0       0.50      1.00      0.67         1
           1       1.00      0.96      0.98        25

    accuracy                           0.96        26
   macro avg       0.75      0.98      0.82        26
weighted avg       0.98      0.96      0.97        26
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [0]
 [1]
 [1]
 [1]
 [0]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 8Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAfter Nodes removed: Rows 24 cols 8
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.         0.         0.         0.43569134 1.
 0.70290089 0.6791002  0.         0.         0.75118184 0.82749274
 0.2992663  1.         0.         0.         0.41005874 0.98031402
 0.98915431 0.59403497 0.         1.         0.         0.
 0.15874391 0.10352226]
wv_ed shape (26,)
[0.         0.         0.03896549 0.         0.35729427 1.
 0.68713554 0.02659478 0.         0.         0.85982    0.40026599
 0.         1.         0.         0.         0.80352305 0.50273354
 0.14098211 0.43901819 0.         1.         0.         0.
 0.67849615 0.        ]
wv_lg shape (26, 1)
[[0.02297952]
 [0.02177211]
 [0.02175317]
 [0.02173372]
 [0.02173666]
 [0.02176239]
 [0.02174366]
 [0.02175085]
 [0.02175819]
 [0.0217574 ]
 [0.02171941]
 [0.02174925]
 [0.02171525]
 [0.02173405]
 [0.02175744]
 [0.02177059]
 [0.02175509]
 [0.02175899]
 [0.02173368]
 [0.02173354]
 [0.02175342]
 [0.02174706]
 [0.0217521 ]
 [0.02173666]
 [0.02172589]
 [0.02175913]]
wv_ndT shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_std shape (26,)
[0.         0.         0.37605893 0.         0.85814169 1.
 0.64437414 0.4647537  0.4916842  0.         1.         0.
 0.1723283  1.         0.         0.         0.96319484 0.76473559
 0.         0.40406175 0.         1.         0.         0.
 1.         0.40040966]
xy shape: (26, 8)
[[0.         1.         0.         0.         0.02297952 0.
  0.         0.        ]
 [1.         0.         0.         0.         0.02177211 1.
  0.         1.        ]
 [1.         0.         0.         0.03896549 0.02175317 1.
  0.37605893 1.        ]
 [1.         0.         0.         0.         0.02173372 1.
  0.         1.        ]
 [1.         0.         0.43569134 0.35729427 0.02173666 1.
  0.85814169 1.        ]
 [1.         0.         1.         1.         0.02176239 1.
  1.         1.        ]
 [1.         0.         0.70290089 0.68713554 0.02174366 1.
  0.64437414 1.        ]
 [1.         0.         0.6791002  0.02659478 0.02175085 1.
  0.4647537  1.        ]
 [1.         0.         0.         0.         0.02175819 1.
  0.4916842  1.        ]
 [1.         0.         0.         0.         0.0217574  1.
  0.         1.        ]
 [1.         0.         0.75118184 0.85982    0.02171941 1.
  1.         1.        ]
 [1.         0.         0.82749274 0.40026599 0.02174925 1.
  0.         1.        ]
 [1.         0.         0.2992663  0.         0.02171525 1.
  0.1723283  1.        ]
 [1.         0.         1.         1.         0.02173405 1.
  1.         1.        ]
 [1.         0.         0.         0.         0.02175744 1.
  0.         1.        ]
 [0.         0.         0.         0.         0.02177059 1.
  0.         1.        ]
 [1.         0.         0.41005874 0.80352305 0.02175509 1.
  0.96319484 1.        ]
 [1.         0.         0.98031402 0.50273354 0.02175899 1.
  0.76473559 1.        ]
 [1.         0.         0.98915431 0.14098211 0.02173368 1.
  0.         1.        ]
 [1.         0.         0.59403497 0.43901819 0.02173354 1.
  0.40406175 1.        ]
 [1.         0.         0.         0.         0.02175342 1.
  0.         1.        ]
 [1.         0.         1.         1.         0.02174706 1.
  1.         1.        ]
 [1.         0.         0.         0.         0.0217521  1.
  0.         1.        ]
 [1.         0.         0.         0.         0.02173666 1.
  0.         1.        ]
 [1.         0.         0.15874391 0.67849615 0.02172589 1.
  1.         1.        ]
 [1.         0.         0.10352226 0.         0.02175913 1.
  0.40040966 1.        ]]
#####################         POISON         ###############################################

############################################################################################

comm_round: 7 | global_test_acc: 73.077% | global_f1: 0.8444444444444444 | global_precision: 0.95
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.95      0.76      0.84        25

    accuracy                           0.73        26
   macro avg       0.47      0.38      0.42        26
weighted avg       0.91      0.73      0.81        26
poison scaling shape: (26, 1)
[[1]
 [0]
 [0]
 [0]
 [0]
 [1]
 [1]
 [1]
 [1]
 [0]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [0]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 8Adding node: 0 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAfter Nodes removed: Rows 20 cols 8
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         1.         1.         0.         0.05910942 0.
 0.         0.26811027 1.         0.         0.         0.
 0.         1.         1.         0.90995672 1.         1.
 0.         0.         0.72754154 1.         0.         0.
 0.         0.91311823]
wv_ed shape (26,)
[0.         1.         1.         0.67422781 0.8390768  0.29266989
 0.         0.         1.         0.38593181 0.31834135 0.
 0.         1.         1.         1.         1.         1.
 0.         0.         1.         1.         0.         1.
 0.         0.75194119]
wv_lg shape (26, 1)
[[0.02250452]
 [0.02096535]
 [0.02095636]
 [0.02096442]
 [0.02095768]
 [0.02093674]
 [0.02095235]
 [0.02095427]
 [0.02088339]
 [0.02092632]
 [0.02090261]
 [0.02091419]
 [0.02093593]
 [0.0208882 ]
 [0.02093331]
 [0.02091295]
 [0.02090959]
 [0.02095647]
 [0.02093954]
 [0.02093163]
 [0.02094476]
 [0.02089578]
 [0.02088555]
 [0.02093715]
 [0.02094998]
 [0.02095641]]
wv_ndT shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_std shape (26,)
[0.         0.89895681 0.8881861  0.5671064  0.         0.
 0.3234216  0.         1.         0.3348513  0.32679062 0.
 0.76745935 0.65172084 0.94436048 0.         1.         1.
 0.         0.21873091 0.84291357 0.67190876 0.         1.
 0.62040713 1.        ]
xy shape: (26, 8)
[[0.         1.         0.         0.         0.02250452 0.
  0.         0.        ]
 [1.         0.         1.         1.         0.02096535 1.
  0.89895681 1.        ]
 [1.         0.         1.         1.         0.02095636 1.
  0.8881861  1.        ]
 [1.         0.         0.         0.67422781 0.02096442 1.
  0.5671064  1.        ]
 [1.         0.         0.05910942 0.8390768  0.02095768 1.
  0.         1.        ]
 [1.         0.         0.         0.29266989 0.02093674 1.
  0.         1.        ]
 [1.         0.         0.         0.         0.02095235 1.
  0.3234216  1.        ]
 [1.         0.         0.26811027 0.         0.02095427 1.
  0.         1.        ]
 [1.         0.         1.         1.         0.02088339 1.
  1.         1.        ]
 [1.         0.         0.         0.38593181 0.02092632 1.
  0.3348513  1.        ]
 [1.         0.         0.         0.31834135 0.02090261 1.
  0.32679062 1.        ]
 [1.         0.         0.         0.         0.02091419 1.
  0.         1.        ]
 [0.         0.         0.         0.         0.02093593 1.
  0.76745935 1.        ]
 [1.         0.         1.         1.         0.0208882  1.
  0.65172084 1.        ]
 [1.         0.         1.         1.         0.02093331 1.
  0.94436048 1.        ]
 [1.         0.         0.90995672 1.         0.02091295 1.
  0.         1.        ]
 [1.         0.         1.         1.         0.02090959 1.
  1.         1.        ]
 [1.         0.         1.         1.         0.02095647 1.
  1.         1.        ]
 [1.         0.         0.         0.         0.02093954 1.
  0.         1.        ]
 [1.         0.         0.         0.         0.02093163 1.
  0.21873091 1.        ]
 [1.         0.         0.72754154 1.         0.02094476 1.
  0.84291357 1.        ]
 [1.         0.         1.         1.         0.02089578 1.
  0.67190876 1.        ]
 [1.         0.         0.         0.         0.02088555 1.
  0.         1.        ]
 [1.         0.         0.         1.         0.02093715 1.
  1.         1.        ]
 [1.         0.         0.         0.         0.02094998 1.
  0.62040713 1.        ]
 [1.         0.         0.91311823 0.75194119 0.02095641 1.
  1.         1.        ]]
#####################         POISON         ###############################################

############################################################################################

comm_round: 8 | global_test_acc: 92.308% | global_f1: 0.96 | global_precision: 0.96
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.96      0.96      0.96        25

    accuracy                           0.92        26
   macro avg       0.48      0.48      0.48        26
weighted avg       0.92      0.92      0.92        26
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [0]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 8Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAfter Nodes removed: Rows 25 cols 8
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.         1.         0.96537211 1.         0.
 0.         0.74543405 1.         0.         0.94011562 0.46419717
 1.         0.31844792 0.         1.         1.         1.
 0.77927549 1.         0.31053758 0.         1.         0.
 1.         0.79780754]
wv_ed shape (26,)
[0.         0.17738278 0.71334141 0.21010786 1.         0.
 0.         0.30046369 0.77151112 0.         0.49141689 0.85029201
 0.24736126 0.         0.         1.         1.         1.
 0.         1.         0.11436518 0.         1.         0.
 0.91181757 0.        ]
wv_lg shape (26, 1)
[[0.02247101]
 [0.02113613]
 [0.02110764]
 [0.02113912]
 [0.02114391]
 [0.02111007]
 [0.02111268]
 [0.0211241 ]
 [0.02110864]
 [0.02109132]
 [0.0211177 ]
 [0.02111671]
 [0.02111739]
 [0.02112748]
 [0.02113069]
 [0.02115211]
 [0.02112238]
 [0.02110575]
 [0.02113524]
 [0.0211128 ]
 [0.02111783]
 [0.02110097]
 [0.02111799]
 [0.02112764]
 [0.02113083]
 [0.02112047]]
wv_ndT shape (26,)
[0.         1.         0.88947008 0.41059069 0.35513586 1.
 0.41103719 0.52617356 0.70402141 1.         1.         0.57097835
 0.27428788 0.58774499 0.70287911 0.52424912 0.72812175 0.07867681
 0.47154708 0.84738049 0.71994196 0.79551122 1.         0.96690672
 0.51758742 0.95413415]
wv_std shape (26,)
[0.         0.35300453 0.61952125 0.         1.         0.
 0.         0.32852956 0.50265253 0.         1.         0.94048702
 0.         0.         0.         1.         1.         1.
 0.59070318 1.         0.         0.         0.92417469 0.
 0.51529378 0.        ]
xy shape: (26, 8)
[[0.         1.         0.         0.         0.02247101 0.
  0.         0.        ]
 [1.         0.         0.         0.17738278 0.02113613 1.
  0.35300453 1.        ]
 [1.         0.         1.         0.71334141 0.02110764 0.88947008
  0.61952125 1.        ]
 [1.         0.         0.96537211 0.21010786 0.02113912 0.41059069
  0.         1.        ]
 [1.         0.         1.         1.         0.02114391 0.35513586
  1.         1.        ]
 [0.         0.         0.         0.         0.02111007 1.
  0.         1.        ]
 [1.         0.         0.         0.         0.02111268 0.41103719
  0.         1.        ]
 [1.         0.         0.74543405 0.30046369 0.0211241  0.52617356
  0.32852956 1.        ]
 [1.         0.         1.         0.77151112 0.02110864 0.70402141
  0.50265253 1.        ]
 [1.         0.         0.         0.         0.02109132 1.
  0.         1.        ]
 [1.         0.         0.94011562 0.49141689 0.0211177  1.
  1.         1.        ]
 [1.         0.         0.46419717 0.85029201 0.02111671 0.57097835
  0.94048702 1.        ]
 [1.         0.         1.         0.24736126 0.02111739 0.27428788
  0.         1.        ]
 [1.         0.         0.31844792 0.         0.02112748 0.58774499
  0.         1.        ]
 [1.         0.         0.         0.         0.02113069 0.70287911
  0.         1.        ]
 [1.         0.         1.         1.         0.02115211 0.52424912
  1.         1.        ]
 [1.         0.         1.         1.         0.02112238 0.72812175
  1.         1.        ]
 [1.         0.         1.         1.         0.02110575 0.07867681
  1.         1.        ]
 [1.         0.         0.77927549 0.         0.02113524 0.47154708
  0.59070318 1.        ]
 [1.         0.         1.         1.         0.0211128  0.84738049
  1.         1.        ]
 [1.         0.         0.31053758 0.11436518 0.02111783 0.71994196
  0.         1.        ]
 [1.         0.         0.         0.         0.02110097 0.79551122
  0.         1.        ]
 [1.         0.         1.         1.         0.02111799 1.
  0.92417469 1.        ]
 [1.         0.         0.         0.         0.02112764 0.96690672
  0.         1.        ]
 [1.         0.         1.         0.91181757 0.02113083 0.51758742
  0.51529378 1.        ]
 [1.         0.         0.79780754 0.         0.02112047 0.95413415
  0.         1.        ]]
#####################         POISON         ###############################################

############################################################################################

comm_round: 9 | global_test_acc: 88.462% | global_f1: 0.9361702127659575 | global_precision: 1.0
              precision    recall  f1-score   support

           0       0.25      1.00      0.40         1
           1       1.00      0.88      0.94        25

    accuracy                           0.88        26
   macro avg       0.62      0.94      0.67        26
weighted avg       0.97      0.88      0.92        26
poison scaling shape: (26, 1)
[[1]
 [0]
 [1]
 [1]
 [0]
 [0]
 [0]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 8Adding node: 0 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAfter Nodes removed: Rows 22 cols 8
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         1.         1.         0.         1.         1.
 1.         0.         1.         0.98055961 0.94846705 0.73141338
 1.         1.         1.         1.         1.         1.
 0.86756724 0.76909859 0.30894177 1.         0.47139422 1.
 1.         1.        ]
wv_ed shape (26,)
[0.         1.         1.         0.         1.         1.
 1.         0.10837453 1.         0.20836314 0.         0.9200281
 1.         1.         1.         1.         1.         1.
 1.         1.         0.         1.         0.         1.
 1.         0.39673695]
wv_lg shape (26, 1)
[[0.02226989]
 [0.02075941]
 [0.02076106]
 [0.02078519]
 [0.02076119]
 [0.02079907]
 [0.02080518]
 [0.02079089]
 [0.02079188]
 [0.02078982]
 [0.02078738]
 [0.02079238]
 [0.02076183]
 [0.02076872]
 [0.02079168]
 [0.02074756]
 [0.02076137]
 [0.02080037]
 [0.02077801]
 [0.0207855 ]
 [0.02079702]
 [0.02079567]
 [0.0207954 ]
 [0.02078034]
 [0.02077015]
 [0.02077899]]
wv_ndT shape (26,)
[0.         1.         1.         0.87154754 0.97712212 1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.92892777 1.
 1.         1.         1.         1.         1.         1.
 1.         1.        ]
wv_std shape (26,)
[0.         0.29270824 1.         0.         1.         1.
 0.15193617 0.27550969 1.         0.         0.         0.87025554
 0.94486747 1.         0.98802496 1.         1.         0.47437599
 1.         1.         0.         1.         0.         1.
 1.         0.07327144]
xy shape: (26, 8)
[[0.         1.         0.         0.         0.02226989 0.
  0.         0.        ]
 [1.         0.         1.         1.         0.02075941 1.
  0.29270824 1.        ]
 [1.         0.         1.         1.         0.02076106 1.
  1.         1.        ]
 [0.         0.         0.         0.         0.02078519 0.87154754
  0.         1.        ]
 [1.         0.         1.         1.         0.02076119 0.97712212
  1.         1.        ]
 [1.         0.         1.         1.         0.02079907 1.
  1.         1.        ]
 [1.         0.         1.         1.         0.02080518 1.
  0.15193617 1.        ]
 [1.         0.         0.         0.10837453 0.02079089 1.
  0.27550969 1.        ]
 [1.         0.         1.         1.         0.02079188 1.
  1.         1.        ]
 [1.         0.         0.98055961 0.20836314 0.02078982 1.
  0.         1.        ]
 [1.         0.         0.94846705 0.         0.02078738 1.
  0.         1.        ]
 [1.         0.         0.73141338 0.9200281  0.02079238 1.
  0.87025554 1.        ]
 [1.         0.         1.         1.         0.02076183 1.
  0.94486747 1.        ]
 [1.         0.         1.         1.         0.02076872 1.
  1.         1.        ]
 [1.         0.         1.         1.         0.02079168 1.
  0.98802496 1.        ]
 [1.         0.         1.         1.         0.02074756 1.
  1.         1.        ]
 [1.         0.         1.         1.         0.02076137 0.92892777
  1.         1.        ]
 [1.         0.         1.         1.         0.02080037 1.
  0.47437599 1.        ]
 [1.         0.         0.86756724 1.         0.02077801 1.
  1.         1.        ]
 [1.         0.         0.76909859 1.         0.0207855  1.
  1.         1.        ]
 [1.         0.         0.30894177 0.         0.02079702 1.
  0.         1.        ]
 [1.         0.         1.         1.         0.02079567 1.
  1.         1.        ]
 [1.         0.         0.47139422 0.         0.0207954  1.
  0.         1.        ]
 [1.         0.         1.         1.         0.02078034 1.
  1.         1.        ]
 [1.         0.         1.         1.         0.02077015 1.
  1.         1.        ]
 [1.         0.         1.         0.39673695 0.02077899 1.
  0.07327144 1.        ]]
#####################         POISON         ###############################################

############################################################################################

comm_round: 10 | global_test_acc: 92.308% | global_f1: 0.96 | global_precision: 0.96
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.96      0.96      0.96        25

    accuracy                           0.92        26
   macro avg       0.48      0.48      0.48        26
weighted avg       0.92      0.92      0.92        26
poison scaling shape: (26, 1)
[[1]
 [0]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 8Adding node: 0 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAfter Nodes removed: Rows 25 cols 8
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         1.         0.10645947 0.         0.65228055 0.
 0.1310038  0.         1.         1.         1.         0.
 1.         1.         0.         0.         1.         0.
 0.24559045 1.         0.         0.         0.         1.
 0.         0.        ]
wv_ed shape (26,)
[0.         1.         0.         0.         0.78184304 0.01030359
 0.47060665 0.07526923 1.         1.         1.         0.
 1.         1.         0.         0.         0.82330113 0.
 0.54748044 1.         0.         0.44109919 0.70192352 1.
 0.         0.49348769]
wv_lg shape (26, 1)
[[0.02232456]
 [0.02094054]
 [0.02095165]
 [0.02091758]
 [0.02095633]
 [0.02096038]
 [0.020968  ]
 [0.02095362]
 [0.02094772]
 [0.02096512]
 [0.02094699]
 [0.02096502]
 [0.0209759 ]
 [0.02093698]
 [0.02095257]
 [0.02096049]
 [0.02094474]
 [0.0209702 ]
 [0.02095202]
 [0.02094056]
 [0.02095002]
 [0.02094138]
 [0.02095443]
 [0.02093299]
 [0.02093109]
 [0.02090501]]
wv_ndT shape (26,)
[1.         0.         0.82734822 0.45382158 0.55848043 1.
 0.49047041 0.57010731 0.         0.         0.38122604 0.
 0.         0.21433284 1.         1.         0.51523959 0.
 0.6852318  0.81291884 0.         0.1442281  1.         0.
 0.6675826  0.50995002]
wv_std shape (26,)
[0.         1.         0.         0.         0.31267807 0.
 0.34580679 0.         1.         1.         0.97976987 0.
 1.         1.         0.         0.         0.3627146  0.05585131
 0.18370766 0.69721101 0.         0.25460486 0.76716532 1.
 0.         0.36868462]
xy shape: (26, 8)
[[0.         1.         0.         0.         0.02232456 1.
  0.         0.        ]
 [1.         0.         1.         1.         0.02094054 0.
  1.         1.        ]
 [1.         0.         0.10645947 0.         0.02095165 0.82734822
  0.         1.        ]
 [1.         0.         0.         0.         0.02091758 0.45382158
  0.         1.        ]
 [1.         0.         0.65228055 0.78184304 0.02095633 0.55848043
  0.31267807 1.        ]
 [1.         0.         0.         0.01030359 0.02096038 1.
  0.         1.        ]
 [1.         0.         0.1310038  0.47060665 0.020968   0.49047041
  0.34580679 1.        ]
 [1.         0.         0.         0.07526923 0.02095362 0.57010731
  0.         1.        ]
 [1.         0.         1.         1.         0.02094772 0.
  1.         1.        ]
 [1.         0.         1.         1.         0.02096512 0.
  1.         1.        ]
 [1.         0.         1.         1.         0.02094699 0.38122604
  0.97976987 1.        ]
 [1.         0.         0.         0.         0.02096502 0.
  0.         1.        ]
 [1.         0.         1.         1.         0.0209759  0.
  1.         1.        ]
 [1.         0.         1.         1.         0.02093698 0.21433284
  1.         1.        ]
 [0.         0.         0.         0.         0.02095257 1.
  0.         1.        ]
 [1.         0.         0.         0.         0.02096049 1.
  0.         1.        ]
 [1.         0.         1.         0.82330113 0.02094474 0.51523959
  0.3627146  1.        ]
 [1.         0.         0.         0.         0.0209702  0.
  0.05585131 1.        ]
 [1.         0.         0.24559045 0.54748044 0.02095202 0.6852318
  0.18370766 1.        ]
 [1.         0.         1.         1.         0.02094056 0.81291884
  0.69721101 1.        ]
 [1.         0.         0.         0.         0.02095002 0.
  0.         1.        ]
 [1.         0.         0.         0.44109919 0.02094138 0.1442281
  0.25460486 1.        ]
 [1.         0.         0.         0.70192352 0.02095443 1.
  0.76716532 1.        ]
 [1.         0.         1.         1.         0.02093299 0.
  1.         1.        ]
 [1.         0.         0.         0.         0.02093109 0.6675826
  0.         1.        ]
 [1.         0.         0.         0.49348769 0.02090501 0.50995002
  0.36868462 1.        ]]
#####################         POISON         ###############################################

############################################################################################

comm_round: 11 | global_test_acc: 96.154% | global_f1: 0.9803921568627451 | global_precision: 0.9615384615384616
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.96      1.00      0.98        25

    accuracy                           0.96        26
   macro avg       0.48      0.50      0.49        26
weighted avg       0.92      0.96      0.94        26
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 8Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAfter Nodes removed: Rows 26 cols 8
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.         1.         0.24621092 0.02150393 0.
 0.         0.0538904  1.         0.09582039 0.69619087 0.54039188
 1.         0.         1.         0.60898143 0.         0.69694656
 0.         0.         1.         1.         1.         0.
 1.         0.        ]
wv_ed shape (26,)
[0.         0.26807577 0.77585423 0.04129921 0.         0.
 0.         0.15328651 1.         0.         0.78034616 0.69345814
 1.         0.         1.         0.51814902 0.         0.76667668
 0.         0.         1.         1.         1.         0.
 1.         0.        ]
wv_lg shape (26, 1)
[[0.02239071]
 [0.0212201 ]
 [0.02121209]
 [0.02122282]
 [0.02121081]
 [0.02122351]
 [0.02123778]
 [0.02122319]
 [0.02122093]
 [0.02121169]
 [0.0212438 ]
 [0.02122504]
 [0.02123253]
 [0.02124053]
 [0.02126192]
 [0.02123447]
 [0.02119424]
 [0.02124347]
 [0.02123815]
 [0.02122407]
 [0.02119062]
 [0.0212229 ]
 [0.02122177]
 [0.0212186 ]
 [0.02120173]
 [0.02122442]]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.60517817 0.70890631 0.4059609  0.2455946  0.
 0.         0.52829655 1.         0.         0.70183243 0.76082833
 1.         0.         1.         0.76547391 0.         0.56231093
 0.         0.         1.         1.         1.         0.
 1.         0.        ]
xy shape: (26, 8)
[[0.         1.         0.         0.         0.02239071 1.
  0.         0.        ]
 [1.         0.         0.         0.26807577 0.0212201  0.
  0.60517817 1.        ]
 [1.         0.         1.         0.77585423 0.02121209 0.
  0.70890631 1.        ]
 [1.         0.         0.24621092 0.04129921 0.02122282 0.
  0.4059609  1.        ]
 [1.         0.         0.02150393 0.         0.02121081 0.
  0.2455946  1.        ]
 [1.         0.         0.         0.         0.02122351 0.
  0.         1.        ]
 [0.         0.         0.         0.         0.02123778 0.
  0.         1.        ]
 [1.         0.         0.0538904  0.15328651 0.02122319 0.
  0.52829655 1.        ]
 [1.         0.         1.         1.         0.02122093 0.
  1.         1.        ]
 [1.         0.         0.09582039 0.         0.02121169 0.
  0.         1.        ]
 [1.         0.         0.69619087 0.78034616 0.0212438  0.
  0.70183243 1.        ]
 [1.         0.         0.54039188 0.69345814 0.02122504 0.
  0.76082833 1.        ]
 [1.         0.         1.         1.         0.02123253 0.
  1.         1.        ]
 [1.         0.         0.         0.         0.02124053 0.
  0.         1.        ]
 [1.         0.         1.         1.         0.02126192 0.
  1.         1.        ]
 [1.         0.         0.60898143 0.51814902 0.02123447 0.
  0.76547391 1.        ]
 [1.         0.         0.         0.         0.02119424 0.
  0.         1.        ]
 [1.         0.         0.69694656 0.76667668 0.02124347 0.
  0.56231093 1.        ]
 [1.         0.         0.         0.         0.02123815 0.
  0.         1.        ]
 [1.         0.         0.         0.         0.02122407 0.
  0.         1.        ]
 [1.         0.         1.         1.         0.02119062 0.
  1.         1.        ]
 [1.         0.         1.         1.         0.0212229  0.
  1.         1.        ]
 [1.         0.         1.         1.         0.02122177 0.
  1.         1.        ]
 [1.         0.         0.         0.         0.0212186  0.
  0.         1.        ]
 [1.         0.         1.         1.         0.02120173 0.
  1.         1.        ]
 [1.         0.         0.         0.         0.02122442 0.
  0.         1.        ]]
#####################         POISON         ###############################################

############################################################################################

comm_round: 12 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           0       1.00      1.00      1.00         1
           1       1.00      1.00      1.00        25

    accuracy                           1.00        26
   macro avg       1.00      1.00      1.00        26
weighted avg       1.00      1.00      1.00        26
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [0]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 8Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAfter Nodes removed: Rows 25 cols 8
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.         0.         0.60792362 0.         0.31919333
 1.         0.41133912 0.         1.         1.         0.03631178
 0.         1.         0.         0.71536373 0.         0.6786874
 0.         0.62847781 0.         0.         0.         0.1697237
 0.         0.21933055]
wv_ed shape (26,)
[0.         0.02950574 0.         0.5224796  0.         0.18828916
 1.         0.73777948 0.         1.         1.         0.18600122
 0.         1.         0.         0.25317722 0.         0.64402821
 0.17205842 0.42768586 0.         0.         0.         0.
 0.         0.17078141]
wv_lg shape (26, 1)
[[0.02240394]
 [0.02131256]
 [0.02130822]
 [0.02130782]
 [0.02129574]
 [0.02129631]
 [0.02128477]
 [0.02129785]
 [0.02129943]
 [0.02129619]
 [0.02130252]
 [0.02130234]
 [0.02130967]
 [0.0213139 ]
 [0.0213057 ]
 [0.02130014]
 [0.02130685]
 [0.02132165]
 [0.02130186]
 [0.02130302]
 [0.02129733]
 [0.02130546]
 [0.02128418]
 [0.02129613]
 [0.02130473]
 [0.02130009]]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.06473167 0.         0.17863693 0.         0.09796798
 0.87294189 0.59880869 0.         1.         1.         0.
 0.         0.87438344 0.         0.         0.         0.583752
 0.         0.42304328 0.         0.         0.         0.0101151
 0.         0.        ]
xy shape: (26, 8)
[[0.         1.         0.         0.         0.02240394 1.
  0.         0.        ]
 [1.         0.         0.         0.02950574 0.02131256 0.
  0.06473167 1.        ]
 [1.         0.         0.         0.         0.02130822 0.
  0.         1.        ]
 [1.         0.         0.60792362 0.5224796  0.02130782 0.
  0.17863693 1.        ]
 [1.         0.         0.         0.         0.02129574 0.
  0.         1.        ]
 [1.         0.         0.31919333 0.18828916 0.02129631 0.
  0.09796798 1.        ]
 [1.         0.         1.         1.         0.02128477 0.
  0.87294189 1.        ]
 [1.         0.         0.41133912 0.73777948 0.02129785 0.
  0.59880869 1.        ]
 [1.         0.         0.         0.         0.02129943 0.
  0.         1.        ]
 [1.         0.         1.         1.         0.02129619 0.
  1.         1.        ]
 [1.         0.         1.         1.         0.02130252 0.
  1.         1.        ]
 [1.         0.         0.03631178 0.18600122 0.02130234 0.
  0.         1.        ]
 [1.         0.         0.         0.         0.02130967 0.
  0.         1.        ]
 [1.         0.         1.         1.         0.0213139  0.
  0.87438344 1.        ]
 [1.         0.         0.         0.         0.0213057  0.
  0.         1.        ]
 [1.         0.         0.71536373 0.25317722 0.02130014 0.
  0.         1.        ]
 [1.         0.         0.         0.         0.02130685 0.
  0.         1.        ]
 [1.         0.         0.6786874  0.64402821 0.02132165 0.
  0.583752   1.        ]
 [1.         0.         0.         0.17205842 0.02130186 0.
  0.         1.        ]
 [1.         0.         0.62847781 0.42768586 0.02130302 0.
  0.42304328 1.        ]
 [1.         0.         0.         0.         0.02129733 0.
  0.         1.        ]
 [0.         0.         0.         0.         0.02130546 0.
  0.         1.        ]
 [1.         0.         0.         0.         0.02128418 0.
  0.         1.        ]
 [1.         0.         0.1697237  0.         0.02129613 0.
  0.0101151  1.        ]
 [1.         0.         0.         0.         0.02130473 0.
  0.         1.        ]
 [1.         0.         0.21933055 0.17078141 0.02130009 0.
  0.         1.        ]]
#####################         POISON         ###############################################

############################################################################################

comm_round: 13 | global_test_acc: 92.308% | global_f1: 0.96 | global_precision: 0.96
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.96      0.96      0.96        25

    accuracy                           0.92        26
   macro avg       0.48      0.48      0.48        26
weighted avg       0.92      0.92      0.92        26
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [0]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 8Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAfter Nodes removed: Rows 25 cols 8
y shape (26,)
[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (26,)
[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1.]
wv_fg shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_mn shape (26,)
[0.         0.         0.         0.         0.         0.72535345
 0.         1.         0.         0.17389463 0.02362609 0.
 0.         0.70530272 0.         1.         0.         0.1643343
 0.         0.         1.         0.         0.66001455 0.
 0.         1.        ]
wv_ed shape (26,)
[0.         0.         0.1221585  0.         0.         0.6364088
 0.         1.         0.         0.         0.         0.
 0.         0.35822719 0.         1.         0.         0.
 0.         0.         1.         0.         1.         0.
 0.         1.        ]
wv_lg shape (26, 1)
[[0.02243115]
 [0.02135084]
 [0.02136098]
 [0.02133721]
 [0.02134834]
 [0.02134771]
 [0.02135115]
 [0.02136715]
 [0.02136249]
 [0.02133596]
 [0.02135691]
 [0.0213289 ]
 [0.0213449 ]
 [0.02134598]
 [0.02134165]
 [0.02135436]
 [0.02135674]
 [0.02135002]
 [0.02135918]
 [0.02134692]
 [0.02136888]
 [0.02136417]
 [0.02134041]
 [0.0213483 ]
 [0.02136502]
 [0.02135914]]
wv_ndT shape (26,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0.]
wv_std shape (26,)
[0.         0.         0.22904207 0.         0.         0.53854252
 0.37128475 1.         0.         0.         0.         0.
 0.         0.17473974 0.         1.         0.         0.
 0.         0.         1.         0.         1.         0.
 0.         1.        ]
xy shape: (26, 8)
[[0.         1.         0.         0.         0.02243115 1.
  0.         0.        ]
 [1.         0.         0.         0.         0.02135084 0.
  0.         1.        ]
 [1.         0.         0.         0.1221585  0.02136098 0.
  0.22904207 1.        ]
 [1.         0.         0.         0.         0.02133721 0.
  0.         1.        ]
 [1.         0.         0.         0.         0.02134834 0.
  0.         1.        ]
 [1.         0.         0.72535345 0.6364088  0.02134771 0.
  0.53854252 1.        ]
 [1.         0.         0.         0.         0.02135115 0.
  0.37128475 1.        ]
 [1.         0.         1.         1.         0.02136715 0.
  1.         1.        ]
 [1.         0.         0.         0.         0.02136249 0.
  0.         1.        ]
 [1.         0.         0.17389463 0.         0.02133596 0.
  0.         1.        ]
 [1.         0.         0.02362609 0.         0.02135691 0.
  0.         1.        ]
 [0.         0.         0.         0.         0.0213289  0.
  0.         1.        ]
 [1.         0.         0.         0.         0.0213449  0.
  0.         1.        ]
 [1.         0.         0.70530272 0.35822719 0.02134598 0.
  0.17473974 1.        ]
 [1.         0.         0.         0.         0.02134165 0.
  0.         1.        ]
 [1.         0.         1.         1.         0.02135436 0.
  1.         1.        ]
 [1.         0.         0.         0.         0.02135674 0.
  0.         1.        ]
 [1.         0.         0.1643343  0.         0.02135002 0.
  0.         1.        ]
 [1.         0.         0.         0.         0.02135918 0.
  0.         1.        ]
 [1.         0.         0.         0.         0.02134692 0.
  0.         1.        ]
 [1.         0.         1.         1.         0.02136888 0.
  1.         1.        ]
 [1.         0.         0.         0.         0.02136417 0.
  0.         1.        ]
 [1.         0.         0.66001455 1.         0.02134041 0.
  1.         1.        ]
 [1.         0.         0.         0.         0.0213483  0.
  0.         1.        ]
 [1.         0.         0.         0.         0.02136502 0.
  0.         1.        ]
 [1.         0.         1.         1.         0.02135914 0.
  1.         1.        ]]
#####################         POISON         ###############################################

############################################################################################

comm_round: 14 | global_test_acc: 92.308% | global_f1: 0.96 | global_precision: 0.96
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.96      0.96      0.96        25

    accuracy                           0.92        26
   macro avg       0.48      0.48      0.48        26
weighted avg       0.92      0.92      0.92        26
poison scaling shape: (26, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [0]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 26 cols 8Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAfter Nodes removed: Rows 25 cols 8