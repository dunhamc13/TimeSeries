
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_fg shape (30,)
[1.         1.         0.86681902 0.86681902 1.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.        ]
wv_mn shape (30,)
[1.         1.         0.         0.06506894 1.         0.
 0.76881289 0.         0.         0.69282501 0.         0.
 0.         0.         0.         0.28510991 0.         0.35418051
 0.18040379 0.14804833 0.         0.         0.02392669 0.
 0.         0.94554399 0.         0.04919641 0.         0.        ]
wv_ed shape (30,)
[1.         1.         0.         0.06737893 1.         0.
 0.67968617 0.         0.         0.62228574 0.         0.
 0.         0.         0.         0.20772542 0.         0.32669636
 0.08524269 0.09312486 0.         0.         0.         0.
 0.         0.86538408 0.         0.         0.         0.        ]
wv_lg shape (30, 1)
[[0.33807616]
 [0.3380569 ]
 [0.33814093]
 [0.33824884]
 [0.33828372]
 [0.33285142]
 [0.33281997]
 [0.3328868 ]
 [0.3328508 ]
 [0.33294209]
 [0.33287552]
 [0.33274529]
 [0.33294112]
 [0.33287638]
 [0.33288441]
 [0.33289293]
 [0.33301694]
 [0.33272654]
 [0.33308216]
 [0.33283842]
 [0.33288068]
 [0.33284589]
 [0.33279474]
 [0.33282521]
 [0.33288997]
 [0.33290644]
 [0.33266908]
 [0.33266946]
 [0.33282165]
 [0.33275866]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_std shape (30,)
[0.52044835 1.         0.         0.         1.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.        ]
xy shape: (30, 9)
[[1.         1.         1.         1.         0.33807616 1.
  1.         0.52044835 0.        ]
 [1.         1.         1.         1.         0.3380569  1.
  1.         1.         0.        ]
 [0.         0.86681902 0.         0.         0.33814093 1.
  1.         0.         0.        ]
 [0.         0.86681902 0.06506894 0.06737893 0.33824884 1.
  1.         0.         0.        ]
 [1.         1.         1.         1.         0.33828372 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.33285142 1.
  0.         0.         1.        ]
 [0.         0.         0.76881289 0.67968617 0.33281997 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3328868  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3328508  1.
  0.         0.         1.        ]
 [0.         0.         0.69282501 0.62228574 0.33294209 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33287552 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33274529 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33294112 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33287638 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33288441 1.
  0.         0.         1.        ]
 [0.         0.         0.28510991 0.20772542 0.33289293 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33301694 1.
  0.         0.         1.        ]
 [0.         0.         0.35418051 0.32669636 0.33272654 1.
  0.         0.         1.        ]
 [0.         0.         0.18040379 0.08524269 0.33308216 1.
  0.         0.         1.        ]
 [0.         0.         0.14804833 0.09312486 0.33283842 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33288068 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33284589 1.
  0.         0.         1.        ]
 [0.         0.         0.02392669 0.         0.33279474 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33282521 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33288997 1.
  0.         0.         1.        ]
 [0.         0.         0.94554399 0.86538408 0.33290644 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33266908 1.
  0.         0.         1.        ]
 [0.         0.         0.04919641 0.         0.33266946 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33282165 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33275866 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.7857142686843872
#####################         POISON         ###############################################

############################################################################################

comm_round: 0 | global_test_acc: 80.000% | global_f1: 0.888888888888889 | global_precision: 0.8
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.80      1.00      0.89         8

    accuracy                           0.80        10
   macro avg       0.40      0.50      0.44        10
weighted avg       0.64      0.80      0.71        10

Accuracy per class:
[[8 0]
 [2 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 1. 1. 0. 1. 0.]
wv_fg shape (30,)
[0.06620774 1.         0.06620774 1.         0.82385636 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.        ]
wv_mn shape (30,)
[0.         0.         1.         0.37932611 0.         0.
 1.         0.         0.34837045 1.         0.         0.
 0.         0.         0.15832527 1.         0.12847996 0.55559051
 0.58874039 1.         0.83350862 0.         0.3150669  0.4566647
 0.35118794 1.         1.         0.         1.         0.23319486]
wv_ed shape (30,)
[0.20371702 0.         1.         0.         0.         0.
 1.         0.         0.04828884 1.         0.         0.
 0.         0.         0.1276471  1.         0.         0.50893078
 0.39134805 1.         0.64557306 0.         0.25578685 0.38103129
 0.27686514 1.         1.         0.         1.         0.0736591 ]
wv_lg shape (30, 1)
[[0.33912339]
 [0.33920672]
 [0.33906005]
 [0.33936369]
 [0.33910171]
 [0.33401542]
 [0.33408676]
 [0.33384866]
 [0.33406357]
 [0.33398008]
 [0.33388864]
 [0.33401816]
 [0.33397547]
 [0.33389293]
 [0.33387783]
 [0.33404939]
 [0.33396339]
 [0.33392569]
 [0.33399797]
 [0.33410516]
 [0.33404243]
 [0.33407048]
 [0.33392117]
 [0.3339763 ]
 [0.33399891]
 [0.33389401]
 [0.33394911]
 [0.33397082]
 [0.33394871]
 [0.33414147]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_std shape (30,)
[0.         0.         0.         0.         0.         0.
 1.         0.         0.0332573  1.         0.         0.
 0.         0.         0.11621356 0.69733702 0.         0.
 0.67103626 1.         1.         0.76337356 0.         0.19660313
 0.04882158 0.97236846 0.57419671 0.         1.         0.06086347]
xy shape: (30, 9)
[[0.         0.06620774 0.         0.20371702 0.33912339 1.
  1.         0.         0.        ]
 [0.         1.         0.         0.         0.33920672 1.
  1.         0.         0.        ]
 [0.         0.06620774 1.         1.         0.33906005 1.
  1.         0.         0.        ]
 [0.         1.         0.37932611 0.         0.33936369 1.
  1.         0.         0.        ]
 [0.         0.82385636 0.         0.         0.33910171 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.33401542 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.33408676 1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.33384866 1.
  0.         0.         1.        ]
 [0.         0.         0.34837045 0.04828884 0.33406357 1.
  0.         0.0332573  1.        ]
 [0.         0.         1.         1.         0.33398008 1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.33388864 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33401816 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33397547 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33389293 1.
  0.         0.         1.        ]
 [0.         0.         0.15832527 0.1276471  0.33387783 1.
  0.         0.11621356 1.        ]
 [0.         0.         1.         1.         0.33404939 1.
  0.         0.69733702 1.        ]
 [0.         0.         0.12847996 0.         0.33396339 1.
  0.         0.         1.        ]
 [0.         0.         0.55559051 0.50893078 0.33392569 1.
  0.         0.         1.        ]
 [0.         0.         0.58874039 0.39134805 0.33399797 1.
  0.         0.67103626 1.        ]
 [1.         0.         1.         1.         0.33410516 1.
  0.         1.         1.        ]
 [0.         0.         0.83350862 0.64557306 0.33404243 1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.33407048 1.
  0.         0.76337356 1.        ]
 [0.         0.         0.3150669  0.25578685 0.33392117 1.
  0.         0.         1.        ]
 [0.         0.         0.4566647  0.38103129 0.3339763  1.
  0.         0.19660313 1.        ]
 [0.         0.         0.35118794 0.27686514 0.33399891 1.
  0.         0.04882158 1.        ]
 [1.         0.         1.         1.         0.33389401 1.
  0.         0.97236846 1.        ]
 [1.         0.         1.         1.         0.33394911 1.
  0.         0.57419671 1.        ]
 [0.         0.         0.         0.         0.33397082 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.33394871 1.
  0.         1.         1.        ]
 [0.         0.         0.23319486 0.0736591  0.33414147 1.
  0.         0.06086347 1.        ]]

Best Training Poisoning Accuracy:
1.0
#####################         POISON         ###############################################

############################################################################################

comm_round: 1 | global_test_acc: 70.000% | global_f1: 0.8235294117647058 | global_precision: 0.7
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.70      1.00      0.82         7

    accuracy                           0.70        10
   macro avg       0.35      0.50      0.41        10
weighted avg       0.49      0.70      0.58        10

Accuracy per class:
[[7 0]
 [3 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_fg shape (30,)
[1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_mn shape (30,)
[0.36722481 1.         1.         1.         0.         0.40983567
 0.79149016 0.         1.         0.         0.25625253 1.
 0.65307941 0.25253961 0.         0.         0.0871054  0.72039694
 0.09650814 0.         0.         0.3758744  0.94789614 1.
 0.29397305 0.11633417 0.05856147 0.50012063 0.91546942 0.        ]
wv_ed shape (30,)
[0.1525442  1.         1.         1.         0.         0.57693905
 1.         0.         1.         0.         0.4422521  1.
 0.73619129 0.4414836  0.         0.         0.23645733 0.81302545
 0.19100765 0.         0.         0.5395691  1.         1.
 0.44797488 0.19468857 0.12088956 0.61672634 1.         0.        ]
wv_lg shape (30, 1)
[[0.34022201]
 [0.34001551]
 [0.33980824]
 [0.34030093]
 [0.34012271]
 [0.33505785]
 [0.33500225]
 [0.33482158]
 [0.33519998]
 [0.33506427]
 [0.33499399]
 [0.3349453 ]
 [0.3351554 ]
 [0.33497906]
 [0.33498437]
 [0.33488144]
 [0.33507787]
 [0.33511804]
 [0.33497549]
 [0.33499071]
 [0.33503466]
 [0.3351339 ]
 [0.33501516]
 [0.33521509]
 [0.33498269]
 [0.33488651]
 [0.33485992]
 [0.33495108]
 [0.33511887]
 [0.33515191]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_std shape (30,)
[0.         0.99524419 0.8937584  0.         0.         0.
 0.         0.         1.         0.         0.         1.
 0.12191601 0.         0.         0.         0.         0.42279433
 0.         0.         0.         0.         0.         1.
 0.         0.         0.         0.         0.33169774 0.        ]
xy shape: (30, 9)
[[0.         1.         0.36722481 0.1525442  0.34022201 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.34001551 1.
  1.         0.99524419 0.        ]
 [0.         0.         1.         1.         0.33980824 1.
  1.         0.8937584  0.        ]
 [0.         0.         1.         1.         0.34030093 1.
  1.         0.         0.        ]
 [0.         1.         0.         0.         0.34012271 1.
  1.         0.         0.        ]
 [0.         0.         0.40983567 0.57693905 0.33505785 1.
  0.         0.         1.        ]
 [0.         0.         0.79149016 1.         0.33500225 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33482158 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.33519998 1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.33506427 1.
  0.         0.         1.        ]
 [0.         0.         0.25625253 0.4422521  0.33499399 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.3349453  1.
  0.         1.         1.        ]
 [0.         0.         0.65307941 0.73619129 0.3351554  1.
  0.         0.12191601 1.        ]
 [0.         0.         0.25253961 0.4414836  0.33497906 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33498437 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33488144 1.
  0.         0.         1.        ]
 [0.         0.         0.0871054  0.23645733 0.33507787 1.
  0.         0.         1.        ]
 [0.         0.         0.72039694 0.81302545 0.33511804 1.
  0.         0.42279433 1.        ]
 [0.         0.         0.09650814 0.19100765 0.33497549 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33499071 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33503466 1.
  0.         0.         1.        ]
 [0.         0.         0.3758744  0.5395691  0.3351339  1.
  0.         0.         1.        ]
 [0.         0.         0.94789614 1.         0.33501516 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.33521509 1.
  0.         1.         1.        ]
 [0.         0.         0.29397305 0.44797488 0.33498269 1.
  0.         0.         1.        ]
 [0.         0.         0.11633417 0.19468857 0.33488651 1.
  0.         0.         1.        ]
 [0.         0.         0.05856147 0.12088956 0.33485992 1.
  0.         0.         1.        ]
 [0.         0.         0.50012063 0.61672634 0.33495108 1.
  0.         0.         1.        ]
 [0.         0.         0.91546942 1.         0.33511887 1.
  0.         0.33169774 1.        ]
 [0.         0.         0.         0.         0.33515191 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.9285714030265808
#####################         POISON         ###############################################

############################################################################################

comm_round: 2 | global_test_acc: 90.000% | global_f1: 0.9473684210526316 | global_precision: 0.9
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.90      1.00      0.95         9

    accuracy                           0.90        10
   macro avg       0.45      0.50      0.47        10
weighted avg       0.81      0.90      0.85        10

Accuracy per class:
[[9 0]
 [1 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_fg shape (30,)
[1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_mn shape (30,)
[0.         1.         1.         0.         0.         0.
 0.         0.89637854 0.         1.         0.         1.
 0.         0.07826976 0.95130459 0.10985128 0.         0.38189774
 0.         0.50780814 0.81627495 0.         0.         1.
 0.24014462 1.         0.         0.69756005 0.04077842 0.45097503]
wv_ed shape (30,)
[0.         1.         1.         0.         0.         0.
 0.         0.88525208 0.         1.         0.         1.
 0.         0.0961473  0.91499731 0.11022682 0.         0.3900347
 0.         0.54175281 0.77700309 0.         0.         1.
 0.21112523 1.         0.         0.5955099  0.         0.33108865]
wv_lg shape (30, 1)
[[0.34121783]
 [0.34103319]
 [0.34093419]
 [0.34068299]
 [0.34125908]
 [0.33598931]
 [0.33608712]
 [0.33607282]
 [0.33601628]
 [0.33600474]
 [0.33613546]
 [0.33613536]
 [0.33601401]
 [0.33613161]
 [0.33617782]
 [0.33607626]
 [0.33593012]
 [0.33614266]
 [0.33606394]
 [0.33616843]
 [0.33610588]
 [0.33599405]
 [0.33612204]
 [0.33629932]
 [0.33624177]
 [0.33620181]
 [0.33599674]
 [0.33602421]
 [0.33608102]
 [0.33612753]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_std shape (30,)
[0.         0.99404348 1.         0.         0.         0.
 0.         0.         0.         0.         0.         0.63504692
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.        ]
xy shape: (30, 9)
[[0.         1.         0.         0.         0.34121783 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.34103319 1.
  1.         0.99404348 0.        ]
 [0.         1.         1.         1.         0.34093419 1.
  1.         1.         0.        ]
 [0.         1.         0.         0.         0.34068299 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.34125908 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.33598931 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33608712 1.
  0.         0.         1.        ]
 [0.         0.         0.89637854 0.88525208 0.33607282 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33601628 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.33600474 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33613546 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.33613536 1.
  0.         0.63504692 1.        ]
 [0.         0.         0.         0.         0.33601401 1.
  0.         0.         1.        ]
 [0.         0.         0.07826976 0.0961473  0.33613161 1.
  0.         0.         1.        ]
 [0.         0.         0.95130459 0.91499731 0.33617782 1.
  0.         0.         1.        ]
 [0.         0.         0.10985128 0.11022682 0.33607626 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33593012 1.
  0.         0.         1.        ]
 [0.         0.         0.38189774 0.3900347  0.33614266 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33606394 1.
  0.         0.         1.        ]
 [0.         0.         0.50780814 0.54175281 0.33616843 1.
  0.         0.         1.        ]
 [0.         0.         0.81627495 0.77700309 0.33610588 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33599405 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33612204 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.33629932 1.
  0.         0.         1.        ]
 [0.         0.         0.24014462 0.21112523 0.33624177 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.33620181 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33599674 1.
  0.         0.         1.        ]
 [0.         0.         0.69756005 0.5955099  0.33602421 1.
  0.         0.         1.        ]
 [0.         0.         0.04077842 0.         0.33608102 1.
  0.         0.         1.        ]
 [0.         0.         0.45097503 0.33108865 0.33612753 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.7857142686843872
#####################         POISON         ###############################################

############################################################################################

comm_round: 3 | global_test_acc: 80.000% | global_f1: 0.888888888888889 | global_precision: 0.8
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.80      1.00      0.89         8

    accuracy                           0.80        10
   macro avg       0.40      0.50      0.44        10
weighted avg       0.64      0.80      0.71        10

Accuracy per class:
[[8 0]
 [2 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_fg shape (30,)
[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_mn shape (30,)
[1.         1.         1.         0.         0.         0.04869051
 0.05843116 0.         0.         1.         0.         0.73869516
 0.         0.         0.         0.22075081 0.         0.56387247
 1.         0.97192922 0.         0.         0.19661291 0.29739355
 0.98226763 0.05648963 0.2343598  0.64672206 0.3502686  0.        ]
wv_ed shape (30,)
[1.         1.         1.         0.         0.         0.03161744
 0.10712691 0.         0.         0.9596931  0.         0.72289296
 0.         0.         0.         0.28373055 0.         0.60734927
 1.         1.         0.         0.         0.19691662 0.3464906
 0.98283763 0.0806976  0.26432216 0.64881702 0.32467784 0.        ]
wv_lg shape (30, 1)
[[0.34206984]
 [0.34194793]
 [0.34173042]
 [0.34223731]
 [0.34170998]
 [0.33722379]
 [0.33722663]
 [0.33715973]
 [0.33713418]
 [0.33735398]
 [0.33719089]
 [0.33726612]
 [0.33710035]
 [0.33734264]
 [0.33715253]
 [0.33738159]
 [0.3372261 ]
 [0.33719275]
 [0.33740446]
 [0.33740809]
 [0.33721379]
 [0.33723278]
 [0.33718893]
 [0.33716834]
 [0.33713947]
 [0.33734348]
 [0.33746655]
 [0.33730453]
 [0.33722261]
 [0.33730791]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_std shape (30,)
[1.         1.         1.         0.         0.27371599 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.        ]
xy shape: (30, 9)
[[1.         1.         1.         1.         0.34206984 1.
  1.         1.         0.        ]
 [1.         1.         1.         1.         0.34194793 1.
  1.         1.         0.        ]
 [1.         1.         1.         1.         0.34173042 1.
  1.         1.         0.        ]
 [0.         1.         0.         0.         0.34223731 1.
  1.         0.         0.        ]
 [0.         1.         0.         0.         0.34170998 1.
  1.         0.27371599 0.        ]
 [0.         0.         0.04869051 0.03161744 0.33722379 1.
  0.         0.         1.        ]
 [0.         0.         0.05843116 0.10712691 0.33722663 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33715973 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33713418 1.
  0.         0.         1.        ]
 [0.         0.         1.         0.9596931  0.33735398 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33719089 1.
  0.         0.         1.        ]
 [0.         0.         0.73869516 0.72289296 0.33726612 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33710035 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33734264 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33715253 1.
  0.         0.         1.        ]
 [0.         0.         0.22075081 0.28373055 0.33738159 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3372261  1.
  0.         0.         1.        ]
 [0.         0.         0.56387247 0.60734927 0.33719275 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.33740446 1.
  0.         0.         1.        ]
 [0.         0.         0.97192922 1.         0.33740809 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33721379 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33723278 1.
  0.         0.         1.        ]
 [0.         0.         0.19661291 0.19691662 0.33718893 1.
  0.         0.         1.        ]
 [0.         0.         0.29739355 0.3464906  0.33716834 1.
  0.         0.         1.        ]
 [0.         0.         0.98226763 0.98283763 0.33713947 1.
  0.         0.         1.        ]
 [0.         0.         0.05648963 0.0806976  0.33734348 1.
  0.         0.         1.        ]
 [0.         0.         0.2343598  0.26432216 0.33746655 1.
  0.         0.         1.        ]
 [0.         0.         0.64672206 0.64881702 0.33730453 1.
  0.         0.         1.        ]
 [0.         0.         0.3502686  0.32467784 0.33722261 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33730791 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.9285714030265808
#####################         POISON         ###############################################

############################################################################################

comm_round: 4 | global_test_acc: 90.000% | global_f1: 0.9473684210526316 | global_precision: 0.9
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.90      1.00      0.95         9

    accuracy                           0.90        10
   macro avg       0.45      0.50      0.47        10
weighted avg       0.81      0.90      0.85        10

Accuracy per class:
[[9 0]
 [1 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0.]
wv_fg shape (30,)
[1.       0.       0.587279 0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.      ]
wv_mn shape (30,)
[0.38487815 1.         0.         0.         0.71717531 0.
 0.         0.6276441  1.         0.         0.         0.4196254
 0.88039551 1.         0.         0.         0.90123811 0.19545467
 0.47658282 1.         0.47346596 0.79960413 1.         0.
 0.         0.97207092 0.         1.         1.         1.        ]
wv_ed shape (30,)
[0.49129499 1.         0.         0.         0.98292922 0.
 0.         0.50367351 1.         0.         0.         0.33201769
 0.83617646 1.         0.         0.         0.81649867 0.15466076
 0.46771918 1.         0.36221185 0.70569159 1.         0.
 0.         0.91020199 0.         1.         1.         1.        ]
wv_lg shape (30, 1)
[[0.34276573]
 [0.34279271]
 [0.34282357]
 [0.34296902]
 [0.34281612]
 [0.33840156]
 [0.3382931 ]
 [0.33847225]
 [0.33838225]
 [0.33832948]
 [0.33858689]
 [0.33833343]
 [0.33841389]
 [0.33841923]
 [0.33837015]
 [0.33852056]
 [0.33848485]
 [0.3384597 ]
 [0.33839103]
 [0.33839985]
 [0.33836613]
 [0.33847243]
 [0.33839823]
 [0.33845549]
 [0.33838398]
 [0.33846956]
 [0.33841055]
 [0.33845126]
 [0.33842448]
 [0.33840418]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_std shape (30,)
[0.         1.         0.         0.         0.         0.
 0.         0.         1.         0.         0.         0.
 0.10830361 0.23651695 0.         0.         0.         0.
 0.         0.36803431 0.         0.         1.         0.
 0.         0.25487086 0.         0.44651448 1.         0.        ]
xy shape: (30, 9)
[[0.         1.         0.38487815 0.49129499 0.34276573 1.
  1.         0.         0.        ]
 [0.         0.         1.         1.         0.34279271 1.
  1.         1.         0.        ]
 [0.         0.587279   0.         0.         0.34282357 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.34296902 1.
  1.         0.         0.        ]
 [0.         0.         0.71717531 0.98292922 0.34281612 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.33840156 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3382931  1.
  0.         0.         1.        ]
 [0.         0.         0.6276441  0.50367351 0.33847225 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.33838225 1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.33832948 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33858689 1.
  0.         0.         1.        ]
 [0.         0.         0.4196254  0.33201769 0.33833343 1.
  0.         0.         1.        ]
 [0.         0.         0.88039551 0.83617646 0.33841389 1.
  0.         0.10830361 1.        ]
 [0.         0.         1.         1.         0.33841923 1.
  0.         0.23651695 1.        ]
 [0.         0.         0.         0.         0.33837015 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33852056 1.
  0.         0.         1.        ]
 [0.         0.         0.90123811 0.81649867 0.33848485 1.
  0.         0.         1.        ]
 [0.         0.         0.19545467 0.15466076 0.3384597  1.
  0.         0.         1.        ]
 [0.         0.         0.47658282 0.46771918 0.33839103 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.33839985 1.
  0.         0.36803431 1.        ]
 [0.         0.         0.47346596 0.36221185 0.33836613 1.
  0.         0.         1.        ]
 [0.         0.         0.79960413 0.70569159 0.33847243 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.33839823 1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.33845549 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33838398 1.
  0.         0.         1.        ]
 [0.         0.         0.97207092 0.91020199 0.33846956 1.
  0.         0.25487086 1.        ]
 [0.         0.         0.         0.         0.33841055 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.33845126 1.
  0.         0.44651448 1.        ]
 [1.         0.         1.         1.         0.33842448 1.
  0.         1.         1.        ]
 [0.         0.         1.         1.         0.33840418 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.8571428656578064
#####################         POISON         ###############################################

############################################################################################

comm_round: 5 | global_test_acc: 90.000% | global_f1: 0.9473684210526316 | global_precision: 0.9
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.90      1.00      0.95         9

    accuracy                           0.90        10
   macro avg       0.45      0.50      0.47        10
weighted avg       0.81      0.90      0.85        10

Accuracy per class:
[[9 0]
 [1 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_fg shape (30,)
[1.         1.         1.         1.         1.         0.
 0.         0.         0.         0.         0.         0.
 0.37838731 0.         0.         0.         0.         0.
 0.         0.         0.         0.61108877 0.         0.02557148
 0.         0.         0.         0.         0.         0.        ]
wv_mn shape (30,)
[1.         0.         0.         0.45065879 1.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.39983106
 0.         0.         0.         0.         0.         0.        ]
wv_ed shape (30,)
[1.         0.         0.         0.37352667 1.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.49962501
 0.         0.03060125 0.         0.         0.         0.        ]
wv_lg shape (30, 1)
[[0.3436207 ]
 [0.34372368]
 [0.34382387]
 [0.34383576]
 [0.34369438]
 [0.33935041]
 [0.33929277]
 [0.33938106]
 [0.33933829]
 [0.33938554]
 [0.33925441]
 [0.33948413]
 [0.33918703]
 [0.33933964]
 [0.33950035]
 [0.33934386]
 [0.33932958]
 [0.33946058]
 [0.33932668]
 [0.33926371]
 [0.33930875]
 [0.33936682]
 [0.33939121]
 [0.33950445]
 [0.33934106]
 [0.33940187]
 [0.33934886]
 [0.33958519]
 [0.33937533]
 [0.3393659 ]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_std shape (30,)
[1.         0.         0.         0.06186191 1.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.        ]
xy shape: (30, 9)
[[1.         1.         1.         1.         0.3436207  1.
  1.         1.         0.        ]
 [0.         1.         0.         0.         0.34372368 1.
  1.         0.         0.        ]
 [0.         1.         0.         0.         0.34382387 1.
  1.         0.         0.        ]
 [1.         1.         0.45065879 0.37352667 0.34383576 1.
  1.         0.06186191 0.        ]
 [1.         1.         1.         1.         0.34369438 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.33935041 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33929277 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33938106 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33933829 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33938554 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33925441 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33948413 1.
  0.         0.         1.        ]
 [0.         0.37838731 0.         0.         0.33918703 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33933964 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33950035 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33934386 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33932958 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33946058 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33932668 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33926371 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33930875 1.
  0.         0.         1.        ]
 [0.         0.61108877 0.         0.         0.33936682 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33939121 1.
  0.         0.         1.        ]
 [0.         0.02557148 0.39983106 0.49962501 0.33950445 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33934106 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.03060125 0.33940187 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33934886 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33958519 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33937533 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3393659  1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.8571428656578064
#####################         POISON         ###############################################

############################################################################################

comm_round: 6 | global_test_acc: 70.000% | global_f1: 0.8235294117647058 | global_precision: 0.7
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.70      1.00      0.82         7

    accuracy                           0.70        10
   macro avg       0.35      0.50      0.41        10
weighted avg       0.49      0.70      0.58        10

Accuracy per class:
[[7 0]
 [3 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 1. 0. 0. 0.]
wv_fg shape (30,)
[0.         1.         0.34724857 1.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.        ]
wv_mn shape (30,)
[0.50194838 0.         1.         0.         0.62418085 0.
 1.         0.         0.         0.         0.         0.
 0.54404351 0.         0.         0.41978457 0.11055306 0.
 0.         1.         1.         1.         0.         0.
 0.27169424 0.         1.         0.26562949 1.         0.16864643]
wv_ed shape (30,)
[0.30432122 0.         1.         0.         0.48170437 0.
 1.         0.         0.         0.         0.         0.
 0.66150658 0.         0.         0.50272227 0.26399286 0.
 0.         1.         1.         1.         0.         0.
 0.35048783 0.         1.         0.30556082 1.         0.19013873]
wv_lg shape (30, 1)
[[0.34445347]
 [0.34458067]
 [0.34456406]
 [0.34449703]
 [0.34455425]
 [0.34032656]
 [0.34032472]
 [0.34028048]
 [0.34034979]
 [0.34037913]
 [0.34024794]
 [0.34045761]
 [0.34045985]
 [0.34037688]
 [0.34029143]
 [0.34024853]
 [0.34032769]
 [0.34031779]
 [0.34032667]
 [0.34026847]
 [0.34048048]
 [0.34028883]
 [0.34043175]
 [0.34038528]
 [0.34053014]
 [0.3402523 ]
 [0.34053692]
 [0.34035811]
 [0.34025897]
 [0.34039213]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_std shape (30,)
[0.10748405 0.         1.         0.         0.         0.
 1.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.69654541 0.34195167 0.         0.         0.
 0.         0.         1.         0.         0.         0.        ]
xy shape: (30, 9)
[[0.         0.         0.50194838 0.30432122 0.34445347 1.
  1.         0.10748405 0.        ]
 [0.         1.         0.         0.         0.34458067 1.
  1.         0.         0.        ]
 [0.         0.34724857 1.         1.         0.34456406 1.
  1.         1.         0.        ]
 [0.         1.         0.         0.         0.34449703 1.
  1.         0.         0.        ]
 [0.         0.         0.62418085 0.48170437 0.34455425 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.34032656 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.34032472 1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.34028048 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34034979 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34037913 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34024794 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34045761 1.
  0.         0.         1.        ]
 [0.         0.         0.54404351 0.66150658 0.34045985 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34037688 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34029143 1.
  0.         0.         1.        ]
 [0.         0.         0.41978457 0.50272227 0.34024853 1.
  0.         0.         1.        ]
 [0.         0.         0.11055306 0.26399286 0.34032769 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34031779 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34032667 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.34026847 1.
  0.         0.69654541 1.        ]
 [0.         0.         1.         1.         0.34048048 1.
  0.         0.34195167 1.        ]
 [0.         0.         1.         1.         0.34028883 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34043175 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34038528 1.
  0.         0.         1.        ]
 [0.         0.         0.27169424 0.35048783 0.34053014 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3402523  1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.34053692 1.
  0.         1.         1.        ]
 [0.         0.         0.26562949 0.30556082 0.34035811 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.34025897 1.
  0.         0.         1.        ]
 [0.         0.         0.16864643 0.19013873 0.34039213 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.7857142686843872
#####################         POISON         ###############################################

############################################################################################

comm_round: 7 | global_test_acc: 90.000% | global_f1: 0.9473684210526316 | global_precision: 0.9
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.90      1.00      0.95         9

    accuracy                           0.90        10
   macro avg       0.45      0.50      0.47        10
weighted avg       0.81      0.90      0.85        10

Accuracy per class:
[[9 0]
 [1 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_fg shape (30,)
[1.        1.        0.        0.3066891 0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.       ]
wv_mn shape (30,)
[0.         0.43663885 0.34825482 0.55129888 1.         0.
 0.27292948 0.42861812 0.15315512 0.03973006 0.2766457  0.
 1.         1.         0.         1.         0.         1.
 1.         0.         0.         0.3316584  0.         0.
 0.         0.14882149 0.         0.         0.25600581 0.        ]
wv_ed shape (30,)
[0.         0.65970861 0.48565736 0.72598226 1.         0.
 0.29706104 0.40635134 0.13220585 0.         0.05626715 0.
 1.         1.         0.         1.         0.         1.
 1.         0.         0.         0.20224377 0.         0.
 0.         0.         0.         0.         0.2805046  0.        ]
wv_lg shape (30, 1)
[[0.34534484]
 [0.3454192 ]
 [0.34534503]
 [0.34533505]
 [0.34522393]
 [0.34110643]
 [0.34121103]
 [0.34127356]
 [0.34102179]
 [0.34118055]
 [0.34097941]
 [0.34114116]
 [0.34130679]
 [0.34127338]
 [0.34113519]
 [0.34112672]
 [0.34105   ]
 [0.34130196]
 [0.3412705 ]
 [0.34104979]
 [0.34125019]
 [0.34122286]
 [0.34110673]
 [0.34118359]
 [0.34128933]
 [0.34122048]
 [0.34119971]
 [0.3412739 ]
 [0.34122153]
 [0.34114331]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_std shape (30,)
[0.         0.         0.80864598 0.1072973  1.         0.
 0.         0.         0.         0.         0.         0.
 0.0136039  0.07621104 0.         1.         0.         0.
 1.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.        ]
xy shape: (30, 9)
[[0.         1.         0.         0.         0.34534484 1.
  1.         0.         0.        ]
 [0.         1.         0.43663885 0.65970861 0.3454192  1.
  1.         0.         0.        ]
 [0.         0.         0.34825482 0.48565736 0.34534503 1.
  1.         0.80864598 0.        ]
 [0.         0.3066891  0.55129888 0.72598226 0.34533505 1.
  1.         0.1072973  0.        ]
 [0.         0.         1.         1.         0.34522393 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.34110643 1.
  0.         0.         1.        ]
 [0.         0.         0.27292948 0.29706104 0.34121103 1.
  0.         0.         1.        ]
 [0.         0.         0.42861812 0.40635134 0.34127356 1.
  0.         0.         1.        ]
 [0.         0.         0.15315512 0.13220585 0.34102179 1.
  0.         0.         1.        ]
 [0.         0.         0.03973006 0.         0.34118055 1.
  0.         0.         1.        ]
 [0.         0.         0.2766457  0.05626715 0.34097941 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34114116 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.34130679 1.
  0.         0.0136039  1.        ]
 [0.         0.         1.         1.         0.34127338 1.
  0.         0.07621104 1.        ]
 [0.         0.         0.         0.         0.34113519 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.34112672 1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.34105    1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.34130196 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.3412705  1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.34104979 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34125019 1.
  0.         0.         1.        ]
 [0.         0.         0.3316584  0.20224377 0.34122286 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34110673 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34118359 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34128933 1.
  0.         0.         1.        ]
 [0.         0.         0.14882149 0.         0.34122048 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34119971 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3412739  1.
  0.         0.         1.        ]
 [0.         0.         0.25600581 0.2805046  0.34122153 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34114331 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.7857142686843872
#####################         POISON         ###############################################

############################################################################################

comm_round: 8 | global_test_acc: 80.000% | global_f1: 0.888888888888889 | global_precision: 0.8
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.80      1.00      0.89         8

    accuracy                           0.80        10
   macro avg       0.40      0.50      0.44        10
weighted avg       0.64      0.80      0.71        10

Accuracy per class:
[[8 0]
 [2 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_fg shape (30,)
[0.44010394 0.         1.         0.         0.44010394 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.        ]
wv_mn shape (30,)
[1.         1.         0.         1.         1.         0.21665711
 0.         0.         0.24923448 1.         0.41304843 0.
 0.         0.         0.59792229 0.         0.         0.
 0.         0.         0.14089505 1.         0.         0.
 0.91092502 0.         0.         0.         0.         0.        ]
wv_ed shape (30,)
[1.         1.         0.         1.         1.         0.1665204
 0.         0.         0.26412651 1.         0.396156   0.
 0.         0.         0.58000195 0.         0.         0.
 0.         0.         0.08870103 0.99731725 0.         0.
 0.91235203 0.         0.         0.         0.         0.        ]
wv_lg shape (30, 1)
[[0.34613088]
 [0.34584795]
 [0.3462444 ]
 [0.34614281]
 [0.34579125]
 [0.34194196]
 [0.34198503]
 [0.34207048]
 [0.34203275]
 [0.3420247 ]
 [0.3420076 ]
 [0.34215727]
 [0.34211371]
 [0.34201857]
 [0.34202667]
 [0.34216586]
 [0.34203683]
 [0.34205451]
 [0.3420779 ]
 [0.34207756]
 [0.34199844]
 [0.34209628]
 [0.34227115]
 [0.342023  ]
 [0.34207347]
 [0.34198805]
 [0.34195409]
 [0.34211873]
 [0.34214762]
 [0.34219541]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_std shape (30,)
[1.         1.         0.         0.48662786 1.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.        ]
xy shape: (30, 9)
[[1.         0.44010394 1.         1.         0.34613088 1.
  1.         1.         0.        ]
 [1.         0.         1.         1.         0.34584795 1.
  1.         1.         0.        ]
 [0.         1.         0.         0.         0.3462444  1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.34614281 1.
  1.         0.48662786 0.        ]
 [1.         0.44010394 1.         1.         0.34579125 1.
  1.         1.         0.        ]
 [0.         0.         0.21665711 0.1665204  0.34194196 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34198503 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34207048 1.
  0.         0.         1.        ]
 [0.         0.         0.24923448 0.26412651 0.34203275 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.3420247  1.
  0.         0.         1.        ]
 [0.         0.         0.41304843 0.396156   0.3420076  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34215727 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34211371 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34201857 1.
  0.         0.         1.        ]
 [0.         0.         0.59792229 0.58000195 0.34202667 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34216586 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34203683 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34205451 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3420779  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34207756 1.
  0.         0.         1.        ]
 [0.         0.         0.14089505 0.08870103 0.34199844 1.
  0.         0.         1.        ]
 [0.         0.         1.         0.99731725 0.34209628 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34227115 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.342023   1.
  0.         0.         1.        ]
 [0.         0.         0.91092502 0.91235203 0.34207347 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34198805 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34195409 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34211873 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34214762 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34219541 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
1.0
#####################         POISON         ###############################################

############################################################################################

comm_round: 9 | global_test_acc: 70.000% | global_f1: 0.8235294117647058 | global_precision: 0.7
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.70      1.00      0.82         7

    accuracy                           0.70        10
   macro avg       0.35      0.50      0.41        10
weighted avg       0.49      0.70      0.58        10

Accuracy per class:
[[7 0]
 [3 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 0.]
wv_fg shape (30,)
[1.         1.         0.09611407 1.         0.09611407 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         1.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.        ]
wv_mn shape (30,)
[0.         1.         0.42573477 0.         1.         0.94246709
 1.         0.97969545 1.         0.54349326 1.         0.02488449
 0.78530363 1.         1.         1.         1.         0.6313552
 1.         1.         0.66089825 1.         1.         0.
 1.         0.44463737 0.20094129 0.8814911  1.         0.0400632 ]
wv_ed shape (30,)
[0.         1.         0.48639271 0.         1.         1.
 1.         0.88740827 1.         0.52758793 1.         0.
 0.74056481 1.         1.         1.         1.         0.61946549
 1.         1.         0.69076731 0.98949321 1.         0.
 1.         0.50248322 0.28930796 0.98367886 1.         0.        ]
wv_lg shape (30, 1)
[[0.34675583]
 [0.34679601]
 [0.34657799]
 [0.34678242]
 [0.34671879]
 [0.34314619]
 [0.34294418]
 [0.34298532]
 [0.34310572]
 [0.34288709]
 [0.34308858]
 [0.34291794]
 [0.34297375]
 [0.34308477]
 [0.34308639]
 [0.34309467]
 [0.34326531]
 [0.34315914]
 [0.34303159]
 [0.34307002]
 [0.3428871 ]
 [0.34296904]
 [0.34309294]
 [0.34298006]
 [0.34302315]
 [0.34297295]
 [0.34298542]
 [0.34293543]
 [0.34315061]
 [0.34291692]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_std shape (30,)
[0.         1.         0.03458548 0.         0.81018436 0.
 0.         0.         1.         0.         1.         0.
 0.         0.         0.02130771 0.48808293 1.         0.
 0.         0.         0.         0.         0.         0.
 1.         0.         0.         0.         0.         0.        ]
xy shape: (30, 9)
[[0.         1.         0.         0.         0.34675583 1.
  1.         0.         0.        ]
 [0.         1.         1.         1.         0.34679601 1.
  1.         1.         0.        ]
 [0.         0.09611407 0.42573477 0.48639271 0.34657799 1.
  1.         0.03458548 0.        ]
 [0.         1.         0.         0.         0.34678242 1.
  1.         0.         0.        ]
 [0.         0.09611407 1.         1.         0.34671879 1.
  1.         0.81018436 0.        ]
 [0.         0.         0.94246709 1.         0.34314619 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.34294418 1.
  0.         0.         1.        ]
 [0.         0.         0.97969545 0.88740827 0.34298532 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.34310572 1.
  0.         1.         1.        ]
 [0.         0.         0.54349326 0.52758793 0.34288709 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.34308858 1.
  0.         1.         1.        ]
 [0.         0.         0.02488449 0.         0.34291794 1.
  0.         0.         1.        ]
 [0.         0.         0.78530363 0.74056481 0.34297375 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.34308477 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.34308639 1.
  0.         0.02130771 1.        ]
 [0.         0.         1.         1.         0.34309467 1.
  0.         0.48808293 1.        ]
 [1.         1.         1.         1.         0.34326531 1.
  0.         1.         1.        ]
 [0.         0.         0.6313552  0.61946549 0.34315914 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.34303159 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.34307002 1.
  0.         0.         1.        ]
 [0.         0.         0.66089825 0.69076731 0.3428871  1.
  0.         0.         1.        ]
 [0.         0.         1.         0.98949321 0.34296904 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.34309294 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34298006 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.34302315 1.
  0.         1.         1.        ]
 [0.         0.         0.44463737 0.50248322 0.34297295 1.
  0.         0.         1.        ]
 [0.         0.         0.20094129 0.28930796 0.34298542 1.
  0.         0.         1.        ]
 [0.         0.         0.8814911  0.98367886 0.34293543 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.34315061 1.
  0.         0.         1.        ]
 [0.         0.         0.0400632  0.         0.34291692 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.8571428656578064
#####################         POISON         ###############################################

############################################################################################

comm_round: 10 | global_test_acc: 90.000% | global_f1: 0.9473684210526316 | global_precision: 0.9
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.90      1.00      0.95         9

    accuracy                           0.90        10
   macro avg       0.45      0.50      0.47        10
weighted avg       0.81      0.90      0.85        10

Accuracy per class:
[[9 0]
 [1 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_fg shape (30,)
[0.20978176 0.20978176 0.86593035 1.         0.26073944 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.00372998 0.
 0.         0.         0.         0.         0.         0.        ]
wv_mn shape (30,)
[1.         1.         0.         1.         1.         1.
 1.         0.         1.         0.         0.01767855 0.17232883
 0.         0.         1.         0.         0.         0.
 0.11131044 1.         0.         0.         0.         1.
 0.73056151 0.         0.22705337 0.05572598 0.         1.        ]
wv_ed shape (30,)
[1.         1.         0.         1.         1.         1.
 1.         0.         1.         0.         0.02502728 0.25593953
 0.         0.         1.         0.         0.         0.
 0.0357365  1.         0.         0.07774155 0.         1.
 0.93253604 0.         0.2812989  0.1393124  0.         1.        ]
wv_lg shape (30, 1)
[[0.34735187]
 [0.3474705 ]
 [0.347557  ]
 [0.34749096]
 [0.34730687]
 [0.34397163]
 [0.34410666]
 [0.343935  ]
 [0.34398821]
 [0.34399943]
 [0.3440387 ]
 [0.34403479]
 [0.34376011]
 [0.3439771 ]
 [0.3439157 ]
 [0.34376648]
 [0.34393573]
 [0.34388771]
 [0.34395728]
 [0.34380625]
 [0.34399256]
 [0.34404955]
 [0.34403443]
 [0.34412606]
 [0.34405172]
 [0.34387499]
 [0.34415199]
 [0.34400516]
 [0.34389018]
 [0.34402453]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_std shape (30,)
[0.73265113 0.94747887 0.         1.         1.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.        ]
xy shape: (30, 9)
[[0.         0.20978176 1.         1.         0.34735187 1.
  1.         0.73265113 0.        ]
 [1.         0.20978176 1.         1.         0.3474705  1.
  1.         0.94747887 0.        ]
 [0.         0.86593035 0.         0.         0.347557   1.
  1.         0.         0.        ]
 [1.         1.         1.         1.         0.34749096 1.
  1.         1.         0.        ]
 [1.         0.26073944 1.         1.         0.34730687 1.
  1.         1.         0.        ]
 [0.         0.         1.         1.         0.34397163 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.34410666 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.343935   1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.34398821 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34399943 1.
  0.         0.         1.        ]
 [0.         0.         0.01767855 0.02502728 0.3440387  1.
  0.         0.         1.        ]
 [0.         0.         0.17232883 0.25593953 0.34403479 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34376011 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3439771  1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.3439157  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34376648 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34393573 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34388771 1.
  0.         0.         1.        ]
 [0.         0.         0.11131044 0.0357365  0.34395728 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.34380625 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34399256 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.07774155 0.34404955 1.
  0.         0.         1.        ]
 [0.         0.00372998 0.         0.         0.34403443 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.34412606 1.
  0.         0.         1.        ]
 [0.         0.         0.73056151 0.93253604 0.34405172 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34387499 1.
  0.         0.         1.        ]
 [0.         0.         0.22705337 0.2812989  0.34415199 1.
  0.         0.         1.        ]
 [0.         0.         0.05572598 0.1393124  0.34400516 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34389018 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.34402453 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.8571428656578064
#####################         POISON         ###############################################

############################################################################################

comm_round: 11 | global_test_acc: 80.000% | global_f1: 0.888888888888889 | global_precision: 0.8
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.80      1.00      0.89         8

    accuracy                           0.80        10
   macro avg       0.40      0.50      0.44        10
weighted avg       0.64      0.80      0.71        10

Accuracy per class:
[[8 0]
 [2 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_fg shape (30,)
[0.00871885 0.92017134 1.         0.14937434 0.00871885 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.        ]
wv_mn shape (30,)
[1.         0.         1.         0.         0.5536774  1.
 1.         1.         1.         0.         0.         1.
 0.84204604 1.         0.         0.91843477 0.         0.
 0.         0.91908376 1.         0.         0.56317623 0.67663395
 1.         0.         1.         0.         1.         1.        ]
wv_ed shape (30,)
[1.         0.         1.         0.         0.46037912 1.
 1.         1.         1.         0.         0.         1.
 0.8379368  1.         0.         0.78167835 0.         0.
 0.         0.88657317 1.         0.         0.50502537 0.66175009
 1.         0.         1.         0.         1.         1.        ]
wv_lg shape (30, 1)
[[0.3481868 ]
 [0.34831197]
 [0.34784342]
 [0.34838659]
 [0.34825678]
 [0.34469513]
 [0.3446387 ]
 [0.34448199]
 [0.3446177 ]
 [0.34447586]
 [0.34460674]
 [0.3445863 ]
 [0.34468032]
 [0.34464923]
 [0.34457548]
 [0.34454059]
 [0.34465632]
 [0.34463032]
 [0.34448801]
 [0.34456961]
 [0.34462934]
 [0.34460878]
 [0.34462133]
 [0.34464452]
 [0.34468543]
 [0.34455244]
 [0.3447213 ]
 [0.34457058]
 [0.34474003]
 [0.34468698]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_std shape (30,)
[1.        0.        1.        0.        0.6726483 0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.       ]
xy shape: (30, 9)
[[0.         0.00871885 1.         1.         0.3481868  1.
  1.         1.         0.        ]
 [0.         0.92017134 0.         0.         0.34831197 1.
  1.         0.         0.        ]
 [1.         1.         1.         1.         0.34784342 1.
  1.         1.         0.        ]
 [0.         0.14937434 0.         0.         0.34838659 1.
  1.         0.         0.        ]
 [0.         0.00871885 0.5536774  0.46037912 0.34825678 1.
  1.         0.6726483  0.        ]
 [0.         0.         1.         1.         0.34469513 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.3446387  1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.34448199 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.3446177  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34447586 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34460674 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.3445863  1.
  0.         0.         1.        ]
 [0.         0.         0.84204604 0.8379368  0.34468032 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.34464923 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34457548 1.
  0.         0.         1.        ]
 [0.         0.         0.91843477 0.78167835 0.34454059 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34465632 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34463032 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34448801 1.
  0.         0.         1.        ]
 [0.         0.         0.91908376 0.88657317 0.34456961 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.34462934 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34460878 1.
  0.         0.         1.        ]
 [0.         0.         0.56317623 0.50502537 0.34462133 1.
  0.         0.         1.        ]
 [0.         0.         0.67663395 0.66175009 0.34464452 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.34468543 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34455244 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.3447213  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34457058 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.34474003 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.34468698 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.8571428656578064
#####################         POISON         ###############################################

############################################################################################

comm_round: 12 | global_test_acc: 70.000% | global_f1: 0.8235294117647058 | global_precision: 0.7
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.70      1.00      0.82         7

    accuracy                           0.70        10
   macro avg       0.35      0.50      0.41        10
weighted avg       0.49      0.70      0.58        10

Accuracy per class:
[[7 0]
 [3 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1.
 0. 0. 0. 0. 0. 0.]
wv_fg shape (30,)
[0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_mn shape (30,)
[0.         0.         0.         0.44314738 0.         0.47947703
 1.         1.         0.         1.         0.         1.
 0.         0.         0.         1.         0.         0.
 0.49708648 0.76069956 0.         1.         0.67067902 1.
 0.19778053 0.38571737 0.07819732 0.         0.52241249 0.        ]
wv_ed shape (30,)
[0.         0.         0.05819479 0.73709059 0.         0.50590255
 1.         1.         0.06590668 1.         0.07419667 1.
 0.         0.         0.         1.         0.         0.
 0.43237616 0.82712576 0.         1.         0.6975898  1.
 0.17945604 0.39048743 0.14669041 0.         0.75685859 0.        ]
wv_lg shape (30, 1)
[[0.34894565]
 [0.34898402]
 [0.34878036]
 [0.34856483]
 [0.34844573]
 [0.34539606]
 [0.34525308]
 [0.34545392]
 [0.34521106]
 [0.34539763]
 [0.34538301]
 [0.34520866]
 [0.34536534]
 [0.34533176]
 [0.34528136]
 [0.3453914 ]
 [0.34529321]
 [0.34537897]
 [0.34536226]
 [0.34532568]
 [0.34519997]
 [0.34528017]
 [0.34522383]
 [0.34531574]
 [0.34533602]
 [0.34521052]
 [0.34536963]
 [0.3452769 ]
 [0.34526055]
 [0.34529243]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_std shape (30,)
[0.         0.         0.         0.         0.         0.
 1.         0.72312876 0.         1.         0.         0.
 0.         0.         0.         0.19903932 0.         0.
 0.04178343 0.11253617 0.         1.         0.         0.44274762
 0.         0.         0.         0.         0.         0.        ]
xy shape: (30, 9)
[[0.         0.         0.         0.         0.34894565 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.34898402 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.05819479 0.34878036 1.
  1.         0.         0.        ]
 [0.         0.         0.44314738 0.73709059 0.34856483 1.
  1.         0.         0.        ]
 [0.         1.         0.         0.         0.34844573 1.
  1.         0.         0.        ]
 [0.         0.         0.47947703 0.50590255 0.34539606 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.34525308 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.34545392 1.
  0.         0.72312876 1.        ]
 [0.         0.         0.         0.06590668 0.34521106 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.34539763 1.
  0.         1.         1.        ]
 [0.         0.         0.         0.07419667 0.34538301 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.34520866 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34536534 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34533176 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34528136 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.3453914  1.
  0.         0.19903932 1.        ]
 [0.         0.         0.         0.         0.34529321 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34537897 1.
  0.         0.         1.        ]
 [0.         0.         0.49708648 0.43237616 0.34536226 1.
  0.         0.04178343 1.        ]
 [1.         0.         0.76069956 0.82712576 0.34532568 1.
  0.         0.11253617 1.        ]
 [0.         0.         0.         0.         0.34519997 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.34528017 1.
  0.         1.         1.        ]
 [1.         0.         0.67067902 0.6975898  0.34522383 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.34531574 1.
  0.         0.44274762 1.        ]
 [0.         0.         0.19778053 0.17945604 0.34533602 1.
  0.         0.         1.        ]
 [0.         0.         0.38571737 0.39048743 0.34521052 1.
  0.         0.         1.        ]
 [0.         0.         0.07819732 0.14669041 0.34536963 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3452769  1.
  0.         0.         1.        ]
 [0.         0.         0.52241249 0.75685859 0.34526055 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34529243 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.9285714030265808
#####################         POISON         ###############################################

############################################################################################

comm_round: 13 | global_test_acc: 70.000% | global_f1: 0.8235294117647058 | global_precision: 0.7
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.70      1.00      0.82         7

    accuracy                           0.70        10
   macro avg       0.35      0.50      0.41        10
weighted avg       0.49      0.70      0.58        10

Accuracy per class:
[[7 0]
 [3 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_fg shape (30,)
[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_mn shape (30,)
[1.         0.         0.         0.         0.72882889 1.
 1.         0.00368559 0.14277181 1.         0.         0.9657205
 0.         1.         1.         1.         1.         0.6639425
 0.65550517 0.         0.         0.         0.2602786  0.48022312
 0.53325756 0.31946023 1.         0.44427453 1.         0.5174648 ]
wv_ed shape (30,)
[1.         0.         0.         0.         0.88616976 1.
 1.         0.01510209 0.22121685 1.         0.         1.
 0.01210131 1.         1.         1.         1.         0.79119669
 0.58451289 0.         0.         0.         0.36245069 0.46079997
 0.59334265 0.36085256 1.         0.58019307 1.         0.59906903]
wv_lg shape (30, 1)
[[0.34960521]
 [0.34942997]
 [0.34923091]
 [0.34932061]
 [0.34958206]
 [0.34603283]
 [0.3459652 ]
 [0.34595661]
 [0.34602857]
 [0.34610825]
 [0.34606898]
 [0.34593234]
 [0.34602245]
 [0.34604542]
 [0.34613799]
 [0.34616235]
 [0.3461199 ]
 [0.34608051]
 [0.346158  ]
 [0.3459866 ]
 [0.3460147 ]
 [0.3461776 ]
 [0.3460866 ]
 [0.34605854]
 [0.34607713]
 [0.34620034]
 [0.34616313]
 [0.34607724]
 [0.3460629 ]
 [0.3459571 ]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_std shape (30,)
[0.41930343 0.         0.         0.         0.         0.86117507
 1.         0.         0.         1.         0.         0.37060975
 0.         1.         1.         1.         1.         0.
 1.         0.         0.         0.         0.         0.
 0.39070442 0.         1.         0.         0.13462443 0.        ]
xy shape: (30, 9)
[[1.         0.         1.         1.         0.34960521 1.
  1.         0.41930343 0.        ]
 [0.         1.         0.         0.         0.34942997 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.34923091 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.34932061 1.
  1.         0.         0.        ]
 [0.         0.         0.72882889 0.88616976 0.34958206 1.
  1.         0.         0.        ]
 [0.         0.         1.         1.         0.34603283 1.
  0.         0.86117507 1.        ]
 [0.         0.         1.         1.         0.3459652  1.
  0.         1.         1.        ]
 [0.         0.         0.00368559 0.01510209 0.34595661 1.
  0.         0.         1.        ]
 [0.         0.         0.14277181 0.22121685 0.34602857 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.34610825 1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.34606898 1.
  0.         0.         1.        ]
 [0.         0.         0.9657205  1.         0.34593234 1.
  0.         0.37060975 1.        ]
 [0.         0.         0.         0.01210131 0.34602245 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.34604542 1.
  0.         1.         1.        ]
 [0.         0.         1.         1.         0.34613799 1.
  0.         1.         1.        ]
 [0.         0.         1.         1.         0.34616235 1.
  0.         1.         1.        ]
 [0.         0.         1.         1.         0.3461199  1.
  0.         1.         1.        ]
 [0.         0.         0.6639425  0.79119669 0.34608051 1.
  0.         0.         1.        ]
 [0.         0.         0.65550517 0.58451289 0.346158   1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.3459866  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3460147  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3461776  1.
  0.         0.         1.        ]
 [0.         0.         0.2602786  0.36245069 0.3460866  1.
  0.         0.         1.        ]
 [0.         0.         0.48022312 0.46079997 0.34605854 1.
  0.         0.         1.        ]
 [0.         0.         0.53325756 0.59334265 0.34607713 1.
  0.         0.39070442 1.        ]
 [0.         0.         0.31946023 0.36085256 0.34620034 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.34616313 1.
  0.         1.         1.        ]
 [0.         0.         0.44427453 0.58019307 0.34607724 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.3460629  1.
  0.         0.13462443 1.        ]
 [0.         0.         0.5174648  0.59906903 0.3459571  1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
1.0
#####################         POISON         ###############################################

############################################################################################

comm_round: 14 | global_test_acc: 80.000% | global_f1: 0.888888888888889 | global_precision: 0.8
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.80      1.00      0.89         8

    accuracy                           0.80        10
   macro avg       0.40      0.50      0.44        10
weighted avg       0.64      0.80      0.71        10

Accuracy per class:
[[8 0]
 [2 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_fg shape (30,)
[0.13970613 0.         0.         0.         1.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.        ]
wv_mn shape (30,)
[0.         0.         1.         0.         0.         1.
 0.23372055 0.15632394 0.         1.         0.         1.
 1.         0.         0.46137748 0.79544268 0.88465571 0.75397904
 0.         0.         0.         1.         1.         0.83592334
 0.24070877 0.         1.         1.         0.         0.        ]
wv_ed shape (30,)
[0.         0.         1.         0.         0.         1.
 0.27707771 0.25341726 0.         1.         0.         1.
 1.         0.         0.48858719 0.84165342 0.99859756 0.85094664
 0.         0.         0.         1.         1.         0.91507862
 0.29349964 0.         1.         1.         0.         0.        ]
wv_lg shape (30, 1)
[[0.3500584 ]
 [0.3501618 ]
 [0.34994208]
 [0.35019693]
 [0.35025429]
 [0.34704545]
 [0.34703645]
 [0.34706325]
 [0.34704669]
 [0.34692909]
 [0.34699445]
 [0.3470783 ]
 [0.34703362]
 [0.34696051]
 [0.34698882]
 [0.34709594]
 [0.34692169]
 [0.34701445]
 [0.34698063]
 [0.34699731]
 [0.34692142]
 [0.34698043]
 [0.34701641]
 [0.34701071]
 [0.34711208]
 [0.34705409]
 [0.34710196]
 [0.3468947 ]
 [0.34698701]
 [0.34700066]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_std shape (30,)
[1.         0.         1.         0.         0.         1.
 0.         0.         0.         1.         0.         0.
 1.         0.         0.         0.50098566 0.         0.
 0.         0.         0.         1.         1.         0.
 0.         0.         1.         0.         0.         0.        ]
xy shape: (30, 9)
[[0.         0.13970613 0.         0.         0.3500584  1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.3501618  1.
  1.         0.         0.        ]
 [0.         0.         1.         1.         0.34994208 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.35019693 1.
  1.         0.         0.        ]
 [0.         1.         0.         0.         0.35025429 1.
  1.         0.         0.        ]
 [0.         0.         1.         1.         0.34704545 1.
  0.         1.         1.        ]
 [0.         0.         0.23372055 0.27707771 0.34703645 1.
  0.         0.         1.        ]
 [0.         0.         0.15632394 0.25341726 0.34706325 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34704669 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.34692909 1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.34699445 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.3470783  1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.34703362 1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.34696051 1.
  0.         0.         1.        ]
 [0.         0.         0.46137748 0.48858719 0.34698882 1.
  0.         0.         1.        ]
 [0.         0.         0.79544268 0.84165342 0.34709594 1.
  0.         0.50098566 1.        ]
 [0.         0.         0.88465571 0.99859756 0.34692169 1.
  0.         0.         1.        ]
 [0.         0.         0.75397904 0.85094664 0.34701445 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34698063 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34699731 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34692142 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.34698043 1.
  0.         1.         1.        ]
 [0.         0.         1.         1.         0.34701641 1.
  0.         1.         1.        ]
 [0.         0.         0.83592334 0.91507862 0.34701071 1.
  0.         0.         1.        ]
 [0.         0.         0.24070877 0.29349964 0.34711208 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34705409 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.34710196 1.
  0.         1.         1.        ]
 [0.         0.         1.         1.         0.3468947  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34698701 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34700066 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.7857142686843872
#####################         POISON         ###############################################

############################################################################################

comm_round: 15 | global_test_acc: 90.000% | global_f1: 0.9473684210526316 | global_precision: 0.9
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.90      1.00      0.95         9

    accuracy                           0.90        10
   macro avg       0.45      0.50      0.47        10
weighted avg       0.81      0.90      0.85        10

Accuracy per class:
[[9 0]
 [1 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0.         0.         0.         0.         1.         0.
 0.         0.         0.         0.         0.         0.19845034
 0.         0.         0.         0.         0.         0.
 0.04672376 0.         0.         0.         0.2481697  0.
 0.         0.         0.         0.         0.03365509 0.        ]
wv_fg shape (30,)
[1.         0.13157617 0.13157617 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.        ]
wv_mn shape (30,)
[0.         0.         0.         0.         1.         0.
 0.05378136 0.         0.10766115 0.04372044 0.         1.
 0.         0.         0.         0.58260786 0.49330597 0.
 1.         0.9996099  0.         0.29739582 1.         0.
 0.62131287 0.         0.03451548 0.         1.         0.09125216]
wv_ed shape (30,)
[0.         0.         0.         0.17381154 1.         0.
 0.         0.         0.09407883 0.11494642 0.         1.
 0.         0.         0.         0.66111432 0.3359927  0.
 1.         1.         0.         0.36804026 1.         0.
 0.5831507  0.04184615 0.11354102 0.         1.         0.        ]
wv_lg shape (30, 1)
[[0.35082606]
 [0.35057538]
 [0.35042075]
 [0.35052364]
 [0.35049734]
 [0.34752832]
 [0.34750218]
 [0.34743045]
 [0.34754831]
 [0.34752361]
 [0.34747405]
 [0.34759943]
 [0.3474064 ]
 [0.34757949]
 [0.34750625]
 [0.3474638 ]
 [0.34763532]
 [0.34738773]
 [0.34761697]
 [0.34757372]
 [0.34754609]
 [0.34761415]
 [0.34753874]
 [0.34757906]
 [0.34747402]
 [0.34749355]
 [0.34755341]
 [0.34747533]
 [0.34758686]
 [0.34747298]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_std shape (30,)
[0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
xy shape: (30, 9)
[[0.         1.         0.         0.         0.35082606 1.
  1.         0.         0.        ]
 [0.         0.13157617 0.         0.         0.35057538 1.
  1.         0.         0.        ]
 [0.         0.13157617 0.         0.         0.35042075 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.17381154 0.35052364 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.35049734 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.34752832 1.
  0.         0.         1.        ]
 [0.         0.         0.05378136 0.         0.34750218 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34743045 1.
  0.         0.         1.        ]
 [0.         0.         0.10766115 0.09407883 0.34754831 1.
  0.         0.         1.        ]
 [0.         0.         0.04372044 0.11494642 0.34752361 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34747405 1.
  0.         0.         1.        ]
 [0.19845034 0.         1.         1.         0.34759943 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3474064  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34757949 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34750625 1.
  0.         0.         1.        ]
 [0.         0.         0.58260786 0.66111432 0.3474638  1.
  0.         0.         1.        ]
 [0.         0.         0.49330597 0.3359927  0.34763532 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34738773 1.
  0.         0.         1.        ]
 [0.04672376 0.         1.         1.         0.34761697 1.
  0.         0.         1.        ]
 [0.         0.         0.9996099  1.         0.34757372 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34754609 1.
  0.         0.         1.        ]
 [0.         0.         0.29739582 0.36804026 0.34761415 1.
  0.         0.         1.        ]
 [0.2481697  0.         1.         1.         0.34753874 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34757906 1.
  0.         0.         1.        ]
 [0.         0.         0.62131287 0.5831507  0.34747402 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.04184615 0.34749355 1.
  0.         0.         1.        ]
 [0.         0.         0.03451548 0.11354102 0.34755341 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34747533 1.
  0.         0.         1.        ]
 [0.03365509 0.         1.         1.         0.34758686 1.
  0.         0.         1.        ]
 [0.         0.         0.09125216 0.         0.34747298 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.8571428656578064
#####################         POISON         ###############################################

############################################################################################

comm_round: 16 | global_test_acc: 70.000% | global_f1: 0.8235294117647058 | global_precision: 0.7
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.70      1.00      0.82         7

    accuracy                           0.70        10
   macro avg       0.35      0.50      0.41        10
weighted avg       0.49      0.70      0.58        10

Accuracy per class:
[[7 0]
 [3 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0.
 1. 1. 0. 1. 1. 0.]
wv_fg shape (30,)
[0.        0.2504574 0.        0.2504574 1.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.       ]
wv_mn shape (30,)
[0.         0.         0.         0.60721832 0.         0.25266764
 0.99077528 1.         0.         1.         0.96473619 1.
 0.         1.         0.48021051 1.         1.         1.
 1.         0.11203029 1.         1.         1.         0.2714492
 1.         1.         0.02341475 1.         1.         0.        ]
wv_ed shape (30,)
[0.         0.         0.         0.68871345 0.         0.2569921
 1.         1.         0.         1.         0.97029784 1.
 0.         1.         0.5057908  1.         1.         1.
 1.         0.072735   1.         1.         1.         0.2072447
 1.         1.         0.10357861 1.         1.         0.        ]
wv_lg shape (30, 1)
[[0.35126488]
 [0.3514946 ]
 [0.35130225]
 [0.35146405]
 [0.35134318]
 [0.34838412]
 [0.34844119]
 [0.34828839]
 [0.34843649]
 [0.34827103]
 [0.34828772]
 [0.34831497]
 [0.34833871]
 [0.34831534]
 [0.34833546]
 [0.34841978]
 [0.34841505]
 [0.34837382]
 [0.34821096]
 [0.34827202]
 [0.34831494]
 [0.34833583]
 [0.34846037]
 [0.3483587 ]
 [0.34846723]
 [0.34852396]
 [0.34838271]
 [0.3482605 ]
 [0.3483373 ]
 [0.3482526 ]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_std shape (30,)
[0.         0.         0.         0.         0.         0.
 0.42893754 1.         0.         0.2542431  0.         1.
 0.         0.         0.         0.9191519  0.17470624 1.
 0.600551   0.         0.09846337 0.40556172 1.         0.
 1.         0.87080331 0.         0.37559683 0.21889245 0.        ]
xy shape: (30, 9)
[[0.         0.         0.         0.         0.35126488 1.
  1.         0.         0.        ]
 [0.         0.2504574  0.         0.         0.3514946  1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.35130225 1.
  1.         0.         0.        ]
 [0.         0.2504574  0.60721832 0.68871345 0.35146405 1.
  1.         0.         0.        ]
 [0.         1.         0.         0.         0.35134318 1.
  1.         0.         0.        ]
 [0.         0.         0.25266764 0.2569921  0.34838412 1.
  0.         0.         1.        ]
 [1.         0.         0.99077528 1.         0.34844119 1.
  0.         0.42893754 1.        ]
 [1.         0.         1.         1.         0.34828839 1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.34843649 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.34827103 1.
  0.         0.2542431  1.        ]
 [1.         0.         0.96473619 0.97029784 0.34828772 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.34831497 1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.34833871 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.34831534 1.
  0.         0.         1.        ]
 [1.         0.         0.48021051 0.5057908  0.34833546 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.34841978 1.
  0.         0.9191519  1.        ]
 [1.         0.         1.         1.         0.34841505 1.
  0.         0.17470624 1.        ]
 [1.         0.         1.         1.         0.34837382 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.34821096 1.
  0.         0.600551   1.        ]
 [0.         0.         0.11203029 0.072735   0.34827202 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.34831494 1.
  0.         0.09846337 1.        ]
 [1.         0.         1.         1.         0.34833583 1.
  0.         0.40556172 1.        ]
 [1.         0.         1.         1.         0.34846037 1.
  0.         1.         1.        ]
 [0.         0.         0.2714492  0.2072447  0.3483587  1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.34846723 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.34852396 1.
  0.         0.87080331 1.        ]
 [0.         0.         0.02341475 0.10357861 0.34838271 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.3482605  1.
  0.         0.37559683 1.        ]
 [1.         0.         1.         1.         0.3483373  1.
  0.         0.21889245 1.        ]
 [0.         0.         0.         0.         0.3482526  1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.8571428656578064
#####################         POISON         ###############################################

############################################################################################

comm_round: 17 | global_test_acc: 80.000% | global_f1: 0.888888888888889 | global_precision: 0.8
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.80      1.00      0.89         8

    accuracy                           0.80        10
   macro avg       0.40      0.50      0.44        10
weighted avg       0.64      0.80      0.71        10

Accuracy per class:
[[8 0]
 [2 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_fg shape (30,)
[1.         1.         0.         0.         0.71018925 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.        ]
wv_mn shape (30,)
[0.         0.70862058 1.         1.         0.         0.08365209
 0.         0.74343552 0.         1.         0.06636976 0.52207054
 0.9486264  0.         0.         0.69125086 0.         1.
 1.         0.85741477 0.47348213 0.         0.71393839 0.
 0.967162   0.         1.         0.         0.         0.31028898]
wv_ed shape (30,)
[0.         0.57304257 1.         1.         0.         0.
 0.         0.5238499  0.         1.         0.         0.46306743
 0.97241813 0.         0.         0.61659364 0.         1.
 1.         0.74109978 0.22117446 0.         0.77372478 0.
 0.75256788 0.         1.         0.         0.         0.12928589]
wv_lg shape (30, 1)
[[0.3521109 ]
 [0.35163463]
 [0.35177783]
 [0.35172911]
 [0.35184532]
 [0.34877795]
 [0.34874396]
 [0.34870349]
 [0.34880662]
 [0.34880462]
 [0.34867382]
 [0.34876159]
 [0.34878562]
 [0.34875734]
 [0.34886104]
 [0.34872869]
 [0.34867616]
 [0.34875719]
 [0.34877303]
 [0.34883681]
 [0.34871656]
 [0.34881266]
 [0.34875718]
 [0.3487117 ]
 [0.34874828]
 [0.3488379 ]
 [0.34881028]
 [0.34875825]
 [0.34878667]
 [0.34873985]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_std shape (30,)
[0.         1.         1.         1.         0.69773599 0.
 0.         0.         0.         0.0336282  0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.        ]
xy shape: (30, 9)
[[0.         1.         0.         0.         0.3521109  1.
  1.         0.         0.        ]
 [0.         1.         0.70862058 0.57304257 0.35163463 1.
  1.         1.         0.        ]
 [0.         0.         1.         1.         0.35177783 1.
  1.         1.         0.        ]
 [1.         0.         1.         1.         0.35172911 1.
  1.         1.         0.        ]
 [0.         0.71018925 0.         0.         0.35184532 1.
  1.         0.69773599 0.        ]
 [0.         0.         0.08365209 0.         0.34877795 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34874396 1.
  0.         0.         1.        ]
 [0.         0.         0.74343552 0.5238499  0.34870349 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34880662 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.34880462 1.
  0.         0.0336282  1.        ]
 [0.         0.         0.06636976 0.         0.34867382 1.
  0.         0.         1.        ]
 [0.         0.         0.52207054 0.46306743 0.34876159 1.
  0.         0.         1.        ]
 [0.         0.         0.9486264  0.97241813 0.34878562 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34875734 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34886104 1.
  0.         0.         1.        ]
 [0.         0.         0.69125086 0.61659364 0.34872869 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34867616 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.34875719 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.34877303 1.
  0.         0.         1.        ]
 [0.         0.         0.85741477 0.74109978 0.34883681 1.
  0.         0.         1.        ]
 [0.         0.         0.47348213 0.22117446 0.34871656 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34881266 1.
  0.         0.         1.        ]
 [0.         0.         0.71393839 0.77372478 0.34875718 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3487117  1.
  0.         0.         1.        ]
 [0.         0.         0.967162   0.75256788 0.34874828 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3488379  1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.34881028 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34875825 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34878667 1.
  0.         0.         1.        ]
 [0.         0.         0.31028898 0.12928589 0.34873985 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.9285714030265808
#####################         POISON         ###############################################

############################################################################################

comm_round: 18 | global_test_acc: 80.000% | global_f1: 0.888888888888889 | global_precision: 0.8
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.80      1.00      0.89         8

    accuracy                           0.80        10
   macro avg       0.40      0.50      0.44        10
weighted avg       0.64      0.80      0.71        10

Accuracy per class:
[[8 0]
 [2 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_fg shape (30,)
[1.         0.57227525 0.         1.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.        ]
wv_mn shape (30,)
[1.         0.         0.47442571 1.         0.         0.
 0.         0.49584376 1.         0.52645764 0.22882228 0.
 0.33257491 0.87311502 0.56021768 0.         0.         0.
 0.         0.         0.         0.         0.         0.32004773
 0.         1.         0.         0.         0.         0.23919279]
wv_ed shape (30,)
[1.         0.         0.24241025 0.98113444 0.         0.
 0.         0.4433908  1.         0.40593912 0.17248129 0.
 0.25961322 0.76188779 0.4244225  0.         0.         0.
 0.         0.         0.         0.         0.         0.21610632
 0.         1.         0.         0.         0.         0.14619258]
wv_lg shape (30, 1)
[[0.35242198]
 [0.35254318]
 [0.35255077]
 [0.35266043]
 [0.35256721]
 [0.34969384]
 [0.34965403]
 [0.34967778]
 [0.34973618]
 [0.34963457]
 [0.34971056]
 [0.34967284]
 [0.34971196]
 [0.34979842]
 [0.34969959]
 [0.34970211]
 [0.34963853]
 [0.3497447 ]
 [0.34968283]
 [0.34957842]
 [0.34964405]
 [0.34965869]
 [0.34957155]
 [0.34965889]
 [0.3496162 ]
 [0.34972822]
 [0.34975692]
 [0.34961299]
 [0.34960198]
 [0.34964526]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_std shape (30,)
[1.         0.91928207 0.88873459 0.45144347 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.        ]
xy shape: (30, 9)
[[1.         1.         1.         1.         0.35242198 1.
  1.         1.         0.        ]
 [0.         0.57227525 0.         0.         0.35254318 1.
  1.         0.91928207 0.        ]
 [0.         0.         0.47442571 0.24241025 0.35255077 1.
  1.         0.88873459 0.        ]
 [0.         1.         1.         0.98113444 0.35266043 1.
  1.         0.45144347 0.        ]
 [0.         0.         0.         0.         0.35256721 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.34969384 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34965403 1.
  0.         0.         1.        ]
 [0.         0.         0.49584376 0.4433908  0.34967778 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.34973618 1.
  0.         0.         1.        ]
 [0.         0.         0.52645764 0.40593912 0.34963457 1.
  0.         0.         1.        ]
 [0.         0.         0.22882228 0.17248129 0.34971056 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34967284 1.
  0.         0.         1.        ]
 [0.         0.         0.33257491 0.25961322 0.34971196 1.
  0.         0.         1.        ]
 [0.         0.         0.87311502 0.76188779 0.34979842 1.
  0.         0.         1.        ]
 [0.         0.         0.56021768 0.4244225  0.34969959 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34970211 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34963853 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3497447  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34968283 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34957842 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34964405 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34965869 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34957155 1.
  0.         0.         1.        ]
 [0.         0.         0.32004773 0.21610632 0.34965889 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3496162  1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.34972822 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34975692 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34961299 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34960198 1.
  0.         0.         1.        ]
 [0.         0.         0.23919279 0.14619258 0.34964526 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.7857142686843872
#####################         POISON         ###############################################

############################################################################################

comm_round: 19 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00        10

    accuracy                           1.00        10
   macro avg       1.00      1.00      1.00        10
weighted avg       1.00      1.00      1.00        10

Accuracy per class:
[[10  0]
 [ 0  0]]
[ 1. nan]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[1.         1.         0.         1.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.02428968 0.         0.         0.         0.         0.        ]
wv_fg shape (30,)
[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_mn shape (30,)
[1.         1.         0.         1.         1.         0.
 0.         0.55461493 0.         0.         0.         0.
 0.         0.05475926 0.         0.         0.         0.
 0.         0.4476141  0.01667787 0.03077794 0.59005214 0.
 0.99066449 0.18697862 0.         0.         0.49871637 0.        ]
wv_ed shape (30,)
[1.         1.         0.         1.         0.99598904 0.
 0.         0.62174981 0.         0.         0.         0.
 0.05403294 0.04883869 0.00817862 0.         0.         0.
 0.         0.36968571 0.         0.         0.58021588 0.
 0.91494336 0.14461408 0.         0.         0.55839514 0.        ]
wv_lg shape (30, 1)
[[0.35298936]
 [0.35303776]
 [0.35310667]
 [0.35292325]
 [0.35312076]
 [0.35020624]
 [0.35029235]
 [0.35021279]
 [0.35036176]
 [0.35030757]
 [0.3502326 ]
 [0.3502091 ]
 [0.35020565]
 [0.35040112]
 [0.35018124]
 [0.35034203]
 [0.350211  ]
 [0.35029233]
 [0.35032058]
 [0.35030305]
 [0.35034109]
 [0.35033085]
 [0.3503489 ]
 [0.3503765 ]
 [0.35028234]
 [0.35045271]
 [0.35034786]
 [0.35034075]
 [0.35045913]
 [0.35026233]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_std shape (30,)
[1.         1.         0.         1.         0.66970788 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.        ]
xy shape: (30, 9)
[[1.         0.         1.         1.         0.35298936 1.
  1.         1.         0.        ]
 [1.         0.         1.         1.         0.35303776 1.
  1.         1.         0.        ]
 [0.         1.         0.         0.         0.35310667 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.35292325 1.
  1.         1.         0.        ]
 [0.         0.         1.         0.99598904 0.35312076 1.
  1.         0.66970788 0.        ]
 [0.         0.         0.         0.         0.35020624 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35029235 1.
  0.         0.         1.        ]
 [0.         0.         0.55461493 0.62174981 0.35021279 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35036176 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35030757 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3502326  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3502091  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.05403294 0.35020565 1.
  0.         0.         1.        ]
 [0.         0.         0.05475926 0.04883869 0.35040112 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.00817862 0.35018124 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35034203 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.350211   1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35029233 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35032058 1.
  0.         0.         1.        ]
 [0.         0.         0.4476141  0.36968571 0.35030305 1.
  0.         0.         1.        ]
 [0.         0.         0.01667787 0.         0.35034109 1.
  0.         0.         1.        ]
 [0.         0.         0.03077794 0.         0.35033085 1.
  0.         0.         1.        ]
 [0.         0.         0.59005214 0.58021588 0.3503489  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3503765  1.
  0.         0.         1.        ]
 [0.02428968 0.         0.99066449 0.91494336 0.35028234 1.
  0.         0.         1.        ]
 [0.         0.         0.18697862 0.14461408 0.35045271 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35034786 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35034075 1.
  0.         0.         1.        ]
 [0.         0.         0.49871637 0.55839514 0.35045913 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35026233 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
1.0
#####################         POISON         ###############################################

############################################################################################

comm_round: 20 | global_test_acc: 80.000% | global_f1: 0.888888888888889 | global_precision: 0.8
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.80      1.00      0.89         8

    accuracy                           0.80        10
   macro avg       0.40      0.50      0.44        10
weighted avg       0.64      0.80      0.71        10

Accuracy per class:
[[8 0]
 [2 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_fg shape (30,)
[1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_mn shape (30,)
[0.         0.         1.         0.         0.13712676 0.25849558
 1.         0.         0.33031183 0.20983918 0.44647873 0.97615262
 0.         1.         0.09550418 0.99341362 1.         0.
 0.74030028 0.38791631 1.         0.         1.         0.50244059
 0.92977334 0.99399397 0.79845657 1.         0.29515738 1.        ]
wv_ed shape (30,)
[0.         0.         1.         0.         0.38579264 0.45505053
 1.         0.         0.55465791 0.41713566 0.56271361 1.
 0.         1.         0.21638187 1.         1.         0.
 0.84246135 0.53218103 1.         0.         1.         0.70045499
 1.         1.         1.         1.         0.59423946 1.        ]
wv_lg shape (30, 1)
[[0.3537468 ]
 [0.35345137]
 [0.3534773 ]
 [0.35352281]
 [0.3534625 ]
 [0.35076271]
 [0.35084732]
 [0.35060624]
 [0.3506173 ]
 [0.35063235]
 [0.35075177]
 [0.35076208]
 [0.35071105]
 [0.350639  ]
 [0.35059621]
 [0.35068827]
 [0.3506711 ]
 [0.35068294]
 [0.35059412]
 [0.35079489]
 [0.35068554]
 [0.35069593]
 [0.35065904]
 [0.35073873]
 [0.35066691]
 [0.35060974]
 [0.35068664]
 [0.35062353]
 [0.35072287]
 [0.35074632]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_std shape (30,)
[0.         0.         1.         0.         0.         0.
 0.08467139 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.        ]
xy shape: (30, 9)
[[0.         1.         0.         0.         0.3537468  1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.35345137 1.
  1.         0.         0.        ]
 [1.         1.         1.         1.         0.3534773  1.
  1.         1.         0.        ]
 [0.         1.         0.         0.         0.35352281 1.
  1.         0.         0.        ]
 [0.         0.         0.13712676 0.38579264 0.3534625  1.
  1.         0.         0.        ]
 [0.         0.         0.25849558 0.45505053 0.35076271 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.35084732 1.
  0.         0.08467139 1.        ]
 [0.         0.         0.         0.         0.35060624 1.
  0.         0.         1.        ]
 [0.         0.         0.33031183 0.55465791 0.3506173  1.
  0.         0.         1.        ]
 [0.         0.         0.20983918 0.41713566 0.35063235 1.
  0.         0.         1.        ]
 [0.         0.         0.44647873 0.56271361 0.35075177 1.
  0.         0.         1.        ]
 [0.         0.         0.97615262 1.         0.35076208 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35071105 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.350639   1.
  0.         0.         1.        ]
 [0.         0.         0.09550418 0.21638187 0.35059621 1.
  0.         0.         1.        ]
 [0.         0.         0.99341362 1.         0.35068827 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.3506711  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35068294 1.
  0.         0.         1.        ]
 [0.         0.         0.74030028 0.84246135 0.35059412 1.
  0.         0.         1.        ]
 [0.         0.         0.38791631 0.53218103 0.35079489 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.35068554 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35069593 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.35065904 1.
  0.         0.         1.        ]
 [0.         0.         0.50244059 0.70045499 0.35073873 1.
  0.         0.         1.        ]
 [0.         0.         0.92977334 1.         0.35066691 1.
  0.         0.         1.        ]
 [0.         0.         0.99399397 1.         0.35060974 1.
  0.         0.         1.        ]
 [0.         0.         0.79845657 1.         0.35068664 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.35062353 1.
  0.         0.         1.        ]
 [0.         0.         0.29515738 0.59423946 0.35072287 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.35074632 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.7142857313156128
#####################         POISON         ###############################################

############################################################################################

comm_round: 21 | global_test_acc: 90.000% | global_f1: 0.9473684210526316 | global_precision: 0.9
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.90      1.00      0.95         9

    accuracy                           0.90        10
   macro avg       0.45      0.50      0.47        10
weighted avg       0.81      0.90      0.85        10

Accuracy per class:
[[9 0]
 [1 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_fg shape (30,)
[0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_mn shape (30,)
[0.56839971 0.         0.         0.58360901 1.         0.39556847
 0.5600538  0.         1.         0.         0.         0.04863572
 1.         0.33904915 0.         0.         0.32063807 0.
 0.         0.46308012 0.         0.         0.         0.
 0.         0.         0.37912977 0.38426934 0.6818773  0.        ]
wv_ed shape (30,)
[0.74197765 0.         0.         0.74784133 1.         0.23717716
 0.30381386 0.         1.         0.         0.         0.06802556
 1.         0.19892555 0.         0.         0.1715916  0.
 0.         0.3497425  0.         0.         0.         0.
 0.         0.         0.3164338  0.23243688 0.4183305  0.        ]
wv_lg shape (30, 1)
[[0.35410038]
 [0.35404865]
 [0.35414441]
 [0.35408831]
 [0.35421817]
 [0.3513948 ]
 [0.3515433 ]
 [0.35134926]
 [0.35143783]
 [0.35162878]
 [0.35143639]
 [0.35138911]
 [0.35162616]
 [0.35157413]
 [0.35137083]
 [0.35143978]
 [0.35156717]
 [0.3515523 ]
 [0.35139715]
 [0.35139356]
 [0.35157366]
 [0.35150554]
 [0.35146729]
 [0.35153674]
 [0.35141839]
 [0.35146319]
 [0.35156472]
 [0.35146411]
 [0.35136298]
 [0.35136876]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_std shape (30,)
[0.63792119 0.         0.         0.31577823 0.47488848 0.
 0.83986739 0.         1.         0.         0.         0.
 1.         0.88407726 0.         0.         0.25170698 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.0378248  0.         0.43366243 0.        ]
xy shape: (30, 9)
[[0.         0.         0.56839971 0.74197765 0.35410038 1.
  1.         0.63792119 0.        ]
 [0.         0.         0.         0.         0.35404865 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.35414441 1.
  1.         0.         0.        ]
 [0.         0.         0.58360901 0.74784133 0.35408831 1.
  1.         0.31577823 0.        ]
 [1.         1.         1.         1.         0.35421817 1.
  1.         0.47488848 0.        ]
 [0.         0.         0.39556847 0.23717716 0.3513948  1.
  0.         0.         1.        ]
 [0.         0.         0.5600538  0.30381386 0.3515433  1.
  0.         0.83986739 1.        ]
 [0.         0.         0.         0.         0.35134926 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.35143783 1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.35162878 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35143639 1.
  0.         0.         1.        ]
 [0.         0.         0.04863572 0.06802556 0.35138911 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.35162616 1.
  0.         1.         1.        ]
 [0.         0.         0.33904915 0.19892555 0.35157413 1.
  0.         0.88407726 1.        ]
 [0.         0.         0.         0.         0.35137083 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35143978 1.
  0.         0.         1.        ]
 [0.         0.         0.32063807 0.1715916  0.35156717 1.
  0.         0.25170698 1.        ]
 [0.         0.         0.         0.         0.3515523  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35139715 1.
  0.         0.         1.        ]
 [0.         0.         0.46308012 0.3497425  0.35139356 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35157366 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35150554 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35146729 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35153674 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35141839 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35146319 1.
  0.         0.         1.        ]
 [0.         0.         0.37912977 0.3164338  0.35156472 1.
  0.         0.0378248  1.        ]
 [0.         0.         0.38426934 0.23243688 0.35146411 1.
  0.         0.         1.        ]
 [0.         0.         0.6818773  0.4183305  0.35136298 1.
  0.         0.43366243 1.        ]
 [0.         0.         0.         0.         0.35136876 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.7857142686843872
#####################         POISON         ###############################################

############################################################################################

comm_round: 22 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00        10

    accuracy                           1.00        10
   macro avg       1.00      1.00      1.00        10
weighted avg       1.00      1.00      1.00        10

Accuracy per class:
[[10  0]
 [ 0  0]]
[ 1. nan]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0.         0.         0.02353545 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         1.         0.         0.
 0.         0.         0.         0.         0.         0.        ]
wv_fg shape (30,)
[1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_mn shape (30,)
[0.         1.         1.         0.24610342 0.77720248 0.22243909
 0.77300439 0.         0.10795133 1.         0.08476133 0.05467894
 0.00612891 0.23342115 0.         0.         0.         0.59030799
 0.         0.         0.         1.         0.96941793 0.
 0.         0.         0.         0.38864226 0.         0.        ]
wv_ed shape (30,)
[0.         1.         1.         0.         1.         0.40397597
 0.67927027 0.         0.19884681 1.         0.0407569  0.06977629
 0.07049937 0.25502567 0.         0.         0.         0.62765617
 0.         0.         0.         1.         0.99801223 0.
 0.         0.         0.         0.48001351 0.         0.        ]
wv_lg shape (30, 1)
[[0.35459508]
 [0.35448347]
 [0.35458679]
 [0.35479248]
 [0.35463166]
 [0.35201592]
 [0.35216142]
 [0.35204952]
 [0.35206928]
 [0.35209479]
 [0.35217483]
 [0.3521138 ]
 [0.35207083]
 [0.35213596]
 [0.35211597]
 [0.35203601]
 [0.35197745]
 [0.35197589]
 [0.35212116]
 [0.35199375]
 [0.35208322]
 [0.35215991]
 [0.35202859]
 [0.35206158]
 [0.35199398]
 [0.35205859]
 [0.35198662]
 [0.35205677]
 [0.35217227]
 [0.35198902]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_std shape (30,)
[0.         0.         0.24710832 0.         0.         0.
 1.         0.         0.         1.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         1.         1.         0.
 0.         0.         0.         0.         0.         0.        ]
xy shape: (30, 9)
[[0.         1.         0.         0.         0.35459508 1.
  1.         0.         0.        ]
 [0.         1.         1.         1.         0.35448347 1.
  1.         0.         0.        ]
 [0.02353545 0.         1.         1.         0.35458679 1.
  1.         0.24710832 0.        ]
 [0.         1.         0.24610342 0.         0.35479248 1.
  1.         0.         0.        ]
 [0.         0.         0.77720248 1.         0.35463166 1.
  1.         0.         0.        ]
 [0.         0.         0.22243909 0.40397597 0.35201592 1.
  0.         0.         1.        ]
 [0.         0.         0.77300439 0.67927027 0.35216142 1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.35204952 1.
  0.         0.         1.        ]
 [0.         0.         0.10795133 0.19884681 0.35206928 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.35209479 1.
  0.         1.         1.        ]
 [0.         0.         0.08476133 0.0407569  0.35217483 1.
  0.         0.         1.        ]
 [0.         0.         0.05467894 0.06977629 0.3521138  1.
  0.         0.         1.        ]
 [0.         0.         0.00612891 0.07049937 0.35207083 1.
  0.         0.         1.        ]
 [0.         0.         0.23342115 0.25502567 0.35213596 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35211597 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35203601 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35197745 1.
  0.         0.         1.        ]
 [0.         0.         0.59030799 0.62765617 0.35197589 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35212116 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35199375 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35208322 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35215991 1.
  0.         1.         1.        ]
 [0.         0.         0.96941793 0.99801223 0.35202859 1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.35206158 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35199398 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35205859 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35198662 1.
  0.         0.         1.        ]
 [0.         0.         0.38864226 0.48001351 0.35205677 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35217227 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35198902 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.9285714030265808
#####################         POISON         ###############################################

############################################################################################

comm_round: 23 | global_test_acc: 70.000% | global_f1: 0.8235294117647058 | global_precision: 0.7
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.70      1.00      0.82         7

    accuracy                           0.70        10
   macro avg       0.35      0.50      0.41        10
weighted avg       0.49      0.70      0.58        10

Accuracy per class:
[[7 0]
 [3 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_fg shape (30,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_mn shape (30,)
[0.         0.17895338 1.         0.57512365 1.         0.
 0.         0.17690852 0.         0.         0.         0.08676077
 0.         0.         0.         0.         0.         0.1395987
 0.         0.         0.         0.         0.         0.
 0.40706964 0.29435383 0.         0.57234703 0.         0.        ]
wv_ed shape (30,)
[0.         0.4116099  1.         0.64921151 1.         0.
 0.         0.14031957 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.09105708
 0.         0.         0.         0.         0.         0.
 0.34917226 0.2663215  0.         0.5672225  0.         0.        ]
wv_lg shape (30, 1)
[[0.35523912]
 [0.35507115]
 [0.35506562]
 [0.35518079]
 [0.35499014]
 [0.35250599]
 [0.35261538]
 [0.35258685]
 [0.35256609]
 [0.35246542]
 [0.35238177]
 [0.35243271]
 [0.35258623]
 [0.35248828]
 [0.35246248]
 [0.35248134]
 [0.35244501]
 [0.35252644]
 [0.35238956]
 [0.3525394 ]
 [0.35247222]
 [0.35250101]
 [0.3523976 ]
 [0.35241106]
 [0.35251623]
 [0.35260542]
 [0.35254735]
 [0.35243649]
 [0.35254345]
 [0.35247123]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_std shape (30,)
[0.         0.         0.         0.46296394 1.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.        ]
xy shape: (30, 9)
[[0.         1.         0.         0.         0.35523912 1.
  1.         0.         0.        ]
 [0.         0.         0.17895338 0.4116099  0.35507115 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.35506562 1.
  1.         0.         0.        ]
 [0.         0.         0.57512365 0.64921151 0.35518079 1.
  1.         0.46296394 0.        ]
 [1.         0.         1.         1.         0.35499014 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.35250599 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35261538 1.
  0.         0.         1.        ]
 [0.         0.         0.17690852 0.14031957 0.35258685 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35256609 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35246542 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35238177 1.
  0.         0.         1.        ]
 [0.         0.         0.08676077 0.         0.35243271 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35258623 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35248828 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35246248 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35248134 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35244501 1.
  0.         0.         1.        ]
 [0.         0.         0.1395987  0.09105708 0.35252644 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35238956 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3525394  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35247222 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35250101 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3523976  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35241106 1.
  0.         0.         1.        ]
 [0.         0.         0.40706964 0.34917226 0.35251623 1.
  0.         0.         1.        ]
 [0.         0.         0.29435383 0.2663215  0.35260542 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35254735 1.
  0.         0.         1.        ]
 [0.         0.         0.57234703 0.5672225  0.35243649 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35254345 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35247123 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.7857142686843872
#####################         POISON         ###############################################

############################################################################################

comm_round: 24 | global_test_acc: 90.000% | global_f1: 0.9473684210526316 | global_precision: 0.9
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.90      1.00      0.95         9

    accuracy                           0.90        10
   macro avg       0.45      0.50      0.47        10
weighted avg       0.81      0.90      0.85        10

Accuracy per class:
[[9 0]
 [1 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_fg shape (30,)
[0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_mn shape (30,)
[1.         0.         0.         1.         1.         0.86373114
 0.7261781  1.         0.1235801  0.         0.1142587  1.
 1.         1.         0.         0.21259551 0.89984134 0.2512006
 0.84679594 1.         0.         0.25130519 0.20606728 0.58684778
 1.         1.         1.         1.         0.         0.39093402]
wv_ed shape (30,)
[1.         0.         0.         1.         1.         0.87925936
 0.72553972 1.         0.02357025 0.         0.02475266 1.
 1.         1.         0.         0.17687393 0.91031236 0.26474768
 0.77251736 1.         0.         0.26448149 0.10592968 0.6486446
 1.         1.         1.         1.         0.         0.28594566]
wv_lg shape (30, 1)
[[0.35554967]
 [0.35577556]
 [0.3556903 ]
 [0.35552136]
 [0.35558026]
 [0.35325601]
 [0.35329173]
 [0.35319626]
 [0.35322329]
 [0.35329257]
 [0.35324232]
 [0.35329958]
 [0.35319714]
 [0.35320259]
 [0.35319054]
 [0.35318441]
 [0.35317065]
 [0.35323914]
 [0.35325319]
 [0.35317583]
 [0.3531638 ]
 [0.35320162]
 [0.35318072]
 [0.35318004]
 [0.35319423]
 [0.3533066 ]
 [0.35313734]
 [0.35323918]
 [0.3532423 ]
 [0.35316161]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_std shape (30,)
[1.         0.         0.         1.         1.         0.
 0.         0.         0.         0.         0.         0.
 1.         0.         0.         0.         0.         0.
 0.52498785 0.08597809 0.         0.         0.         0.
 0.         0.         0.07191436 0.06497545 0.         0.        ]
xy shape: (30, 9)
[[1.         0.         1.         1.         0.35554967 1.
  1.         1.         0.        ]
 [0.         1.         0.         0.         0.35577556 1.
  1.         0.         0.        ]
 [0.         1.         0.         0.         0.3556903  1.
  1.         0.         0.        ]
 [0.         1.         1.         1.         0.35552136 1.
  1.         1.         0.        ]
 [1.         0.         1.         1.         0.35558026 1.
  1.         1.         0.        ]
 [0.         0.         0.86373114 0.87925936 0.35325601 1.
  0.         0.         1.        ]
 [0.         0.         0.7261781  0.72553972 0.35329173 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.35319626 1.
  0.         0.         1.        ]
 [0.         0.         0.1235801  0.02357025 0.35322329 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35329257 1.
  0.         0.         1.        ]
 [0.         0.         0.1142587  0.02475266 0.35324232 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.35329958 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.35319714 1.
  0.         1.         1.        ]
 [0.         0.         1.         1.         0.35320259 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35319054 1.
  0.         0.         1.        ]
 [0.         0.         0.21259551 0.17687393 0.35318441 1.
  0.         0.         1.        ]
 [0.         0.         0.89984134 0.91031236 0.35317065 1.
  0.         0.         1.        ]
 [0.         0.         0.2512006  0.26474768 0.35323914 1.
  0.         0.         1.        ]
 [0.         0.         0.84679594 0.77251736 0.35325319 1.
  0.         0.52498785 1.        ]
 [0.         0.         1.         1.         0.35317583 1.
  0.         0.08597809 1.        ]
 [0.         0.         0.         0.         0.3531638  1.
  0.         0.         1.        ]
 [0.         0.         0.25130519 0.26448149 0.35320162 1.
  0.         0.         1.        ]
 [0.         0.         0.20606728 0.10592968 0.35318072 1.
  0.         0.         1.        ]
 [0.         0.         0.58684778 0.6486446  0.35318004 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.35319423 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.3533066  1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.35313734 1.
  0.         0.07191436 1.        ]
 [0.         0.         1.         1.         0.35323918 1.
  0.         0.06497545 1.        ]
 [0.         0.         0.         0.         0.3532423  1.
  0.         0.         1.        ]
 [0.         0.         0.39093402 0.28594566 0.35316161 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.9285714030265808
#####################         POISON         ###############################################

############################################################################################

comm_round: 25 | global_test_acc: 70.000% | global_f1: 0.8235294117647058 | global_precision: 0.7
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.70      1.00      0.82         7

    accuracy                           0.70        10
   macro avg       0.35      0.50      0.41        10
weighted avg       0.49      0.70      0.58        10

Accuracy per class:
[[7 0]
 [3 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_fg shape (30,)
[0.         1.         0.64203597 1.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.        ]
wv_mn shape (30,)
[1.         1.         0.         1.         1.         0.
 0.4366957  0.44195559 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.04908631
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.22637562 0.        ]
wv_ed shape (30,)
[1.         1.         0.         1.         1.         0.
 0.48845395 0.49679426 0.         0.         0.         0.
 0.04052661 0.         0.         0.         0.         0.06958358
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.2844924  0.        ]
wv_lg shape (30, 1)
[[0.35609487]
 [0.35621039]
 [0.35619007]
 [0.35622013]
 [0.35608709]
 [0.35365916]
 [0.35382294]
 [0.35378367]
 [0.35378028]
 [0.35368174]
 [0.35360126]
 [0.35372036]
 [0.35358977]
 [0.3537302 ]
 [0.35366374]
 [0.35370453]
 [0.35368516]
 [0.3538546 ]
 [0.35366586]
 [0.35370182]
 [0.35365194]
 [0.35382125]
 [0.35365185]
 [0.35365519]
 [0.35360107]
 [0.35367559]
 [0.35370103]
 [0.35367327]
 [0.35364853]
 [0.35365111]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_std shape (30,)
[1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
xy shape: (30, 9)
[[1.         0.         1.         1.         0.35609487 1.
  1.         1.         0.        ]
 [1.         1.         1.         1.         0.35621039 1.
  1.         1.         0.        ]
 [0.         0.64203597 0.         0.         0.35619007 1.
  1.         0.         0.        ]
 [1.         1.         1.         1.         0.35622013 1.
  1.         1.         0.        ]
 [1.         0.         1.         1.         0.35608709 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.35365916 1.
  0.         0.         1.        ]
 [0.         0.         0.4366957  0.48845395 0.35382294 1.
  0.         0.         1.        ]
 [0.         0.         0.44195559 0.49679426 0.35378367 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35378028 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35368174 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35360126 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35372036 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.04052661 0.35358977 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3537302  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35366374 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35370453 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35368516 1.
  0.         0.         1.        ]
 [0.         0.         0.04908631 0.06958358 0.3538546  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35366586 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35370182 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35365194 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35382125 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35365185 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35365519 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35360107 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35367559 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35370103 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35367327 1.
  0.         0.         1.        ]
 [0.         0.         0.22637562 0.2844924  0.35364853 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35365111 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.9285714030265808
#####################         POISON         ###############################################

############################################################################################

comm_round: 26 | global_test_acc: 70.000% | global_f1: 0.8235294117647058 | global_precision: 0.7
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.70      1.00      0.82         7

    accuracy                           0.70        10
   macro avg       0.35      0.50      0.41        10
weighted avg       0.49      0.70      0.58        10

Accuracy per class:
[[7 0]
 [3 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_fg shape (30,)
[0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_mn shape (30,)
[1.         0.         0.16775887 0.         0.14681532 1.
 1.         1.         0.         1.         0.         0.
 0.         0.         1.         0.         0.46465628 0.
 0.28408947 0.24358676 0.         0.         1.         0.0942001
 0.         0.         0.97988076 0.07050108 0.53977251 0.1399038 ]
wv_ed shape (30,)
[1.         0.         0.34694163 0.         0.30013434 1.
 1.         1.         0.         1.         0.         0.
 0.         0.         1.         0.         0.61347396 0.
 0.2246154  0.36295863 0.         0.         1.         0.07581044
 0.         0.         1.         0.05574883 0.61686632 0.1780741 ]
wv_lg shape (30, 1)
[[0.35657796]
 [0.35644438]
 [0.35661573]
 [0.35659194]
 [0.35676989]
 [0.35421416]
 [0.35419028]
 [0.35427604]
 [0.35424251]
 [0.3542699 ]
 [0.35425441]
 [0.3541828 ]
 [0.354204  ]
 [0.35423801]
 [0.35420345]
 [0.35416602]
 [0.35417546]
 [0.35420195]
 [0.35426271]
 [0.35432004]
 [0.35427439]
 [0.35426401]
 [0.35415459]
 [0.35423963]
 [0.35415422]
 [0.35424421]
 [0.35420535]
 [0.35415675]
 [0.35429227]
 [0.35422227]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_std shape (30,)
[0.75554095 0.         0.         0.         0.         0.13571471
 1.         0.63381983 0.         1.         0.         0.
 0.         0.         1.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.42175181 0.        ]
xy shape: (30, 9)
[[0.         0.         1.         1.         0.35657796 1.
  1.         0.75554095 0.        ]
 [0.         0.         0.         0.         0.35644438 1.
  1.         0.         0.        ]
 [0.         0.         0.16775887 0.34694163 0.35661573 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.35659194 1.
  1.         0.         0.        ]
 [0.         1.         0.14681532 0.30013434 0.35676989 1.
  1.         0.         0.        ]
 [0.         0.         1.         1.         0.35421416 1.
  0.         0.13571471 1.        ]
 [1.         0.         1.         1.         0.35419028 1.
  0.         1.         1.        ]
 [0.         0.         1.         1.         0.35427604 1.
  0.         0.63381983 1.        ]
 [0.         0.         0.         0.         0.35424251 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.3542699  1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.35425441 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3541828  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.354204   1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35423801 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35420345 1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.35416602 1.
  0.         0.         1.        ]
 [0.         0.         0.46465628 0.61347396 0.35417546 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35420195 1.
  0.         0.         1.        ]
 [0.         0.         0.28408947 0.2246154  0.35426271 1.
  0.         0.         1.        ]
 [0.         0.         0.24358676 0.36295863 0.35432004 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35427439 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35426401 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.35415459 1.
  0.         0.         1.        ]
 [0.         0.         0.0942001  0.07581044 0.35423963 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35415422 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35424421 1.
  0.         0.         1.        ]
 [0.         0.         0.97988076 1.         0.35420535 1.
  0.         0.         1.        ]
 [0.         0.         0.07050108 0.05574883 0.35415675 1.
  0.         0.         1.        ]
 [0.         0.         0.53977251 0.61686632 0.35429227 1.
  0.         0.42175181 1.        ]
 [0.         0.         0.1399038  0.1780741  0.35422227 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.7142857313156128
#####################         POISON         ###############################################

############################################################################################

comm_round: 27 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00        10

    accuracy                           1.00        10
   macro avg       1.00      1.00      1.00        10
weighted avg       1.00      1.00      1.00        10

Accuracy per class:
[[10  0]
 [ 0  0]]
[ 1. nan]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_fg shape (30,)
[0.         0.         0.14108358 0.         1.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.        ]
wv_mn shape (30,)
[1.         0.91218811 0.         0.         1.         0.
 0.33828835 0.         0.         0.         0.         0.
 0.         0.3710646  0.         0.         0.         0.
 0.         0.8134612  0.         0.         0.         0.
 0.18673104 0.         0.         1.         0.         0.0236638 ]
wv_ed shape (30,)
[1.         1.         0.         0.         1.         0.03125229
 0.38189476 0.         0.0154503  0.         0.         0.
 0.         0.38409149 0.         0.         0.         0.
 0.         0.82932556 0.         0.         0.         0.
 0.12345384 0.         0.         1.         0.         0.05395167]
wv_lg shape (30, 1)
[[0.35698943]
 [0.35707128]
 [0.35701178]
 [0.35701818]
 [0.35713762]
 [0.35478209]
 [0.35485782]
 [0.35474688]
 [0.35477269]
 [0.3548102 ]
 [0.35494306]
 [0.35471725]
 [0.35480589]
 [0.35484192]
 [0.35475361]
 [0.3547291 ]
 [0.35478075]
 [0.35473702]
 [0.35477815]
 [0.35471631]
 [0.35476394]
 [0.35475938]
 [0.35475175]
 [0.35487764]
 [0.35476983]
 [0.35483817]
 [0.3547911 ]
 [0.35488492]
 [0.35477064]
 [0.3548133 ]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_std shape (30,)
[1.         0.94594486 0.         0.         1.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.37067343 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.        ]
xy shape: (30, 9)
[[1.         0.         1.         1.         0.35698943 1.
  1.         1.         0.        ]
 [0.         0.         0.91218811 1.         0.35707128 1.
  1.         0.94594486 0.        ]
 [0.         0.14108358 0.         0.         0.35701178 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.35701818 1.
  1.         0.         0.        ]
 [1.         1.         1.         1.         0.35713762 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.03125229 0.35478209 1.
  0.         0.         1.        ]
 [0.         0.         0.33828835 0.38189476 0.35485782 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35474688 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.0154503  0.35477269 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3548102  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35494306 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35471725 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35480589 1.
  0.         0.         1.        ]
 [0.         0.         0.3710646  0.38409149 0.35484192 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35475361 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3547291  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35478075 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35473702 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35477815 1.
  0.         0.         1.        ]
 [0.         0.         0.8134612  0.82932556 0.35471631 1.
  0.         0.37067343 1.        ]
 [0.         0.         0.         0.         0.35476394 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35475938 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35475175 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35487764 1.
  0.         0.         1.        ]
 [0.         0.         0.18673104 0.12345384 0.35476983 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35483817 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3547911  1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.35488492 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35477064 1.
  0.         0.         1.        ]
 [0.         0.         0.0236638  0.05395167 0.3548133  1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.8571428656578064
#####################         POISON         ###############################################

############################################################################################

comm_round: 28 | global_test_acc: 80.000% | global_f1: 0.888888888888889 | global_precision: 0.8
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.80      1.00      0.89         8

    accuracy                           0.80        10
   macro avg       0.40      0.50      0.44        10
weighted avg       0.64      0.80      0.71        10

Accuracy per class:
[[8 0]
 [2 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_fg shape (30,)
[1.         0.78929192 0.         0.         0.78929192 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.        ]
wv_mn shape (30,)
[0.         1.         0.         1.         1.         0.
 0.         0.18308874 0.         0.28773653 0.41244298 1.
 0.         0.55353934 0.         1.         0.         1.
 1.         0.43827928 0.34621629 0.71504879 1.         1.
 1.         1.         0.         0.24043584 0.         0.        ]
wv_ed shape (30,)
[0.         1.         0.         1.         0.91276786 0.
 0.         0.16036738 0.         0.36807947 0.50979578 1.
 0.         0.53172009 0.         1.         0.         1.
 1.         0.3920578  0.34995966 0.71739577 1.         1.
 1.         1.         0.         0.19455531 0.         0.        ]
wv_lg shape (30, 1)
[[0.35749786]
 [0.35759023]
 [0.35759655]
 [0.35756522]
 [0.35751779]
 [0.35524615]
 [0.35525339]
 [0.35521878]
 [0.35529152]
 [0.35527709]
 [0.35526921]
 [0.35519364]
 [0.35512932]
 [0.35524863]
 [0.35522683]
 [0.35539641]
 [0.35523209]
 [0.35520781]
 [0.35536968]
 [0.35522763]
 [0.35529471]
 [0.35524151]
 [0.35527723]
 [0.35533019]
 [0.35529509]
 [0.35516656]
 [0.35508472]
 [0.35523424]
 [0.35521435]
 [0.35514479]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_std shape (30,)
[1.         1.         0.         1.         1.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.07734348 0.         0.
 0.2609341  0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.        ]
xy shape: (30, 9)
[[0.         1.         0.         0.         0.35749786 1.
  1.         1.         0.        ]
 [0.         0.78929192 1.         1.         0.35759023 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.35759655 1.
  1.         0.         0.        ]
 [0.         0.         1.         1.         0.35756522 1.
  1.         1.         0.        ]
 [0.         0.78929192 1.         0.91276786 0.35751779 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.35524615 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35525339 1.
  0.         0.         1.        ]
 [0.         0.         0.18308874 0.16036738 0.35521878 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35529152 1.
  0.         0.         1.        ]
 [0.         0.         0.28773653 0.36807947 0.35527709 1.
  0.         0.         1.        ]
 [0.         0.         0.41244298 0.50979578 0.35526921 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35519364 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35512932 1.
  0.         0.         1.        ]
 [0.         0.         0.55353934 0.53172009 0.35524863 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35522683 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.35539641 1.
  0.         0.07734348 1.        ]
 [0.         0.         0.         0.         0.35523209 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.35520781 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35536968 1.
  0.         0.2609341  1.        ]
 [0.         0.         0.43827928 0.3920578  0.35522763 1.
  0.         0.         1.        ]
 [0.         0.         0.34621629 0.34995966 0.35529471 1.
  0.         0.         1.        ]
 [0.         0.         0.71504879 0.71739577 0.35524151 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.35527723 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.35533019 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.35529509 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.35516656 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35508472 1.
  0.         0.         1.        ]
 [0.         0.         0.24043584 0.19455531 0.35523424 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35521435 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35514479 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.7857142686843872
#####################         POISON         ###############################################

############################################################################################

comm_round: 29 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00        10

    accuracy                           1.00        10
   macro avg       1.00      1.00      1.00        10
weighted avg       1.00      1.00      1.00        10

Accuracy per class:
[[10  0]
 [ 0  0]]
[ 1. nan]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients