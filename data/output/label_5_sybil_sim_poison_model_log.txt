
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_fg shape (30,)
[1.         1.         0.86681902 0.86681902 1.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.        ]
wv_mn shape (30,)
[1.         1.         0.         0.06506894 1.         0.
 0.76881289 0.         0.         0.69282501 0.         0.
 0.         0.         0.         0.28510991 0.         0.35418051
 0.18040379 0.14804833 0.         0.         0.02392669 0.
 0.         0.94554399 0.         0.04919641 0.         0.        ]
wv_ed shape (30,)
[1.         1.         0.         0.06737893 1.         0.
 0.67968617 0.         0.         0.62228574 0.         0.
 0.         0.         0.         0.20772542 0.         0.32669636
 0.08524269 0.09312486 0.         0.         0.         0.
 0.         0.86538408 0.         0.         0.         0.        ]
wv_lg shape (30, 1)
[[0.33807616]
 [0.3380569 ]
 [0.33814093]
 [0.33824884]
 [0.33828372]
 [0.33285142]
 [0.33281997]
 [0.3328868 ]
 [0.3328508 ]
 [0.33294209]
 [0.33287552]
 [0.33274529]
 [0.33294112]
 [0.33287638]
 [0.33288441]
 [0.33289293]
 [0.33301694]
 [0.33272654]
 [0.33308216]
 [0.33283842]
 [0.33288068]
 [0.33284589]
 [0.33279474]
 [0.33282521]
 [0.33288997]
 [0.33290644]
 [0.33266908]
 [0.33266946]
 [0.33282165]
 [0.33275866]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_std shape (30,)
[0.52044835 1.         0.         0.         1.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.        ]
xy shape: (30, 9)
[[1.         1.         1.         1.         0.33807616 1.
  1.         0.52044835 0.        ]
 [1.         1.         1.         1.         0.3380569  1.
  1.         1.         0.        ]
 [0.         0.86681902 0.         0.         0.33814093 1.
  1.         0.         0.        ]
 [0.         0.86681902 0.06506894 0.06737893 0.33824884 1.
  1.         0.         0.        ]
 [1.         1.         1.         1.         0.33828372 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.33285142 1.
  0.         0.         1.        ]
 [0.         0.         0.76881289 0.67968617 0.33281997 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3328868  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3328508  1.
  0.         0.         1.        ]
 [0.         0.         0.69282501 0.62228574 0.33294209 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33287552 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33274529 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33294112 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33287638 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33288441 1.
  0.         0.         1.        ]
 [0.         0.         0.28510991 0.20772542 0.33289293 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33301694 1.
  0.         0.         1.        ]
 [0.         0.         0.35418051 0.32669636 0.33272654 1.
  0.         0.         1.        ]
 [0.         0.         0.18040379 0.08524269 0.33308216 1.
  0.         0.         1.        ]
 [0.         0.         0.14804833 0.09312486 0.33283842 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33288068 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33284589 1.
  0.         0.         1.        ]
 [0.         0.         0.02392669 0.         0.33279474 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33282521 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33288997 1.
  0.         0.         1.        ]
 [0.         0.         0.94554399 0.86538408 0.33290644 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33266908 1.
  0.         0.         1.        ]
 [0.         0.         0.04919641 0.         0.33266946 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33282165 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33275866 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.7857142686843872
#####################         POISON         ###############################################

############################################################################################

comm_round: 0 | global_test_acc: 80.000% | global_f1: 0.888888888888889 | global_precision: 0.8
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.80      1.00      0.89         8

    accuracy                           0.80        10
   macro avg       0.40      0.50      0.44        10
weighted avg       0.64      0.80      0.71        10

Accuracy per class:
[[8 0]
 [2 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 1. 1. 0. 1. 0.]
wv_fg shape (30,)
[0.06620774 1.         0.06620774 1.         0.82385636 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.        ]
wv_mn shape (30,)
[0.         0.         1.         0.37932611 0.         0.
 1.         0.         0.34837045 1.         0.         0.
 0.         0.         0.15832527 1.         0.12847996 0.55559051
 0.58874039 1.         0.83350862 0.         0.3150669  0.4566647
 0.35118794 1.         1.         0.         1.         0.23319486]
wv_ed shape (30,)
[0.20371702 0.         1.         0.         0.         0.
 1.         0.         0.04828884 1.         0.         0.
 0.         0.         0.1276471  1.         0.         0.50893078
 0.39134805 1.         0.64557306 0.         0.25578685 0.38103129
 0.27686514 1.         1.         0.         1.         0.0736591 ]
wv_lg shape (30, 1)
[[0.33912339]
 [0.33920672]
 [0.33906005]
 [0.33936369]
 [0.33910171]
 [0.33401542]
 [0.33408676]
 [0.33384866]
 [0.33406357]
 [0.33398008]
 [0.33388864]
 [0.33401816]
 [0.33397547]
 [0.33389293]
 [0.33387783]
 [0.33404939]
 [0.33396339]
 [0.33392569]
 [0.33399797]
 [0.33410516]
 [0.33404243]
 [0.33407048]
 [0.33392117]
 [0.3339763 ]
 [0.33399891]
 [0.33389401]
 [0.33394911]
 [0.33397082]
 [0.33394871]
 [0.33414147]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_std shape (30,)
[0.         0.         0.         0.         0.         0.
 1.         0.         0.0332573  1.         0.         0.
 0.         0.         0.11621356 0.69733702 0.         0.
 0.67103626 1.         1.         0.76337356 0.         0.19660313
 0.04882158 0.97236846 0.57419671 0.         1.         0.06086347]
xy shape: (30, 9)
[[0.         0.06620774 0.         0.20371702 0.33912339 1.
  1.         0.         0.        ]
 [0.         1.         0.         0.         0.33920672 1.
  1.         0.         0.        ]
 [0.         0.06620774 1.         1.         0.33906005 1.
  1.         0.         0.        ]
 [0.         1.         0.37932611 0.         0.33936369 1.
  1.         0.         0.        ]
 [0.         0.82385636 0.         0.         0.33910171 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.33401542 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.33408676 1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.33384866 1.
  0.         0.         1.        ]
 [0.         0.         0.34837045 0.04828884 0.33406357 1.
  0.         0.0332573  1.        ]
 [0.         0.         1.         1.         0.33398008 1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.33388864 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33401816 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33397547 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33389293 1.
  0.         0.         1.        ]
 [0.         0.         0.15832527 0.1276471  0.33387783 1.
  0.         0.11621356 1.        ]
 [0.         0.         1.         1.         0.33404939 1.
  0.         0.69733702 1.        ]
 [0.         0.         0.12847996 0.         0.33396339 1.
  0.         0.         1.        ]
 [0.         0.         0.55559051 0.50893078 0.33392569 1.
  0.         0.         1.        ]
 [0.         0.         0.58874039 0.39134805 0.33399797 1.
  0.         0.67103626 1.        ]
 [1.         0.         1.         1.         0.33410516 1.
  0.         1.         1.        ]
 [0.         0.         0.83350862 0.64557306 0.33404243 1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.33407048 1.
  0.         0.76337356 1.        ]
 [0.         0.         0.3150669  0.25578685 0.33392117 1.
  0.         0.         1.        ]
 [0.         0.         0.4566647  0.38103129 0.3339763  1.
  0.         0.19660313 1.        ]
 [0.         0.         0.35118794 0.27686514 0.33399891 1.
  0.         0.04882158 1.        ]
 [1.         0.         1.         1.         0.33389401 1.
  0.         0.97236846 1.        ]
 [1.         0.         1.         1.         0.33394911 1.
  0.         0.57419671 1.        ]
 [0.         0.         0.         0.         0.33397082 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.33394871 1.
  0.         1.         1.        ]
 [0.         0.         0.23319486 0.0736591  0.33414147 1.
  0.         0.06086347 1.        ]]

Best Training Poisoning Accuracy:
1.0
#####################         POISON         ###############################################

############################################################################################

comm_round: 1 | global_test_acc: 70.000% | global_f1: 0.8235294117647058 | global_precision: 0.7
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.70      1.00      0.82         7

    accuracy                           0.70        10
   macro avg       0.35      0.50      0.41        10
weighted avg       0.49      0.70      0.58        10

Accuracy per class:
[[7 0]
 [3 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_fg shape (30,)
[1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_mn shape (30,)
[0.36722481 1.         1.         1.         0.         0.40983567
 0.79149016 0.         1.         0.         0.25625253 1.
 0.65307941 0.25253961 0.         0.         0.0871054  0.72039694
 0.09650814 0.         0.         0.3758744  0.94789614 1.
 0.29397305 0.11633417 0.05856147 0.50012063 0.91546942 0.        ]
wv_ed shape (30,)
[0.1525442  1.         1.         1.         0.         0.57693905
 1.         0.         1.         0.         0.4422521  1.
 0.73619129 0.4414836  0.         0.         0.23645733 0.81302545
 0.19100765 0.         0.         0.5395691  1.         1.
 0.44797488 0.19468857 0.12088956 0.61672634 1.         0.        ]
wv_lg shape (30, 1)
[[0.34022201]
 [0.34001551]
 [0.33980824]
 [0.34030093]
 [0.34012271]
 [0.33505785]
 [0.33500225]
 [0.33482158]
 [0.33519998]
 [0.33506427]
 [0.33499399]
 [0.3349453 ]
 [0.3351554 ]
 [0.33497906]
 [0.33498437]
 [0.33488144]
 [0.33507787]
 [0.33511804]
 [0.33497549]
 [0.33499071]
 [0.33503466]
 [0.3351339 ]
 [0.33501516]
 [0.33521509]
 [0.33498269]
 [0.33488651]
 [0.33485992]
 [0.33495108]
 [0.33511887]
 [0.33515191]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_std shape (30,)
[0.         0.99524419 0.8937584  0.         0.         0.
 0.         0.         1.         0.         0.         1.
 0.12191601 0.         0.         0.         0.         0.42279433
 0.         0.         0.         0.         0.         1.
 0.         0.         0.         0.         0.33169774 0.        ]
xy shape: (30, 9)
[[0.         1.         0.36722481 0.1525442  0.34022201 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.34001551 1.
  1.         0.99524419 0.        ]
 [0.         0.         1.         1.         0.33980824 1.
  1.         0.8937584  0.        ]
 [0.         0.         1.         1.         0.34030093 1.
  1.         0.         0.        ]
 [0.         1.         0.         0.         0.34012271 1.
  1.         0.         0.        ]
 [0.         0.         0.40983567 0.57693905 0.33505785 1.
  0.         0.         1.        ]
 [0.         0.         0.79149016 1.         0.33500225 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33482158 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.33519998 1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.33506427 1.
  0.         0.         1.        ]
 [0.         0.         0.25625253 0.4422521  0.33499399 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.3349453  1.
  0.         1.         1.        ]
 [0.         0.         0.65307941 0.73619129 0.3351554  1.
  0.         0.12191601 1.        ]
 [0.         0.         0.25253961 0.4414836  0.33497906 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33498437 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33488144 1.
  0.         0.         1.        ]
 [0.         0.         0.0871054  0.23645733 0.33507787 1.
  0.         0.         1.        ]
 [0.         0.         0.72039694 0.81302545 0.33511804 1.
  0.         0.42279433 1.        ]
 [0.         0.         0.09650814 0.19100765 0.33497549 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33499071 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33503466 1.
  0.         0.         1.        ]
 [0.         0.         0.3758744  0.5395691  0.3351339  1.
  0.         0.         1.        ]
 [0.         0.         0.94789614 1.         0.33501516 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.33521509 1.
  0.         1.         1.        ]
 [0.         0.         0.29397305 0.44797488 0.33498269 1.
  0.         0.         1.        ]
 [0.         0.         0.11633417 0.19468857 0.33488651 1.
  0.         0.         1.        ]
 [0.         0.         0.05856147 0.12088956 0.33485992 1.
  0.         0.         1.        ]
 [0.         0.         0.50012063 0.61672634 0.33495108 1.
  0.         0.         1.        ]
 [0.         0.         0.91546942 1.         0.33511887 1.
  0.         0.33169774 1.        ]
 [0.         0.         0.         0.         0.33515191 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.9285714030265808
#####################         POISON         ###############################################

############################################################################################

comm_round: 2 | global_test_acc: 90.000% | global_f1: 0.9473684210526316 | global_precision: 0.9
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.90      1.00      0.95         9

    accuracy                           0.90        10
   macro avg       0.45      0.50      0.47        10
weighted avg       0.81      0.90      0.85        10

Accuracy per class:
[[9 0]
 [1 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_fg shape (30,)
[1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_mn shape (30,)
[0.         1.         1.         0.         0.         0.
 0.         0.89637854 0.         1.         0.         1.
 0.         0.07826976 0.95130459 0.10985128 0.         0.38189774
 0.         0.50780814 0.81627495 0.         0.         1.
 0.24014462 1.         0.         0.69756005 0.04077842 0.45097503]
wv_ed shape (30,)
[0.         1.         1.         0.         0.         0.
 0.         0.88525208 0.         1.         0.         1.
 0.         0.0961473  0.91499731 0.11022682 0.         0.3900347
 0.         0.54175281 0.77700309 0.         0.         1.
 0.21112523 1.         0.         0.5955099  0.         0.33108865]
wv_lg shape (30, 1)
[[0.34121783]
 [0.34103319]
 [0.34093419]
 [0.34068299]
 [0.34125908]
 [0.33598931]
 [0.33608712]
 [0.33607282]
 [0.33601628]
 [0.33600474]
 [0.33613546]
 [0.33613536]
 [0.33601401]
 [0.33613161]
 [0.33617782]
 [0.33607626]
 [0.33593012]
 [0.33614266]
 [0.33606394]
 [0.33616843]
 [0.33610588]
 [0.33599405]
 [0.33612204]
 [0.33629932]
 [0.33624177]
 [0.33620181]
 [0.33599674]
 [0.33602421]
 [0.33608102]
 [0.33612753]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_std shape (30,)
[0.         0.99404348 1.         0.         0.         0.
 0.         0.         0.         0.         0.         0.63504692
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.        ]
xy shape: (30, 9)
[[0.         1.         0.         0.         0.34121783 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.34103319 1.
  1.         0.99404348 0.        ]
 [0.         1.         1.         1.         0.34093419 1.
  1.         1.         0.        ]
 [0.         1.         0.         0.         0.34068299 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.34125908 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.33598931 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33608712 1.
  0.         0.         1.        ]
 [0.         0.         0.89637854 0.88525208 0.33607282 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33601628 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.33600474 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33613546 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.33613536 1.
  0.         0.63504692 1.        ]
 [0.         0.         0.         0.         0.33601401 1.
  0.         0.         1.        ]
 [0.         0.         0.07826976 0.0961473  0.33613161 1.
  0.         0.         1.        ]
 [0.         0.         0.95130459 0.91499731 0.33617782 1.
  0.         0.         1.        ]
 [0.         0.         0.10985128 0.11022682 0.33607626 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33593012 1.
  0.         0.         1.        ]
 [0.         0.         0.38189774 0.3900347  0.33614266 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33606394 1.
  0.         0.         1.        ]
 [0.         0.         0.50780814 0.54175281 0.33616843 1.
  0.         0.         1.        ]
 [0.         0.         0.81627495 0.77700309 0.33610588 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33599405 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33612204 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.33629932 1.
  0.         0.         1.        ]
 [0.         0.         0.24014462 0.21112523 0.33624177 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.33620181 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33599674 1.
  0.         0.         1.        ]
 [0.         0.         0.69756005 0.5955099  0.33602421 1.
  0.         0.         1.        ]
 [0.         0.         0.04077842 0.         0.33608102 1.
  0.         0.         1.        ]
 [0.         0.         0.45097503 0.33108865 0.33612753 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.7857142686843872
#####################         POISON         ###############################################

############################################################################################

comm_round: 3 | global_test_acc: 80.000% | global_f1: 0.888888888888889 | global_precision: 0.8
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.80      1.00      0.89         8

    accuracy                           0.80        10
   macro avg       0.40      0.50      0.44        10
weighted avg       0.64      0.80      0.71        10

Accuracy per class:
[[8 0]
 [2 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_fg shape (30,)
[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_mn shape (30,)
[1.         1.         1.         0.         0.         0.04869051
 0.05843116 0.         0.         1.         0.         0.73869516
 0.         0.         0.         0.22075081 0.         0.56387247
 1.         0.97192922 0.         0.         0.19661291 0.29739355
 0.98226763 0.05648963 0.2343598  0.64672206 0.3502686  0.        ]
wv_ed shape (30,)
[1.         1.         1.         0.         0.         0.03161744
 0.10712691 0.         0.         0.9596931  0.         0.72289296
 0.         0.         0.         0.28373055 0.         0.60734927
 1.         1.         0.         0.         0.19691662 0.3464906
 0.98283763 0.0806976  0.26432216 0.64881702 0.32467784 0.        ]
wv_lg shape (30, 1)
[[0.34206984]
 [0.34194793]
 [0.34173042]
 [0.34223731]
 [0.34170998]
 [0.33722379]
 [0.33722663]
 [0.33715973]
 [0.33713418]
 [0.33735398]
 [0.33719089]
 [0.33726612]
 [0.33710035]
 [0.33734264]
 [0.33715253]
 [0.33738159]
 [0.3372261 ]
 [0.33719275]
 [0.33740446]
 [0.33740809]
 [0.33721379]
 [0.33723278]
 [0.33718893]
 [0.33716834]
 [0.33713947]
 [0.33734348]
 [0.33746655]
 [0.33730453]
 [0.33722261]
 [0.33730791]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_std shape (30,)
[1.         1.         1.         0.         0.27371599 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.        ]
xy shape: (30, 9)
[[1.         1.         1.         1.         0.34206984 1.
  1.         1.         0.        ]
 [1.         1.         1.         1.         0.34194793 1.
  1.         1.         0.        ]
 [1.         1.         1.         1.         0.34173042 1.
  1.         1.         0.        ]
 [0.         1.         0.         0.         0.34223731 1.
  1.         0.         0.        ]
 [0.         1.         0.         0.         0.34170998 1.
  1.         0.27371599 0.        ]
 [0.         0.         0.04869051 0.03161744 0.33722379 1.
  0.         0.         1.        ]
 [0.         0.         0.05843116 0.10712691 0.33722663 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33715973 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33713418 1.
  0.         0.         1.        ]
 [0.         0.         1.         0.9596931  0.33735398 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33719089 1.
  0.         0.         1.        ]
 [0.         0.         0.73869516 0.72289296 0.33726612 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33710035 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33734264 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33715253 1.
  0.         0.         1.        ]
 [0.         0.         0.22075081 0.28373055 0.33738159 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3372261  1.
  0.         0.         1.        ]
 [0.         0.         0.56387247 0.60734927 0.33719275 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.33740446 1.
  0.         0.         1.        ]
 [0.         0.         0.97192922 1.         0.33740809 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33721379 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33723278 1.
  0.         0.         1.        ]
 [0.         0.         0.19661291 0.19691662 0.33718893 1.
  0.         0.         1.        ]
 [0.         0.         0.29739355 0.3464906  0.33716834 1.
  0.         0.         1.        ]
 [0.         0.         0.98226763 0.98283763 0.33713947 1.
  0.         0.         1.        ]
 [0.         0.         0.05648963 0.0806976  0.33734348 1.
  0.         0.         1.        ]
 [0.         0.         0.2343598  0.26432216 0.33746655 1.
  0.         0.         1.        ]
 [0.         0.         0.64672206 0.64881702 0.33730453 1.
  0.         0.         1.        ]
 [0.         0.         0.3502686  0.32467784 0.33722261 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33730791 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.9285714030265808
#####################         POISON         ###############################################

############################################################################################

comm_round: 4 | global_test_acc: 90.000% | global_f1: 0.9473684210526316 | global_precision: 0.9
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.90      1.00      0.95         9

    accuracy                           0.90        10
   macro avg       0.45      0.50      0.47        10
weighted avg       0.81      0.90      0.85        10

Accuracy per class:
[[9 0]
 [1 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0.]
wv_fg shape (30,)
[1.       0.       0.587279 0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.      ]
wv_mn shape (30,)
[0.38487815 1.         0.         0.         0.71717531 0.
 0.         0.6276441  1.         0.         0.         0.4196254
 0.88039551 1.         0.         0.         0.90123811 0.19545467
 0.47658282 1.         0.47346596 0.79960413 1.         0.
 0.         0.97207092 0.         1.         1.         1.        ]
wv_ed shape (30,)
[0.49129499 1.         0.         0.         0.98292922 0.
 0.         0.50367351 1.         0.         0.         0.33201769
 0.83617646 1.         0.         0.         0.81649867 0.15466076
 0.46771918 1.         0.36221185 0.70569159 1.         0.
 0.         0.91020199 0.         1.         1.         1.        ]
wv_lg shape (30, 1)
[[0.34276573]
 [0.34279271]
 [0.34282357]
 [0.34296902]
 [0.34281612]
 [0.33840156]
 [0.3382931 ]
 [0.33847225]
 [0.33838225]
 [0.33832948]
 [0.33858689]
 [0.33833343]
 [0.33841389]
 [0.33841923]
 [0.33837015]
 [0.33852056]
 [0.33848485]
 [0.3384597 ]
 [0.33839103]
 [0.33839985]
 [0.33836613]
 [0.33847243]
 [0.33839823]
 [0.33845549]
 [0.33838398]
 [0.33846956]
 [0.33841055]
 [0.33845126]
 [0.33842448]
 [0.33840418]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_std shape (30,)
[0.         1.         0.         0.         0.         0.
 0.         0.         1.         0.         0.         0.
 0.10830361 0.23651695 0.         0.         0.         0.
 0.         0.36803431 0.         0.         1.         0.
 0.         0.25487086 0.         0.44651448 1.         0.        ]
xy shape: (30, 9)
[[0.         1.         0.38487815 0.49129499 0.34276573 1.
  1.         0.         0.        ]
 [0.         0.         1.         1.         0.34279271 1.
  1.         1.         0.        ]
 [0.         0.587279   0.         0.         0.34282357 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.34296902 1.
  1.         0.         0.        ]
 [0.         0.         0.71717531 0.98292922 0.34281612 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.33840156 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3382931  1.
  0.         0.         1.        ]
 [0.         0.         0.6276441  0.50367351 0.33847225 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.33838225 1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.33832948 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33858689 1.
  0.         0.         1.        ]
 [0.         0.         0.4196254  0.33201769 0.33833343 1.
  0.         0.         1.        ]
 [0.         0.         0.88039551 0.83617646 0.33841389 1.
  0.         0.10830361 1.        ]
 [0.         0.         1.         1.         0.33841923 1.
  0.         0.23651695 1.        ]
 [0.         0.         0.         0.         0.33837015 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33852056 1.
  0.         0.         1.        ]
 [0.         0.         0.90123811 0.81649867 0.33848485 1.
  0.         0.         1.        ]
 [0.         0.         0.19545467 0.15466076 0.3384597  1.
  0.         0.         1.        ]
 [0.         0.         0.47658282 0.46771918 0.33839103 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.33839985 1.
  0.         0.36803431 1.        ]
 [0.         0.         0.47346596 0.36221185 0.33836613 1.
  0.         0.         1.        ]
 [0.         0.         0.79960413 0.70569159 0.33847243 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.33839823 1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.33845549 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33838398 1.
  0.         0.         1.        ]
 [0.         0.         0.97207092 0.91020199 0.33846956 1.
  0.         0.25487086 1.        ]
 [0.         0.         0.         0.         0.33841055 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.33845126 1.
  0.         0.44651448 1.        ]
 [1.         0.         1.         1.         0.33842448 1.
  0.         1.         1.        ]
 [0.         0.         1.         1.         0.33840418 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.8571428656578064
#####################         POISON         ###############################################

############################################################################################

comm_round: 5 | global_test_acc: 90.000% | global_f1: 0.9473684210526316 | global_precision: 0.9
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.90      1.00      0.95         9

    accuracy                           0.90        10
   macro avg       0.45      0.50      0.47        10
weighted avg       0.81      0.90      0.85        10

Accuracy per class:
[[9 0]
 [1 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_fg shape (30,)
[1.         1.         1.         1.         1.         0.
 0.         0.         0.         0.         0.         0.
 0.37838731 0.         0.         0.         0.         0.
 0.         0.         0.         0.61108877 0.         0.02557148
 0.         0.         0.         0.         0.         0.        ]
wv_mn shape (30,)
[1.         0.         0.         0.45065879 1.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.39983106
 0.         0.         0.         0.         0.         0.        ]
wv_ed shape (30,)
[1.         0.         0.         0.37352667 1.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.49962501
 0.         0.03060125 0.         0.         0.         0.        ]
wv_lg shape (30, 1)
[[0.3436207 ]
 [0.34372368]
 [0.34382387]
 [0.34383576]
 [0.34369438]
 [0.33935041]
 [0.33929277]
 [0.33938106]
 [0.33933829]
 [0.33938554]
 [0.33925441]
 [0.33948413]
 [0.33918703]
 [0.33933964]
 [0.33950035]
 [0.33934386]
 [0.33932958]
 [0.33946058]
 [0.33932668]
 [0.33926371]
 [0.33930875]
 [0.33936682]
 [0.33939121]
 [0.33950445]
 [0.33934106]
 [0.33940187]
 [0.33934886]
 [0.33958519]
 [0.33937533]
 [0.3393659 ]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_std shape (30,)
[1.         0.         0.         0.06186191 1.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.        ]
xy shape: (30, 9)
[[1.         1.         1.         1.         0.3436207  1.
  1.         1.         0.        ]
 [0.         1.         0.         0.         0.34372368 1.
  1.         0.         0.        ]
 [0.         1.         0.         0.         0.34382387 1.
  1.         0.         0.        ]
 [1.         1.         0.45065879 0.37352667 0.34383576 1.
  1.         0.06186191 0.        ]
 [1.         1.         1.         1.         0.34369438 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.33935041 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33929277 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33938106 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33933829 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33938554 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33925441 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33948413 1.
  0.         0.         1.        ]
 [0.         0.37838731 0.         0.         0.33918703 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33933964 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33950035 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33934386 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33932958 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33946058 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33932668 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33926371 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33930875 1.
  0.         0.         1.        ]
 [0.         0.61108877 0.         0.         0.33936682 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33939121 1.
  0.         0.         1.        ]
 [0.         0.02557148 0.39983106 0.49962501 0.33950445 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33934106 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.03060125 0.33940187 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33934886 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33958519 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.33937533 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3393659  1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.8571428656578064
#####################         POISON         ###############################################

############################################################################################

comm_round: 6 | global_test_acc: 70.000% | global_f1: 0.8235294117647058 | global_precision: 0.7
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.70      1.00      0.82         7

    accuracy                           0.70        10
   macro avg       0.35      0.50      0.41        10
weighted avg       0.49      0.70      0.58        10

Accuracy per class:
[[7 0]
 [3 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 1. 0. 0. 0.]
wv_fg shape (30,)
[0.         1.         0.34724857 1.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.        ]
wv_mn shape (30,)
[0.50194838 0.         1.         0.         0.62418085 0.
 1.         0.         0.         0.         0.         0.
 0.54404351 0.         0.         0.41978457 0.11055306 0.
 0.         1.         1.         1.         0.         0.
 0.27169424 0.         1.         0.26562949 1.         0.16864643]
wv_ed shape (30,)
[0.30432122 0.         1.         0.         0.48170437 0.
 1.         0.         0.         0.         0.         0.
 0.66150658 0.         0.         0.50272227 0.26399286 0.
 0.         1.         1.         1.         0.         0.
 0.35048783 0.         1.         0.30556082 1.         0.19013873]
wv_lg shape (30, 1)
[[0.34445347]
 [0.34458067]
 [0.34456406]
 [0.34449703]
 [0.34455425]
 [0.34032656]
 [0.34032472]
 [0.34028048]
 [0.34034979]
 [0.34037913]
 [0.34024794]
 [0.34045761]
 [0.34045985]
 [0.34037688]
 [0.34029143]
 [0.34024853]
 [0.34032769]
 [0.34031779]
 [0.34032667]
 [0.34026847]
 [0.34048048]
 [0.34028883]
 [0.34043175]
 [0.34038528]
 [0.34053014]
 [0.3402523 ]
 [0.34053692]
 [0.34035811]
 [0.34025897]
 [0.34039213]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_std shape (30,)
[0.10748405 0.         1.         0.         0.         0.
 1.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.69654541 0.34195167 0.         0.         0.
 0.         0.         1.         0.         0.         0.        ]
xy shape: (30, 9)
[[0.         0.         0.50194838 0.30432122 0.34445347 1.
  1.         0.10748405 0.        ]
 [0.         1.         0.         0.         0.34458067 1.
  1.         0.         0.        ]
 [0.         0.34724857 1.         1.         0.34456406 1.
  1.         1.         0.        ]
 [0.         1.         0.         0.         0.34449703 1.
  1.         0.         0.        ]
 [0.         0.         0.62418085 0.48170437 0.34455425 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.34032656 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.34032472 1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.34028048 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34034979 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34037913 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34024794 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34045761 1.
  0.         0.         1.        ]
 [0.         0.         0.54404351 0.66150658 0.34045985 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34037688 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34029143 1.
  0.         0.         1.        ]
 [0.         0.         0.41978457 0.50272227 0.34024853 1.
  0.         0.         1.        ]
 [0.         0.         0.11055306 0.26399286 0.34032769 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34031779 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34032667 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.34026847 1.
  0.         0.69654541 1.        ]
 [0.         0.         1.         1.         0.34048048 1.
  0.         0.34195167 1.        ]
 [0.         0.         1.         1.         0.34028883 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34043175 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34038528 1.
  0.         0.         1.        ]
 [0.         0.         0.27169424 0.35048783 0.34053014 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3402523  1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.34053692 1.
  0.         1.         1.        ]
 [0.         0.         0.26562949 0.30556082 0.34035811 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.34025897 1.
  0.         0.         1.        ]
 [0.         0.         0.16864643 0.19013873 0.34039213 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.7857142686843872
#####################         POISON         ###############################################

############################################################################################

comm_round: 7 | global_test_acc: 90.000% | global_f1: 0.9473684210526316 | global_precision: 0.9
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.90      1.00      0.95         9

    accuracy                           0.90        10
   macro avg       0.45      0.50      0.47        10
weighted avg       0.81      0.90      0.85        10

Accuracy per class:
[[9 0]
 [1 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_fg shape (30,)
[1.        1.        0.        0.3066891 0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.       ]
wv_mn shape (30,)
[0.         0.43663885 0.34825482 0.55129888 1.         0.
 0.27292948 0.42861812 0.15315512 0.03973006 0.2766457  0.
 1.         1.         0.         1.         0.         1.
 1.         0.         0.         0.3316584  0.         0.
 0.         0.14882149 0.         0.         0.25600581 0.        ]
wv_ed shape (30,)
[0.         0.65970861 0.48565736 0.72598226 1.         0.
 0.29706104 0.40635134 0.13220585 0.         0.05626715 0.
 1.         1.         0.         1.         0.         1.
 1.         0.         0.         0.20224377 0.         0.
 0.         0.         0.         0.         0.2805046  0.        ]
wv_lg shape (30, 1)
[[0.34534484]
 [0.3454192 ]
 [0.34534503]
 [0.34533505]
 [0.34522393]
 [0.34110643]
 [0.34121103]
 [0.34127356]
 [0.34102179]
 [0.34118055]
 [0.34097941]
 [0.34114116]
 [0.34130679]
 [0.34127338]
 [0.34113519]
 [0.34112672]
 [0.34105   ]
 [0.34130196]
 [0.3412705 ]
 [0.34104979]
 [0.34125019]
 [0.34122286]
 [0.34110673]
 [0.34118359]
 [0.34128933]
 [0.34122048]
 [0.34119971]
 [0.3412739 ]
 [0.34122153]
 [0.34114331]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_std shape (30,)
[0.         0.         0.80864598 0.1072973  1.         0.
 0.         0.         0.         0.         0.         0.
 0.0136039  0.07621104 0.         1.         0.         0.
 1.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.        ]
xy shape: (30, 9)
[[0.         1.         0.         0.         0.34534484 1.
  1.         0.         0.        ]
 [0.         1.         0.43663885 0.65970861 0.3454192  1.
  1.         0.         0.        ]
 [0.         0.         0.34825482 0.48565736 0.34534503 1.
  1.         0.80864598 0.        ]
 [0.         0.3066891  0.55129888 0.72598226 0.34533505 1.
  1.         0.1072973  0.        ]
 [0.         0.         1.         1.         0.34522393 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.34110643 1.
  0.         0.         1.        ]
 [0.         0.         0.27292948 0.29706104 0.34121103 1.
  0.         0.         1.        ]
 [0.         0.         0.42861812 0.40635134 0.34127356 1.
  0.         0.         1.        ]
 [0.         0.         0.15315512 0.13220585 0.34102179 1.
  0.         0.         1.        ]
 [0.         0.         0.03973006 0.         0.34118055 1.
  0.         0.         1.        ]
 [0.         0.         0.2766457  0.05626715 0.34097941 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34114116 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.34130679 1.
  0.         0.0136039  1.        ]
 [0.         0.         1.         1.         0.34127338 1.
  0.         0.07621104 1.        ]
 [0.         0.         0.         0.         0.34113519 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.34112672 1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.34105    1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.34130196 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.3412705  1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.34104979 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34125019 1.
  0.         0.         1.        ]
 [0.         0.         0.3316584  0.20224377 0.34122286 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34110673 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34118359 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34128933 1.
  0.         0.         1.        ]
 [0.         0.         0.14882149 0.         0.34122048 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34119971 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3412739  1.
  0.         0.         1.        ]
 [0.         0.         0.25600581 0.2805046  0.34122153 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34114331 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.7857142686843872
#####################         POISON         ###############################################

############################################################################################

comm_round: 8 | global_test_acc: 80.000% | global_f1: 0.888888888888889 | global_precision: 0.8
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.80      1.00      0.89         8

    accuracy                           0.80        10
   macro avg       0.40      0.50      0.44        10
weighted avg       0.64      0.80      0.71        10

Accuracy per class:
[[8 0]
 [2 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_fg shape (30,)
[0.44010394 0.         1.         0.         0.44010394 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.        ]
wv_mn shape (30,)
[1.         1.         0.         1.         1.         0.21665711
 0.         0.         0.24923448 1.         0.41304843 0.
 0.         0.         0.59792229 0.         0.         0.
 0.         0.         0.14089505 1.         0.         0.
 0.91092502 0.         0.         0.         0.         0.        ]
wv_ed shape (30,)
[1.         1.         0.         1.         1.         0.1665204
 0.         0.         0.26412651 1.         0.396156   0.
 0.         0.         0.58000195 0.         0.         0.
 0.         0.         0.08870103 0.99731725 0.         0.
 0.91235203 0.         0.         0.         0.         0.        ]
wv_lg shape (30, 1)
[[0.34613088]
 [0.34584795]
 [0.3462444 ]
 [0.34614281]
 [0.34579125]
 [0.34194196]
 [0.34198503]
 [0.34207048]
 [0.34203275]
 [0.3420247 ]
 [0.3420076 ]
 [0.34215727]
 [0.34211371]
 [0.34201857]
 [0.34202667]
 [0.34216586]
 [0.34203683]
 [0.34205451]
 [0.3420779 ]
 [0.34207756]
 [0.34199844]
 [0.34209628]
 [0.34227115]
 [0.342023  ]
 [0.34207347]
 [0.34198805]
 [0.34195409]
 [0.34211873]
 [0.34214762]
 [0.34219541]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_std shape (30,)
[1.         1.         0.         0.48662786 1.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.        ]
xy shape: (30, 9)
[[1.         0.44010394 1.         1.         0.34613088 1.
  1.         1.         0.        ]
 [1.         0.         1.         1.         0.34584795 1.
  1.         1.         0.        ]
 [0.         1.         0.         0.         0.3462444  1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.34614281 1.
  1.         0.48662786 0.        ]
 [1.         0.44010394 1.         1.         0.34579125 1.
  1.         1.         0.        ]
 [0.         0.         0.21665711 0.1665204  0.34194196 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34198503 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34207048 1.
  0.         0.         1.        ]
 [0.         0.         0.24923448 0.26412651 0.34203275 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.3420247  1.
  0.         0.         1.        ]
 [0.         0.         0.41304843 0.396156   0.3420076  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34215727 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34211371 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34201857 1.
  0.         0.         1.        ]
 [0.         0.         0.59792229 0.58000195 0.34202667 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34216586 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34203683 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34205451 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3420779  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34207756 1.
  0.         0.         1.        ]
 [0.         0.         0.14089505 0.08870103 0.34199844 1.
  0.         0.         1.        ]
 [0.         0.         1.         0.99731725 0.34209628 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34227115 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.342023   1.
  0.         0.         1.        ]
 [0.         0.         0.91092502 0.91235203 0.34207347 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34198805 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34195409 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34211873 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34214762 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34219541 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
1.0
#####################         POISON         ###############################################

############################################################################################

comm_round: 9 | global_test_acc: 70.000% | global_f1: 0.8235294117647058 | global_precision: 0.7
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.70      1.00      0.82         7

    accuracy                           0.70        10
   macro avg       0.35      0.50      0.41        10
weighted avg       0.49      0.70      0.58        10

Accuracy per class:
[[7 0]
 [3 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 0.]
wv_fg shape (30,)
[1.         1.         0.09611407 1.         0.09611407 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         1.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.        ]
wv_mn shape (30,)
[0.         1.         0.42573477 0.         1.         0.94246709
 1.         0.97969545 1.         0.54349326 1.         0.02488449
 0.78530363 1.         1.         1.         1.         0.6313552
 1.         1.         0.66089825 1.         1.         0.
 1.         0.44463737 0.20094129 0.8814911  1.         0.0400632 ]
wv_ed shape (30,)
[0.         1.         0.48639271 0.         1.         1.
 1.         0.88740827 1.         0.52758793 1.         0.
 0.74056481 1.         1.         1.         1.         0.61946549
 1.         1.         0.69076731 0.98949321 1.         0.
 1.         0.50248322 0.28930796 0.98367886 1.         0.        ]
wv_lg shape (30, 1)
[[0.34675583]
 [0.34679601]
 [0.34657799]
 [0.34678242]
 [0.34671879]
 [0.34314619]
 [0.34294418]
 [0.34298532]
 [0.34310572]
 [0.34288709]
 [0.34308858]
 [0.34291794]
 [0.34297375]
 [0.34308477]
 [0.34308639]
 [0.34309467]
 [0.34326531]
 [0.34315914]
 [0.34303159]
 [0.34307002]
 [0.3428871 ]
 [0.34296904]
 [0.34309294]
 [0.34298006]
 [0.34302315]
 [0.34297295]
 [0.34298542]
 [0.34293543]
 [0.34315061]
 [0.34291692]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_std shape (30,)
[0.         1.         0.03458548 0.         0.81018436 0.
 0.         0.         1.         0.         1.         0.
 0.         0.         0.02130771 0.48808293 1.         0.
 0.         0.         0.         0.         0.         0.
 1.         0.         0.         0.         0.         0.        ]
xy shape: (30, 9)
[[0.         1.         0.         0.         0.34675583 1.
  1.         0.         0.        ]
 [0.         1.         1.         1.         0.34679601 1.
  1.         1.         0.        ]
 [0.         0.09611407 0.42573477 0.48639271 0.34657799 1.
  1.         0.03458548 0.        ]
 [0.         1.         0.         0.         0.34678242 1.
  1.         0.         0.        ]
 [0.         0.09611407 1.         1.         0.34671879 1.
  1.         0.81018436 0.        ]
 [0.         0.         0.94246709 1.         0.34314619 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.34294418 1.
  0.         0.         1.        ]
 [0.         0.         0.97969545 0.88740827 0.34298532 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.34310572 1.
  0.         1.         1.        ]
 [0.         0.         0.54349326 0.52758793 0.34288709 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.34308858 1.
  0.         1.         1.        ]
 [0.         0.         0.02488449 0.         0.34291794 1.
  0.         0.         1.        ]
 [0.         0.         0.78530363 0.74056481 0.34297375 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.34308477 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.34308639 1.
  0.         0.02130771 1.        ]
 [0.         0.         1.         1.         0.34309467 1.
  0.         0.48808293 1.        ]
 [1.         1.         1.         1.         0.34326531 1.
  0.         1.         1.        ]
 [0.         0.         0.6313552  0.61946549 0.34315914 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.34303159 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.34307002 1.
  0.         0.         1.        ]
 [0.         0.         0.66089825 0.69076731 0.3428871  1.
  0.         0.         1.        ]
 [0.         0.         1.         0.98949321 0.34296904 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.34309294 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34298006 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.34302315 1.
  0.         1.         1.        ]
 [0.         0.         0.44463737 0.50248322 0.34297295 1.
  0.         0.         1.        ]
 [0.         0.         0.20094129 0.28930796 0.34298542 1.
  0.         0.         1.        ]
 [0.         0.         0.8814911  0.98367886 0.34293543 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.34315061 1.
  0.         0.         1.        ]
 [0.         0.         0.0400632  0.         0.34291692 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.8571428656578064
#####################         POISON         ###############################################

############################################################################################

comm_round: 10 | global_test_acc: 90.000% | global_f1: 0.9473684210526316 | global_precision: 0.9
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.90      1.00      0.95         9

    accuracy                           0.90        10
   macro avg       0.45      0.50      0.47        10
weighted avg       0.81      0.90      0.85        10

Accuracy per class:
[[9 0]
 [1 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_fg shape (30,)
[0.20978176 0.20978176 0.86593035 1.         0.26073944 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.00372998 0.
 0.         0.         0.         0.         0.         0.        ]
wv_mn shape (30,)
[1.         1.         0.         1.         1.         1.
 1.         0.         1.         0.         0.01767855 0.17232883
 0.         0.         1.         0.         0.         0.
 0.11131044 1.         0.         0.         0.         1.
 0.73056151 0.         0.22705337 0.05572598 0.         1.        ]
wv_ed shape (30,)
[1.         1.         0.         1.         1.         1.
 1.         0.         1.         0.         0.02502728 0.25593953
 0.         0.         1.         0.         0.         0.
 0.0357365  1.         0.         0.07774155 0.         1.
 0.93253604 0.         0.2812989  0.1393124  0.         1.        ]
wv_lg shape (30, 1)
[[0.34735187]
 [0.3474705 ]
 [0.347557  ]
 [0.34749096]
 [0.34730687]
 [0.34397163]
 [0.34410666]
 [0.343935  ]
 [0.34398821]
 [0.34399943]
 [0.3440387 ]
 [0.34403479]
 [0.34376011]
 [0.3439771 ]
 [0.3439157 ]
 [0.34376648]
 [0.34393573]
 [0.34388771]
 [0.34395728]
 [0.34380625]
 [0.34399256]
 [0.34404955]
 [0.34403443]
 [0.34412606]
 [0.34405172]
 [0.34387499]
 [0.34415199]
 [0.34400516]
 [0.34389018]
 [0.34402453]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_std shape (30,)
[0.73265113 0.94747887 0.         1.         1.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.        ]
xy shape: (30, 9)
[[0.         0.20978176 1.         1.         0.34735187 1.
  1.         0.73265113 0.        ]
 [1.         0.20978176 1.         1.         0.3474705  1.
  1.         0.94747887 0.        ]
 [0.         0.86593035 0.         0.         0.347557   1.
  1.         0.         0.        ]
 [1.         1.         1.         1.         0.34749096 1.
  1.         1.         0.        ]
 [1.         0.26073944 1.         1.         0.34730687 1.
  1.         1.         0.        ]
 [0.         0.         1.         1.         0.34397163 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.34410666 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.343935   1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.34398821 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34399943 1.
  0.         0.         1.        ]
 [0.         0.         0.01767855 0.02502728 0.3440387  1.
  0.         0.         1.        ]
 [0.         0.         0.17232883 0.25593953 0.34403479 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34376011 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3439771  1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.3439157  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34376648 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34393573 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34388771 1.
  0.         0.         1.        ]
 [0.         0.         0.11131044 0.0357365  0.34395728 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.34380625 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34399256 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.07774155 0.34404955 1.
  0.         0.         1.        ]
 [0.         0.00372998 0.         0.         0.34403443 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.34412606 1.
  0.         0.         1.        ]
 [0.         0.         0.73056151 0.93253604 0.34405172 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34387499 1.
  0.         0.         1.        ]
 [0.         0.         0.22705337 0.2812989  0.34415199 1.
  0.         0.         1.        ]
 [0.         0.         0.05572598 0.1393124  0.34400516 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34389018 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.34402453 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.8571428656578064
#####################         POISON         ###############################################

############################################################################################

comm_round: 11 | global_test_acc: 80.000% | global_f1: 0.888888888888889 | global_precision: 0.8
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.80      1.00      0.89         8

    accuracy                           0.80        10
   macro avg       0.40      0.50      0.44        10
weighted avg       0.64      0.80      0.71        10

Accuracy per class:
[[8 0]
 [2 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_fg shape (30,)
[0.00871885 0.92017134 1.         0.14937434 0.00871885 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.        ]
wv_mn shape (30,)
[1.         0.         1.         0.         0.5536774  1.
 1.         1.         1.         0.         0.         1.
 0.84204604 1.         0.         0.91843477 0.         0.
 0.         0.91908376 1.         0.         0.56317623 0.67663395
 1.         0.         1.         0.         1.         1.        ]
wv_ed shape (30,)
[1.         0.         1.         0.         0.46037912 1.
 1.         1.         1.         0.         0.         1.
 0.8379368  1.         0.         0.78167835 0.         0.
 0.         0.88657317 1.         0.         0.50502537 0.66175009
 1.         0.         1.         0.         1.         1.        ]
wv_lg shape (30, 1)
[[0.3481868 ]
 [0.34831197]
 [0.34784342]
 [0.34838659]
 [0.34825678]
 [0.34469513]
 [0.3446387 ]
 [0.34448199]
 [0.3446177 ]
 [0.34447586]
 [0.34460674]
 [0.3445863 ]
 [0.34468032]
 [0.34464923]
 [0.34457548]
 [0.34454059]
 [0.34465632]
 [0.34463032]
 [0.34448801]
 [0.34456961]
 [0.34462934]
 [0.34460878]
 [0.34462133]
 [0.34464452]
 [0.34468543]
 [0.34455244]
 [0.3447213 ]
 [0.34457058]
 [0.34474003]
 [0.34468698]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_std shape (30,)
[1.        0.        1.        0.        0.6726483 0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.       ]
xy shape: (30, 9)
[[0.         0.00871885 1.         1.         0.3481868  1.
  1.         1.         0.        ]
 [0.         0.92017134 0.         0.         0.34831197 1.
  1.         0.         0.        ]
 [1.         1.         1.         1.         0.34784342 1.
  1.         1.         0.        ]
 [0.         0.14937434 0.         0.         0.34838659 1.
  1.         0.         0.        ]
 [0.         0.00871885 0.5536774  0.46037912 0.34825678 1.
  1.         0.6726483  0.        ]
 [0.         0.         1.         1.         0.34469513 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.3446387  1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.34448199 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.3446177  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34447586 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34460674 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.3445863  1.
  0.         0.         1.        ]
 [0.         0.         0.84204604 0.8379368  0.34468032 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.34464923 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34457548 1.
  0.         0.         1.        ]
 [0.         0.         0.91843477 0.78167835 0.34454059 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34465632 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34463032 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34448801 1.
  0.         0.         1.        ]
 [0.         0.         0.91908376 0.88657317 0.34456961 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.34462934 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34460878 1.
  0.         0.         1.        ]
 [0.         0.         0.56317623 0.50502537 0.34462133 1.
  0.         0.         1.        ]
 [0.         0.         0.67663395 0.66175009 0.34464452 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.34468543 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34455244 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.3447213  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34457058 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.34474003 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.34468698 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.8571428656578064
#####################         POISON         ###############################################

############################################################################################

comm_round: 12 | global_test_acc: 70.000% | global_f1: 0.8235294117647058 | global_precision: 0.7
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.70      1.00      0.82         7

    accuracy                           0.70        10
   macro avg       0.35      0.50      0.41        10
weighted avg       0.49      0.70      0.58        10

Accuracy per class:
[[7 0]
 [3 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1.
 0. 0. 0. 0. 0. 0.]
wv_fg shape (30,)
[0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_mn shape (30,)
[0.         0.         0.         0.44314738 0.         0.47947703
 1.         1.         0.         1.         0.         1.
 0.         0.         0.         1.         0.         0.
 0.49708648 0.76069956 0.         1.         0.67067902 1.
 0.19778053 0.38571737 0.07819732 0.         0.52241249 0.        ]
wv_ed shape (30,)
[0.         0.         0.05819479 0.73709059 0.         0.50590255
 1.         1.         0.06590668 1.         0.07419667 1.
 0.         0.         0.         1.         0.         0.
 0.43237616 0.82712576 0.         1.         0.6975898  1.
 0.17945604 0.39048743 0.14669041 0.         0.75685859 0.        ]
wv_lg shape (30, 1)
[[0.34894565]
 [0.34898402]
 [0.34878036]
 [0.34856483]
 [0.34844573]
 [0.34539606]
 [0.34525308]
 [0.34545392]
 [0.34521106]
 [0.34539763]
 [0.34538301]
 [0.34520866]
 [0.34536534]
 [0.34533176]
 [0.34528136]
 [0.3453914 ]
 [0.34529321]
 [0.34537897]
 [0.34536226]
 [0.34532568]
 [0.34519997]
 [0.34528017]
 [0.34522383]
 [0.34531574]
 [0.34533602]
 [0.34521052]
 [0.34536963]
 [0.3452769 ]
 [0.34526055]
 [0.34529243]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_std shape (30,)
[0.         0.         0.         0.         0.         0.
 1.         0.72312876 0.         1.         0.         0.
 0.         0.         0.         0.19903932 0.         0.
 0.04178343 0.11253617 0.         1.         0.         0.44274762
 0.         0.         0.         0.         0.         0.        ]
xy shape: (30, 9)
[[0.         0.         0.         0.         0.34894565 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.34898402 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.05819479 0.34878036 1.
  1.         0.         0.        ]
 [0.         0.         0.44314738 0.73709059 0.34856483 1.
  1.         0.         0.        ]
 [0.         1.         0.         0.         0.34844573 1.
  1.         0.         0.        ]
 [0.         0.         0.47947703 0.50590255 0.34539606 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.34525308 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.34545392 1.
  0.         0.72312876 1.        ]
 [0.         0.         0.         0.06590668 0.34521106 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.34539763 1.
  0.         1.         1.        ]
 [0.         0.         0.         0.07419667 0.34538301 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.34520866 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34536534 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34533176 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34528136 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.3453914  1.
  0.         0.19903932 1.        ]
 [0.         0.         0.         0.         0.34529321 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34537897 1.
  0.         0.         1.        ]
 [0.         0.         0.49708648 0.43237616 0.34536226 1.
  0.         0.04178343 1.        ]
 [1.         0.         0.76069956 0.82712576 0.34532568 1.
  0.         0.11253617 1.        ]
 [0.         0.         0.         0.         0.34519997 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.34528017 1.
  0.         1.         1.        ]
 [1.         0.         0.67067902 0.6975898  0.34522383 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.34531574 1.
  0.         0.44274762 1.        ]
 [0.         0.         0.19778053 0.17945604 0.34533602 1.
  0.         0.         1.        ]
 [0.         0.         0.38571737 0.39048743 0.34521052 1.
  0.         0.         1.        ]
 [0.         0.         0.07819732 0.14669041 0.34536963 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3452769  1.
  0.         0.         1.        ]
 [0.         0.         0.52241249 0.75685859 0.34526055 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34529243 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.9285714030265808
#####################         POISON         ###############################################

############################################################################################

comm_round: 13 | global_test_acc: 70.000% | global_f1: 0.8235294117647058 | global_precision: 0.7
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.70      1.00      0.82         7

    accuracy                           0.70        10
   macro avg       0.35      0.50      0.41        10
weighted avg       0.49      0.70      0.58        10

Accuracy per class:
[[7 0]
 [3 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_fg shape (30,)
[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_mn shape (30,)
[1.         0.         0.         0.         0.72882889 1.
 1.         0.00368559 0.14277181 1.         0.         0.9657205
 0.         1.         1.         1.         1.         0.6639425
 0.65550517 0.         0.         0.         0.2602786  0.48022312
 0.53325756 0.31946023 1.         0.44427453 1.         0.5174648 ]
wv_ed shape (30,)
[1.         0.         0.         0.         0.88616976 1.
 1.         0.01510209 0.22121685 1.         0.         1.
 0.01210131 1.         1.         1.         1.         0.79119669
 0.58451289 0.         0.         0.         0.36245069 0.46079997
 0.59334265 0.36085256 1.         0.58019307 1.         0.59906903]
wv_lg shape (30, 1)
[[0.34960521]
 [0.34942997]
 [0.34923091]
 [0.34932061]
 [0.34958206]
 [0.34603283]
 [0.3459652 ]
 [0.34595661]
 [0.34602857]
 [0.34610825]
 [0.34606898]
 [0.34593234]
 [0.34602245]
 [0.34604542]
 [0.34613799]
 [0.34616235]
 [0.3461199 ]
 [0.34608051]
 [0.346158  ]
 [0.3459866 ]
 [0.3460147 ]
 [0.3461776 ]
 [0.3460866 ]
 [0.34605854]
 [0.34607713]
 [0.34620034]
 [0.34616313]
 [0.34607724]
 [0.3460629 ]
 [0.3459571 ]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_std shape (30,)
[0.41930343 0.         0.         0.         0.         0.86117507
 1.         0.         0.         1.         0.         0.37060975
 0.         1.         1.         1.         1.         0.
 1.         0.         0.         0.         0.         0.
 0.39070442 0.         1.         0.         0.13462443 0.        ]
xy shape: (30, 9)
[[1.         0.         1.         1.         0.34960521 1.
  1.         0.41930343 0.        ]
 [0.         1.         0.         0.         0.34942997 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.34923091 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.34932061 1.
  1.         0.         0.        ]
 [0.         0.         0.72882889 0.88616976 0.34958206 1.
  1.         0.         0.        ]
 [0.         0.         1.         1.         0.34603283 1.
  0.         0.86117507 1.        ]
 [0.         0.         1.         1.         0.3459652  1.
  0.         1.         1.        ]
 [0.         0.         0.00368559 0.01510209 0.34595661 1.
  0.         0.         1.        ]
 [0.         0.         0.14277181 0.22121685 0.34602857 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.34610825 1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.34606898 1.
  0.         0.         1.        ]
 [0.         0.         0.9657205  1.         0.34593234 1.
  0.         0.37060975 1.        ]
 [0.         0.         0.         0.01210131 0.34602245 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.34604542 1.
  0.         1.         1.        ]
 [0.         0.         1.         1.         0.34613799 1.
  0.         1.         1.        ]
 [0.         0.         1.         1.         0.34616235 1.
  0.         1.         1.        ]
 [0.         0.         1.         1.         0.3461199  1.
  0.         1.         1.        ]
 [0.         0.         0.6639425  0.79119669 0.34608051 1.
  0.         0.         1.        ]
 [0.         0.         0.65550517 0.58451289 0.346158   1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.3459866  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3460147  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3461776  1.
  0.         0.         1.        ]
 [0.         0.         0.2602786  0.36245069 0.3460866  1.
  0.         0.         1.        ]
 [0.         0.         0.48022312 0.46079997 0.34605854 1.
  0.         0.         1.        ]
 [0.         0.         0.53325756 0.59334265 0.34607713 1.
  0.         0.39070442 1.        ]
 [0.         0.         0.31946023 0.36085256 0.34620034 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.34616313 1.
  0.         1.         1.        ]
 [0.         0.         0.44427453 0.58019307 0.34607724 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.3460629  1.
  0.         0.13462443 1.        ]
 [0.         0.         0.5174648  0.59906903 0.3459571  1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
1.0
#####################         POISON         ###############################################

############################################################################################

comm_round: 14 | global_test_acc: 80.000% | global_f1: 0.888888888888889 | global_precision: 0.8
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.80      1.00      0.89         8

    accuracy                           0.80        10
   macro avg       0.40      0.50      0.44        10
weighted avg       0.64      0.80      0.71        10

Accuracy per class:
[[8 0]
 [2 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_fg shape (30,)
[0.13970613 0.         0.         0.         1.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.        ]
wv_mn shape (30,)
[0.         0.         1.         0.         0.         1.
 0.23372055 0.15632394 0.         1.         0.         1.
 1.         0.         0.46137748 0.79544268 0.88465571 0.75397904
 0.         0.         0.         1.         1.         0.83592334
 0.24070877 0.         1.         1.         0.         0.        ]
wv_ed shape (30,)
[0.         0.         1.         0.         0.         1.
 0.27707771 0.25341726 0.         1.         0.         1.
 1.         0.         0.48858719 0.84165342 0.99859756 0.85094664
 0.         0.         0.         1.         1.         0.91507862
 0.29349964 0.         1.         1.         0.         0.        ]
wv_lg shape (30, 1)
[[0.3500584 ]
 [0.3501618 ]
 [0.34994208]
 [0.35019693]
 [0.35025429]
 [0.34704545]
 [0.34703645]
 [0.34706325]
 [0.34704669]
 [0.34692909]
 [0.34699445]
 [0.3470783 ]
 [0.34703362]
 [0.34696051]
 [0.34698882]
 [0.34709594]
 [0.34692169]
 [0.34701445]
 [0.34698063]
 [0.34699731]
 [0.34692142]
 [0.34698043]
 [0.34701641]
 [0.34701071]
 [0.34711208]
 [0.34705409]
 [0.34710196]
 [0.3468947 ]
 [0.34698701]
 [0.34700066]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_std shape (30,)
[1.         0.         1.         0.         0.         1.
 0.         0.         0.         1.         0.         0.
 1.         0.         0.         0.50098566 0.         0.
 0.         0.         0.         1.         1.         0.
 0.         0.         1.         0.         0.         0.        ]
xy shape: (30, 9)
[[0.         0.13970613 0.         0.         0.3500584  1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.3501618  1.
  1.         0.         0.        ]
 [0.         0.         1.         1.         0.34994208 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.35019693 1.
  1.         0.         0.        ]
 [0.         1.         0.         0.         0.35025429 1.
  1.         0.         0.        ]
 [0.         0.         1.         1.         0.34704545 1.
  0.         1.         1.        ]
 [0.         0.         0.23372055 0.27707771 0.34703645 1.
  0.         0.         1.        ]
 [0.         0.         0.15632394 0.25341726 0.34706325 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34704669 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.34692909 1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.34699445 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.3470783  1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.34703362 1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.34696051 1.
  0.         0.         1.        ]
 [0.         0.         0.46137748 0.48858719 0.34698882 1.
  0.         0.         1.        ]
 [0.         0.         0.79544268 0.84165342 0.34709594 1.
  0.         0.50098566 1.        ]
 [0.         0.         0.88465571 0.99859756 0.34692169 1.
  0.         0.         1.        ]
 [0.         0.         0.75397904 0.85094664 0.34701445 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34698063 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34699731 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34692142 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.34698043 1.
  0.         1.         1.        ]
 [0.         0.         1.         1.         0.34701641 1.
  0.         1.         1.        ]
 [0.         0.         0.83592334 0.91507862 0.34701071 1.
  0.         0.         1.        ]
 [0.         0.         0.24070877 0.29349964 0.34711208 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34705409 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.34710196 1.
  0.         1.         1.        ]
 [0.         0.         1.         1.         0.3468947  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34698701 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34700066 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.7857142686843872
#####################         POISON         ###############################################

############################################################################################

comm_round: 15 | global_test_acc: 90.000% | global_f1: 0.9473684210526316 | global_precision: 0.9
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.90      1.00      0.95         9

    accuracy                           0.90        10
   macro avg       0.45      0.50      0.47        10
weighted avg       0.81      0.90      0.85        10

Accuracy per class:
[[9 0]
 [1 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0.         0.         0.         0.         1.         0.
 0.         0.         0.         0.         0.         0.19845034
 0.         0.         0.         0.         0.         0.
 0.04672376 0.         0.         0.         0.2481697  0.
 0.         0.         0.         0.         0.03365509 0.        ]
wv_fg shape (30,)
[1.         0.13157617 0.13157617 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.        ]
wv_mn shape (30,)
[0.         0.         0.         0.         1.         0.
 0.05378136 0.         0.10766115 0.04372044 0.         1.
 0.         0.         0.         0.58260786 0.49330597 0.
 1.         0.9996099  0.         0.29739582 1.         0.
 0.62131287 0.         0.03451548 0.         1.         0.09125216]
wv_ed shape (30,)
[0.         0.         0.         0.17381154 1.         0.
 0.         0.         0.09407883 0.11494642 0.         1.
 0.         0.         0.         0.66111432 0.3359927  0.
 1.         1.         0.         0.36804026 1.         0.
 0.5831507  0.04184615 0.11354102 0.         1.         0.        ]
wv_lg shape (30, 1)
[[0.35082606]
 [0.35057538]
 [0.35042075]
 [0.35052364]
 [0.35049734]
 [0.34752832]
 [0.34750218]
 [0.34743045]
 [0.34754831]
 [0.34752361]
 [0.34747405]
 [0.34759943]
 [0.3474064 ]
 [0.34757949]
 [0.34750625]
 [0.3474638 ]
 [0.34763532]
 [0.34738773]
 [0.34761697]
 [0.34757372]
 [0.34754609]
 [0.34761415]
 [0.34753874]
 [0.34757906]
 [0.34747402]
 [0.34749355]
 [0.34755341]
 [0.34747533]
 [0.34758686]
 [0.34747298]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_std shape (30,)
[0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
xy shape: (30, 9)
[[0.         1.         0.         0.         0.35082606 1.
  1.         0.         0.        ]
 [0.         0.13157617 0.         0.         0.35057538 1.
  1.         0.         0.        ]
 [0.         0.13157617 0.         0.         0.35042075 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.17381154 0.35052364 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.35049734 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.34752832 1.
  0.         0.         1.        ]
 [0.         0.         0.05378136 0.         0.34750218 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34743045 1.
  0.         0.         1.        ]
 [0.         0.         0.10766115 0.09407883 0.34754831 1.
  0.         0.         1.        ]
 [0.         0.         0.04372044 0.11494642 0.34752361 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34747405 1.
  0.         0.         1.        ]
 [0.19845034 0.         1.         1.         0.34759943 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3474064  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34757949 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34750625 1.
  0.         0.         1.        ]
 [0.         0.         0.58260786 0.66111432 0.3474638  1.
  0.         0.         1.        ]
 [0.         0.         0.49330597 0.3359927  0.34763532 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34738773 1.
  0.         0.         1.        ]
 [0.04672376 0.         1.         1.         0.34761697 1.
  0.         0.         1.        ]
 [0.         0.         0.9996099  1.         0.34757372 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34754609 1.
  0.         0.         1.        ]
 [0.         0.         0.29739582 0.36804026 0.34761415 1.
  0.         0.         1.        ]
 [0.2481697  0.         1.         1.         0.34753874 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34757906 1.
  0.         0.         1.        ]
 [0.         0.         0.62131287 0.5831507  0.34747402 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.04184615 0.34749355 1.
  0.         0.         1.        ]
 [0.         0.         0.03451548 0.11354102 0.34755341 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34747533 1.
  0.         0.         1.        ]
 [0.03365509 0.         1.         1.         0.34758686 1.
  0.         0.         1.        ]
 [0.         0.         0.09125216 0.         0.34747298 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.8571428656578064
#####################         POISON         ###############################################

############################################################################################

comm_round: 16 | global_test_acc: 70.000% | global_f1: 0.8235294117647058 | global_precision: 0.7
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.70      1.00      0.82         7

    accuracy                           0.70        10
   macro avg       0.35      0.50      0.41        10
weighted avg       0.49      0.70      0.58        10

Accuracy per class:
[[7 0]
 [3 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0.
 1. 1. 0. 1. 1. 0.]
wv_fg shape (30,)
[0.        0.2504574 0.        0.2504574 1.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.       ]
wv_mn shape (30,)
[0.         0.         0.         0.60721832 0.         0.25266764
 0.99077528 1.         0.         1.         0.96473619 1.
 0.         1.         0.48021051 1.         1.         1.
 1.         0.11203029 1.         1.         1.         0.2714492
 1.         1.         0.02341475 1.         1.         0.        ]
wv_ed shape (30,)
[0.         0.         0.         0.68871345 0.         0.2569921
 1.         1.         0.         1.         0.97029784 1.
 0.         1.         0.5057908  1.         1.         1.
 1.         0.072735   1.         1.         1.         0.2072447
 1.         1.         0.10357861 1.         1.         0.        ]
wv_lg shape (30, 1)
[[0.35126488]
 [0.3514946 ]
 [0.35130225]
 [0.35146405]
 [0.35134318]
 [0.34838412]
 [0.34844119]
 [0.34828839]
 [0.34843649]
 [0.34827103]
 [0.34828772]
 [0.34831497]
 [0.34833871]
 [0.34831534]
 [0.34833546]
 [0.34841978]
 [0.34841505]
 [0.34837382]
 [0.34821096]
 [0.34827202]
 [0.34831494]
 [0.34833583]
 [0.34846037]
 [0.3483587 ]
 [0.34846723]
 [0.34852396]
 [0.34838271]
 [0.3482605 ]
 [0.3483373 ]
 [0.3482526 ]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_std shape (30,)
[0.         0.         0.         0.         0.         0.
 0.42893754 1.         0.         0.2542431  0.         1.
 0.         0.         0.         0.9191519  0.17470624 1.
 0.600551   0.         0.09846337 0.40556172 1.         0.
 1.         0.87080331 0.         0.37559683 0.21889245 0.        ]
xy shape: (30, 9)
[[0.         0.         0.         0.         0.35126488 1.
  1.         0.         0.        ]
 [0.         0.2504574  0.         0.         0.3514946  1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.35130225 1.
  1.         0.         0.        ]
 [0.         0.2504574  0.60721832 0.68871345 0.35146405 1.
  1.         0.         0.        ]
 [0.         1.         0.         0.         0.35134318 1.
  1.         0.         0.        ]
 [0.         0.         0.25266764 0.2569921  0.34838412 1.
  0.         0.         1.        ]
 [1.         0.         0.99077528 1.         0.34844119 1.
  0.         0.42893754 1.        ]
 [1.         0.         1.         1.         0.34828839 1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.34843649 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.34827103 1.
  0.         0.2542431  1.        ]
 [1.         0.         0.96473619 0.97029784 0.34828772 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.34831497 1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.34833871 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.34831534 1.
  0.         0.         1.        ]
 [1.         0.         0.48021051 0.5057908  0.34833546 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.34841978 1.
  0.         0.9191519  1.        ]
 [1.         0.         1.         1.         0.34841505 1.
  0.         0.17470624 1.        ]
 [1.         0.         1.         1.         0.34837382 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.34821096 1.
  0.         0.600551   1.        ]
 [0.         0.         0.11203029 0.072735   0.34827202 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.34831494 1.
  0.         0.09846337 1.        ]
 [1.         0.         1.         1.         0.34833583 1.
  0.         0.40556172 1.        ]
 [1.         0.         1.         1.         0.34846037 1.
  0.         1.         1.        ]
 [0.         0.         0.2714492  0.2072447  0.3483587  1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.34846723 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.34852396 1.
  0.         0.87080331 1.        ]
 [0.         0.         0.02341475 0.10357861 0.34838271 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.3482605  1.
  0.         0.37559683 1.        ]
 [1.         0.         1.         1.         0.3483373  1.
  0.         0.21889245 1.        ]
 [0.         0.         0.         0.         0.3482526  1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.8571428656578064
#####################         POISON         ###############################################

############################################################################################

comm_round: 17 | global_test_acc: 80.000% | global_f1: 0.888888888888889 | global_precision: 0.8
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.80      1.00      0.89         8

    accuracy                           0.80        10
   macro avg       0.40      0.50      0.44        10
weighted avg       0.64      0.80      0.71        10

Accuracy per class:
[[8 0]
 [2 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_fg shape (30,)
[1.         1.         0.         0.         0.71018925 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.        ]
wv_mn shape (30,)
[0.         0.70862058 1.         1.         0.         0.08365209
 0.         0.74343552 0.         1.         0.06636976 0.52207054
 0.9486264  0.         0.         0.69125086 0.         1.
 1.         0.85741477 0.47348213 0.         0.71393839 0.
 0.967162   0.         1.         0.         0.         0.31028898]
wv_ed shape (30,)
[0.         0.57304257 1.         1.         0.         0.
 0.         0.5238499  0.         1.         0.         0.46306743
 0.97241813 0.         0.         0.61659364 0.         1.
 1.         0.74109978 0.22117446 0.         0.77372478 0.
 0.75256788 0.         1.         0.         0.         0.12928589]
wv_lg shape (30, 1)
[[0.3521109 ]
 [0.35163463]
 [0.35177783]
 [0.35172911]
 [0.35184532]
 [0.34877795]
 [0.34874396]
 [0.34870349]
 [0.34880662]
 [0.34880462]
 [0.34867382]
 [0.34876159]
 [0.34878562]
 [0.34875734]
 [0.34886104]
 [0.34872869]
 [0.34867616]
 [0.34875719]
 [0.34877303]
 [0.34883681]
 [0.34871656]
 [0.34881266]
 [0.34875718]
 [0.3487117 ]
 [0.34874828]
 [0.3488379 ]
 [0.34881028]
 [0.34875825]
 [0.34878667]
 [0.34873985]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_std shape (30,)
[0.         1.         1.         1.         0.69773599 0.
 0.         0.         0.         0.0336282  0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.        ]
xy shape: (30, 9)
[[0.         1.         0.         0.         0.3521109  1.
  1.         0.         0.        ]
 [0.         1.         0.70862058 0.57304257 0.35163463 1.
  1.         1.         0.        ]
 [0.         0.         1.         1.         0.35177783 1.
  1.         1.         0.        ]
 [1.         0.         1.         1.         0.35172911 1.
  1.         1.         0.        ]
 [0.         0.71018925 0.         0.         0.35184532 1.
  1.         0.69773599 0.        ]
 [0.         0.         0.08365209 0.         0.34877795 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34874396 1.
  0.         0.         1.        ]
 [0.         0.         0.74343552 0.5238499  0.34870349 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34880662 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.34880462 1.
  0.         0.0336282  1.        ]
 [0.         0.         0.06636976 0.         0.34867382 1.
  0.         0.         1.        ]
 [0.         0.         0.52207054 0.46306743 0.34876159 1.
  0.         0.         1.        ]
 [0.         0.         0.9486264  0.97241813 0.34878562 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34875734 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34886104 1.
  0.         0.         1.        ]
 [0.         0.         0.69125086 0.61659364 0.34872869 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34867616 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.34875719 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.34877303 1.
  0.         0.         1.        ]
 [0.         0.         0.85741477 0.74109978 0.34883681 1.
  0.         0.         1.        ]
 [0.         0.         0.47348213 0.22117446 0.34871656 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34881266 1.
  0.         0.         1.        ]
 [0.         0.         0.71393839 0.77372478 0.34875718 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3487117  1.
  0.         0.         1.        ]
 [0.         0.         0.967162   0.75256788 0.34874828 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3488379  1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.34881028 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34875825 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34878667 1.
  0.         0.         1.        ]
 [0.         0.         0.31028898 0.12928589 0.34873985 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.9285714030265808
#####################         POISON         ###############################################

############################################################################################

comm_round: 18 | global_test_acc: 80.000% | global_f1: 0.888888888888889 | global_precision: 0.8
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.80      1.00      0.89         8

    accuracy                           0.80        10
   macro avg       0.40      0.50      0.44        10
weighted avg       0.64      0.80      0.71        10

Accuracy per class:
[[8 0]
 [2 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_fg shape (30,)
[1.         0.57227525 0.         1.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.        ]
wv_mn shape (30,)
[1.         0.         0.47442571 1.         0.         0.
 0.         0.49584376 1.         0.52645764 0.22882228 0.
 0.33257491 0.87311502 0.56021768 0.         0.         0.
 0.         0.         0.         0.         0.         0.32004773
 0.         1.         0.         0.         0.         0.23919279]
wv_ed shape (30,)
[1.         0.         0.24241025 0.98113444 0.         0.
 0.         0.4433908  1.         0.40593912 0.17248129 0.
 0.25961322 0.76188779 0.4244225  0.         0.         0.
 0.         0.         0.         0.         0.         0.21610632
 0.         1.         0.         0.         0.         0.14619258]
wv_lg shape (30, 1)
[[0.35242198]
 [0.35254318]
 [0.35255077]
 [0.35266043]
 [0.35256721]
 [0.34969384]
 [0.34965403]
 [0.34967778]
 [0.34973618]
 [0.34963457]
 [0.34971056]
 [0.34967284]
 [0.34971196]
 [0.34979842]
 [0.34969959]
 [0.34970211]
 [0.34963853]
 [0.3497447 ]
 [0.34968283]
 [0.34957842]
 [0.34964405]
 [0.34965869]
 [0.34957155]
 [0.34965889]
 [0.3496162 ]
 [0.34972822]
 [0.34975692]
 [0.34961299]
 [0.34960198]
 [0.34964526]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_std shape (30,)
[1.         0.91928207 0.88873459 0.45144347 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.        ]
xy shape: (30, 9)
[[1.         1.         1.         1.         0.35242198 1.
  1.         1.         0.        ]
 [0.         0.57227525 0.         0.         0.35254318 1.
  1.         0.91928207 0.        ]
 [0.         0.         0.47442571 0.24241025 0.35255077 1.
  1.         0.88873459 0.        ]
 [0.         1.         1.         0.98113444 0.35266043 1.
  1.         0.45144347 0.        ]
 [0.         0.         0.         0.         0.35256721 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.34969384 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34965403 1.
  0.         0.         1.        ]
 [0.         0.         0.49584376 0.4433908  0.34967778 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.34973618 1.
  0.         0.         1.        ]
 [0.         0.         0.52645764 0.40593912 0.34963457 1.
  0.         0.         1.        ]
 [0.         0.         0.22882228 0.17248129 0.34971056 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34967284 1.
  0.         0.         1.        ]
 [0.         0.         0.33257491 0.25961322 0.34971196 1.
  0.         0.         1.        ]
 [0.         0.         0.87311502 0.76188779 0.34979842 1.
  0.         0.         1.        ]
 [0.         0.         0.56021768 0.4244225  0.34969959 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34970211 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34963853 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3497447  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34968283 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34957842 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34964405 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34965869 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34957155 1.
  0.         0.         1.        ]
 [0.         0.         0.32004773 0.21610632 0.34965889 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3496162  1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.34972822 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34975692 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34961299 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34960198 1.
  0.         0.         1.        ]
 [0.         0.         0.23919279 0.14619258 0.34964526 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.7857142686843872
#####################         POISON         ###############################################

############################################################################################

comm_round: 19 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00        10

    accuracy                           1.00        10
   macro avg       1.00      1.00      1.00        10
weighted avg       1.00      1.00      1.00        10

Accuracy per class:
[[10  0]
 [ 0  0]]
[ 1. nan]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[1.         1.         0.         1.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.02428968 0.         0.         0.         0.         0.        ]
wv_fg shape (30,)
[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_mn shape (30,)
[1.         1.         0.         1.         1.         0.
 0.         0.55461493 0.         0.         0.         0.
 0.         0.05475926 0.         0.         0.         0.
 0.         0.4476141  0.01667787 0.03077794 0.59005214 0.
 0.99066449 0.18697862 0.         0.         0.49871637 0.        ]
wv_ed shape (30,)
[1.         1.         0.         1.         0.99598904 0.
 0.         0.62174981 0.         0.         0.         0.
 0.05403294 0.04883869 0.00817862 0.         0.         0.
 0.         0.36968571 0.         0.         0.58021588 0.
 0.91494336 0.14461408 0.         0.         0.55839514 0.        ]
wv_lg shape (30, 1)
[[0.35298936]
 [0.35303776]
 [0.35310667]
 [0.35292325]
 [0.35312076]
 [0.35020624]
 [0.35029235]
 [0.35021279]
 [0.35036176]
 [0.35030757]
 [0.3502326 ]
 [0.3502091 ]
 [0.35020565]
 [0.35040112]
 [0.35018124]
 [0.35034203]
 [0.350211  ]
 [0.35029233]
 [0.35032058]
 [0.35030305]
 [0.35034109]
 [0.35033085]
 [0.3503489 ]
 [0.3503765 ]
 [0.35028234]
 [0.35045271]
 [0.35034786]
 [0.35034075]
 [0.35045913]
 [0.35026233]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_std shape (30,)
[1.         1.         0.         1.         0.66970788 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.        ]
xy shape: (30, 9)
[[1.         0.         1.         1.         0.35298936 1.
  1.         1.         0.        ]
 [1.         0.         1.         1.         0.35303776 1.
  1.         1.         0.        ]
 [0.         1.         0.         0.         0.35310667 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.35292325 1.
  1.         1.         0.        ]
 [0.         0.         1.         0.99598904 0.35312076 1.
  1.         0.66970788 0.        ]
 [0.         0.         0.         0.         0.35020624 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35029235 1.
  0.         0.         1.        ]
 [0.         0.         0.55461493 0.62174981 0.35021279 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35036176 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35030757 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3502326  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3502091  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.05403294 0.35020565 1.
  0.         0.         1.        ]
 [0.         0.         0.05475926 0.04883869 0.35040112 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.00817862 0.35018124 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35034203 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.350211   1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35029233 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35032058 1.
  0.         0.         1.        ]
 [0.         0.         0.4476141  0.36968571 0.35030305 1.
  0.         0.         1.        ]
 [0.         0.         0.01667787 0.         0.35034109 1.
  0.         0.         1.        ]
 [0.         0.         0.03077794 0.         0.35033085 1.
  0.         0.         1.        ]
 [0.         0.         0.59005214 0.58021588 0.3503489  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3503765  1.
  0.         0.         1.        ]
 [0.02428968 0.         0.99066449 0.91494336 0.35028234 1.
  0.         0.         1.        ]
 [0.         0.         0.18697862 0.14461408 0.35045271 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35034786 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35034075 1.
  0.         0.         1.        ]
 [0.         0.         0.49871637 0.55839514 0.35045913 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35026233 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
1.0
#####################         POISON         ###############################################

############################################################################################

comm_round: 20 | global_test_acc: 80.000% | global_f1: 0.888888888888889 | global_precision: 0.8
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.80      1.00      0.89         8

    accuracy                           0.80        10
   macro avg       0.40      0.50      0.44        10
weighted avg       0.64      0.80      0.71        10

Accuracy per class:
[[8 0]
 [2 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_fg shape (30,)
[1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_mn shape (30,)
[0.         0.         1.         0.         0.13712676 0.25849558
 1.         0.         0.33031183 0.20983918 0.44647873 0.97615262
 0.         1.         0.09550418 0.99341362 1.         0.
 0.74030028 0.38791631 1.         0.         1.         0.50244059
 0.92977334 0.99399397 0.79845657 1.         0.29515738 1.        ]
wv_ed shape (30,)
[0.         0.         1.         0.         0.38579264 0.45505053
 1.         0.         0.55465791 0.41713566 0.56271361 1.
 0.         1.         0.21638187 1.         1.         0.
 0.84246135 0.53218103 1.         0.         1.         0.70045499
 1.         1.         1.         1.         0.59423946 1.        ]
wv_lg shape (30, 1)
[[0.3537468 ]
 [0.35345137]
 [0.3534773 ]
 [0.35352281]
 [0.3534625 ]
 [0.35076271]
 [0.35084732]
 [0.35060624]
 [0.3506173 ]
 [0.35063235]
 [0.35075177]
 [0.35076208]
 [0.35071105]
 [0.350639  ]
 [0.35059621]
 [0.35068827]
 [0.3506711 ]
 [0.35068294]
 [0.35059412]
 [0.35079489]
 [0.35068554]
 [0.35069593]
 [0.35065904]
 [0.35073873]
 [0.35066691]
 [0.35060974]
 [0.35068664]
 [0.35062353]
 [0.35072287]
 [0.35074632]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_std shape (30,)
[0.         0.         1.         0.         0.         0.
 0.08467139 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.        ]
xy shape: (30, 9)
[[0.         1.         0.         0.         0.3537468  1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.35345137 1.
  1.         0.         0.        ]
 [1.         1.         1.         1.         0.3534773  1.
  1.         1.         0.        ]
 [0.         1.         0.         0.         0.35352281 1.
  1.         0.         0.        ]
 [0.         0.         0.13712676 0.38579264 0.3534625  1.
  1.         0.         0.        ]
 [0.         0.         0.25849558 0.45505053 0.35076271 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.35084732 1.
  0.         0.08467139 1.        ]
 [0.         0.         0.         0.         0.35060624 1.
  0.         0.         1.        ]
 [0.         0.         0.33031183 0.55465791 0.3506173  1.
  0.         0.         1.        ]
 [0.         0.         0.20983918 0.41713566 0.35063235 1.
  0.         0.         1.        ]
 [0.         0.         0.44647873 0.56271361 0.35075177 1.
  0.         0.         1.        ]
 [0.         0.         0.97615262 1.         0.35076208 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35071105 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.350639   1.
  0.         0.         1.        ]
 [0.         0.         0.09550418 0.21638187 0.35059621 1.
  0.         0.         1.        ]
 [0.         0.         0.99341362 1.         0.35068827 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.3506711  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35068294 1.
  0.         0.         1.        ]
 [0.         0.         0.74030028 0.84246135 0.35059412 1.
  0.         0.         1.        ]
 [0.         0.         0.38791631 0.53218103 0.35079489 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.35068554 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35069593 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.35065904 1.
  0.         0.         1.        ]
 [0.         0.         0.50244059 0.70045499 0.35073873 1.
  0.         0.         1.        ]
 [0.         0.         0.92977334 1.         0.35066691 1.
  0.         0.         1.        ]
 [0.         0.         0.99399397 1.         0.35060974 1.
  0.         0.         1.        ]
 [0.         0.         0.79845657 1.         0.35068664 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.35062353 1.
  0.         0.         1.        ]
 [0.         0.         0.29515738 0.59423946 0.35072287 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.35074632 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.7142857313156128
#####################         POISON         ###############################################

############################################################################################

comm_round: 21 | global_test_acc: 90.000% | global_f1: 0.9473684210526316 | global_precision: 0.9
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.90      1.00      0.95         9

    accuracy                           0.90        10
   macro avg       0.45      0.50      0.47        10
weighted avg       0.81      0.90      0.85        10

Accuracy per class:
[[9 0]
 [1 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_fg shape (30,)
[0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_mn shape (30,)
[0.56839971 0.         0.         0.58360901 1.         0.39556847
 0.5600538  0.         1.         0.         0.         0.04863572
 1.         0.33904915 0.         0.         0.32063807 0.
 0.         0.46308012 0.         0.         0.         0.
 0.         0.         0.37912977 0.38426934 0.6818773  0.        ]
wv_ed shape (30,)
[0.74197765 0.         0.         0.74784133 1.         0.23717716
 0.30381386 0.         1.         0.         0.         0.06802556
 1.         0.19892555 0.         0.         0.1715916  0.
 0.         0.3497425  0.         0.         0.         0.
 0.         0.         0.3164338  0.23243688 0.4183305  0.        ]
wv_lg shape (30, 1)
[[0.35410038]
 [0.35404865]
 [0.35414441]
 [0.35408831]
 [0.35421817]
 [0.3513948 ]
 [0.3515433 ]
 [0.35134926]
 [0.35143783]
 [0.35162878]
 [0.35143639]
 [0.35138911]
 [0.35162616]
 [0.35157413]
 [0.35137083]
 [0.35143978]
 [0.35156717]
 [0.3515523 ]
 [0.35139715]
 [0.35139356]
 [0.35157366]
 [0.35150554]
 [0.35146729]
 [0.35153674]
 [0.35141839]
 [0.35146319]
 [0.35156472]
 [0.35146411]
 [0.35136298]
 [0.35136876]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_std shape (30,)
[0.63792119 0.         0.         0.31577823 0.47488848 0.
 0.83986739 0.         1.         0.         0.         0.
 1.         0.88407726 0.         0.         0.25170698 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.0378248  0.         0.43366243 0.        ]
xy shape: (30, 9)
[[0.         0.         0.56839971 0.74197765 0.35410038 1.
  1.         0.63792119 0.        ]
 [0.         0.         0.         0.         0.35404865 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.35414441 1.
  1.         0.         0.        ]
 [0.         0.         0.58360901 0.74784133 0.35408831 1.
  1.         0.31577823 0.        ]
 [1.         1.         1.         1.         0.35421817 1.
  1.         0.47488848 0.        ]
 [0.         0.         0.39556847 0.23717716 0.3513948  1.
  0.         0.         1.        ]
 [0.         0.         0.5600538  0.30381386 0.3515433  1.
  0.         0.83986739 1.        ]
 [0.         0.         0.         0.         0.35134926 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.35143783 1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.35162878 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35143639 1.
  0.         0.         1.        ]
 [0.         0.         0.04863572 0.06802556 0.35138911 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.35162616 1.
  0.         1.         1.        ]
 [0.         0.         0.33904915 0.19892555 0.35157413 1.
  0.         0.88407726 1.        ]
 [0.         0.         0.         0.         0.35137083 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35143978 1.
  0.         0.         1.        ]
 [0.         0.         0.32063807 0.1715916  0.35156717 1.
  0.         0.25170698 1.        ]
 [0.         0.         0.         0.         0.3515523  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35139715 1.
  0.         0.         1.        ]
 [0.         0.         0.46308012 0.3497425  0.35139356 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35157366 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35150554 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35146729 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35153674 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35141839 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35146319 1.
  0.         0.         1.        ]
 [0.         0.         0.37912977 0.3164338  0.35156472 1.
  0.         0.0378248  1.        ]
 [0.         0.         0.38426934 0.23243688 0.35146411 1.
  0.         0.         1.        ]
 [0.         0.         0.6818773  0.4183305  0.35136298 1.
  0.         0.43366243 1.        ]
 [0.         0.         0.         0.         0.35136876 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.7857142686843872
#####################         POISON         ###############################################

############################################################################################

comm_round: 22 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00        10

    accuracy                           1.00        10
   macro avg       1.00      1.00      1.00        10
weighted avg       1.00      1.00      1.00        10

Accuracy per class:
[[10  0]
 [ 0  0]]
[ 1. nan]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0.         0.         0.02353545 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         1.         0.         0.
 0.         0.         0.         0.         0.         0.        ]
wv_fg shape (30,)
[1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_mn shape (30,)
[0.         1.         1.         0.24610342 0.77720248 0.22243909
 0.77300439 0.         0.10795133 1.         0.08476133 0.05467894
 0.00612891 0.23342115 0.         0.         0.         0.59030799
 0.         0.         0.         1.         0.96941793 0.
 0.         0.         0.         0.38864226 0.         0.        ]
wv_ed shape (30,)
[0.         1.         1.         0.         1.         0.40397597
 0.67927027 0.         0.19884681 1.         0.0407569  0.06977629
 0.07049937 0.25502567 0.         0.         0.         0.62765617
 0.         0.         0.         1.         0.99801223 0.
 0.         0.         0.         0.48001351 0.         0.        ]
wv_lg shape (30, 1)
[[0.35459508]
 [0.35448347]
 [0.35458679]
 [0.35479248]
 [0.35463166]
 [0.35201592]
 [0.35216142]
 [0.35204952]
 [0.35206928]
 [0.35209479]
 [0.35217483]
 [0.3521138 ]
 [0.35207083]
 [0.35213596]
 [0.35211597]
 [0.35203601]
 [0.35197745]
 [0.35197589]
 [0.35212116]
 [0.35199375]
 [0.35208322]
 [0.35215991]
 [0.35202859]
 [0.35206158]
 [0.35199398]
 [0.35205859]
 [0.35198662]
 [0.35205677]
 [0.35217227]
 [0.35198902]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_std shape (30,)
[0.         0.         0.24710832 0.         0.         0.
 1.         0.         0.         1.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         1.         1.         0.
 0.         0.         0.         0.         0.         0.        ]
xy shape: (30, 9)
[[0.         1.         0.         0.         0.35459508 1.
  1.         0.         0.        ]
 [0.         1.         1.         1.         0.35448347 1.
  1.         0.         0.        ]
 [0.02353545 0.         1.         1.         0.35458679 1.
  1.         0.24710832 0.        ]
 [0.         1.         0.24610342 0.         0.35479248 1.
  1.         0.         0.        ]
 [0.         0.         0.77720248 1.         0.35463166 1.
  1.         0.         0.        ]
 [0.         0.         0.22243909 0.40397597 0.35201592 1.
  0.         0.         1.        ]
 [0.         0.         0.77300439 0.67927027 0.35216142 1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.35204952 1.
  0.         0.         1.        ]
 [0.         0.         0.10795133 0.19884681 0.35206928 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.35209479 1.
  0.         1.         1.        ]
 [0.         0.         0.08476133 0.0407569  0.35217483 1.
  0.         0.         1.        ]
 [0.         0.         0.05467894 0.06977629 0.3521138  1.
  0.         0.         1.        ]
 [0.         0.         0.00612891 0.07049937 0.35207083 1.
  0.         0.         1.        ]
 [0.         0.         0.23342115 0.25502567 0.35213596 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35211597 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35203601 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35197745 1.
  0.         0.         1.        ]
 [0.         0.         0.59030799 0.62765617 0.35197589 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35212116 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35199375 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35208322 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35215991 1.
  0.         1.         1.        ]
 [0.         0.         0.96941793 0.99801223 0.35202859 1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.35206158 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35199398 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35205859 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35198662 1.
  0.         0.         1.        ]
 [0.         0.         0.38864226 0.48001351 0.35205677 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35217227 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35198902 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.9285714030265808
#####################         POISON         ###############################################

############################################################################################

comm_round: 23 | global_test_acc: 70.000% | global_f1: 0.8235294117647058 | global_precision: 0.7
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.70      1.00      0.82         7

    accuracy                           0.70        10
   macro avg       0.35      0.50      0.41        10
weighted avg       0.49      0.70      0.58        10

Accuracy per class:
[[7 0]
 [3 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_fg shape (30,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_mn shape (30,)
[0.         0.17895338 1.         0.57512365 1.         0.
 0.         0.17690852 0.         0.         0.         0.08676077
 0.         0.         0.         0.         0.         0.1395987
 0.         0.         0.         0.         0.         0.
 0.40706964 0.29435383 0.         0.57234703 0.         0.        ]
wv_ed shape (30,)
[0.         0.4116099  1.         0.64921151 1.         0.
 0.         0.14031957 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.09105708
 0.         0.         0.         0.         0.         0.
 0.34917226 0.2663215  0.         0.5672225  0.         0.        ]
wv_lg shape (30, 1)
[[0.35523912]
 [0.35507115]
 [0.35506562]
 [0.35518079]
 [0.35499014]
 [0.35250599]
 [0.35261538]
 [0.35258685]
 [0.35256609]
 [0.35246542]
 [0.35238177]
 [0.35243271]
 [0.35258623]
 [0.35248828]
 [0.35246248]
 [0.35248134]
 [0.35244501]
 [0.35252644]
 [0.35238956]
 [0.3525394 ]
 [0.35247222]
 [0.35250101]
 [0.3523976 ]
 [0.35241106]
 [0.35251623]
 [0.35260542]
 [0.35254735]
 [0.35243649]
 [0.35254345]
 [0.35247123]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_std shape (30,)
[0.         0.         0.         0.46296394 1.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.        ]
xy shape: (30, 9)
[[0.         1.         0.         0.         0.35523912 1.
  1.         0.         0.        ]
 [0.         0.         0.17895338 0.4116099  0.35507115 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.35506562 1.
  1.         0.         0.        ]
 [0.         0.         0.57512365 0.64921151 0.35518079 1.
  1.         0.46296394 0.        ]
 [1.         0.         1.         1.         0.35499014 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.35250599 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35261538 1.
  0.         0.         1.        ]
 [0.         0.         0.17690852 0.14031957 0.35258685 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35256609 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35246542 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35238177 1.
  0.         0.         1.        ]
 [0.         0.         0.08676077 0.         0.35243271 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35258623 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35248828 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35246248 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35248134 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35244501 1.
  0.         0.         1.        ]
 [0.         0.         0.1395987  0.09105708 0.35252644 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35238956 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3525394  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35247222 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35250101 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3523976  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35241106 1.
  0.         0.         1.        ]
 [0.         0.         0.40706964 0.34917226 0.35251623 1.
  0.         0.         1.        ]
 [0.         0.         0.29435383 0.2663215  0.35260542 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35254735 1.
  0.         0.         1.        ]
 [0.         0.         0.57234703 0.5672225  0.35243649 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35254345 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35247123 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.7857142686843872
#####################         POISON         ###############################################

############################################################################################

comm_round: 24 | global_test_acc: 90.000% | global_f1: 0.9473684210526316 | global_precision: 0.9
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.90      1.00      0.95         9

    accuracy                           0.90        10
   macro avg       0.45      0.50      0.47        10
weighted avg       0.81      0.90      0.85        10

Accuracy per class:
[[9 0]
 [1 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_fg shape (30,)
[0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_mn shape (30,)
[1.         0.         0.         1.         1.         0.86373114
 0.7261781  1.         0.1235801  0.         0.1142587  1.
 1.         1.         0.         0.21259551 0.89984134 0.2512006
 0.84679594 1.         0.         0.25130519 0.20606728 0.58684778
 1.         1.         1.         1.         0.         0.39093402]
wv_ed shape (30,)
[1.         0.         0.         1.         1.         0.87925936
 0.72553972 1.         0.02357025 0.         0.02475266 1.
 1.         1.         0.         0.17687393 0.91031236 0.26474768
 0.77251736 1.         0.         0.26448149 0.10592968 0.6486446
 1.         1.         1.         1.         0.         0.28594566]
wv_lg shape (30, 1)
[[0.35554967]
 [0.35577556]
 [0.3556903 ]
 [0.35552136]
 [0.35558026]
 [0.35325601]
 [0.35329173]
 [0.35319626]
 [0.35322329]
 [0.35329257]
 [0.35324232]
 [0.35329958]
 [0.35319714]
 [0.35320259]
 [0.35319054]
 [0.35318441]
 [0.35317065]
 [0.35323914]
 [0.35325319]
 [0.35317583]
 [0.3531638 ]
 [0.35320162]
 [0.35318072]
 [0.35318004]
 [0.35319423]
 [0.3533066 ]
 [0.35313734]
 [0.35323918]
 [0.3532423 ]
 [0.35316161]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_std shape (30,)
[1.         0.         0.         1.         1.         0.
 0.         0.         0.         0.         0.         0.
 1.         0.         0.         0.         0.         0.
 0.52498785 0.08597809 0.         0.         0.         0.
 0.         0.         0.07191436 0.06497545 0.         0.        ]
xy shape: (30, 9)
[[1.         0.         1.         1.         0.35554967 1.
  1.         1.         0.        ]
 [0.         1.         0.         0.         0.35577556 1.
  1.         0.         0.        ]
 [0.         1.         0.         0.         0.3556903  1.
  1.         0.         0.        ]
 [0.         1.         1.         1.         0.35552136 1.
  1.         1.         0.        ]
 [1.         0.         1.         1.         0.35558026 1.
  1.         1.         0.        ]
 [0.         0.         0.86373114 0.87925936 0.35325601 1.
  0.         0.         1.        ]
 [0.         0.         0.7261781  0.72553972 0.35329173 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.35319626 1.
  0.         0.         1.        ]
 [0.         0.         0.1235801  0.02357025 0.35322329 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35329257 1.
  0.         0.         1.        ]
 [0.         0.         0.1142587  0.02475266 0.35324232 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.35329958 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.35319714 1.
  0.         1.         1.        ]
 [0.         0.         1.         1.         0.35320259 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35319054 1.
  0.         0.         1.        ]
 [0.         0.         0.21259551 0.17687393 0.35318441 1.
  0.         0.         1.        ]
 [0.         0.         0.89984134 0.91031236 0.35317065 1.
  0.         0.         1.        ]
 [0.         0.         0.2512006  0.26474768 0.35323914 1.
  0.         0.         1.        ]
 [0.         0.         0.84679594 0.77251736 0.35325319 1.
  0.         0.52498785 1.        ]
 [0.         0.         1.         1.         0.35317583 1.
  0.         0.08597809 1.        ]
 [0.         0.         0.         0.         0.3531638  1.
  0.         0.         1.        ]
 [0.         0.         0.25130519 0.26448149 0.35320162 1.
  0.         0.         1.        ]
 [0.         0.         0.20606728 0.10592968 0.35318072 1.
  0.         0.         1.        ]
 [0.         0.         0.58684778 0.6486446  0.35318004 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.35319423 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.3533066  1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.35313734 1.
  0.         0.07191436 1.        ]
 [0.         0.         1.         1.         0.35323918 1.
  0.         0.06497545 1.        ]
 [0.         0.         0.         0.         0.3532423  1.
  0.         0.         1.        ]
 [0.         0.         0.39093402 0.28594566 0.35316161 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.9285714030265808
#####################         POISON         ###############################################

############################################################################################

comm_round: 25 | global_test_acc: 70.000% | global_f1: 0.8235294117647058 | global_precision: 0.7
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.70      1.00      0.82         7

    accuracy                           0.70        10
   macro avg       0.35      0.50      0.41        10
weighted avg       0.49      0.70      0.58        10

Accuracy per class:
[[7 0]
 [3 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_fg shape (30,)
[0.         1.         0.64203597 1.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.        ]
wv_mn shape (30,)
[1.         1.         0.         1.         1.         0.
 0.4366957  0.44195559 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.04908631
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.22637562 0.        ]
wv_ed shape (30,)
[1.         1.         0.         1.         1.         0.
 0.48845395 0.49679426 0.         0.         0.         0.
 0.04052661 0.         0.         0.         0.         0.06958358
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.2844924  0.        ]
wv_lg shape (30, 1)
[[0.35609487]
 [0.35621039]
 [0.35619007]
 [0.35622013]
 [0.35608709]
 [0.35365916]
 [0.35382294]
 [0.35378367]
 [0.35378028]
 [0.35368174]
 [0.35360126]
 [0.35372036]
 [0.35358977]
 [0.3537302 ]
 [0.35366374]
 [0.35370453]
 [0.35368516]
 [0.3538546 ]
 [0.35366586]
 [0.35370182]
 [0.35365194]
 [0.35382125]
 [0.35365185]
 [0.35365519]
 [0.35360107]
 [0.35367559]
 [0.35370103]
 [0.35367327]
 [0.35364853]
 [0.35365111]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_std shape (30,)
[1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
xy shape: (30, 9)
[[1.         0.         1.         1.         0.35609487 1.
  1.         1.         0.        ]
 [1.         1.         1.         1.         0.35621039 1.
  1.         1.         0.        ]
 [0.         0.64203597 0.         0.         0.35619007 1.
  1.         0.         0.        ]
 [1.         1.         1.         1.         0.35622013 1.
  1.         1.         0.        ]
 [1.         0.         1.         1.         0.35608709 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.35365916 1.
  0.         0.         1.        ]
 [0.         0.         0.4366957  0.48845395 0.35382294 1.
  0.         0.         1.        ]
 [0.         0.         0.44195559 0.49679426 0.35378367 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35378028 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35368174 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35360126 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35372036 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.04052661 0.35358977 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3537302  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35366374 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35370453 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35368516 1.
  0.         0.         1.        ]
 [0.         0.         0.04908631 0.06958358 0.3538546  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35366586 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35370182 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35365194 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35382125 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35365185 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35365519 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35360107 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35367559 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35370103 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35367327 1.
  0.         0.         1.        ]
 [0.         0.         0.22637562 0.2844924  0.35364853 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35365111 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.9285714030265808
#####################         POISON         ###############################################

############################################################################################

comm_round: 26 | global_test_acc: 70.000% | global_f1: 0.8235294117647058 | global_precision: 0.7
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.70      1.00      0.82         7

    accuracy                           0.70        10
   macro avg       0.35      0.50      0.41        10
weighted avg       0.49      0.70      0.58        10

Accuracy per class:
[[7 0]
 [3 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_fg shape (30,)
[0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_mn shape (30,)
[1.         0.         0.16775887 0.         0.14681532 1.
 1.         1.         0.         1.         0.         0.
 0.         0.         1.         0.         0.46465628 0.
 0.28408947 0.24358676 0.         0.         1.         0.0942001
 0.         0.         0.97988076 0.07050108 0.53977251 0.1399038 ]
wv_ed shape (30,)
[1.         0.         0.34694163 0.         0.30013434 1.
 1.         1.         0.         1.         0.         0.
 0.         0.         1.         0.         0.61347396 0.
 0.2246154  0.36295863 0.         0.         1.         0.07581044
 0.         0.         1.         0.05574883 0.61686632 0.1780741 ]
wv_lg shape (30, 1)
[[0.35657796]
 [0.35644438]
 [0.35661573]
 [0.35659194]
 [0.35676989]
 [0.35421416]
 [0.35419028]
 [0.35427604]
 [0.35424251]
 [0.3542699 ]
 [0.35425441]
 [0.3541828 ]
 [0.354204  ]
 [0.35423801]
 [0.35420345]
 [0.35416602]
 [0.35417546]
 [0.35420195]
 [0.35426271]
 [0.35432004]
 [0.35427439]
 [0.35426401]
 [0.35415459]
 [0.35423963]
 [0.35415422]
 [0.35424421]
 [0.35420535]
 [0.35415675]
 [0.35429227]
 [0.35422227]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_std shape (30,)
[0.75554095 0.         0.         0.         0.         0.13571471
 1.         0.63381983 0.         1.         0.         0.
 0.         0.         1.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.42175181 0.        ]
xy shape: (30, 9)
[[0.         0.         1.         1.         0.35657796 1.
  1.         0.75554095 0.        ]
 [0.         0.         0.         0.         0.35644438 1.
  1.         0.         0.        ]
 [0.         0.         0.16775887 0.34694163 0.35661573 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.35659194 1.
  1.         0.         0.        ]
 [0.         1.         0.14681532 0.30013434 0.35676989 1.
  1.         0.         0.        ]
 [0.         0.         1.         1.         0.35421416 1.
  0.         0.13571471 1.        ]
 [1.         0.         1.         1.         0.35419028 1.
  0.         1.         1.        ]
 [0.         0.         1.         1.         0.35427604 1.
  0.         0.63381983 1.        ]
 [0.         0.         0.         0.         0.35424251 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.3542699  1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.35425441 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3541828  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.354204   1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35423801 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35420345 1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.35416602 1.
  0.         0.         1.        ]
 [0.         0.         0.46465628 0.61347396 0.35417546 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35420195 1.
  0.         0.         1.        ]
 [0.         0.         0.28408947 0.2246154  0.35426271 1.
  0.         0.         1.        ]
 [0.         0.         0.24358676 0.36295863 0.35432004 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35427439 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35426401 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.35415459 1.
  0.         0.         1.        ]
 [0.         0.         0.0942001  0.07581044 0.35423963 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35415422 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35424421 1.
  0.         0.         1.        ]
 [0.         0.         0.97988076 1.         0.35420535 1.
  0.         0.         1.        ]
 [0.         0.         0.07050108 0.05574883 0.35415675 1.
  0.         0.         1.        ]
 [0.         0.         0.53977251 0.61686632 0.35429227 1.
  0.         0.42175181 1.        ]
 [0.         0.         0.1399038  0.1780741  0.35422227 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.7142857313156128
#####################         POISON         ###############################################

############################################################################################

comm_round: 27 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00        10

    accuracy                           1.00        10
   macro avg       1.00      1.00      1.00        10
weighted avg       1.00      1.00      1.00        10

Accuracy per class:
[[10  0]
 [ 0  0]]
[ 1. nan]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_fg shape (30,)
[0.         0.         0.14108358 0.         1.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.        ]
wv_mn shape (30,)
[1.         0.91218811 0.         0.         1.         0.
 0.33828835 0.         0.         0.         0.         0.
 0.         0.3710646  0.         0.         0.         0.
 0.         0.8134612  0.         0.         0.         0.
 0.18673104 0.         0.         1.         0.         0.0236638 ]
wv_ed shape (30,)
[1.         1.         0.         0.         1.         0.03125229
 0.38189476 0.         0.0154503  0.         0.         0.
 0.         0.38409149 0.         0.         0.         0.
 0.         0.82932556 0.         0.         0.         0.
 0.12345384 0.         0.         1.         0.         0.05395167]
wv_lg shape (30, 1)
[[0.35698943]
 [0.35707128]
 [0.35701178]
 [0.35701818]
 [0.35713762]
 [0.35478209]
 [0.35485782]
 [0.35474688]
 [0.35477269]
 [0.3548102 ]
 [0.35494306]
 [0.35471725]
 [0.35480589]
 [0.35484192]
 [0.35475361]
 [0.3547291 ]
 [0.35478075]
 [0.35473702]
 [0.35477815]
 [0.35471631]
 [0.35476394]
 [0.35475938]
 [0.35475175]
 [0.35487764]
 [0.35476983]
 [0.35483817]
 [0.3547911 ]
 [0.35488492]
 [0.35477064]
 [0.3548133 ]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_std shape (30,)
[1.         0.94594486 0.         0.         1.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.37067343 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.        ]
xy shape: (30, 9)
[[1.         0.         1.         1.         0.35698943 1.
  1.         1.         0.        ]
 [0.         0.         0.91218811 1.         0.35707128 1.
  1.         0.94594486 0.        ]
 [0.         0.14108358 0.         0.         0.35701178 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.35701818 1.
  1.         0.         0.        ]
 [1.         1.         1.         1.         0.35713762 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.03125229 0.35478209 1.
  0.         0.         1.        ]
 [0.         0.         0.33828835 0.38189476 0.35485782 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35474688 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.0154503  0.35477269 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3548102  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35494306 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35471725 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35480589 1.
  0.         0.         1.        ]
 [0.         0.         0.3710646  0.38409149 0.35484192 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35475361 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3547291  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35478075 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35473702 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35477815 1.
  0.         0.         1.        ]
 [0.         0.         0.8134612  0.82932556 0.35471631 1.
  0.         0.37067343 1.        ]
 [0.         0.         0.         0.         0.35476394 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35475938 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35475175 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35487764 1.
  0.         0.         1.        ]
 [0.         0.         0.18673104 0.12345384 0.35476983 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35483817 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3547911  1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.35488492 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35477064 1.
  0.         0.         1.        ]
 [0.         0.         0.0236638  0.05395167 0.3548133  1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.8571428656578064
#####################         POISON         ###############################################

############################################################################################

comm_round: 28 | global_test_acc: 80.000% | global_f1: 0.888888888888889 | global_precision: 0.8
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.80      1.00      0.89         8

    accuracy                           0.80        10
   macro avg       0.40      0.50      0.44        10
weighted avg       0.64      0.80      0.71        10

Accuracy per class:
[[8 0]
 [2 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_fg shape (30,)
[1.         0.78929192 0.         0.         0.78929192 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.        ]
wv_mn shape (30,)
[0.         1.         0.         1.         1.         0.
 0.         0.18308874 0.         0.28773653 0.41244298 1.
 0.         0.55353934 0.         1.         0.         1.
 1.         0.43827928 0.34621629 0.71504879 1.         1.
 1.         1.         0.         0.24043584 0.         0.        ]
wv_ed shape (30,)
[0.         1.         0.         1.         0.91276786 0.
 0.         0.16036738 0.         0.36807947 0.50979578 1.
 0.         0.53172009 0.         1.         0.         1.
 1.         0.3920578  0.34995966 0.71739577 1.         1.
 1.         1.         0.         0.19455531 0.         0.        ]
wv_lg shape (30, 1)
[[0.35749786]
 [0.35759023]
 [0.35759655]
 [0.35756522]
 [0.35751779]
 [0.35524615]
 [0.35525339]
 [0.35521878]
 [0.35529152]
 [0.35527709]
 [0.35526921]
 [0.35519364]
 [0.35512932]
 [0.35524863]
 [0.35522683]
 [0.35539641]
 [0.35523209]
 [0.35520781]
 [0.35536968]
 [0.35522763]
 [0.35529471]
 [0.35524151]
 [0.35527723]
 [0.35533019]
 [0.35529509]
 [0.35516656]
 [0.35508472]
 [0.35523424]
 [0.35521435]
 [0.35514479]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_std shape (30,)
[1.         1.         0.         1.         1.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.07734348 0.         0.
 0.2609341  0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.        ]
xy shape: (30, 9)
[[0.         1.         0.         0.         0.35749786 1.
  1.         1.         0.        ]
 [0.         0.78929192 1.         1.         0.35759023 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.35759655 1.
  1.         0.         0.        ]
 [0.         0.         1.         1.         0.35756522 1.
  1.         1.         0.        ]
 [0.         0.78929192 1.         0.91276786 0.35751779 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.35524615 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35525339 1.
  0.         0.         1.        ]
 [0.         0.         0.18308874 0.16036738 0.35521878 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35529152 1.
  0.         0.         1.        ]
 [0.         0.         0.28773653 0.36807947 0.35527709 1.
  0.         0.         1.        ]
 [0.         0.         0.41244298 0.50979578 0.35526921 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35519364 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35512932 1.
  0.         0.         1.        ]
 [0.         0.         0.55353934 0.53172009 0.35524863 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35522683 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.35539641 1.
  0.         0.07734348 1.        ]
 [0.         0.         0.         0.         0.35523209 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.35520781 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35536968 1.
  0.         0.2609341  1.        ]
 [0.         0.         0.43827928 0.3920578  0.35522763 1.
  0.         0.         1.        ]
 [0.         0.         0.34621629 0.34995966 0.35529471 1.
  0.         0.         1.        ]
 [0.         0.         0.71504879 0.71739577 0.35524151 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.35527723 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.35533019 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.35529509 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.35516656 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35508472 1.
  0.         0.         1.        ]
 [0.         0.         0.24043584 0.19455531 0.35523424 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35521435 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35514479 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.7857142686843872
#####################         POISON         ###############################################

############################################################################################

comm_round: 29 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00        10

    accuracy                           1.00        10
   macro avg       1.00      1.00      1.00        10
weighted avg       1.00      1.00      1.00        10

Accuracy per class:
[[10  0]
 [ 0  0]]
[ 1. nan]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0.         0.20355598 0.         1.         1.         0.
 0.         0.         0.         0.94489788 0.         0.
 0.96615836 0.90839151 0.98308601 0.         0.0267687  0.
 0.         0.         0.         0.0751145  0.         0.
 0.         0.         0.         0.858262   0.99998717 0.        ]
wv_fg shape (30,)
[0.94811775 0.86396214 0.94811775 0.86396214 1.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.        ]
wv_mn shape (30,)
[0.         0.11623152 0.         1.         1.         0.
 0.         0.         0.         0.54702555 0.         0.
 0.8791462  0.73699486 0.94481975 0.14257993 0.         0.
 0.         0.         0.         0.16743184 0.         0.
 0.         0.         0.         0.46075534 0.74104376 0.        ]
wv_ed shape (30,)
[0.         0.64302094 0.         1.         1.         0.4026029
 0.         0.         0.         0.69297829 0.08181941 0.
 0.95601196 0.8998318  1.         0.24541793 0.16310791 0.
 0.         0.         0.         0.52523227 0.         0.
 0.         0.         0.         0.66135477 0.9049988  0.        ]
wv_lg shape (30, 1)
[[0.39452253]
 [0.3940597 ]
 [0.39384025]
 [0.39455206]
 [0.39411573]
 [0.39360891]
 [0.393551  ]
 [0.39349968]
 [0.39335879]
 [0.39371174]
 [0.39372224]
 [0.39344021]
 [0.39344217]
 [0.39378565]
 [0.39376681]
 [0.39366081]
 [0.39373389]
 [0.39363011]
 [0.39348763]
 [0.39364389]
 [0.39361537]
 [0.39369599]
 [0.39377335]
 [0.39378152]
 [0.39349214]
 [0.39382343]
 [0.39343351]
 [0.39347677]
 [0.39366612]
 [0.39369491]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1.         1.         1.         1.         0.57589091 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.        ]
wv_std shape (30,)
[0.         0.18791693 0.         0.97154362 1.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.        ]
xy shape: (30, 9)
[[0.         0.94811775 0.         0.         0.39452253 1.
  1.         0.         0.        ]
 [0.20355598 0.86396214 0.11623152 0.64302094 0.3940597  1.
  1.         0.18791693 0.        ]
 [0.         0.94811775 0.         0.         0.39384025 1.
  1.         0.         0.        ]
 [1.         0.86396214 1.         1.         0.39455206 1.
  1.         0.97154362 0.        ]
 [1.         1.         1.         1.         0.39411573 1.
  0.57589091 1.         0.        ]
 [0.         0.         0.         0.4026029  0.39360891 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.393551   1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.39349968 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.39335879 1.
  0.         0.         1.        ]
 [0.94489788 0.         0.54702555 0.69297829 0.39371174 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.08181941 0.39372224 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.39344021 1.
  0.         0.         1.        ]
 [0.96615836 0.         0.8791462  0.95601196 0.39344217 1.
  0.         0.         1.        ]
 [0.90839151 0.         0.73699486 0.8998318  0.39378565 1.
  0.         0.         1.        ]
 [0.98308601 0.         0.94481975 1.         0.39376681 1.
  0.         0.         1.        ]
 [0.         0.         0.14257993 0.24541793 0.39366081 1.
  0.         0.         1.        ]
 [0.0267687  0.         0.         0.16310791 0.39373389 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.39363011 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.39348763 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.39364389 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.39361537 1.
  0.         0.         1.        ]
 [0.0751145  0.         0.16743184 0.52523227 0.39369599 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.39377335 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.39378152 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.39349214 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.39382343 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.39343351 1.
  0.         0.         1.        ]
 [0.858262   0.         0.46075534 0.66135477 0.39347677 1.
  0.         0.         1.        ]
 [0.99998717 0.         0.74104376 0.9049988  0.39366612 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.39369491 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.375
#####################         POISON         ###############################################

############################################################################################

comm_round: 0 | global_test_acc: 70.000% | global_f1: 0.8235294117647058 | global_precision: 0.7
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.70      1.00      0.82         7

    accuracy                           0.70        10
   macro avg       0.35      0.50      0.41        10
weighted avg       0.49      0.70      0.58        10
poison scaling shape: (30, 1)
[[1]
 [0]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [0]
 [1]
 [1]
 [0]
 [1]
 [1]
 [1]
 [0]
 [1]
 [0]
 [0]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0.         1.         0.         0.         1.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.35934978 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.58445577 0.         0.         0.         0.        ]
wv_fg shape (30,)
[1.         0.98999958 1.         1.         0.98999958 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.78608457 0.         0.         0.         0.        ]
wv_mn shape (30,)
[0.11580832 1.         0.19402685 0.         1.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.55293607 0.         0.
 0.         0.         0.         0.06756602 0.         0.
 0.         1.         0.         0.         0.         0.12079256]
wv_ed shape (30,)
[0.15993373 1.         0.         0.         1.         0.
 0.         0.0400788  0.05944493 0.         0.         0.
 0.         0.         0.         0.7340248  0.         0.
 0.         0.         0.         0.21176947 0.         0.
 0.         1.         0.02596475 0.         0.         0.2082649 ]
wv_lg shape (30, 1)
[[0.35027857]
 [0.35018253]
 [0.35031635]
 [0.35056214]
 [0.35049649]
 [0.34458321]
 [0.34477722]
 [0.34427937]
 [0.34479798]
 [0.34445059]
 [0.34499148]
 [0.34445197]
 [0.34477977]
 [0.34496707]
 [0.34506044]
 [0.34466717]
 [0.34437111]
 [0.34435429]
 [0.34516935]
 [0.34487725]
 [0.3446385 ]
 [0.3447808 ]
 [0.34498633]
 [0.34434251]
 [0.34445172]
 [0.34480838]
 [0.34482706]
 [0.34468907]
 [0.34471084]
 [0.34474486]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_std shape (30,)
[0.375619   1.         0.47212463 0.         1.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.        ]
xy shape: (30, 9)
[[0.         1.         0.11580832 0.15993373 0.35027857 1.
  1.         0.375619   0.        ]
 [1.         0.98999958 1.         1.         0.35018253 1.
  1.         1.         0.        ]
 [0.         1.         0.19402685 0.         0.35031635 1.
  1.         0.47212463 0.        ]
 [0.         1.         0.         0.         0.35056214 1.
  1.         0.         0.        ]
 [1.         0.98999958 1.         1.         0.35049649 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.34458321 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34477722 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.0400788  0.34427937 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.05944493 0.34479798 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34445059 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34499148 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34445197 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34477977 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34496707 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34506044 1.
  0.         0.         1.        ]
 [0.35934978 0.         0.55293607 0.7340248  0.34466717 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34437111 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34435429 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34516935 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34487725 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3446385  1.
  0.         0.         1.        ]
 [0.         0.         0.06756602 0.21176947 0.3447808  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34498633 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34434251 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34445172 1.
  0.         0.         1.        ]
 [0.58445577 0.78608457 1.         1.         0.34480838 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.02596475 0.34482706 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34468907 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34471084 1.
  0.         0.         1.        ]
 [0.         0.         0.12079256 0.2082649  0.34474486 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.75
#####################         POISON         ###############################################

############################################################################################

comm_round: 1 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00        10

    accuracy                           1.00        10
   macro avg       1.00      1.00      1.00        10
weighted avg       1.00      1.00      1.00        10
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0.         0.         0.         0.         0.18753878 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         1.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.        ]
wv_fg shape (30,)
[0.71581962 0.53303367 0.53303367 1.         0.71581962 0.
 0.30976235 0.         0.         0.         0.         0.
 0.         0.         0.         0.         1.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.        ]
wv_mn shape (30,)
[0.         0.         0.         0.         1.         0.
 1.         0.16862293 0.68724675 0.         0.         0.9680681
 0.66921567 0.         0.25419316 0.         1.         0.
 0.         0.02353159 0.         0.68865393 0.         0.20597563
 0.         0.         0.76053491 0.         0.         0.1594637 ]
wv_ed shape (30,)
[0.28807847 0.         0.         0.         1.         0.
 1.         0.18265573 0.74396688 0.         0.         1.
 0.77999919 0.         0.2081673  0.         1.         0.
 0.         0.17029973 0.         0.5530596  0.         0.33471479
 0.         0.         0.66836069 0.         0.         0.20885061]
wv_lg shape (30, 1)
[[0.35093182]
 [0.35109277]
 [0.3509723 ]
 [0.35081234]
 [0.35034515]
 [0.34637184]
 [0.34653587]
 [0.34648503]
 [0.34642994]
 [0.34667489]
 [0.34633614]
 [0.34640767]
 [0.3460699 ]
 [0.34611473]
 [0.34632082]
 [0.34640175]
 [0.34666927]
 [0.34639676]
 [0.34600054]
 [0.34681511]
 [0.34672317]
 [0.34666817]
 [0.34634439]
 [0.34682263]
 [0.3462037 ]
 [0.3466876 ]
 [0.34658183]
 [0.34604884]
 [0.34650245]
 [0.34620901]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_std shape (30,)
[0.13743173 0.         0.40986185 0.         0.84856865 0.
 0.         0.         0.         0.         0.         0.67713272
 0.         0.         0.         0.         1.         0.
 0.         0.         0.         0.1707885  0.         0.
 0.         0.         0.06157869 0.         0.         0.        ]
xy shape: (30, 9)
[[0.         0.71581962 0.         0.28807847 0.35093182 1.
  1.         0.13743173 0.        ]
 [0.         0.53303367 0.         0.         0.35109277 1.
  1.         0.         0.        ]
 [0.         0.53303367 0.         0.         0.3509723  1.
  1.         0.40986185 0.        ]
 [0.         1.         0.         0.         0.35081234 1.
  1.         0.         0.        ]
 [0.18753878 0.71581962 1.         1.         0.35034515 1.
  1.         0.84856865 0.        ]
 [0.         0.         0.         0.         0.34637184 1.
  0.         0.         1.        ]
 [0.         0.30976235 1.         1.         0.34653587 1.
  0.         0.         1.        ]
 [0.         0.         0.16862293 0.18265573 0.34648503 1.
  0.         0.         1.        ]
 [0.         0.         0.68724675 0.74396688 0.34642994 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34667489 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34633614 1.
  0.         0.         1.        ]
 [0.         0.         0.9680681  1.         0.34640767 1.
  0.         0.67713272 1.        ]
 [0.         0.         0.66921567 0.77999919 0.3460699  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34611473 1.
  0.         0.         1.        ]
 [0.         0.         0.25419316 0.2081673  0.34632082 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34640175 1.
  0.         0.         1.        ]
 [1.         1.         1.         1.         0.34666927 1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.34639676 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34600054 1.
  0.         0.         1.        ]
 [0.         0.         0.02353159 0.17029973 0.34681511 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34672317 1.
  0.         0.         1.        ]
 [0.         0.         0.68865393 0.5530596  0.34666817 1.
  0.         0.1707885  1.        ]
 [0.         0.         0.         0.         0.34634439 1.
  0.         0.         1.        ]
 [0.         0.         0.20597563 0.33471479 0.34682263 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3462037  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3466876  1.
  0.         0.         1.        ]
 [0.         0.         0.76053491 0.66836069 0.34658183 1.
  0.         0.06157869 1.        ]
 [0.         0.         0.         0.         0.34604884 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34650245 1.
  0.         0.         1.        ]
 [0.         0.         0.1594637  0.20885061 0.34620901 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.875
#####################         POISON         ###############################################

############################################################################################

comm_round: 2 | global_test_acc: 80.000% | global_f1: 0.888888888888889 | global_precision: 0.8
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.80      1.00      0.89         8

    accuracy                           0.80        10
   macro avg       0.40      0.50      0.44        10
weighted avg       0.64      0.80      0.71        10
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0.         0.         1.         0.         1.         0.
 0.         0.         0.         0.07275129 0.         0.10911827
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.        ]
wv_fg shape (30,)
[0.40306655 0.40306655 1.         1.         1.         0.
 0.         0.         0.         0.         0.         0.0986489
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.0443836  0.         0.
 0.         1.         0.         0.         0.         0.        ]
wv_mn shape (30,)
[0.         0.         1.         0.         1.         0.
 0.80385055 0.         0.6014863  1.         0.30134027 1.
 0.         0.56690405 0.42153653 0.         0.         0.06877477
 0.38258404 0.33378399 0.32420107 0.22168145 0.         0.11373389
 0.         0.31413427 0.13924413 0.29458999 0.15071066 0.        ]
wv_ed shape (30,)
[0.         0.         1.         0.         1.         0.
 0.9327562  0.         0.60873252 1.         0.38377755 1.
 0.         0.53472105 0.31230547 0.         0.         0.0862311
 0.26477657 0.34762466 0.27276739 0.0421558  0.         0.13206973
 0.         0.54192971 0.19119703 0.30555844 0.14516603 0.        ]
wv_lg shape (30, 1)
[[0.35160829]
 [0.35186903]
 [0.35157537]
 [0.35207895]
 [0.35195619]
 [0.34782193]
 [0.34785438]
 [0.34777639]
 [0.34812941]
 [0.34751473]
 [0.34766324]
 [0.347446  ]
 [0.34778849]
 [0.34772343]
 [0.34769501]
 [0.34847875]
 [0.34763056]
 [0.3476828 ]
 [0.34774326]
 [0.34769123]
 [0.34770775]
 [0.34755359]
 [0.34801259]
 [0.34722421]
 [0.34787573]
 [0.34784113]
 [0.34805718]
 [0.34770153]
 [0.34809399]
 [0.34751385]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1.         1.         0.99919536 1.         1.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.        ]
wv_std shape (30,)
[0.48079369 0.13010084 1.         0.         1.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.        ]
xy shape: (30, 9)
[[0.         0.40306655 0.         0.         0.35160829 1.
  1.         0.48079369 0.        ]
 [0.         0.40306655 0.         0.         0.35186903 1.
  1.         0.13010084 0.        ]
 [1.         1.         1.         1.         0.35157537 1.
  0.99919536 1.         0.        ]
 [0.         1.         0.         0.         0.35207895 1.
  1.         0.         0.        ]
 [1.         1.         1.         1.         0.35195619 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.34782193 1.
  0.         0.         1.        ]
 [0.         0.         0.80385055 0.9327562  0.34785438 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34777639 1.
  0.         0.         1.        ]
 [0.         0.         0.6014863  0.60873252 0.34812941 1.
  0.         0.         1.        ]
 [0.07275129 0.         1.         1.         0.34751473 1.
  0.         0.         1.        ]
 [0.         0.         0.30134027 0.38377755 0.34766324 1.
  0.         0.         1.        ]
 [0.10911827 0.0986489  1.         1.         0.347446   1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34778849 1.
  0.         0.         1.        ]
 [0.         0.         0.56690405 0.53472105 0.34772343 1.
  0.         0.         1.        ]
 [0.         0.         0.42153653 0.31230547 0.34769501 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34847875 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34763056 1.
  0.         0.         1.        ]
 [0.         0.         0.06877477 0.0862311  0.3476828  1.
  0.         0.         1.        ]
 [0.         0.         0.38258404 0.26477657 0.34774326 1.
  0.         0.         1.        ]
 [0.         0.         0.33378399 0.34762466 0.34769123 1.
  0.         0.         1.        ]
 [0.         0.         0.32420107 0.27276739 0.34770775 1.
  0.         0.         1.        ]
 [0.         0.0443836  0.22168145 0.0421558  0.34755359 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34801259 1.
  0.         0.         1.        ]
 [0.         0.         0.11373389 0.13206973 0.34722421 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34787573 1.
  0.         0.         1.        ]
 [0.         1.         0.31413427 0.54192971 0.34784113 1.
  0.         0.         1.        ]
 [0.         0.         0.13924413 0.19119703 0.34805718 1.
  0.         0.         1.        ]
 [0.         0.         0.29458999 0.30555844 0.34770153 1.
  0.         0.         1.        ]
 [0.         0.         0.15071066 0.14516603 0.34809399 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34751385 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.75
#####################         POISON         ###############################################

############################################################################################

comm_round: 3 | global_test_acc: 90.000% | global_f1: 0.9473684210526316 | global_precision: 0.9
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.90      1.00      0.95         9

    accuracy                           0.90        10
   macro avg       0.45      0.50      0.47        10
weighted avg       0.81      0.90      0.85        10
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0.         0.         0.         0.         1.         0.
 0.37369592 0.         0.28294735 0.11801274 0.50002718 0.
 0.         0.         0.         0.48827306 0.         0.
 0.         0.27604328 0.26937499 0.28894647 0.         0.16620597
 0.1643944  0.29169709 0.         0.28943614 0.         0.16067005]
wv_fg shape (30,)
[0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_mn shape (30,)
[0.         0.         0.         0.         1.         0.
 0.69944865 0.         0.53385698 0.         1.         0.
 0.         0.         0.         1.         0.         0.
 0.         0.44597534 0.45117419 0.48877499 0.         0.02181137
 0.         0.53419151 0.         0.5229441  0.         0.12337681]
wv_ed shape (30,)
[0.         0.         0.         0.         1.         0.
 0.51336382 0.         0.43725169 0.         1.         0.
 0.         0.         0.         1.         0.         0.
 0.         0.33794118 0.28202584 0.40337047 0.         0.
 0.         0.47246685 0.         0.2692074  0.         0.0223501 ]
wv_lg shape (30, 1)
[[0.35274408]
 [0.35218908]
 [0.3523714 ]
 [0.35290963]
 [0.35214275]
 [0.34844999]
 [0.34816143]
 [0.34862848]
 [0.34876957]
 [0.34891929]
 [0.34836607]
 [0.34855571]
 [0.34865037]
 [0.34805175]
 [0.34838678]
 [0.34870871]
 [0.34860083]
 [0.34848366]
 [0.34808231]
 [0.34861482]
 [0.34846404]
 [0.34807857]
 [0.34833929]
 [0.3483214 ]
 [0.34794185]
 [0.34885782]
 [0.34862195]
 [0.34838101]
 [0.34837545]
 [0.34810296]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_std shape (30,)
[0.18873555 0.         0.         0.         1.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.        ]
xy shape: (30, 9)
[[0.         0.         0.         0.         0.35274408 1.
  1.         0.18873555 0.        ]
 [0.         0.         0.         0.         0.35218908 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.3523714  1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.35290963 1.
  1.         0.         0.        ]
 [1.         1.         1.         1.         0.35214275 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.34844999 1.
  0.         0.         1.        ]
 [0.37369592 0.         0.69944865 0.51336382 0.34816143 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34862848 1.
  0.         0.         1.        ]
 [0.28294735 0.         0.53385698 0.43725169 0.34876957 1.
  0.         0.         1.        ]
 [0.11801274 0.         0.         0.         0.34891929 1.
  0.         0.         1.        ]
 [0.50002718 0.         1.         1.         0.34836607 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34855571 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34865037 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34805175 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34838678 1.
  0.         0.         1.        ]
 [0.48827306 0.         1.         1.         0.34870871 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34860083 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34848366 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34808231 1.
  0.         0.         1.        ]
 [0.27604328 0.         0.44597534 0.33794118 0.34861482 1.
  0.         0.         1.        ]
 [0.26937499 0.         0.45117419 0.28202584 0.34846404 1.
  0.         0.         1.        ]
 [0.28894647 0.         0.48877499 0.40337047 0.34807857 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34833929 1.
  0.         0.         1.        ]
 [0.16620597 0.         0.02181137 0.         0.3483214  1.
  0.         0.         1.        ]
 [0.1643944  0.         0.         0.         0.34794185 1.
  0.         0.         1.        ]
 [0.29169709 0.         0.53419151 0.47246685 0.34885782 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34862195 1.
  0.         0.         1.        ]
 [0.28943614 0.         0.5229441  0.2692074  0.34838101 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34837545 1.
  0.         0.         1.        ]
 [0.16067005 0.         0.12337681 0.0223501  0.34810296 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.8125
#####################         POISON         ###############################################

############################################################################################

comm_round: 4 | global_test_acc: 80.000% | global_f1: 0.888888888888889 | global_precision: 0.8
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.80      1.00      0.89         8

    accuracy                           0.80        10
   macro avg       0.40      0.50      0.44        10
weighted avg       0.64      0.80      0.71        10
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_fg shape (30,)
[1.         1.         0.60648794 0.60648794 1.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.        ]
wv_mn shape (30,)
[1.         1.         0.         0.23765065 0.         0.
 0.44768945 0.79229326 0.         1.         1.         0.
 1.         0.         0.         0.39997561 0.02546185 0.
 0.18554362 0.65469927 0.         0.49188351 1.         0.
 1.         0.         1.         1.         1.         0.        ]
wv_ed shape (30,)
[1.         1.         0.         0.47998265 0.         0.
 0.45355365 0.54531292 0.         1.         1.         0.
 1.         0.         0.         0.30285739 0.         0.
 0.         0.34051136 0.         0.34852085 1.         0.
 0.90986918 0.         1.         1.         1.         0.        ]
wv_lg shape (30, 1)
[[0.35320262]
 [0.35304893]
 [0.35291586]
 [0.35284536]
 [0.35327622]
 [0.34980808]
 [0.34987694]
 [0.34962122]
 [0.34943338]
 [0.34967696]
 [0.34977277]
 [0.34946775]
 [0.35016324]
 [0.34966338]
 [0.34914578]
 [0.34951714]
 [0.34966412]
 [0.34959146]
 [0.34946675]
 [0.34987838]
 [0.34990209]
 [0.35004166]
 [0.34972046]
 [0.34974214]
 [0.34933999]
 [0.34967774]
 [0.34972107]
 [0.34942657]
 [0.34964322]
 [0.34988287]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_std shape (30,)
[1.         1.         0.         0.38802922 0.16216008 0.
 0.         0.         0.         0.         0.         0.
 0.22859515 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.        ]
xy shape: (30, 9)
[[1.         1.         1.         1.         0.35320262 1.
  1.         1.         0.        ]
 [1.         1.         1.         1.         0.35304893 1.
  1.         1.         0.        ]
 [0.         0.60648794 0.         0.         0.35291586 1.
  1.         0.         0.        ]
 [0.         0.60648794 0.23765065 0.47998265 0.35284536 1.
  1.         0.38802922 0.        ]
 [0.         1.         0.         0.         0.35327622 1.
  1.         0.16216008 0.        ]
 [0.         0.         0.         0.         0.34980808 1.
  0.         0.         1.        ]
 [0.         0.         0.44768945 0.45355365 0.34987694 1.
  0.         0.         1.        ]
 [0.         0.         0.79229326 0.54531292 0.34962122 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34943338 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.34967696 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.34977277 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34946775 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.35016324 1.
  0.         0.22859515 1.        ]
 [0.         0.         0.         0.         0.34966338 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34914578 1.
  0.         0.         1.        ]
 [0.         0.         0.39997561 0.30285739 0.34951714 1.
  0.         0.         1.        ]
 [0.         0.         0.02546185 0.         0.34966412 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34959146 1.
  0.         0.         1.        ]
 [0.         0.         0.18554362 0.         0.34946675 1.
  0.         0.         1.        ]
 [0.         0.         0.65469927 0.34051136 0.34987838 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34990209 1.
  0.         0.         1.        ]
 [0.         0.         0.49188351 0.34852085 0.35004166 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.34972046 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34974214 1.
  0.         0.         1.        ]
 [0.         0.         1.         0.90986918 0.34933999 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34967774 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.34972107 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.34942657 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.34964322 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.34988287 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.9375
#####################         POISON         ###############################################

############################################################################################

comm_round: 5 | global_test_acc: 80.000% | global_f1: 0.888888888888889 | global_precision: 0.8
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.80      1.00      0.89         8

    accuracy                           0.80        10
   macro avg       0.40      0.50      0.44        10
weighted avg       0.64      0.80      0.71        10
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0.         1.         1.         0.         0.         0.06076777
 0.13934719 0.         0.         0.14119669 0.         0.29845782
 0.16343238 0.08326034 0.         0.09188701 0.02021803 0.
 0.         0.19176752 0.03897217 0.         0.         0.02178195
 0.13985092 0.         0.         0.         0.10886954 0.        ]
wv_fg shape (30,)
[1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_mn shape (30,)
[0.         1.         1.         0.         0.         0.2197111
 0.22711485 0.         0.         0.38183225 0.         0.67243003
 0.45077675 0.15572265 0.         0.25560055 0.10157283 0.
 0.         0.44533704 0.05334542 0.         0.         0.03564205
 0.43130374 0.         0.         0.         0.19331734 0.        ]
wv_ed shape (30,)
[0.         1.         1.         0.         0.         0.
 0.17210182 0.         0.         0.33536582 0.         0.63042502
 0.32802573 0.09592585 0.         0.09476413 0.14990911 0.
 0.         0.3746147  0.08390534 0.         0.         0.18187611
 0.49221852 0.         0.         0.         0.18811967 0.        ]
wv_lg shape (30, 1)
[[0.35382135]
 [0.35409259]
 [0.35360189]
 [0.35403885]
 [0.35378893]
 [0.35059918]
 [0.35066431]
 [0.35062511]
 [0.35044524]
 [0.35046411]
 [0.35051406]
 [0.35028045]
 [0.35070863]
 [0.35018308]
 [0.35048078]
 [0.35049608]
 [0.35023441]
 [0.35039444]
 [0.35041419]
 [0.35060522]
 [0.35062975]
 [0.35066104]
 [0.35058431]
 [0.35019888]
 [0.35075553]
 [0.35059555]
 [0.35029591]
 [0.3509224 ]
 [0.35045821]
 [0.35052017]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1.         0.77712146 0.95889405 1.         1.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.        ]
wv_std shape (30,)
[0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
xy shape: (30, 9)
[[0.         1.         0.         0.         0.35382135 1.
  1.         0.         0.        ]
 [1.         1.         1.         1.         0.35409259 1.
  0.77712146 1.         0.        ]
 [1.         0.         1.         1.         0.35360189 1.
  0.95889405 1.         0.        ]
 [0.         1.         0.         0.         0.35403885 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.35378893 1.
  1.         0.         0.        ]
 [0.06076777 0.         0.2197111  0.         0.35059918 1.
  0.         0.         1.        ]
 [0.13934719 0.         0.22711485 0.17210182 0.35066431 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35062511 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35044524 1.
  0.         0.         1.        ]
 [0.14119669 0.         0.38183225 0.33536582 0.35046411 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35051406 1.
  0.         0.         1.        ]
 [0.29845782 0.         0.67243003 0.63042502 0.35028045 1.
  0.         0.         1.        ]
 [0.16343238 0.         0.45077675 0.32802573 0.35070863 1.
  0.         0.         1.        ]
 [0.08326034 0.         0.15572265 0.09592585 0.35018308 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35048078 1.
  0.         0.         1.        ]
 [0.09188701 0.         0.25560055 0.09476413 0.35049608 1.
  0.         0.         1.        ]
 [0.02021803 0.         0.10157283 0.14990911 0.35023441 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35039444 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35041419 1.
  0.         0.         1.        ]
 [0.19176752 0.         0.44533704 0.3746147  0.35060522 1.
  0.         0.         1.        ]
 [0.03897217 0.         0.05334542 0.08390534 0.35062975 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35066104 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35058431 1.
  0.         0.         1.        ]
 [0.02178195 0.         0.03564205 0.18187611 0.35019888 1.
  0.         0.         1.        ]
 [0.13985092 0.         0.43130374 0.49221852 0.35075553 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35059555 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35029591 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3509224  1.
  0.         0.         1.        ]
 [0.10886954 0.         0.19331734 0.18811967 0.35045821 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35052017 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.625
#####################         POISON         ###############################################

############################################################################################

comm_round: 6 | global_test_acc: 90.000% | global_f1: 0.9473684210526316 | global_precision: 0.9
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.90      1.00      0.95         9

    accuracy                           0.90        10
   macro avg       0.45      0.50      0.47        10
weighted avg       0.81      0.90      0.85        10
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 0.]
wv_fg shape (30,)
[1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_mn shape (30,)
[0.         1.         0.59346425 0.         1.         0.
 0.         1.         1.         1.         1.         0.
 1.         1.         0.         1.         0.13412472 0.
 1.         1.         0.89935178 0.46470387 1.         1.
 1.         0.25152284 1.         1.         1.         0.        ]
wv_ed shape (30,)
[0.         0.91714556 0.38367442 0.         1.         0.
 0.         1.         1.         1.         1.         0.
 1.         1.         0.         1.         0.15765554 0.
 1.         1.         0.77396512 0.29939523 1.         1.
 1.         0.05462905 1.         0.99466896 1.         0.        ]
wv_lg shape (30, 1)
[[0.35433514]
 [0.35368403]
 [0.35454454]
 [0.35445032]
 [0.35376701]
 [0.35159958]
 [0.35136129]
 [0.35159605]
 [0.35149898]
 [0.35153305]
 [0.35129917]
 [0.35138454]
 [0.35153357]
 [0.35124337]
 [0.35130169]
 [0.35174886]
 [0.35144059]
 [0.35111924]
 [0.35130962]
 [0.3515615 ]
 [0.35118021]
 [0.35126292]
 [0.35143423]
 [0.35152204]
 [0.35158126]
 [0.35122348]
 [0.3514561 ]
 [0.35126711]
 [0.35130487]
 [0.35134078]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_std shape (30,)
[0.         0.         0.         0.         0.         0.
 0.         1.         1.         1.         1.         0.
 1.         1.         0.         1.         0.         0.
 1.         0.94094845 0.88787333 0.89398162 1.         1.
 1.         0.54767908 1.         1.         0.56729587 0.        ]
xy shape: (30, 9)
[[0.         1.         0.         0.         0.35433514 1.
  1.         0.         0.        ]
 [0.         0.         1.         0.91714556 0.35368403 1.
  1.         0.         0.        ]
 [0.         1.         0.59346425 0.38367442 0.35454454 1.
  1.         0.         0.        ]
 [0.         1.         0.         0.         0.35445032 1.
  1.         0.         0.        ]
 [0.         0.         1.         1.         0.35376701 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.35159958 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35136129 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35159605 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.35149898 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.35153305 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.35129917 1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.35138454 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35153357 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.35124337 1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.35130169 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35174886 1.
  0.         1.         1.        ]
 [0.         0.         0.13412472 0.15765554 0.35144059 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35111924 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35130962 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.3515615  1.
  0.         0.94094845 1.        ]
 [1.         0.         0.89935178 0.77396512 0.35118021 1.
  0.         0.88787333 1.        ]
 [1.         0.         0.46470387 0.29939523 0.35126292 1.
  0.         0.89398162 1.        ]
 [1.         0.         1.         1.         0.35143423 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.35152204 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.35158126 1.
  0.         1.         1.        ]
 [1.         0.         0.25152284 0.05462905 0.35122348 1.
  0.         0.54767908 1.        ]
 [1.         0.         1.         1.         0.3514561  1.
  0.         1.         1.        ]
 [1.         0.         1.         0.99466896 0.35126711 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.35130487 1.
  0.         0.56729587 1.        ]
 [0.         0.         0.         0.         0.35134078 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.3125
#####################         POISON         ###############################################

############################################################################################

comm_round: 7 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00        10

    accuracy                           1.00        10
   macro avg       1.00      1.00      1.00        10
weighted avg       1.00      1.00      1.00        10
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0.46251775 0.         0.         1.         0.         0.
 0.         0.40184874 0.         0.         0.44395645 0.
 0.         0.55976003 0.         0.         0.         0.
 0.25197399 0.         0.06301645 0.         0.         0.24465345
 0.         0.         0.         0.30570771 0.         0.        ]
wv_fg shape (30,)
[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_mn shape (30,)
[1.         0.         0.09992741 1.         0.         0.
 0.         1.         0.13136139 0.17636536 1.         0.
 0.         1.         0.         0.         0.46731074 0.62551912
 1.         0.         1.         0.17665212 0.         1.
 0.         0.03913001 0.16495523 1.         0.         0.        ]
wv_ed shape (30,)
[1.         0.         0.45347828 1.         0.         0.
 0.         1.         0.32758123 0.         1.         0.
 0.         1.         0.         0.         0.26619579 0.38631679
 1.         0.         1.         0.09003826 0.         1.
 0.         0.15588552 0.34789426 1.         0.         0.        ]
wv_lg shape (30, 1)
[[0.35485333]
 [0.3552656 ]
 [0.35500213]
 [0.35511548]
 [0.35503855]
 [0.3520598 ]
 [0.35214764]
 [0.35212757]
 [0.35265537]
 [0.35201106]
 [0.35214591]
 [0.35228554]
 [0.35212142]
 [0.35229815]
 [0.3520774 ]
 [0.35216598]
 [0.35199447]
 [0.35222755]
 [0.35203805]
 [0.35197448]
 [0.35230117]
 [0.35224507]
 [0.35195535]
 [0.35191518]
 [0.35193037]
 [0.35202777]
 [0.35213954]
 [0.35223769]
 [0.35213904]
 [0.35223101]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_std shape (30,)
[1.         0.         0.14319213 1.         0.         0.
 0.         0.26664535 0.         0.         0.         0.
 0.         0.06481872 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.        ]
xy shape: (30, 9)
[[0.46251775 1.         1.         1.         0.35485333 1.
  1.         1.         0.        ]
 [0.         1.         0.         0.         0.3552656  1.
  1.         0.         0.        ]
 [0.         1.         0.09992741 0.45347828 0.35500213 1.
  1.         0.14319213 0.        ]
 [1.         1.         1.         1.         0.35511548 1.
  1.         1.         0.        ]
 [0.         1.         0.         0.         0.35503855 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.3520598  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35214764 1.
  0.         0.         1.        ]
 [0.40184874 0.         1.         1.         0.35212757 1.
  0.         0.26664535 1.        ]
 [0.         0.         0.13136139 0.32758123 0.35265537 1.
  0.         0.         1.        ]
 [0.         0.         0.17636536 0.         0.35201106 1.
  0.         0.         1.        ]
 [0.44395645 0.         1.         1.         0.35214591 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35228554 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35212142 1.
  0.         0.         1.        ]
 [0.55976003 0.         1.         1.         0.35229815 1.
  0.         0.06481872 1.        ]
 [0.         0.         0.         0.         0.3520774  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35216598 1.
  0.         0.         1.        ]
 [0.         0.         0.46731074 0.26619579 0.35199447 1.
  0.         0.         1.        ]
 [0.         0.         0.62551912 0.38631679 0.35222755 1.
  0.         0.         1.        ]
 [0.25197399 0.         1.         1.         0.35203805 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35197448 1.
  0.         0.         1.        ]
 [0.06301645 0.         1.         1.         0.35230117 1.
  0.         0.         1.        ]
 [0.         0.         0.17665212 0.09003826 0.35224507 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35195535 1.
  0.         0.         1.        ]
 [0.24465345 0.         1.         1.         0.35191518 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35193037 1.
  0.         0.         1.        ]
 [0.         0.         0.03913001 0.15588552 0.35202777 1.
  0.         0.         1.        ]
 [0.         0.         0.16495523 0.34789426 0.35213954 1.
  0.         0.         1.        ]
 [0.30570771 0.         1.         1.         0.35223769 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35213904 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35223101 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.875
#####################         POISON         ###############################################

############################################################################################

comm_round: 8 | global_test_acc: 70.000% | global_f1: 0.8235294117647058 | global_precision: 0.7
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.70      1.00      0.82         7

    accuracy                           0.70        10
   macro avg       0.35      0.50      0.41        10
weighted avg       0.49      0.70      0.58        10
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[1.         1.         0.         0.         0.         0.54470254
 0.2738416  0.         0.         0.55599354 0.29974665 0.
 0.         0.19444361 0.215176   0.         0.54049717 0.
 0.2416797  0.         0.14403784 0.20192562 0.         0.
 0.         0.17030104 0.         0.         0.30493242 0.        ]
wv_fg shape (30,)
[0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_mn shape (30,)
[1.         1.         0.         0.11456922 0.         0.74715181
 0.         0.         0.         0.77159864 0.         0.
 0.         0.         0.         0.         0.77301315 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.10771726 0.        ]
wv_ed shape (30,)
[1.         1.         0.         0.44172589 0.         0.61482554
 0.         0.         0.         0.51892191 0.         0.
 0.         0.         0.         0.         0.63784977 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.17067731 0.        ]
wv_lg shape (30, 1)
[[0.35553345]
 [0.35501893]
 [0.35492136]
 [0.3558244 ]
 [0.35549599]
 [0.35267513]
 [0.3527415 ]
 [0.35255628]
 [0.35257656]
 [0.35264905]
 [0.35241033]
 [0.35277046]
 [0.35283903]
 [0.35291628]
 [0.35294986]
 [0.3524353 ]
 [0.35282647]
 [0.35271315]
 [0.35281688]
 [0.352505  ]
 [0.35272231]
 [0.35284653]
 [0.3527703 ]
 [0.35253961]
 [0.35246979]
 [0.35252392]
 [0.35266229]
 [0.35274847]
 [0.35265192]
 [0.35225785]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_std shape (30,)
[1.        1.        0.        0.        0.        0.        0.
 0.        0.        0.1648225 0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.       ]
xy shape: (30, 9)
[[1.         0.         1.         1.         0.35553345 1.
  1.         1.         0.        ]
 [1.         1.         1.         1.         0.35501893 1.
  1.         1.         0.        ]
 [0.         1.         0.         0.         0.35492136 1.
  1.         0.         0.        ]
 [0.         0.         0.11456922 0.44172589 0.3558244  1.
  1.         0.         0.        ]
 [0.         1.         0.         0.         0.35549599 1.
  1.         0.         0.        ]
 [0.54470254 0.         0.74715181 0.61482554 0.35267513 1.
  0.         0.         1.        ]
 [0.2738416  0.         0.         0.         0.3527415  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35255628 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35257656 1.
  0.         0.         1.        ]
 [0.55599354 0.         0.77159864 0.51892191 0.35264905 1.
  0.         0.1648225  1.        ]
 [0.29974665 0.         0.         0.         0.35241033 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35277046 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35283903 1.
  0.         0.         1.        ]
 [0.19444361 0.         0.         0.         0.35291628 1.
  0.         0.         1.        ]
 [0.215176   0.         0.         0.         0.35294986 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3524353  1.
  0.         0.         1.        ]
 [0.54049717 0.         0.77301315 0.63784977 0.35282647 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35271315 1.
  0.         0.         1.        ]
 [0.2416797  0.         0.         0.         0.35281688 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.352505   1.
  0.         0.         1.        ]
 [0.14403784 0.         0.         0.         0.35272231 1.
  0.         0.         1.        ]
 [0.20192562 0.         0.         0.         0.35284653 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3527703  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35253961 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35246979 1.
  0.         0.         1.        ]
 [0.17030104 0.         0.         0.         0.35252392 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35266229 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35274847 1.
  0.         0.         1.        ]
 [0.30493242 0.         0.10771726 0.17067731 0.35265192 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35225785 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.75
#####################         POISON         ###############################################

############################################################################################

comm_round: 9 | global_test_acc: 90.000% | global_f1: 0.9473684210526316 | global_precision: 0.9
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.90      1.00      0.95         9

    accuracy                           0.90        10
   macro avg       0.45      0.50      0.47        10
weighted avg       0.81      0.90      0.85        10
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[1.         1.         0.         1.         1.         0.
 0.         0.         0.         0.         0.         0.04902827
 0.         0.         0.         0.09545058 0.26506506 0.04333203
 0.         0.         0.         0.14120244 0.         0.
 0.         0.         0.07040001 0.         0.         0.41614639]
wv_fg shape (30,)
[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_mn shape (30,)
[0.69263    1.         0.         1.         1.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.03634208 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.24773638]
wv_ed shape (30,)
[0.66695605 1.         0.         0.88996223 1.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.06851226 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.38067337]
wv_lg shape (30, 1)
[[0.35574756]
 [0.3555992 ]
 [0.35608877]
 [0.35576316]
 [0.35552919]
 [0.35331237]
 [0.35361405]
 [0.35347789]
 [0.3533855 ]
 [0.35354128]
 [0.35353874]
 [0.3534785 ]
 [0.35349517]
 [0.35352522]
 [0.35334772]
 [0.35375554]
 [0.35333907]
 [0.35348325]
 [0.35351763]
 [0.35367323]
 [0.35360371]
 [0.35380483]
 [0.3533158 ]
 [0.35345132]
 [0.35368445]
 [0.3534423 ]
 [0.35364073]
 [0.35337673]
 [0.35360308]
 [0.35349464]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_std shape (30,)
[0.6207119 1.        0.        1.        1.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.       ]
xy shape: (30, 9)
[[1.         0.         0.69263    0.66695605 0.35574756 1.
  1.         0.6207119  0.        ]
 [1.         0.         1.         1.         0.3555992  1.
  1.         1.         0.        ]
 [0.         1.         0.         0.         0.35608877 1.
  1.         0.         0.        ]
 [1.         0.         1.         0.88996223 0.35576316 1.
  1.         1.         0.        ]
 [1.         0.         1.         1.         0.35552919 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.35331237 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35361405 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35347789 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3533855  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35354128 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35353874 1.
  0.         0.         1.        ]
 [0.04902827 0.         0.         0.         0.3534785  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35349517 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35352522 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35334772 1.
  0.         0.         1.        ]
 [0.09545058 0.         0.         0.         0.35375554 1.
  0.         0.         1.        ]
 [0.26506506 0.         0.03634208 0.06851226 0.35333907 1.
  0.         0.         1.        ]
 [0.04333203 0.         0.         0.         0.35348325 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35351763 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35367323 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35360371 1.
  0.         0.         1.        ]
 [0.14120244 0.         0.         0.         0.35380483 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3533158  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35345132 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35368445 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3534423  1.
  0.         0.         1.        ]
 [0.07040001 0.         0.         0.         0.35364073 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35337673 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35360308 1.
  0.         0.         1.        ]
 [0.41614639 0.         0.24773638 0.38067337 0.35349464 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.8125
#####################         POISON         ###############################################

############################################################################################

comm_round: 10 | global_test_acc: 80.000% | global_f1: 0.888888888888889 | global_precision: 0.8
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.80      1.00      0.89         8

    accuracy                           0.80        10
   macro avg       0.40      0.50      0.44        10
weighted avg       0.64      0.80      0.71        10
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[1.         1.         0.         0.01970098 0.3214172  0.
 0.         0.40124312 0.         0.21623872 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.40309171 0.         0.         0.21675564 0.28177082 0.        ]
wv_fg shape (30,)
[0.22408983 0.75105597 0.         1.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.        ]
wv_mn shape (30,)
[1.         1.         0.         1.         1.         0.
 1.         1.         0.38951973 1.         0.40379119 0.76898885
 0.         0.         0.78990127 0.88050577 1.         1.
 0.         1.         1.         0.         0.         0.
 1.         0.         0.39911979 1.         1.         0.3223332 ]
wv_ed shape (30,)
[1.         1.         0.         1.         1.         0.
 1.         1.         0.40625984 1.         0.28744152 0.81401605
 0.         0.         0.82125985 0.84316769 0.90055502 0.84527005
 0.         1.         0.76229599 0.         0.         0.
 1.         0.         0.12148185 1.         1.         0.14846331]
wv_lg shape (30, 1)
[[0.35643614]
 [0.35614658]
 [0.35567755]
 [0.35572161]
 [0.3558593 ]
 [0.35369027]
 [0.35381814]
 [0.35385722]
 [0.35385371]
 [0.35381949]
 [0.35413663]
 [0.35386458]
 [0.35374714]
 [0.35383694]
 [0.35388842]
 [0.35368774]
 [0.35408023]
 [0.35385506]
 [0.35358869]
 [0.35361156]
 [0.3537762 ]
 [0.35411873]
 [0.3538374 ]
 [0.35383978]
 [0.35350383]
 [0.3534682 ]
 [0.35388048]
 [0.35401111]
 [0.35417091]
 [0.35379158]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_std shape (30,)
[1.         1.         0.         1.         1.         0.
 0.         1.         0.         0.98773817 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 1.         0.         0.         0.12246879 1.         0.        ]
xy shape: (30, 9)
[[1.         0.22408983 1.         1.         0.35643614 1.
  1.         1.         0.        ]
 [1.         0.75105597 1.         1.         0.35614658 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.35567755 1.
  1.         0.         0.        ]
 [0.01970098 1.         1.         1.         0.35572161 1.
  1.         1.         0.        ]
 [0.3214172  0.         1.         1.         0.3558593  1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.35369027 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.35381814 1.
  0.         0.         1.        ]
 [0.40124312 0.         1.         1.         0.35385722 1.
  0.         1.         1.        ]
 [0.         0.         0.38951973 0.40625984 0.35385371 1.
  0.         0.         1.        ]
 [0.21623872 0.         1.         1.         0.35381949 1.
  0.         0.98773817 1.        ]
 [0.         0.         0.40379119 0.28744152 0.35413663 1.
  0.         0.         1.        ]
 [0.         0.         0.76898885 0.81401605 0.35386458 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35374714 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35383694 1.
  0.         0.         1.        ]
 [0.         0.         0.78990127 0.82125985 0.35388842 1.
  0.         0.         1.        ]
 [0.         0.         0.88050577 0.84316769 0.35368774 1.
  0.         0.         1.        ]
 [0.         0.         1.         0.90055502 0.35408023 1.
  0.         0.         1.        ]
 [0.         0.         1.         0.84527005 0.35385506 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35358869 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.35361156 1.
  0.         0.         1.        ]
 [0.         0.         1.         0.76229599 0.3537762  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35411873 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3538374  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35383978 1.
  0.         0.         1.        ]
 [0.40309171 0.         1.         1.         0.35350383 1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.3534682  1.
  0.         0.         1.        ]
 [0.         0.         0.39911979 0.12148185 0.35388048 1.
  0.         0.         1.        ]
 [0.21675564 0.         1.         1.         0.35401111 1.
  0.         0.12246879 1.        ]
 [0.28177082 0.         1.         1.         0.35417091 1.
  0.         1.         1.        ]
 [0.         0.         0.3223332  0.14846331 0.35379158 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.625
#####################         POISON         ###############################################

############################################################################################

comm_round: 11 | global_test_acc: 90.000% | global_f1: 0.9473684210526316 | global_precision: 0.9
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.90      1.00      0.95         9

    accuracy                           0.90        10
   macro avg       0.45      0.50      0.47        10
weighted avg       0.81      0.90      0.85        10
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[1.         1.         0.         0.14293549 0.14832511 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.65742615
 0.         0.         0.         0.         0.         0.        ]
wv_fg shape (30,)
[0.32928771 1.         1.         0.32928771 1.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.        ]
wv_mn shape (30,)
[1.         1.         0.         0.70214683 0.35468879 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.50293949
 0.         0.         0.         0.         0.         0.        ]
wv_ed shape (30,)
[1.         1.         0.         0.70568498 0.42457774 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.69114726
 0.         0.         0.         0.         0.         0.        ]
wv_lg shape (30, 1)
[[0.35659723]
 [0.35698211]
 [0.35692693]
 [0.35681641]
 [0.35624565]
 [0.35450789]
 [0.35462393]
 [0.35429551]
 [0.35476297]
 [0.35457527]
 [0.35459865]
 [0.35439039]
 [0.35447792]
 [0.3545823 ]
 [0.35463933]
 [0.35441952]
 [0.35446884]
 [0.35472272]
 [0.35448893]
 [0.35465524]
 [0.35472579]
 [0.35475037]
 [0.35456502]
 [0.35475779]
 [0.35452222]
 [0.354385  ]
 [0.35445617]
 [0.35474473]
 [0.35453026]
 [0.35447319]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_std shape (30,)
[1.         1.         0.         0.         0.41994415 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.        ]
xy shape: (30, 9)
[[1.         0.32928771 1.         1.         0.35659723 1.
  1.         1.         0.        ]
 [1.         1.         1.         1.         0.35698211 1.
  1.         1.         0.        ]
 [0.         1.         0.         0.         0.35692693 1.
  1.         0.         0.        ]
 [0.14293549 0.32928771 0.70214683 0.70568498 0.35681641 1.
  1.         0.         0.        ]
 [0.14832511 1.         0.35468879 0.42457774 0.35624565 1.
  1.         0.41994415 0.        ]
 [0.         0.         0.         0.         0.35450789 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35462393 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35429551 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35476297 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35457527 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35459865 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35439039 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35447792 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3545823  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35463933 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35441952 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35446884 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35472272 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35448893 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35465524 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35472579 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35475037 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35456502 1.
  0.         0.         1.        ]
 [0.65742615 0.         0.50293949 0.69114726 0.35475779 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35452222 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.354385   1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35445617 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35474473 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35453026 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35447319 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.875
#####################         POISON         ###############################################

############################################################################################

comm_round: 12 | global_test_acc: 70.000% | global_f1: 0.8235294117647058 | global_precision: 0.7
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.70      1.00      0.82         7

    accuracy                           0.70        10
   macro avg       0.35      0.50      0.41        10
weighted avg       0.49      0.70      0.58        10
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0.         0.         0.         0.83817147 0.         0.32016535
 0.37737473 0.35313864 0.         1.         0.         0.
 0.45756187 0.         0.         0.         0.         0.
 0.         0.         0.55011017 0.66122733 0.27588031 0.
 0.65353321 0.         0.         0.         0.         0.38625711]
wv_fg shape (30,)
[1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_mn shape (30,)
[0.         0.7597551  0.         1.         0.         0.84737451
 1.         1.         0.61231971 1.         0.         0.17823168
 1.         0.         0.         0.06335584 0.         0.51900429
 0.         0.         1.         1.         0.66665842 0.
 1.         0.         0.         0.62378304 0.         1.        ]
wv_ed shape (30,)
[0.         1.         0.         1.         0.         0.9216786
 1.         0.58186704 0.72906779 1.         0.         0.00821399
 1.         0.         0.         0.         0.         0.32540883
 0.         0.         1.         1.         0.63744661 0.
 1.         0.         0.         0.52359318 0.         0.93063493]
wv_lg shape (30, 1)
[[0.35727261]
 [0.35728688]
 [0.35679515]
 [0.35678367]
 [0.35624954]
 [0.35487556]
 [0.3547442 ]
 [0.35482421]
 [0.35470845]
 [0.3545054 ]
 [0.35489134]
 [0.35465979]
 [0.35500257]
 [0.35489779]
 [0.35455737]
 [0.35448861]
 [0.35473285]
 [0.35510718]
 [0.35495273]
 [0.3545947 ]
 [0.35490814]
 [0.35497841]
 [0.35475726]
 [0.35498585]
 [0.3546919 ]
 [0.3549166 ]
 [0.35464615]
 [0.35469017]
 [0.3547741 ]
 [0.35503833]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_std shape (30,)
[0.         0.         0.         0.54410865 0.         0.
 0.         0.28267353 0.         1.         0.         0.
 0.6308832  0.         0.         0.         0.         0.
 0.         0.         0.98461766 1.         0.         0.
 1.         0.         0.         0.         0.         0.11333815]
xy shape: (30, 9)
[[0.         1.         0.         0.         0.35727261 1.
  1.         0.         0.        ]
 [0.         1.         0.7597551  1.         0.35728688 1.
  1.         0.         0.        ]
 [0.         1.         0.         0.         0.35679515 1.
  1.         0.         0.        ]
 [0.83817147 1.         1.         1.         0.35678367 1.
  1.         0.54410865 0.        ]
 [0.         1.         0.         0.         0.35624954 1.
  1.         0.         0.        ]
 [0.32016535 0.         0.84737451 0.9216786  0.35487556 1.
  0.         0.         1.        ]
 [0.37737473 0.         1.         1.         0.3547442  1.
  0.         0.         1.        ]
 [0.35313864 1.         1.         0.58186704 0.35482421 1.
  0.         0.28267353 1.        ]
 [0.         0.         0.61231971 0.72906779 0.35470845 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.3545054  1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.35489134 1.
  0.         0.         1.        ]
 [0.         0.         0.17823168 0.00821399 0.35465979 1.
  0.         0.         1.        ]
 [0.45756187 0.         1.         1.         0.35500257 1.
  0.         0.6308832  1.        ]
 [0.         0.         0.         0.         0.35489779 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35455737 1.
  0.         0.         1.        ]
 [0.         0.         0.06335584 0.         0.35448861 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35473285 1.
  0.         0.         1.        ]
 [0.         0.         0.51900429 0.32540883 0.35510718 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35495273 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3545947  1.
  0.         0.         1.        ]
 [0.55011017 0.         1.         1.         0.35490814 1.
  0.         0.98461766 1.        ]
 [0.66122733 0.         1.         1.         0.35497841 1.
  0.         1.         1.        ]
 [0.27588031 0.         0.66665842 0.63744661 0.35475726 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35498585 1.
  0.         0.         1.        ]
 [0.65353321 0.         1.         1.         0.3546919  1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.3549166  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35464615 1.
  0.         0.         1.        ]
 [0.         0.         0.62378304 0.52359318 0.35469017 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3547741  1.
  0.         0.         1.        ]
 [0.38625711 0.         1.         0.93063493 0.35503833 1.
  0.         0.11333815 1.        ]]

Best Training Poisoning Accuracy:
0.875
#####################         POISON         ###############################################

############################################################################################

comm_round: 13 | global_test_acc: 80.000% | global_f1: 0.888888888888889 | global_precision: 0.8
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.80      1.00      0.89         8

    accuracy                           0.80        10
   macro avg       0.40      0.50      0.44        10
weighted avg       0.64      0.80      0.71        10
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0.54983065 0.         0.         1.         0.         0.
 0.         0.         0.         0.12097268 0.         0.07133162
 0.         0.         0.         0.         0.         0.
 0.97793576 0.         0.         0.         0.         0.
 0.         0.07867972 0.24634524 0.15904908 0.06408021 0.14690513]
wv_fg shape (30,)
[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_mn shape (30,)
[1.         0.55908744 0.58933154 1.         0.         0.
 0.23893579 0.         0.         0.83032659 0.         0.55647341
 0.         0.         0.         0.         0.         0.24154531
 1.         0.42552109 0.         0.         0.41866603 0.00324271
 0.         0.55714133 1.         1.         0.6327395  0.9532748 ]
wv_ed shape (30,)
[1.         0.         0.72789403 1.         0.         0.
 0.05713654 0.         0.         0.79594101 0.         0.3843631
 0.         0.         0.         0.         0.         0.00437304
 1.         0.12094645 0.         0.         0.22827372 0.06998679
 0.         0.52888972 1.         0.70973521 0.46123016 0.9589956 ]
wv_lg shape (30, 1)
[[0.35762703]
 [0.35777712]
 [0.3579097 ]
 [0.3567761 ]
 [0.35740373]
 [0.3553608 ]
 [0.35549348]
 [0.35537052]
 [0.35543976]
 [0.35548798]
 [0.35530132]
 [0.35511285]
 [0.3552031 ]
 [0.35509898]
 [0.3551532 ]
 [0.35541173]
 [0.35525836]
 [0.35549719]
 [0.35533739]
 [0.35507126]
 [0.35539273]
 [0.35531727]
 [0.3549582 ]
 [0.35530497]
 [0.3552344 ]
 [0.35522462]
 [0.35527231]
 [0.35530268]
 [0.35557242]
 [0.35523651]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_std shape (30,)
[1.         0.53772565 0.         1.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.2324795  0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.        ]
xy shape: (30, 9)
[[0.54983065 1.         1.         1.         0.35762703 1.
  1.         1.         0.        ]
 [0.         1.         0.55908744 0.         0.35777712 1.
  1.         0.53772565 0.        ]
 [0.         1.         0.58933154 0.72789403 0.3579097  1.
  1.         0.         0.        ]
 [1.         1.         1.         1.         0.3567761  1.
  1.         1.         0.        ]
 [0.         1.         0.         0.         0.35740373 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.3553608  1.
  0.         0.         1.        ]
 [0.         0.         0.23893579 0.05713654 0.35549348 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35537052 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35543976 1.
  0.         0.         1.        ]
 [0.12097268 0.         0.83032659 0.79594101 0.35548798 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35530132 1.
  0.         0.         1.        ]
 [0.07133162 0.         0.55647341 0.3843631  0.35511285 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3552031  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35509898 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3551532  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35541173 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35525836 1.
  0.         0.         1.        ]
 [0.         0.         0.24154531 0.00437304 0.35549719 1.
  0.         0.         1.        ]
 [0.97793576 0.         1.         1.         0.35533739 1.
  0.         0.2324795  1.        ]
 [0.         0.         0.42552109 0.12094645 0.35507126 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35539273 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35531727 1.
  0.         0.         1.        ]
 [0.         0.         0.41866603 0.22827372 0.3549582  1.
  0.         0.         1.        ]
 [0.         0.         0.00324271 0.06998679 0.35530497 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3552344  1.
  0.         0.         1.        ]
 [0.07867972 0.         0.55714133 0.52888972 0.35522462 1.
  0.         0.         1.        ]
 [0.24634524 0.         1.         1.         0.35527231 1.
  0.         0.         1.        ]
 [0.15904908 0.         1.         0.70973521 0.35530268 1.
  0.         0.         1.        ]
 [0.06408021 0.         0.6327395  0.46123016 0.35557242 1.
  0.         0.         1.        ]
 [0.14690513 0.         0.9532748  0.9589956  0.35523651 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.8125
#####################         POISON         ###############################################

############################################################################################

comm_round: 14 | global_test_acc: 80.000% | global_f1: 0.888888888888889 | global_precision: 0.8
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.80      1.00      0.89         8

    accuracy                           0.80        10
   macro avg       0.40      0.50      0.44        10
weighted avg       0.64      0.80      0.71        10
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[1.         0.         0.         1.         1.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.24945486 0.         0.         0.         0.
 0.         0.         0.         0.         0.2747203  0.
 0.         0.         0.         0.         0.         0.        ]
wv_fg shape (30,)
[0.         1.         0.65886412 0.         0.63413711 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.        ]
wv_mn shape (30,)
[1.         0.         0.         1.         0.80458354 0.
 0.         0.         0.         0.         0.         0.
 0.         0.25436578 0.         0.         0.         0.
 0.         0.         0.         0.         0.29237838 0.
 0.         0.         0.         0.         0.         0.        ]
wv_ed shape (30,)
[1.         0.         0.15485027 1.         0.67106231 0.
 0.         0.         0.         0.         0.         0.
 0.         0.29656182 0.         0.         0.         0.
 0.         0.         0.         0.         0.27645791 0.
 0.         0.         0.         0.         0.         0.        ]
wv_lg shape (30, 1)
[[0.3577397 ]
 [0.35783988]
 [0.35784744]
 [0.35777424]
 [0.3577211 ]
 [0.35637506]
 [0.35595919]
 [0.35605908]
 [0.35603209]
 [0.35619867]
 [0.35619098]
 [0.35618939]
 [0.35601645]
 [0.35594916]
 [0.35597732]
 [0.35628662]
 [0.35621129]
 [0.35609104]
 [0.35617673]
 [0.35604753]
 [0.35616397]
 [0.35593666]
 [0.35593927]
 [0.35602326]
 [0.35596276]
 [0.35594883]
 [0.35597766]
 [0.35607712]
 [0.35586434]
 [0.35588518]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_std shape (30,)
[1.         0.         0.         0.95123376 0.78744762 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.        ]
xy shape: (30, 9)
[[1.         0.         1.         1.         0.3577397  1.
  1.         1.         0.        ]
 [0.         1.         0.         0.         0.35783988 1.
  1.         0.         0.        ]
 [0.         0.65886412 0.         0.15485027 0.35784744 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.35777424 1.
  1.         0.95123376 0.        ]
 [1.         0.63413711 0.80458354 0.67106231 0.3577211  1.
  1.         0.78744762 0.        ]
 [0.         0.         0.         0.         0.35637506 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35595919 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35605908 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35603209 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35619867 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35619098 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35618939 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35601645 1.
  0.         0.         1.        ]
 [0.24945486 0.         0.25436578 0.29656182 0.35594916 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35597732 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35628662 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35621129 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35609104 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35617673 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35604753 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35616397 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35593666 1.
  0.         0.         1.        ]
 [0.2747203  0.         0.29237838 0.27645791 0.35593927 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35602326 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35596276 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35594883 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35597766 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35607712 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35586434 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35588518 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.875
#####################         POISON         ###############################################

############################################################################################

comm_round: 15 | global_test_acc: 80.000% | global_f1: 0.888888888888889 | global_precision: 0.8
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.80      1.00      0.89         8

    accuracy                           0.80        10
   macro avg       0.40      0.50      0.44        10
weighted avg       0.64      0.80      0.71        10
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0.         0.51817567 0.56048568 1.         1.         0.09524449
 0.16357556 0.         0.         1.         0.23051042 0.
 0.         0.         0.         0.12319113 0.         0.
 0.         0.05000679 0.05105328 0.         0.         0.
 0.         0.         0.         0.         0.         0.13106741]
wv_fg shape (30,)
[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_mn shape (30,)
[0.         0.65062812 0.5579458  1.         1.         0.
 0.2388639  0.         0.         0.86329514 0.17759906 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.        ]
wv_ed shape (30,)
[0.         0.70940747 0.35971707 1.         1.         0.
 0.12548526 0.         0.         0.69797428 0.16865161 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.02954865]
wv_lg shape (30, 1)
[[0.35795125]
 [0.35826016]
 [0.35805989]
 [0.35820211]
 [0.35813939]
 [0.35674203]
 [0.35663809]
 [0.35665558]
 [0.35648258]
 [0.35692232]
 [0.356383  ]
 [0.35670336]
 [0.35654409]
 [0.35646836]
 [0.35634771]
 [0.35645694]
 [0.35658549]
 [0.35664636]
 [0.3567165 ]
 [0.35651638]
 [0.35648788]
 [0.3566352 ]
 [0.35654736]
 [0.35670456]
 [0.35671523]
 [0.35684951]
 [0.35652072]
 [0.35651317]
 [0.35646439]
 [0.35654741]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_std shape (30,)
[0.         0.13407997 0.99390113 1.         1.         0.
 0.         0.         0.         0.44740832 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.        ]
xy shape: (30, 9)
[[0.         1.         0.         0.         0.35795125 1.
  1.         0.         0.        ]
 [0.51817567 1.         0.65062812 0.70940747 0.35826016 1.
  1.         0.13407997 0.        ]
 [0.56048568 1.         0.5579458  0.35971707 0.35805989 1.
  1.         0.99390113 0.        ]
 [1.         1.         1.         1.         0.35820211 1.
  1.         1.         0.        ]
 [1.         1.         1.         1.         0.35813939 1.
  1.         1.         0.        ]
 [0.09524449 0.         0.         0.         0.35674203 1.
  0.         0.         1.        ]
 [0.16357556 0.         0.2388639  0.12548526 0.35663809 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35665558 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35648258 1.
  0.         0.         1.        ]
 [1.         0.         0.86329514 0.69797428 0.35692232 1.
  0.         0.44740832 1.        ]
 [0.23051042 0.         0.17759906 0.16865161 0.356383   1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35670336 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35654409 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35646836 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35634771 1.
  0.         0.         1.        ]
 [0.12319113 0.         0.         0.         0.35645694 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35658549 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35664636 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3567165  1.
  0.         0.         1.        ]
 [0.05000679 0.         0.         0.         0.35651638 1.
  0.         0.         1.        ]
 [0.05105328 0.         0.         0.         0.35648788 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3566352  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35654736 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35670456 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35671523 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35684951 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35652072 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35651317 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35646439 1.
  0.         0.         1.        ]
 [0.13106741 0.         0.         0.02954865 0.35654741 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.875
#####################         POISON         ###############################################

############################################################################################

comm_round: 16 | global_test_acc: 70.000% | global_f1: 0.8235294117647058 | global_precision: 0.7
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.70      1.00      0.82         7

    accuracy                           0.70        10
   macro avg       0.35      0.50      0.41        10
weighted avg       0.49      0.70      0.58        10
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0.         0.09977082 0.         0.         0.         0.
 0.         0.05362122 1.         1.         0.         1.
 0.         0.         0.         0.         0.         1.
 0.         1.         0.         1.         0.         1.
 0.         0.         0.         0.         0.         0.        ]
wv_fg shape (30,)
[0.13760437 0.         1.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.        ]
wv_mn shape (30,)
[0.         1.         0.         0.44379976 0.         0.12136831
 0.         1.         1.         1.         0.29622392 1.
 0.         0.         0.43135815 0.         0.22175269 1.
 0.52760388 1.         0.40289284 1.         0.         1.
 0.17011022 0.94711088 0.52545838 0.         0.49693157 0.        ]
wv_ed shape (30,)
[0.         1.         0.         0.         0.         0.19847637
 0.         1.         1.         1.         0.22586848 1.
 0.         0.         0.43737658 0.         0.35675781 1.
 0.68564238 1.         0.34874986 1.         0.         1.
 0.19769821 0.89517044 0.51799423 0.         0.49796402 0.        ]
wv_lg shape (30, 1)
[[0.35837248]
 [0.35861838]
 [0.35867171]
 [0.35869484]
 [0.35858193]
 [0.35672216]
 [0.35693024]
 [0.35688038]
 [0.35692612]
 [0.35666492]
 [0.35697262]
 [0.3569048 ]
 [0.35672964]
 [0.35681824]
 [0.35712594]
 [0.35690491]
 [0.35689081]
 [0.35694609]
 [0.35678289]
 [0.35676247]
 [0.35679806]
 [0.35692844]
 [0.35662255]
 [0.35666174]
 [0.35681822]
 [0.35702805]
 [0.35691506]
 [0.35685186]
 [0.35682411]
 [0.35693195]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_std shape (30,)
[0.         0.75431896 0.17456108 0.         0.         0.
 0.         0.35846206 0.68398405 1.         0.         0.30911994
 0.         0.         0.         0.         0.         1.
 0.         0.73971398 0.         0.82259576 0.         1.
 0.         0.         0.         0.         0.         0.        ]
xy shape: (30, 9)
[[0.         0.13760437 0.         0.         0.35837248 1.
  1.         0.         0.        ]
 [0.09977082 0.         1.         1.         0.35861838 1.
  1.         0.75431896 0.        ]
 [0.         1.         0.         0.         0.35867171 1.
  1.         0.17456108 0.        ]
 [0.         0.         0.44379976 0.         0.35869484 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.35858193 1.
  1.         0.         0.        ]
 [0.         0.         0.12136831 0.19847637 0.35672216 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35693024 1.
  0.         0.         1.        ]
 [0.05362122 0.         1.         1.         0.35688038 1.
  0.         0.35846206 1.        ]
 [1.         0.         1.         1.         0.35692612 1.
  0.         0.68398405 1.        ]
 [1.         0.         1.         1.         0.35666492 1.
  0.         1.         1.        ]
 [0.         0.         0.29622392 0.22586848 0.35697262 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.3569048  1.
  0.         0.30911994 1.        ]
 [0.         0.         0.         0.         0.35672964 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35681824 1.
  0.         0.         1.        ]
 [0.         0.         0.43135815 0.43737658 0.35712594 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35690491 1.
  0.         0.         1.        ]
 [0.         0.         0.22175269 0.35675781 0.35689081 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35694609 1.
  0.         1.         1.        ]
 [0.         0.         0.52760388 0.68564238 0.35678289 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35676247 1.
  0.         0.73971398 1.        ]
 [0.         0.         0.40289284 0.34874986 0.35679806 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35692844 1.
  0.         0.82259576 1.        ]
 [0.         0.         0.         0.         0.35662255 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35666174 1.
  0.         1.         1.        ]
 [0.         0.         0.17011022 0.19769821 0.35681822 1.
  0.         0.         1.        ]
 [0.         0.         0.94711088 0.89517044 0.35702805 1.
  0.         0.         1.        ]
 [0.         0.         0.52545838 0.51799423 0.35691506 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35685186 1.
  0.         0.         1.        ]
 [0.         0.         0.49693157 0.49796402 0.35682411 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35693195 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.9375
#####################         POISON         ###############################################

############################################################################################

comm_round: 17 | global_test_acc: 70.000% | global_f1: 0.8235294117647058 | global_precision: 0.7
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.70      1.00      0.82         7

    accuracy                           0.70        10
   macro avg       0.35      0.50      0.41        10
weighted avg       0.49      0.70      0.58        10
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[1.         1.         0.59244598 0.         1.         0.06453901
 0.05523783 0.14329654 0.16836731 0.         0.         0.
 0.         0.         0.18263951 0.         0.07154399 0.
 0.         0.         0.         0.11126069 1.         0.2276608
 0.00727624 0.23727915 0.         0.         0.         0.        ]
wv_fg shape (30,)
[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_mn shape (30,)
[1.         1.         0.68083414 0.         1.         0.16281929
 0.18933069 0.44991644 0.54565037 0.         0.         0.
 0.         0.         0.44233228 0.         0.219488   0.
 0.         0.         0.         0.23287636 1.         0.62325813
 0.04887909 0.70528483 0.         0.         0.         0.        ]
wv_ed shape (30,)
[1.         1.         0.67497808 0.         1.         0.12033285
 0.25320041 0.34765745 0.66949091 0.         0.         0.
 0.         0.         0.58212402 0.         0.2787225  0.
 0.         0.         0.         0.36509151 1.         0.75954737
 0.03837763 0.87598058 0.03422421 0.         0.         0.        ]
wv_lg shape (30, 1)
[[0.35899212]
 [0.35888243]
 [0.35835947]
 [0.35810867]
 [0.35816449]
 [0.35715585]
 [0.35689093]
 [0.35696212]
 [0.3567392 ]
 [0.35699683]
 [0.3569808 ]
 [0.35706911]
 [0.35698353]
 [0.35717493]
 [0.35683175]
 [0.35669384]
 [0.35695306]
 [0.35702222]
 [0.35691203]
 [0.35709165]
 [0.35687601]
 [0.35684453]
 [0.35708291]
 [0.35712712]
 [0.3570289 ]
 [0.35679264]
 [0.35676653]
 [0.35712823]
 [0.35702549]
 [0.35697956]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_std shape (30,)
[1.         1.         0.73883822 0.         1.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.        ]
xy shape: (30, 9)
[[1.         0.         1.         1.         0.35899212 1.
  1.         1.         0.        ]
 [1.         0.         1.         1.         0.35888243 1.
  1.         1.         0.        ]
 [0.59244598 0.         0.68083414 0.67497808 0.35835947 1.
  1.         0.73883822 0.        ]
 [0.         1.         0.         0.         0.35810867 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.35816449 1.
  1.         1.         0.        ]
 [0.06453901 0.         0.16281929 0.12033285 0.35715585 1.
  0.         0.         1.        ]
 [0.05523783 0.         0.18933069 0.25320041 0.35689093 1.
  0.         0.         1.        ]
 [0.14329654 0.         0.44991644 0.34765745 0.35696212 1.
  0.         0.         1.        ]
 [0.16836731 0.         0.54565037 0.66949091 0.3567392  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35699683 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3569808  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35706911 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35698353 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35717493 1.
  0.         0.         1.        ]
 [0.18263951 0.         0.44233228 0.58212402 0.35683175 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35669384 1.
  0.         0.         1.        ]
 [0.07154399 0.         0.219488   0.2787225  0.35695306 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35702222 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35691203 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35709165 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35687601 1.
  0.         0.         1.        ]
 [0.11126069 0.         0.23287636 0.36509151 0.35684453 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35708291 1.
  0.         0.         1.        ]
 [0.2276608  0.         0.62325813 0.75954737 0.35712712 1.
  0.         0.         1.        ]
 [0.00727624 0.         0.04887909 0.03837763 0.3570289  1.
  0.         0.         1.        ]
 [0.23727915 0.         0.70528483 0.87598058 0.35679264 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.03422421 0.35676653 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35712823 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35702549 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35697956 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.9375
#####################         POISON         ###############################################

############################################################################################

comm_round: 18 | global_test_acc: 80.000% | global_f1: 0.888888888888889 | global_precision: 0.8
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.80      1.00      0.89         8

    accuracy                           0.80        10
   macro avg       0.40      0.50      0.44        10
weighted avg       0.64      0.80      0.71        10
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0.         0.         0.         0.43454824 0.03852172 0.
 0.         0.         0.         0.03652826 0.2675496  0.04449546
 0.         0.         0.         0.         0.01030875 0.
 0.         0.23796313 0.         1.         0.         0.
 0.         0.         0.         0.04717192 0.         1.        ]
wv_fg shape (30,)
[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_mn shape (30,)
[0.50301485 0.         0.         1.         1.         0.15132866
 0.         0.         0.         1.         1.         1.
 0.59272196 0.62275428 0.38827822 0.         0.96861749 0.28332224
 0.         1.         0.         1.         0.61804657 0.
 0.47056584 0.80691549 0.4315391  1.         0.59478853 1.        ]
wv_ed shape (30,)
[0.67119725 0.         0.         0.97681085 0.49488567 0.
 0.         0.         0.         1.         1.         1.
 0.58054456 0.59666133 0.19847099 0.         0.74383122 0.22592107
 0.         1.         0.         1.         0.55366566 0.
 0.12709513 0.77244231 0.24303387 1.         0.44498662 1.        ]
wv_lg shape (30, 1)
[[0.35908493]
 [0.35911749]
 [0.35822348]
 [0.35918749]
 [0.35870035]
 [0.35746984]
 [0.3572072 ]
 [0.35734989]
 [0.35756913]
 [0.35706501]
 [0.35723478]
 [0.35760597]
 [0.35747421]
 [0.35748361]
 [0.35741561]
 [0.35749919]
 [0.35741556]
 [0.35755715]
 [0.35745743]
 [0.35763895]
 [0.35786907]
 [0.35729377]
 [0.35751882]
 [0.35755702]
 [0.35760382]
 [0.35750512]
 [0.35785321]
 [0.35764245]
 [0.35745869]
 [0.35768613]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_std shape (30,)
[0.         0.         0.00160785 1.         1.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.01890609 0.
 0.         0.         0.         1.         0.         0.
 0.         0.         0.         0.         0.         1.        ]
xy shape: (30, 9)
[[0.         1.         0.50301485 0.67119725 0.35908493 1.
  1.         0.         0.        ]
 [0.         1.         0.         0.         0.35911749 1.
  1.         0.         0.        ]
 [0.         1.         0.         0.         0.35822348 1.
  1.         0.00160785 0.        ]
 [0.43454824 1.         1.         0.97681085 0.35918749 1.
  1.         1.         0.        ]
 [0.03852172 1.         1.         0.49488567 0.35870035 1.
  1.         1.         0.        ]
 [0.         0.         0.15132866 0.         0.35746984 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3572072  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35734989 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35756913 1.
  0.         0.         1.        ]
 [0.03652826 0.         1.         1.         0.35706501 1.
  0.         0.         1.        ]
 [0.2675496  0.         1.         1.         0.35723478 1.
  0.         0.         1.        ]
 [0.04449546 0.         1.         1.         0.35760597 1.
  0.         0.         1.        ]
 [0.         0.         0.59272196 0.58054456 0.35747421 1.
  0.         0.         1.        ]
 [0.         0.         0.62275428 0.59666133 0.35748361 1.
  0.         0.         1.        ]
 [0.         0.         0.38827822 0.19847099 0.35741561 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35749919 1.
  0.         0.         1.        ]
 [0.01030875 0.         0.96861749 0.74383122 0.35741556 1.
  0.         0.01890609 1.        ]
 [0.         0.         0.28332224 0.22592107 0.35755715 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35745743 1.
  0.         0.         1.        ]
 [0.23796313 0.         1.         1.         0.35763895 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35786907 1.
  0.         0.         1.        ]
 [1.         1.         1.         1.         0.35729377 1.
  0.         1.         1.        ]
 [0.         0.         0.61804657 0.55366566 0.35751882 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35755702 1.
  0.         0.         1.        ]
 [0.         0.         0.47056584 0.12709513 0.35760382 1.
  0.         0.         1.        ]
 [0.         0.         0.80691549 0.77244231 0.35750512 1.
  0.         0.         1.        ]
 [0.         0.         0.4315391  0.24303387 0.35785321 1.
  0.         0.         1.        ]
 [0.04717192 0.         1.         1.         0.35764245 1.
  0.         0.         1.        ]
 [0.         0.         0.59478853 0.44498662 0.35745869 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35768613 1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.4375
#####################         POISON         ###############################################

############################################################################################

comm_round: 0 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00        10

    accuracy                           1.00        10
   macro avg       1.00      1.00      1.00        10
weighted avg       1.00      1.00      1.00        10
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [0]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0.         0.0333444  0.         0.34640036 0.         0.
 0.         0.         0.         0.         0.         0.
 1.         0.         0.         0.         0.         0.
 0.16581694 0.27416983 0.         0.22838712 0.         0.
 0.         0.         0.         1.         0.         0.        ]
wv_fg shape (30,)
[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_mn shape (30,)
[0.63424571 1.         0.         1.         0.         0.
 0.         1.         0.         0.11811738 0.         1.
 1.         0.10183699 0.6804084  0.89538019 0.43516885 0.
 1.         1.         0.         1.         0.         0.39279805
 0.36527836 0.         0.         1.         0.12988239 0.14376213]
wv_ed shape (30,)
[0.         1.         0.         1.         0.         0.
 0.         1.         0.         0.13638385 0.         0.82247606
 1.         0.         0.29189066 0.62569617 0.38415079 0.
 1.         1.         0.         1.         0.         0.13205843
 0.23219352 0.         0.         1.         0.0050574  0.        ]
wv_lg shape (30, 1)
[[0.35262245]
 [0.3526644 ]
 [0.35277729]
 [0.35276903]
 [0.35304986]
 [0.35101975]
 [0.35122715]
 [0.35117046]
 [0.35129836]
 [0.35128742]
 [0.35113428]
 [0.35102594]
 [0.35104134]
 [0.35127741]
 [0.35113419]
 [0.35117608]
 [0.35119677]
 [0.35082094]
 [0.35125955]
 [0.35106835]
 [0.3511611 ]
 [0.35095287]
 [0.35107603]
 [0.35103165]
 [0.35115601]
 [0.35105338]
 [0.35098009]
 [0.35125461]
 [0.35107668]
 [0.35109038]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_std shape (30,)
[0.         1.         0.         0.78350682 0.         0.
 0.         0.55211436 0.         0.         0.         0.63797795
 1.         0.         0.         0.62692564 0.         0.
 1.         1.         0.         0.90416159 0.         0.19655205
 0.         0.         0.         1.         0.         0.        ]
xy shape: (30, 9)
[[0.         1.         0.63424571 0.         0.35262245 1.
  1.         0.         0.        ]
 [0.0333444  1.         1.         1.         0.3526644  1.
  1.         1.         0.        ]
 [0.         1.         0.         0.         0.35277729 1.
  1.         0.         0.        ]
 [0.34640036 1.         1.         1.         0.35276903 1.
  1.         0.78350682 0.        ]
 [0.         1.         0.         0.         0.35304986 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.35101975 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35122715 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.35117046 1.
  0.         0.55211436 1.        ]
 [0.         0.         0.         0.         0.35129836 1.
  0.         0.         1.        ]
 [0.         0.         0.11811738 0.13638385 0.35128742 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35113428 1.
  0.         0.         1.        ]
 [0.         0.         1.         0.82247606 0.35102594 1.
  0.         0.63797795 1.        ]
 [1.         0.         1.         1.         0.35104134 1.
  0.         1.         1.        ]
 [0.         0.         0.10183699 0.         0.35127741 1.
  0.         0.         1.        ]
 [0.         0.         0.6804084  0.29189066 0.35113419 1.
  0.         0.         1.        ]
 [0.         0.         0.89538019 0.62569617 0.35117608 1.
  0.         0.62692564 1.        ]
 [0.         0.         0.43516885 0.38415079 0.35119677 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35082094 1.
  0.         0.         1.        ]
 [0.16581694 0.         1.         1.         0.35125955 1.
  0.         1.         1.        ]
 [0.27416983 0.         1.         1.         0.35106835 1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.3511611  1.
  0.         0.         1.        ]
 [0.22838712 0.         1.         1.         0.35095287 1.
  0.         0.90416159 1.        ]
 [0.         0.         0.         0.         0.35107603 1.
  0.         0.         1.        ]
 [0.         0.         0.39279805 0.13205843 0.35103165 1.
  0.         0.19655205 1.        ]
 [0.         0.         0.36527836 0.23219352 0.35115601 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35105338 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35098009 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35125461 1.
  0.         1.         1.        ]
 [0.         0.         0.12988239 0.0050574  0.35107668 1.
  0.         0.         1.        ]
 [0.         0.         0.14376213 0.         0.35109038 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.6875
#####################         POISON         ###############################################

############################################################################################

comm_round: 0 | global_test_acc: 70.000% | global_f1: 0.8235294117647058 | global_precision: 0.7
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.70      1.00      0.82         7

    accuracy                           0.70        10
   macro avg       0.35      0.50      0.41        10
weighted avg       0.49      0.70      0.58        10
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0.         0.         0.14961799 0.80881533 0.         0.
 1.         0.43705654 0.         0.43979265 0.         0.
 0.         0.50297986 0.         0.54529946 0.         0.
 0.47324007 0.         0.         0.         0.01687244 0.
 0.40847174 0.46273492 0.         0.         0.         0.        ]
wv_fg shape (30,)
[1.         1.         0.36897284 1.         0.36897284 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.        ]
wv_mn shape (30,)
[0.68550709 0.         0.6202871  1.         0.         0.
 1.         1.         0.36674614 1.         0.18468691 0.44905363
 0.05136826 1.         0.23086686 1.         0.09825513 0.
 1.         0.60641853 0.3968945  0.         0.93325149 0.9849925
 1.         1.         0.57008145 0.32035416 0.         0.        ]
wv_ed shape (30,)
[1.         0.         1.         1.         0.21707372 0.
 1.         1.         0.54654862 1.         0.24775871 0.68503596
 0.3717485  1.         0.41681939 1.         0.28723343 0.
 1.         0.7277651  0.48627788 0.         1.         1.
 1.         1.         0.6856877  0.52593948 0.01499303 0.        ]
wv_lg shape (30, 1)
[[0.35336117]
 [0.35284271]
 [0.35299967]
 [0.35270943]
 [0.35237326]
 [0.3512454 ]
 [0.3509406 ]
 [0.35130272]
 [0.35123344]
 [0.35101943]
 [0.35112835]
 [0.35129512]
 [0.3510802 ]
 [0.35108754]
 [0.3509921 ]
 [0.35146172]
 [0.35126299]
 [0.35102178]
 [0.35103041]
 [0.3508255 ]
 [0.35103401]
 [0.35128149]
 [0.35121238]
 [0.35120101]
 [0.35130482]
 [0.35123021]
 [0.35125349]
 [0.35102617]
 [0.35137732]
 [0.35133614]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_std shape (30,)
[5.27906599e-04 0.00000000e+00 2.05933778e-01 6.85014967e-01
 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00
 0.00000000e+00 5.31309385e-01 0.00000000e+00 0.00000000e+00
 0.00000000e+00 6.58045005e-01 0.00000000e+00 9.49023180e-01
 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
 1.48235042e-03 2.49871717e-01 0.00000000e+00 0.00000000e+00
 0.00000000e+00 0.00000000e+00]
xy shape: (30, 9)
[[0.00000000e+00 1.00000000e+00 6.85507088e-01 1.00000000e+00
  3.53361166e-01 1.00000000e+00 1.00000000e+00 5.27906599e-04
  0.00000000e+00]
 [0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00
  3.52842705e-01 1.00000000e+00 1.00000000e+00 0.00000000e+00
  0.00000000e+00]
 [1.49617987e-01 3.68972836e-01 6.20287102e-01 1.00000000e+00
  3.52999669e-01 1.00000000e+00 1.00000000e+00 2.05933778e-01
  0.00000000e+00]
 [8.08815326e-01 1.00000000e+00 1.00000000e+00 1.00000000e+00
  3.52709432e-01 1.00000000e+00 1.00000000e+00 6.85014967e-01
  0.00000000e+00]
 [0.00000000e+00 3.68972836e-01 0.00000000e+00 2.17073717e-01
  3.52373256e-01 1.00000000e+00 1.00000000e+00 0.00000000e+00
  0.00000000e+00]
 [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
  3.51245398e-01 1.00000000e+00 0.00000000e+00 0.00000000e+00
  1.00000000e+00]
 [1.00000000e+00 0.00000000e+00 1.00000000e+00 1.00000000e+00
  3.50940598e-01 1.00000000e+00 0.00000000e+00 1.00000000e+00
  1.00000000e+00]
 [4.37056544e-01 0.00000000e+00 1.00000000e+00 1.00000000e+00
  3.51302717e-01 1.00000000e+00 0.00000000e+00 0.00000000e+00
  1.00000000e+00]
 [0.00000000e+00 0.00000000e+00 3.66746143e-01 5.46548623e-01
  3.51233442e-01 1.00000000e+00 0.00000000e+00 0.00000000e+00
  1.00000000e+00]
 [4.39792650e-01 0.00000000e+00 1.00000000e+00 1.00000000e+00
  3.51019432e-01 1.00000000e+00 0.00000000e+00 5.31309385e-01
  1.00000000e+00]
 [0.00000000e+00 0.00000000e+00 1.84686911e-01 2.47758714e-01
  3.51128346e-01 1.00000000e+00 0.00000000e+00 0.00000000e+00
  1.00000000e+00]
 [0.00000000e+00 0.00000000e+00 4.49053631e-01 6.85035962e-01
  3.51295115e-01 1.00000000e+00 0.00000000e+00 0.00000000e+00
  1.00000000e+00]
 [0.00000000e+00 0.00000000e+00 5.13682570e-02 3.71748497e-01
  3.51080204e-01 1.00000000e+00 0.00000000e+00 0.00000000e+00
  1.00000000e+00]
 [5.02979856e-01 0.00000000e+00 1.00000000e+00 1.00000000e+00
  3.51087539e-01 1.00000000e+00 0.00000000e+00 6.58045005e-01
  1.00000000e+00]
 [0.00000000e+00 0.00000000e+00 2.30866865e-01 4.16819385e-01
  3.50992103e-01 1.00000000e+00 0.00000000e+00 0.00000000e+00
  1.00000000e+00]
 [5.45299465e-01 0.00000000e+00 1.00000000e+00 1.00000000e+00
  3.51461717e-01 1.00000000e+00 0.00000000e+00 9.49023180e-01
  1.00000000e+00]
 [0.00000000e+00 0.00000000e+00 9.82551267e-02 2.87233433e-01
  3.51262994e-01 1.00000000e+00 0.00000000e+00 0.00000000e+00
  1.00000000e+00]
 [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
  3.51021783e-01 1.00000000e+00 0.00000000e+00 0.00000000e+00
  1.00000000e+00]
 [4.73240069e-01 0.00000000e+00 1.00000000e+00 1.00000000e+00
  3.51030409e-01 1.00000000e+00 0.00000000e+00 0.00000000e+00
  1.00000000e+00]
 [0.00000000e+00 0.00000000e+00 6.06418528e-01 7.27765101e-01
  3.50825502e-01 1.00000000e+00 0.00000000e+00 0.00000000e+00
  1.00000000e+00]
 [0.00000000e+00 0.00000000e+00 3.96894504e-01 4.86277877e-01
  3.51034011e-01 1.00000000e+00 0.00000000e+00 0.00000000e+00
  1.00000000e+00]
 [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
  3.51281493e-01 1.00000000e+00 0.00000000e+00 0.00000000e+00
  1.00000000e+00]
 [1.68724396e-02 0.00000000e+00 9.33251493e-01 1.00000000e+00
  3.51212379e-01 1.00000000e+00 0.00000000e+00 0.00000000e+00
  1.00000000e+00]
 [0.00000000e+00 0.00000000e+00 9.84992503e-01 1.00000000e+00
  3.51201007e-01 1.00000000e+00 0.00000000e+00 0.00000000e+00
  1.00000000e+00]
 [4.08471737e-01 0.00000000e+00 1.00000000e+00 1.00000000e+00
  3.51304824e-01 1.00000000e+00 0.00000000e+00 1.48235042e-03
  1.00000000e+00]
 [4.62734925e-01 0.00000000e+00 1.00000000e+00 1.00000000e+00
  3.51230207e-01 1.00000000e+00 0.00000000e+00 2.49871717e-01
  1.00000000e+00]
 [0.00000000e+00 0.00000000e+00 5.70081447e-01 6.85687705e-01
  3.51253486e-01 1.00000000e+00 0.00000000e+00 0.00000000e+00
  1.00000000e+00]
 [0.00000000e+00 0.00000000e+00 3.20354164e-01 5.25939481e-01
  3.51026166e-01 1.00000000e+00 0.00000000e+00 0.00000000e+00
  1.00000000e+00]
 [0.00000000e+00 0.00000000e+00 0.00000000e+00 1.49930327e-02
  3.51377324e-01 1.00000000e+00 0.00000000e+00 0.00000000e+00
  1.00000000e+00]
 [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
  3.51336137e-01 1.00000000e+00 0.00000000e+00 0.00000000e+00
  1.00000000e+00]]

Best Training Poisoning Accuracy:
0.8125
#####################         POISON         ###############################################

############################################################################################

comm_round: 1 | global_test_acc: 90.000% | global_f1: 0.9473684210526316 | global_precision: 0.9
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.90      1.00      0.95         9

    accuracy                           0.90        10
   macro avg       0.45      0.50      0.47        10
weighted avg       0.81      0.90      0.85        10
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_fg shape (30,)
[0.         0.         0.95401312 0.95401312 1.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.        ]
wv_mn shape (30,)
[1.         1.         0.         0.68511515 1.         0.34148148
 0.09527559 0.         0.         0.         1.         0.
 0.05584776 0.09682567 0.46585266 0.         0.         0.94355361
 0.93703927 0.40095174 0.71311994 0.         0.15766038 0.00120493
 0.         0.00623211 0.         0.22316927 0.         0.21758283]
wv_ed shape (30,)
[1.         1.         0.         0.29407068 1.         0.21382377
 0.01680249 0.         0.         0.         1.         0.
 0.         0.10822504 0.29577444 0.         0.         0.92621258
 1.         0.45334832 0.73176053 0.         0.         0.15210544
 0.         0.02158881 0.         0.48755315 0.         0.33741348]
wv_lg shape (30, 1)
[[0.35335791]
 [0.35345939]
 [0.35340621]
 [0.35355108]
 [0.3537721 ]
 [0.35176076]
 [0.35194118]
 [0.35185963]
 [0.35180697]
 [0.35167028]
 [0.35207536]
 [0.35180994]
 [0.35209468]
 [0.35199928]
 [0.35191669]
 [0.35223563]
 [0.35180709]
 [0.35191193]
 [0.35163954]
 [0.35216981]
 [0.35194289]
 [0.35194795]
 [0.35186714]
 [0.35197058]
 [0.3519592 ]
 [0.35206524]
 [0.35208109]
 [0.35177513]
 [0.35189188]
 [0.35188477]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_std shape (30,)
[1.         1.         0.         1.         1.         0.
 0.         0.         0.         0.         0.17780405 0.
 0.         0.         0.49353509 0.         0.         0.
 0.04037642 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.        ]
xy shape: (30, 9)
[[1.         0.         1.         1.         0.35335791 1.
  1.         1.         0.        ]
 [1.         0.         1.         1.         0.35345939 1.
  1.         1.         0.        ]
 [0.         0.95401312 0.         0.         0.35340621 1.
  1.         0.         0.        ]
 [0.         0.95401312 0.68511515 0.29407068 0.35355108 1.
  1.         1.         0.        ]
 [1.         1.         1.         1.         0.3537721  1.
  1.         1.         0.        ]
 [0.         0.         0.34148148 0.21382377 0.35176076 1.
  0.         0.         1.        ]
 [0.         0.         0.09527559 0.01680249 0.35194118 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35185963 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35180697 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35167028 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.35207536 1.
  0.         0.17780405 1.        ]
 [0.         0.         0.         0.         0.35180994 1.
  0.         0.         1.        ]
 [0.         0.         0.05584776 0.         0.35209468 1.
  0.         0.         1.        ]
 [0.         0.         0.09682567 0.10822504 0.35199928 1.
  0.         0.         1.        ]
 [0.         0.         0.46585266 0.29577444 0.35191669 1.
  0.         0.49353509 1.        ]
 [0.         0.         0.         0.         0.35223563 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35180709 1.
  0.         0.         1.        ]
 [0.         0.         0.94355361 0.92621258 0.35191193 1.
  0.         0.         1.        ]
 [0.         0.         0.93703927 1.         0.35163954 1.
  0.         0.04037642 1.        ]
 [0.         0.         0.40095174 0.45334832 0.35216981 1.
  0.         0.         1.        ]
 [0.         0.         0.71311994 0.73176053 0.35194289 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35194795 1.
  0.         0.         1.        ]
 [0.         0.         0.15766038 0.         0.35186714 1.
  0.         0.         1.        ]
 [0.         0.         0.00120493 0.15210544 0.35197058 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3519592  1.
  0.         0.         1.        ]
 [0.         0.         0.00623211 0.02158881 0.35206524 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35208109 1.
  0.         0.         1.        ]
 [0.         0.         0.22316927 0.48755315 0.35177513 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35189188 1.
  0.         0.         1.        ]
 [0.         0.         0.21758283 0.33741348 0.35188477 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.8125
#####################         POISON         ###############################################

############################################################################################

comm_round: 2 | global_test_acc: 80.000% | global_f1: 0.888888888888889 | global_precision: 0.8
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.80      1.00      0.89         8

    accuracy                           0.80        10
   macro avg       0.40      0.50      0.44        10
weighted avg       0.64      0.80      0.71        10
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0.         0.         1.         1.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.01573241 0.         0.         0.        ]
wv_fg shape (30,)
[1.         0.18311461 0.         1.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.        ]
wv_mn shape (30,)
[0.43886305 0.         0.82855443 1.         0.33191526 0.
 0.         0.         0.2289602  0.         0.         0.
 0.         0.         0.         0.38173408 0.         0.
 0.50412425 0.         0.         0.         0.         0.
 0.         0.         0.39037756 0.2475013  0.         0.        ]
wv_ed shape (30,)
[0.46033621 0.         0.61266365 1.         0.         0.
 0.         0.         0.07737102 0.         0.         0.
 0.         0.         0.         0.19017868 0.         0.
 0.47436851 0.         0.         0.         0.         0.
 0.         0.         0.46981528 0.26858484 0.         0.        ]
wv_lg shape (30, 1)
[[0.35390124]
 [0.35346539]
 [0.35374016]
 [0.35405299]
 [0.35361164]
 [0.35197162]
 [0.35209126]
 [0.35218165]
 [0.35210902]
 [0.35215173]
 [0.35228183]
 [0.35221728]
 [0.35224351]
 [0.35207313]
 [0.35189277]
 [0.35218259]
 [0.35207094]
 [0.35214589]
 [0.35191105]
 [0.3518213 ]
 [0.35219199]
 [0.35210965]
 [0.35209764]
 [0.35200392]
 [0.35205988]
 [0.35228444]
 [0.35210957]
 [0.35225879]
 [0.35210831]
 [0.35189301]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_std shape (30,)
[0.11055049 0.         0.61928986 1.         0.7230447  0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.        ]
xy shape: (30, 9)
[[0.         1.         0.43886305 0.46033621 0.35390124 1.
  1.         0.11055049 0.        ]
 [0.         0.18311461 0.         0.         0.35346539 1.
  1.         0.         0.        ]
 [1.         0.         0.82855443 0.61266365 0.35374016 1.
  1.         0.61928986 0.        ]
 [1.         1.         1.         1.         0.35405299 1.
  1.         1.         0.        ]
 [0.         0.         0.33191526 0.         0.35361164 1.
  1.         0.7230447  0.        ]
 [0.         0.         0.         0.         0.35197162 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35209126 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35218165 1.
  0.         0.         1.        ]
 [0.         0.         0.2289602  0.07737102 0.35210902 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35215173 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35228183 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35221728 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35224351 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35207313 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35189277 1.
  0.         0.         1.        ]
 [0.         0.         0.38173408 0.19017868 0.35218259 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35207094 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35214589 1.
  0.         0.         1.        ]
 [0.         0.         0.50412425 0.47436851 0.35191105 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3518213  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35219199 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35210965 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35209764 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35200392 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35205988 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35228444 1.
  0.         0.         1.        ]
 [0.01573241 0.         0.39037756 0.46981528 0.35210957 1.
  0.         0.         1.        ]
 [0.         0.         0.2475013  0.26858484 0.35225879 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35210831 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35189301 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.75
#####################         POISON         ###############################################

############################################################################################

comm_round: 3 | global_test_acc: 90.000% | global_f1: 0.9473684210526316 | global_precision: 0.9
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.90      1.00      0.95         9

    accuracy                           0.90        10
   macro avg       0.45      0.50      0.47        10
weighted avg       0.81      0.90      0.85        10
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[1.         0.         0.12675862 1.         1.         0.53633957
 0.56158428 0.56624992 0.06109586 0.         0.         0.
 0.82546663 0.04124559 0.59571655 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.56116231 0.         0.         0.         0.        ]
wv_fg shape (30,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_mn shape (30,)
[1.         0.         0.         0.5842417  1.         0.02447022
 0.02150971 0.09943907 0.         0.         0.         0.
 0.64351759 0.         0.14808647 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.18065042 0.         0.         0.         0.        ]
wv_ed shape (30,)
[1.         0.         0.         0.60150715 1.         0.
 0.         0.0274997  0.         0.         0.         0.
 0.52199412 0.         0.0355808  0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.13918687 0.         0.         0.         0.        ]
wv_lg shape (30, 1)
[[0.35428648]
 [0.35418192]
 [0.35418597]
 [0.35375582]
 [0.35333309]
 [0.35253933]
 [0.35247698]
 [0.35236452]
 [0.35219343]
 [0.35228209]
 [0.3524262 ]
 [0.35243417]
 [0.35232069]
 [0.35242724]
 [0.3520566 ]
 [0.35238983]
 [0.35228469]
 [0.35237968]
 [0.35256056]
 [0.35227696]
 [0.35230625]
 [0.35251261]
 [0.35244871]
 [0.35220417]
 [0.35256366]
 [0.35231448]
 [0.352357  ]
 [0.3524535 ]
 [0.35219939]
 [0.35212911]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_std shape (30,)
[1.         0.         0.36989101 1.         1.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.        ]
xy shape: (30, 9)
[[1.         1.         1.         1.         0.35428648 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.35418192 1.
  1.         0.         0.        ]
 [0.12675862 0.         0.         0.         0.35418597 1.
  1.         0.36989101 0.        ]
 [1.         0.         0.5842417  0.60150715 0.35375582 1.
  1.         1.         0.        ]
 [1.         0.         1.         1.         0.35333309 1.
  1.         1.         0.        ]
 [0.53633957 0.         0.02447022 0.         0.35253933 1.
  0.         0.         1.        ]
 [0.56158428 0.         0.02150971 0.         0.35247698 1.
  0.         0.         1.        ]
 [0.56624992 0.         0.09943907 0.0274997  0.35236452 1.
  0.         0.         1.        ]
 [0.06109586 0.         0.         0.         0.35219343 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35228209 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3524262  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35243417 1.
  0.         0.         1.        ]
 [0.82546663 0.         0.64351759 0.52199412 0.35232069 1.
  0.         0.         1.        ]
 [0.04124559 0.         0.         0.         0.35242724 1.
  0.         0.         1.        ]
 [0.59571655 0.         0.14808647 0.0355808  0.3520566  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35238983 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35228469 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35237968 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35256056 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35227696 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35230625 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35251261 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35244871 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35220417 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35256366 1.
  0.         0.         1.        ]
 [0.56116231 0.         0.18065042 0.13918687 0.35231448 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.352357   1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3524535  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35219939 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35212911 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.8125
#####################         POISON         ###############################################

############################################################################################

comm_round: 4 | global_test_acc: 90.000% | global_f1: 0.9473684210526316 | global_precision: 0.9
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.90      1.00      0.95         9

    accuracy                           0.90        10
   macro avg       0.45      0.50      0.47        10
weighted avg       0.81      0.90      0.85        10
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0.         0.45582159 0.30171011 0.12173967 0.         0.
 1.         1.         1.         0.         0.         0.03233723
 0.40880917 0.         1.         0.         0.         0.
 0.22756632 0.         0.         0.         0.         0.23449162
 0.40539785 0.         0.         0.         1.         0.39959707]
wv_fg shape (30,)
[1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_mn shape (30,)
[0.         0.70892339 0.72514353 0.5309806  0.         0.
 1.         1.         1.         0.55437376 0.14028458 0.581508
 1.         0.03672493 1.         0.2206838  0.5048025  0.
 0.90289609 0.18846654 0.31336208 0.         0.         0.94666115
 1.         0.         0.         0.         1.         1.        ]
wv_ed shape (30,)
[0.         1.         1.         0.74328316 0.         0.
 1.         1.         1.         0.58107077 0.         0.52960687
 1.         0.         1.         0.21231306 0.57026076 0.
 0.98261279 0.22746663 0.27639086 0.         0.         1.
 1.         0.         0.         0.         1.         1.        ]
wv_lg shape (30, 1)
[[0.35417348]
 [0.35436758]
 [0.35409702]
 [0.35461446]
 [0.35422833]
 [0.35323404]
 [0.35344258]
 [0.35307771]
 [0.35300148]
 [0.3530772 ]
 [0.35320379]
 [0.35328744]
 [0.35327706]
 [0.35300606]
 [0.35296204]
 [0.35312226]
 [0.35305241]
 [0.35318087]
 [0.35298498]
 [0.35321319]
 [0.35305239]
 [0.3531589 ]
 [0.35332515]
 [0.35337875]
 [0.35313207]
 [0.35304876]
 [0.35291526]
 [0.35319297]
 [0.35314577]
 [0.35327767]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_std shape (30,)
[0.         1.         0.75613955 0.50801039 0.         0.
 1.         1.         1.         0.         0.         0.19161274
 0.78592252 0.         1.         0.         0.         0.
 0.43576821 0.         0.         0.         0.         0.46318932
 0.77512022 0.         0.         0.         1.         1.        ]
xy shape: (30, 9)
[[0.         1.         0.         0.         0.35417348 1.
  1.         0.         0.        ]
 [0.45582159 0.         0.70892339 1.         0.35436758 1.
  1.         1.         0.        ]
 [0.30171011 0.         0.72514353 1.         0.35409702 1.
  1.         0.75613955 0.        ]
 [0.12173967 1.         0.5309806  0.74328316 0.35461446 1.
  1.         0.50801039 0.        ]
 [0.         0.         0.         0.         0.35422833 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.35323404 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35344258 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.35307771 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.35300148 1.
  0.         1.         1.        ]
 [0.         0.         0.55437376 0.58107077 0.3530772  1.
  0.         0.         1.        ]
 [0.         0.         0.14028458 0.         0.35320379 1.
  0.         0.         1.        ]
 [0.03233723 0.         0.581508   0.52960687 0.35328744 1.
  0.         0.19161274 1.        ]
 [0.40880917 0.         1.         1.         0.35327706 1.
  0.         0.78592252 1.        ]
 [0.         0.         0.03672493 0.         0.35300606 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35296204 1.
  0.         1.         1.        ]
 [0.         0.         0.2206838  0.21231306 0.35312226 1.
  0.         0.         1.        ]
 [0.         0.         0.5048025  0.57026076 0.35305241 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35318087 1.
  0.         0.         1.        ]
 [0.22756632 0.         0.90289609 0.98261279 0.35298498 1.
  0.         0.43576821 1.        ]
 [0.         0.         0.18846654 0.22746663 0.35321319 1.
  0.         0.         1.        ]
 [0.         0.         0.31336208 0.27639086 0.35305239 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3531589  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35332515 1.
  0.         0.         1.        ]
 [0.23449162 0.         0.94666115 1.         0.35337875 1.
  0.         0.46318932 1.        ]
 [0.40539785 0.         1.         1.         0.35313207 1.
  0.         0.77512022 1.        ]
 [0.         0.         0.         0.         0.35304876 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35291526 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35319297 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.35314577 1.
  0.         1.         1.        ]
 [0.39959707 0.         1.         1.         0.35327767 1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.8125
#####################         POISON         ###############################################

############################################################################################

comm_round: 5 | global_test_acc: 90.000% | global_f1: 0.9473684210526316 | global_precision: 0.9
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.90      1.00      0.95         9

    accuracy                           0.90        10
   macro avg       0.45      0.50      0.47        10
weighted avg       0.81      0.90      0.85        10
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0.56861915 0.         1.         0.         0.58600906 0.26553827
 0.3034039  0.         0.         0.59666248 0.         0.
 0.44015143 0.70134157 0.74696679 0.33305126 0.         0.
 0.52889201 0.33303641 0.         0.         0.         0.33066385
 0.51034395 0.         0.73286948 0.         0.         0.        ]
wv_fg shape (30,)
[0.07435409 0.         1.         0.07435409 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.        ]
wv_mn shape (30,)
[1.         0.7394035  1.         0.         1.         0.72881178
 0.99522663 0.         0.58620679 1.         0.12223866 0.61362058
 1.         1.         1.         1.         0.99630923 0.18592196
 1.         1.         0.         0.84634568 0.72061212 1.
 1.         0.40762749 1.         0.         0.         0.13370935]
wv_ed shape (30,)
[1.         0.87355994 1.         0.         1.         0.36146939
 0.61050952 0.         0.17451919 1.         0.         0.18496637
 1.         1.         1.         0.87563565 0.61603663 0.
 1.         0.77719278 0.         0.50527217 0.39268179 0.52010491
 1.         0.         1.         0.         0.         0.        ]
wv_lg shape (30, 1)
[[0.35438568]
 [0.35487274]
 [0.35469128]
 [0.35452695]
 [0.35491708]
 [0.35365435]
 [0.35349586]
 [0.35337974]
 [0.35361097]
 [0.35335693]
 [0.35351184]
 [0.35345078]
 [0.35360086]
 [0.35366725]
 [0.35367144]
 [0.35334705]
 [0.35370794]
 [0.35357748]
 [0.35370254]
 [0.35360279]
 [0.35351133]
 [0.3537529 ]
 [0.35360181]
 [0.35333266]
 [0.3536216 ]
 [0.35358624]
 [0.35347662]
 [0.35348348]
 [0.35342466]
 [0.35337556]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_std shape (30,)
[1.         0.28313713 0.90984424 0.         1.         0.18776498
 0.04465076 0.         0.         1.         0.         0.
 0.77946429 1.         1.         0.         0.         0.
 1.         0.         0.         0.         0.         0.79457046
 1.         0.         1.         0.         0.         0.        ]
xy shape: (30, 9)
[[0.56861915 0.07435409 1.         1.         0.35438568 1.
  1.         1.         0.        ]
 [0.         0.         0.7394035  0.87355994 0.35487274 1.
  1.         0.28313713 0.        ]
 [1.         1.         1.         1.         0.35469128 1.
  1.         0.90984424 0.        ]
 [0.         0.07435409 0.         0.         0.35452695 1.
  1.         0.         0.        ]
 [0.58600906 0.         1.         1.         0.35491708 1.
  1.         1.         0.        ]
 [0.26553827 0.         0.72881178 0.36146939 0.35365435 1.
  0.         0.18776498 1.        ]
 [0.3034039  0.         0.99522663 0.61050952 0.35349586 1.
  0.         0.04465076 1.        ]
 [0.         0.         0.         0.         0.35337974 1.
  0.         0.         1.        ]
 [0.         0.         0.58620679 0.17451919 0.35361097 1.
  0.         0.         1.        ]
 [0.59666248 0.         1.         1.         0.35335693 1.
  0.         1.         1.        ]
 [0.         0.         0.12223866 0.         0.35351184 1.
  0.         0.         1.        ]
 [0.         0.         0.61362058 0.18496637 0.35345078 1.
  0.         0.         1.        ]
 [0.44015143 0.         1.         1.         0.35360086 1.
  0.         0.77946429 1.        ]
 [0.70134157 0.         1.         1.         0.35366725 1.
  0.         1.         1.        ]
 [0.74696679 0.         1.         1.         0.35367144 1.
  0.         1.         1.        ]
 [0.33305126 0.         1.         0.87563565 0.35334705 1.
  0.         0.         1.        ]
 [0.         0.         0.99630923 0.61603663 0.35370794 1.
  0.         0.         1.        ]
 [0.         0.         0.18592196 0.         0.35357748 1.
  0.         0.         1.        ]
 [0.52889201 0.         1.         1.         0.35370254 1.
  0.         1.         1.        ]
 [0.33303641 0.         1.         0.77719278 0.35360279 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35351133 1.
  0.         0.         1.        ]
 [0.         0.         0.84634568 0.50527217 0.3537529  1.
  0.         0.         1.        ]
 [0.         0.         0.72061212 0.39268179 0.35360181 1.
  0.         0.         1.        ]
 [0.33066385 0.         1.         0.52010491 0.35333266 1.
  0.         0.79457046 1.        ]
 [0.51034395 0.         1.         1.         0.3536216  1.
  0.         1.         1.        ]
 [0.         0.         0.40762749 0.         0.35358624 1.
  0.         0.         1.        ]
 [0.73286948 0.         1.         1.         0.35347662 1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.35348348 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35342466 1.
  0.         0.         1.        ]
 [0.         0.         0.13370935 0.         0.35337556 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.875
#####################         POISON         ###############################################

############################################################################################

comm_round: 6 | global_test_acc: 70.000% | global_f1: 0.8235294117647058 | global_precision: 0.7
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.70      1.00      0.82         7

    accuracy                           0.70        10
   macro avg       0.35      0.50      0.41        10
weighted avg       0.49      0.70      0.58        10
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0.         0.02492246 0.         0.21016047 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.00586922 1.         0.         0.
 0.         0.         0.         0.         0.         0.10216417]
wv_fg shape (30,)
[0.         0.72243613 1.         1.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.        ]
wv_mn shape (30,)
[1.         1.         0.23838611 1.         0.         1.
 1.         0.8897573  0.         1.         1.         0.19919619
 1.         0.68922506 0.         0.99770262 0.76539686 1.
 0.1394986  0.         1.         1.         0.         0.64336995
 1.         0.88479177 0.         0.50712108 0.         1.        ]
wv_ed shape (30,)
[0.81851429 1.         0.         1.         0.         1.
 1.         0.71264124 0.         1.         1.         0.062239
 1.         0.42670357 0.         0.66321154 0.47420691 1.
 0.10010645 0.         1.         1.         0.         0.45148904
 1.         0.98418777 0.         0.46707728 0.         1.        ]
wv_lg shape (30, 1)
[[0.35491257]
 [0.35499504]
 [0.3552181 ]
 [0.35481944]
 [0.35509079]
 [0.35353616]
 [0.353498  ]
 [0.35358719]
 [0.35360546]
 [0.35351552]
 [0.35350827]
 [0.35367626]
 [0.35350152]
 [0.35381177]
 [0.35337314]
 [0.35356564]
 [0.35360132]
 [0.35357536]
 [0.35361607]
 [0.35352405]
 [0.35363669]
 [0.35325628]
 [0.35357547]
 [0.3535886 ]
 [0.3536115 ]
 [0.35369799]
 [0.3535209 ]
 [0.35347162]
 [0.35356078]
 [0.35365739]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_std shape (30,)
[1.         1.         0.         1.         0.         1.
 0.60111328 0.         0.         0.69423823 0.16434678 0.
 0.         0.         0.         0.3373161  0.         0.80477407
 0.         0.         0.37270909 1.         0.         0.
 0.         0.         0.         0.         0.         0.25981087]
xy shape: (30, 9)
[[0.         0.         1.         0.81851429 0.35491257 1.
  1.         1.         0.        ]
 [0.02492246 0.72243613 1.         1.         0.35499504 1.
  1.         1.         0.        ]
 [0.         1.         0.23838611 0.         0.3552181  1.
  1.         0.         0.        ]
 [0.21016047 1.         1.         1.         0.35481944 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.35509079 1.
  1.         0.         0.        ]
 [0.         0.         1.         1.         0.35353616 1.
  0.         1.         1.        ]
 [0.         0.         1.         1.         0.353498   1.
  0.         0.60111328 1.        ]
 [0.         0.         0.8897573  0.71264124 0.35358719 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35360546 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.35351552 1.
  0.         0.69423823 1.        ]
 [0.         0.         1.         1.         0.35350827 1.
  0.         0.16434678 1.        ]
 [0.         0.         0.19919619 0.062239   0.35367626 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.35350152 1.
  0.         0.         1.        ]
 [0.         0.         0.68922506 0.42670357 0.35381177 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35337314 1.
  0.         0.         1.        ]
 [0.         0.         0.99770262 0.66321154 0.35356564 1.
  0.         0.3373161  1.        ]
 [0.         0.         0.76539686 0.47420691 0.35360132 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.35357536 1.
  0.         0.80477407 1.        ]
 [0.         0.         0.1394986  0.10010645 0.35361607 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35352405 1.
  0.         0.         1.        ]
 [0.00586922 0.         1.         1.         0.35363669 1.
  0.         0.37270909 1.        ]
 [1.         0.         1.         1.         0.35325628 1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.35357547 1.
  0.         0.         1.        ]
 [0.         0.         0.64336995 0.45148904 0.3535886  1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.3536115  1.
  0.         0.         1.        ]
 [0.         0.         0.88479177 0.98418777 0.35369799 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.3535209  1.
  0.         0.         1.        ]
 [0.         0.         0.50712108 0.46707728 0.35347162 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35356078 1.
  0.         0.         1.        ]
 [0.10216417 0.         1.         1.         0.35365739 1.
  0.         0.25981087 1.        ]]

Best Training Poisoning Accuracy:
0.8125
#####################         POISON         ###############################################

############################################################################################

comm_round: 7 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00        10

    accuracy                           1.00        10
   macro avg       1.00      1.00      1.00        10
weighted avg       1.00      1.00      1.00        10
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0.         1.         1.         0.36770618 0.         0.
 1.         0.04343968 0.3132559  0.04768643 0.03952696 0.
 0.         0.05137926 0.07227984 0.13181733 0.18768599 0.
 0.         0.         0.08840143 0.         0.         0.
 0.23782546 1.         0.         0.14624195 0.19078035 0.04915179]
wv_fg shape (30,)
[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_mn shape (30,)
[0.         1.         1.         0.85898336 0.         0.
 0.73656006 0.         0.65952391 0.         0.10569226 0.
 0.         0.13465311 0.06382244 0.25239499 0.35953623 0.10000361
 0.         0.         0.31262363 0.         0.         0.
 0.52688458 1.         0.         0.30642608 0.48522014 0.01147714]
wv_ed shape (30,)
[0.         1.         1.         0.74773572 0.         0.04968796
 0.80854045 0.03438513 0.75387974 0.01854632 0.22731453 0.
 0.         0.06630732 0.18375737 0.27476707 0.4375208  0.18522277
 0.         0.01321167 0.3239582  0.         0.         0.
 0.66871686 1.         0.         0.31469349 0.56833637 0.12413487]
wv_lg shape (30, 1)
[[0.35505138]
 [0.35537404]
 [0.35515779]
 [0.35534745]
 [0.35518219]
 [0.35410614]
 [0.35423674]
 [0.35407308]
 [0.35403329]
 [0.35411578]
 [0.35400612]
 [0.35398262]
 [0.35403308]
 [0.35405397]
 [0.35384438]
 [0.35405081]
 [0.35421387]
 [0.35396876]
 [0.35394567]
 [0.35423466]
 [0.35401869]
 [0.35418523]
 [0.35413264]
 [0.35376538]
 [0.35384277]
 [0.3538656 ]
 [0.35395281]
 [0.35397882]
 [0.35402244]
 [0.35397072]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1.        1.        0.9482555 1.        1.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.       ]
wv_std shape (30,)
[0.         1.         1.         0.61368906 0.35624616 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.        ]
xy shape: (30, 9)
[[0.         0.         0.         0.         0.35505138 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.35537404 1.
  1.         1.         0.        ]
 [1.         1.         1.         1.         0.35515779 1.
  0.9482555  1.         0.        ]
 [0.36770618 0.         0.85898336 0.74773572 0.35534745 1.
  1.         0.61368906 0.        ]
 [0.         0.         0.         0.         0.35518219 1.
  1.         0.35624616 0.        ]
 [0.         0.         0.         0.04968796 0.35410614 1.
  0.         0.         1.        ]
 [1.         0.         0.73656006 0.80854045 0.35423674 1.
  0.         0.         1.        ]
 [0.04343968 0.         0.         0.03438513 0.35407308 1.
  0.         0.         1.        ]
 [0.3132559  0.         0.65952391 0.75387974 0.35403329 1.
  0.         0.         1.        ]
 [0.04768643 0.         0.         0.01854632 0.35411578 1.
  0.         0.         1.        ]
 [0.03952696 0.         0.10569226 0.22731453 0.35400612 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35398262 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35403308 1.
  0.         0.         1.        ]
 [0.05137926 0.         0.13465311 0.06630732 0.35405397 1.
  0.         0.         1.        ]
 [0.07227984 0.         0.06382244 0.18375737 0.35384438 1.
  0.         0.         1.        ]
 [0.13181733 0.         0.25239499 0.27476707 0.35405081 1.
  0.         0.         1.        ]
 [0.18768599 0.         0.35953623 0.4375208  0.35421387 1.
  0.         0.         1.        ]
 [0.         0.         0.10000361 0.18522277 0.35396876 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35394567 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.01321167 0.35423466 1.
  0.         0.         1.        ]
 [0.08840143 0.         0.31262363 0.3239582  0.35401869 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35418523 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35413264 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35376538 1.
  0.         0.         1.        ]
 [0.23782546 0.         0.52688458 0.66871686 0.35384277 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.3538656  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35395281 1.
  0.         0.         1.        ]
 [0.14624195 0.         0.30642608 0.31469349 0.35397882 1.
  0.         0.         1.        ]
 [0.19078035 0.         0.48522014 0.56833637 0.35402244 1.
  0.         0.         1.        ]
 [0.04915179 0.         0.01147714 0.12413487 0.35397072 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.8125
#####################         POISON         ###############################################

############################################################################################

comm_round: 8 | global_test_acc: 80.000% | global_f1: 0.888888888888889 | global_precision: 0.8
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.80      1.00      0.89         8

    accuracy                           0.80        10
   macro avg       0.40      0.50      0.44        10
weighted avg       0.64      0.80      0.71        10
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0.         0.         0.         1.         0.         1.
 0.         0.         0.         1.         1.         1.
 1.         1.         1.         0.95639317 0.         1.
 1.         1.         1.         0.         0.9865736  0.92747046
 1.         1.         1.         0.         1.         0.        ]
wv_fg shape (30,)
[0.60546189 0.         0.         1.         1.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.        ]
wv_mn shape (30,)
[0.         0.         0.         1.         0.         0.2190344
 0.         0.         0.         0.42916391 0.44522465 0.08591979
 0.65966402 0.58556942 0.         0.         0.         0.34970758
 0.         0.         0.1073938  0.         0.         0.
 0.         0.13764005 0.33229577 0.         0.         0.        ]
wv_ed shape (30,)
[0.         0.         0.         1.         0.         0.02330786
 0.         0.         0.         0.30229744 0.2575381  0.
 0.44879365 0.40615794 0.         0.         0.         0.29435497
 0.         0.         0.         0.         0.         0.
 0.         0.08190781 0.26211321 0.         0.         0.        ]
wv_lg shape (30, 1)
[[0.35564324]
 [0.35518365]
 [0.35524212]
 [0.35540363]
 [0.35466166]
 [0.35392188]
 [0.35404956]
 [0.35387243]
 [0.35387963]
 [0.35395081]
 [0.35380753]
 [0.35399404]
 [0.35418076]
 [0.35401532]
 [0.35399151]
 [0.35403964]
 [0.35399376]
 [0.35406093]
 [0.35408136]
 [0.35379251]
 [0.35400462]
 [0.35390339]
 [0.35420708]
 [0.35403349]
 [0.35397248]
 [0.35397718]
 [0.35395435]
 [0.35382446]
 [0.35394212]
 [0.35390116]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_std shape (30,)
[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
xy shape: (30, 9)
[[0.         0.60546189 0.         0.         0.35564324 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.35518365 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.35524212 1.
  1.         0.         0.        ]
 [1.         1.         1.         1.         0.35540363 1.
  1.         1.         0.        ]
 [0.         1.         0.         0.         0.35466166 1.
  1.         0.         0.        ]
 [1.         0.         0.2190344  0.02330786 0.35392188 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35404956 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35387243 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35387963 1.
  0.         0.         1.        ]
 [1.         0.         0.42916391 0.30229744 0.35395081 1.
  0.         0.         1.        ]
 [1.         0.         0.44522465 0.2575381  0.35380753 1.
  0.         0.         1.        ]
 [1.         0.         0.08591979 0.         0.35399404 1.
  0.         0.         1.        ]
 [1.         0.         0.65966402 0.44879365 0.35418076 1.
  0.         0.         1.        ]
 [1.         0.         0.58556942 0.40615794 0.35401532 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.35399151 1.
  0.         0.         1.        ]
 [0.95639317 0.         0.         0.         0.35403964 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35399376 1.
  0.         0.         1.        ]
 [1.         0.         0.34970758 0.29435497 0.35406093 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.35408136 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.35379251 1.
  0.         0.         1.        ]
 [1.         0.         0.1073938  0.         0.35400462 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35390339 1.
  0.         0.         1.        ]
 [0.9865736  0.         0.         0.         0.35420708 1.
  0.         0.         1.        ]
 [0.92747046 0.         0.         0.         0.35403349 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.35397248 1.
  0.         0.         1.        ]
 [1.         0.         0.13764005 0.08190781 0.35397718 1.
  0.         0.         1.        ]
 [1.         0.         0.33229577 0.26211321 0.35395435 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35382446 1.
  0.         0.         1.        ]
 [1.         0.         0.         0.         0.35394212 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.35390116 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.9375
#####################         POISON         ###############################################

############################################################################################

comm_round: 9 | global_test_acc: 70.000% | global_f1: 0.8235294117647058 | global_precision: 0.7
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.70      1.00      0.82         7

    accuracy                           0.70        10
   macro avg       0.35      0.50      0.41        10
weighted avg       0.49      0.70      0.58        10
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_fg shape (30,)
[0.26621876 0.         0.         1.         1.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.        ]
wv_mn shape (30,)
[0.         1.         0.90481734 0.5044985  0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.        ]
wv_ed shape (30,)
[0.         1.         0.92773582 0.85368959 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.        ]
wv_lg shape (30, 1)
[[0.1378064 ]
 [0.13779783]
 [0.13781021]
 [0.1377972 ]
 [0.13781003]
 [0.13658604]
 [0.13658823]
 [0.13659291]
 [0.13659909]
 [0.13658629]
 [0.13658014]
 [0.13658594]
 [0.13659212]
 [0.1365745 ]
 [0.13658783]
 [0.13658292]
 [0.1365888 ]
 [0.13658886]
 [0.13658556]
 [0.13658914]
 [0.13658608]
 [0.13659609]
 [0.13658869]
 [0.13659091]
 [0.13658814]
 [0.13659645]
 [0.13658856]
 [0.13659168]
 [0.13658376]
 [0.13658269]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_std shape (30,)
[0.         1.         0.93474336 0.87077985 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.        ]
xy shape: (30, 9)
[[0.         0.26621876 0.         0.         0.1378064  1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.13779783 1.
  1.         1.         0.        ]
 [1.         0.         0.90481734 0.92773582 0.13781021 1.
  1.         0.93474336 0.        ]
 [1.         1.         0.5044985  0.85368959 0.1377972  1.
  1.         0.87077985 0.        ]
 [0.         1.         0.         0.         0.13781003 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.13658604 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.13658823 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.13659291 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.13659909 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.13658629 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.13658014 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.13658594 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.13659212 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.1365745  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.13658783 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.13658292 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.1365888  1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.13658886 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.13658556 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.13658914 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.13658608 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.13659609 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.13658869 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.13659091 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.13658814 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.13659645 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.13658856 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.13659168 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.13658376 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.13658269 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.3333333432674408
#####################         POISON         ###############################################

############################################################################################

comm_round: 0 | global_test_acc: 40.000% | global_f1: 0.5 | global_precision: 1.0
              precision    recall  f1-score   support

           0       0.14      1.00      0.25         1
           1       1.00      0.33      0.50         9

    accuracy                           0.40        10
   macro avg       0.57      0.67      0.38        10
weighted avg       0.91      0.40      0.47        10
poison scaling shape: (30, 1)
[[0]
 [0]
 [0]
 [0]
 [0]
 [1]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [1]
 [0]
 [0]
 [1]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [1]
 [1]
 [0]
 [0]
 [0]
 [0]]scaled_weight_list: Rows 30 cols 21Adding node: 5 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 0. 0. 1. 0. 0.]
wv_fg shape (30,)
[0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_mn shape (30,)
[1.         1.         1.         0.         0.         1.
 0.83055431 0.66421619 0.         0.53764115 1.         1.
 0.         1.         0.60972393 0.42487514 1.         0.86625963
 0.62138693 1.         1.         1.         1.         1.
 0.90407547 0.95044385 0.80684646 1.         0.         1.        ]
wv_ed shape (30,)
[0.70428454 1.         1.         0.         0.         1.
 0.88368065 0.62938121 0.         0.58781434 1.         1.
 0.         1.         0.64305842 0.40180647 1.         0.9202179
 0.9081903  1.         1.         1.         1.         1.
 0.66385536 1.         0.97060257 1.         0.         1.        ]
wv_lg shape (30, 1)
[[0.12727913]
 [0.12727985]
 [0.12727963]
 [0.12728289]
 [0.12728478]
 [0.12679405]
 [0.1267909 ]
 [0.12679264]
 [0.12678753]
 [0.126793  ]
 [0.12679325]
 [0.12679345]
 [0.12678528]
 [0.12679133]
 [0.12679204]
 [0.12679133]
 [0.1267894 ]
 [0.12679036]
 [0.12679239]
 [0.12679249]
 [0.12679351]
 [0.12679139]
 [0.12679077]
 [0.12679489]
 [0.12679084]
 [0.12679185]
 [0.12679093]
 [0.12679381]
 [0.12678831]
 [0.12679293]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_std shape (30,)
[0.0346437  0.26652033 0.73437652 0.         0.         1.
 0.         0.         0.         0.         1.         1.
 0.         1.         0.         0.         0.68533847 0.
 0.         0.97799762 1.         0.51392355 1.         0.8413427
 0.         0.43860999 0.07244275 1.         0.         1.        ]
xy shape: (30, 9)
[[0.         0.         1.         0.70428454 0.12727913 1.
  1.         0.0346437  0.        ]
 [0.         0.         1.         1.         0.12727985 1.
  1.         0.26652033 0.        ]
 [0.         0.         1.         1.         0.12727963 1.
  1.         0.73437652 0.        ]
 [0.         0.         0.         0.         0.12728289 1.
  1.         0.         0.        ]
 [0.         1.         0.         0.         0.12728478 1.
  1.         0.         0.        ]
 [0.         0.         1.         1.         0.12679405 1.
  0.         1.         1.        ]
 [0.         0.         0.83055431 0.88368065 0.1267909  1.
  0.         0.         1.        ]
 [0.         0.         0.66421619 0.62938121 0.12679264 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.12678753 1.
  0.         0.         1.        ]
 [0.         0.         0.53764115 0.58781434 0.126793   1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.12679325 1.
  0.         1.         1.        ]
 [0.         0.         1.         1.         0.12679345 1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.12678528 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.12679133 1.
  0.         1.         1.        ]
 [0.         0.         0.60972393 0.64305842 0.12679204 1.
  0.         0.         1.        ]
 [0.         0.         0.42487514 0.40180647 0.12679133 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.1267894  1.
  0.         0.68533847 1.        ]
 [0.         0.         0.86625963 0.9202179  0.12679036 1.
  0.         0.         1.        ]
 [0.         0.         0.62138693 0.9081903  0.12679239 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.12679249 1.
  0.         0.97799762 1.        ]
 [1.         0.         1.         1.         0.12679351 1.
  0.         1.         1.        ]
 [0.         0.         1.         1.         0.12679139 1.
  0.         0.51392355 1.        ]
 [0.         0.         1.         1.         0.12679077 1.
  0.         1.         1.        ]
 [0.         0.         1.         1.         0.12679489 1.
  0.         0.8413427  1.        ]
 [0.         0.         0.90407547 0.66385536 0.12679084 1.
  0.         0.         1.        ]
 [0.         0.         0.95044385 1.         0.12679185 1.
  0.         0.43860999 1.        ]
 [0.         0.         0.80684646 0.97060257 0.12679093 1.
  0.         0.07244275 1.        ]
 [1.         0.         1.         1.         0.12679381 1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.12678831 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.12679293 1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.7222222089767456
#####################         POISON         ###############################################

############################################################################################

comm_round: 1 | global_test_acc: 70.000% | global_f1: 0.8235294117647058 | global_precision: 0.7
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.70      1.00      0.82         7

    accuracy                           0.70        10
   macro avg       0.35      0.50      0.41        10
weighted avg       0.49      0.70      0.58        10
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_fg shape (30,)
[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_mn shape (30,)
[1.         0.         0.05272901 1.         0.         0.
 0.47286957 0.         0.         0.8577739  0.         0.
 0.         0.         0.         0.         0.96803597 0.73183858
 0.         1.         0.         0.         1.         0.31017966
 0.         0.         0.17354633 0.66904173 0.         0.        ]
wv_ed shape (30,)
[1.         0.         0.         1.         0.         0.
 0.83629397 0.         0.         1.         0.         0.
 0.         0.3819383  0.         0.         1.         0.76341598
 0.         1.         0.         0.01786764 1.         0.46724959
 0.         0.         0.24257836 0.66649365 0.         0.19709166]
wv_lg shape (30, 1)
[[0.12736505]
 [0.12735653]
 [0.12736711]
 [0.12735226]
 [0.12737   ]
 [0.12686288]
 [0.12686637]
 [0.12686632]
 [0.12686361]
 [0.12686853]
 [0.12686204]
 [0.12686387]
 [0.12686445]
 [0.12686714]
 [0.12686252]
 [0.12686318]
 [0.126867  ]
 [0.12686315]
 [0.12686532]
 [0.12686853]
 [0.12686323]
 [0.12686519]
 [0.12686821]
 [0.12686568]
 [0.12686545]
 [0.12686581]
 [0.12686453]
 [0.12686535]
 [0.12686174]
 [0.12686409]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_std shape (30,)
[1.         0.         0.         1.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.85121343 0.         0.         0.06305274 0.
 0.         0.         0.         0.         0.         0.        ]
xy shape: (30, 9)
[[0.         0.         1.         1.         0.12736505 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.12735653 1.
  1.         0.         0.        ]
 [0.         1.         0.05272901 0.         0.12736711 1.
  1.         0.         0.        ]
 [1.         0.         1.         1.         0.12735226 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.12737    1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.12686288 1.
  0.         0.         1.        ]
 [0.         0.         0.47286957 0.83629397 0.12686637 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.12686632 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.12686361 1.
  0.         0.         1.        ]
 [0.         0.         0.8577739  1.         0.12686853 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.12686204 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.12686387 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.12686445 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.3819383  0.12686714 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.12686252 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.12686318 1.
  0.         0.         1.        ]
 [0.         0.         0.96803597 1.         0.126867   1.
  0.         0.         1.        ]
 [0.         0.         0.73183858 0.76341598 0.12686315 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.12686532 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.12686853 1.
  0.         0.85121343 1.        ]
 [0.         0.         0.         0.         0.12686323 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.01786764 0.12686519 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.12686821 1.
  0.         0.06305274 1.        ]
 [0.         0.         0.31017966 0.46724959 0.12686568 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.12686545 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.12686581 1.
  0.         0.         1.        ]
 [0.         0.         0.17354633 0.24257836 0.12686453 1.
  0.         0.         1.        ]
 [0.         0.         0.66904173 0.66649365 0.12686535 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.12686174 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.19709166 0.12686409 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.7777777910232544
#####################         POISON         ###############################################

############################################################################################

comm_round: 2 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00        10

    accuracy                           1.00        10
   macro avg       1.00      1.00      1.00        10
weighted avg       1.00      1.00      1.00        10
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients